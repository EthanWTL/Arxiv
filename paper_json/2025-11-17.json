[
  {
    "id": "http://arxiv.org/abs/2511.13545v1",
    "title": "Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks",
    "summary": "The advent of multimodal deep learning models, such as CLIP, has unlocked new frontiers in a wide range of applications, from image-text understanding to classification tasks. However, these models are not safe for adversarial attacks, particularly backdoor attacks, which can subtly manipulate model behavior. Moreover, existing defense methods typically involve training from scratch or fine-tuning using a large dataset without pinpointing the specific labels that are affected. In this study, we introduce an innovative strategy to enhance the robustness of multimodal contrastive learning models against such attacks. In particular, given a poisoned CLIP model, our approach can identify the backdoor trigger and pinpoint the victim samples and labels in an efficient manner. To that end, an image segmentation ``oracle'' is introduced as the supervisor for the output of the poisoned CLIP. We develop two algorithms to rectify the poisoned model: (1) differentiating between CLIP and Oracle's knowledge to identify potential triggers; (2) pinpointing affected labels and victim samples, and curating a compact fine-tuning dataset. With this knowledge, we are allowed to rectify the poisoned CLIP model to negate backdoor effects. Extensive experiments on visual recognition benchmarks demonstrate our strategy is effective in CLIP-based backdoor defense.",
    "published": "2025-11-17T16:16:50Z",
    "updated": "2025-11-17T16:16:50Z",
    "link": "http://arxiv.org/pdf/2511.13545v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Md. Iqbal Hossain",
      "Afia Sajeeda",
      "Neeresh Kumar Perla",
      "Ming Shao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13542v1",
    "title": "Making Evidence Actionable in Adaptive Learning Closing the Diagnostic Pedagogical Loop",
    "summary": "Adaptive learning often diagnoses precisely yet intervenes weakly, producing help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted microinterventions. The adaptive learning algorithm includes three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted limit for time and redundancy, and diversity as protection against overfitting to a single resource. We formulate intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows derived from ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy with diversity. Greedy selection serves low-richness and tight-latency settings, gradient-based relaxation serves rich repositories, and a hybrid switches along a richness-latency frontier. In simulation and in an introductory physics deployment with 1204 students, both solvers achieved full skill coverage for nearly all learners within bounded watch time. The gradient-based method reduced redundant coverage by about 12 percentage points relative to greedy and produced more consistent difficulty alignment, while greedy delivered comparable adequacy at lower computational cost in resource-scarce environments. Slack variables localized missing content and guided targeted curation, sustaining sufficiency across student subgroups. The result is a tractable and auditable controller that closes the diagnostic pedagogical loop and enables equitable, load-aware personalization at the classroom scale.",
    "published": "2025-11-17T16:15:50Z",
    "updated": "2025-11-17T16:15:50Z",
    "link": "http://arxiv.org/pdf/2511.13542v1.pdf",
    "category": [
      "cs.CE",
      "cs.AI",
      "cs.CY",
      "stat.AP"
    ],
    "authors": [
      "Amirreza Mehrabi",
      "Jason Wade Morphew",
      "Breejha Quezada",
      "N. Sanjay Rebello"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.14507v6",
    "title": "A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders",
    "summary": "Sparse Autoencoders (SAEs) aim to decompose the activation space of large language models (LLMs) into human-interpretable latent directions or features. As we increase the number of features in the SAE, hierarchical features tend to split into finer features (\"math\" may split into \"algebra\", \"geometry\", etc.), a phenomenon referred to as feature splitting. However, we show that sparse decomposition and splitting of hierarchical features is not robust. Specifically, we show that seemingly monosemantic features fail to fire where they should, and instead get \"absorbed\" into their children features. We coin this phenomenon feature absorption, and show that it is caused by optimizing for sparsity in SAEs whenever the underlying features form a hierarchy. We introduce a metric to detect absorption in SAEs, and validate our findings empirically on hundreds of LLM SAEs. Our investigation suggests that varying SAE sizes or sparsity is insufficient to solve this issue. We discuss the implications of feature absorption in SAEs and some potential approaches to solve the fundamental theoretical issues before SAEs can be used for interpreting LLMs robustly and at scale.",
    "published": "2024-09-22T16:11:02Z",
    "updated": "2025-11-17T16:10:06Z",
    "link": "http://arxiv.org/pdf/2409.14507v6.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "David Chanin",
      "James Wilken-Smith",
      "Tomáš Dulka",
      "Hardik Bhatnagar",
      "Satvik Golechha",
      "Joseph Bloom"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.11935v2",
    "title": "AI-Native Open RAN for Non-Terrestrial Networks: An Overview",
    "summary": "Non-terrestrial network (NTN) is expected to be a critical component of Sixth Generation (6G) networks, providing ubiquitous services and enhancing the system resilience. However, the high-altitude operation and inherent mobility of NTN introduce significant challenges across the development and operations (DevOps) lifecycle. Apart from that, how to achieve artificial intelligence native (AI-Native) capabilities in NTN for intelligent network management and orchestration remains an important challenge. To solve the challenges above, we propose integrating the Open Radio Access Network (ORAN) with NTN as a promising solution, leveraging its principles of disaggregation, openness, virtualization, and embedded intelligence. Despite extensive technical literature on ORAN and NTN, respectively, there is a lack of a holistic view of the integration of ORAN and NTN architectures, particularly in terms of how intelligent ORAN can address the scalability challenge in NTN management. To address this gap, this paper provides a comprehensive and structured overview of an AI-native ORAN-based NTN framework to support dynamic configuration, scalability, and intelligent orchestration. The paper commences with an in-depth review of the existing literature from leading industry and academic institutions, subsequently providing the necessary background knowledge related to ORAN, NTN, and AI-Native for communication. Furthermore, the paper analyzes the unique DevOps challenges for NTN and proposes the orchestrated AI-Native ORAN-based NTN framework, with a detailed discussion on the key technological enablers within the framework. Finally, this paper presents various use cases and outlines the prospective research directions of this study in detail.",
    "published": "2025-07-16T05:58:45Z",
    "updated": "2025-11-17T16:07:54Z",
    "link": "http://arxiv.org/pdf/2507.11935v2.pdf",
    "category": [
      "cs.NI",
      "cs.AI",
      "eess.SY"
    ],
    "authors": [
      "Jikang Deng",
      "Fizza Hassan",
      "Hui Zhou",
      "Saad Al-Ahmadi",
      "Mohamed-Slim Alouini",
      "Daniel B. Da Costa"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13530v1",
    "title": "Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety",
    "summary": "Social anxiety is a prevalent condition that affects interpersonal interactions and social functioning. Recent advances in artificial intelligence and social robotics offer new opportunities to examine social anxiety in the human-robot interaction context. Accurate detection of affective states and behaviours associated with social anxiety requires multimodal datasets, where each signal modality provides complementary insights into its manifestations. However, such datasets remain scarce, limiting progress in both research and applications. To address this, this paper presents a protocol for multimodal dataset collection designed to reflect social anxiety in a human-robot interaction context. The dataset will consist of synchronised audio, video, and physiological recordings acquired from at least 70 participants, grouped according to their level of social anxiety, as they engage in approximately 10-minute interactive Wizard-of-Oz role-play scenarios with the Furhat social robot under controlled experimental conditions. In addition to multimodal data, the dataset will be enriched with contextual data providing deeper insight into individual variability in social anxiety responses. This work can contribute to research on affect-adaptive human-robot interaction by providing support for robust multimodal detection of social anxiety.",
    "published": "2025-11-17T16:03:33Z",
    "updated": "2025-11-17T16:03:33Z",
    "link": "http://arxiv.org/pdf/2511.13530v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Vesna Poprcova",
      "Iulia Lefter",
      "Matthias Wieser",
      "Martijn Warnier",
      "Frances Brazier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13529v1",
    "title": "Toward Conversational Hungarian Speech Recognition: Introducing the BEA-Large and BEA-Dialogue Datasets",
    "summary": "The advancement of automatic speech recognition (ASR) has been largely enhanced by extensive datasets in high-resource languages, while languages such as Hungarian remain underrepresented due to limited spontaneous and conversational corpora. To address this gap, we introduce two new datasets -- BEA-Large and BEA-Dialogue -- constructed from the previously unprocessed portions of the Hungarian speech corpus named BEA. BEA-Large extends BEA-Base with 255 hours of spontaneous speech from 433 speakers, enriched with detailed segment-level metadata. BEA-Dialogue, comprising 85 hours of spontaneous conversations, is a Hungarian speech corpus featuring natural dialogues partitioned into speaker-independent subsets, supporting research in conversational ASR and speaker diarization. We establish reproducible baselines on these datasets using publicly available ASR models, with the fine-tuned Fast Conformer model achieving word error rates as low as 14.18\\% on spontaneous and 4.8\\% on repeated speech. Diarization experiments yield diarization error rates between 13.05\\% and 18.26\\%, providing reference points for future improvements. The results highlight the persistent difficulty of conversational ASR, particularly due to disfluencies, overlaps, and informal speech patterns. By releasing these datasets and baselines, we aim to advance Hungarian speech technology and offer a methodological framework for developing spontaneous and conversational benchmarks in other languages.",
    "published": "2025-11-17T16:02:08Z",
    "updated": "2025-11-17T16:02:08Z",
    "link": "http://arxiv.org/pdf/2511.13529v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "authors": [
      "Máté Gedeon",
      "Piroska Zsófia Barta",
      "Péter Mihajlik",
      "Tekla Etelka Gráczi",
      "Anna Kohári",
      "Katalin Mády"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13526v1",
    "title": "Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval Augmented Large Language Models",
    "summary": "Artificial intelligence (AI) is reshaping modern healthcare by advancing disease diagnosis, treatment decision-making, and biomedical research. Among AI technologies, large language models (LLMs) have become especially impactful, enabling deep knowledge extraction and semantic reasoning from complex medical texts. However, effective clinical decision support requires knowledge in structured, interoperable formats. Knowledge graphs serve this role by integrating heterogeneous medical information into semantically consistent networks. Yet, current clinical knowledge graphs still depend heavily on manual curation and rule-based extraction, which is limited by the complexity and contextual ambiguity of medical guidelines and literature. To overcome these challenges, we propose an automated framework that combines retrieval-augmented generation (RAG) with LLMs to construct medical indicator knowledge graphs. The framework incorporates guideline-driven data acquisition, ontology-based schema design, and expert-in-the-loop validation to ensure scalability, accuracy, and clinical reliability. The resulting knowledge graphs can be integrated into intelligent diagnosis and question-answering systems, accelerating the development of AI-driven healthcare solutions.",
    "published": "2025-11-17T16:00:42Z",
    "updated": "2025-11-17T16:00:42Z",
    "link": "http://arxiv.org/pdf/2511.13526v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zhengda Wang",
      "Daqian Shi",
      "Jingyi Zhao",
      "Xiaolei Diao",
      "Xiongfeng Tang",
      "Yanguo Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11238v2",
    "title": "Virtual Width Networks",
    "summary": "We introduce Virtual Width Networks (VWN), a framework that delivers the benefits of wider representations without incurring the quadratic cost of increasing the hidden size. VWN decouples representational width from backbone width, expanding the embedding space while keeping backbone compute nearly constant. In our large-scale experiment, an 8-times expansion accelerates optimization by over 2 times for next-token and 3 times for next-2-token prediction. The advantage amplifies over training as both the loss gap grows and the convergence-speedup ratio increases, showing that VWN is not only token-efficient but also increasingly effective with scale. Moreover, we identify an approximately log-linear scaling relation between virtual width and loss reduction, offering an initial empirical basis and motivation for exploring virtual-width scaling as a new dimension of large-model efficiency.",
    "published": "2025-11-14T12:41:57Z",
    "updated": "2025-11-17T16:00:09Z",
    "link": "http://arxiv.org/pdf/2511.11238v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      " Seed",
      "Baisheng Li",
      "Banggu Wu",
      "Bole Ma",
      "Bowen Xiao",
      "Chaoyi Zhang",
      "Cheng Li",
      "Chengyi Wang",
      "Chengyin Xu",
      "Chi Zhang",
      "Chong Hu",
      "Daoguang Zan",
      "Defa Zhu",
      "Dongyu Xu",
      "Du Li",
      "Faming Wu",
      "Fan Xia",
      "Ge Zhang",
      "Guang Shi",
      "Haobin Chen",
      "Hongyu Zhu",
      "Hongzhi Huang",
      "Huan Zhou",
      "Huanzhang Dou",
      "Jianhui Duan",
      "Jianqiao Lu",
      "Jianyu Jiang",
      "Jiayi Xu",
      "Jiecao Chen",
      "Jin Chen",
      "Jin Ma",
      "Jing Su",
      "Jingji Chen",
      "Jun Wang",
      "Jun Yuan",
      "Juncai Liu",
      "Jundong Zhou",
      "Kai Hua",
      "Kai Shen",
      "Kai Xiang",
      "Kaiyuan Chen",
      "Kang Liu",
      "Ke Shen",
      "Liang Xiang",
      "Lin Yan",
      "Lishu Luo",
      "Mengyao Zhang",
      "Ming Ding",
      "Mofan Zhang",
      "Nianning Liang",
      "Peng Li",
      "Penghao Huang",
      "Pengpeng Mu",
      "Qi Huang",
      "Qianli Ma",
      "Qiyang Min",
      "Qiying Yu",
      "Renming Pang",
      "Ru Zhang",
      "Shen Yan",
      "Shen Yan",
      "Shixiong Zhao",
      "Shuaishuai Cao",
      "Shuang Wu",
      "Siyan Chen",
      "Siyu Li",
      "Siyuan Qiao",
      "Tao Sun",
      "Tian Xin",
      "Tiantian Fan",
      "Ting Huang",
      "Ting-Han Fan",
      "Wei Jia",
      "Wenqiang Zhang",
      "Wenxuan Liu",
      "Xiangzhong Wu",
      "Xiaochen Zuo",
      "Xiaoying Jia",
      "Ximing Yang",
      "Xin Liu",
      "Xin Yu",
      "Xingyan Bin",
      "Xintong Hao",
      "Xiongcai Luo",
      "Xujing Li",
      "Xun Zhou",
      "Yanghua Peng",
      "Yangrui Chen",
      "Yi Lin",
      "Yichong Leng",
      "Yinghao Li",
      "Yingshuan Song",
      "Yiyuan Ma",
      "Yong Shan",
      "Yongan Xiang",
      "Yonghui Wu",
      "Yongtao Zhang",
      "Yongzhen Yao",
      "Yu Bao",
      "Yuehang Yang",
      "Yufeng Yuan",
      "Yunshui Li",
      "Yuqiao Xian",
      "Yutao Zeng",
      "Yuxuan Wang",
      "Zehua Hong",
      "Zehua Wang",
      "Zengzhi Wang",
      "Zeyu Yang",
      "Zhengqiang Yin",
      "Zhenyi Lu",
      "Zhexi Zhang",
      "Zhi Chen",
      "Zhi Zhang",
      "Zhiqi Lin",
      "Zihao Huang",
      "Zilin Xu",
      "Ziyun Wei",
      "Zuo Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13525v1",
    "title": "AI Fairness Beyond Complete Demographics: Current Achievements and Future Directions",
    "summary": "Fairness in artificial intelligence (AI) has become a growing concern due to discriminatory outcomes in AI-based decision-making systems. While various methods have been proposed to mitigate bias, most rely on complete demographic information, an assumption often impractical due to legal constraints and the risk of reinforcing discrimination. This survey examines fairness in AI when demographics are incomplete, addressing the gap between traditional approaches and real-world challenges. We introduce a novel taxonomy of fairness notions in this setting, clarifying their relationships and distinctions. Additionally, we summarize existing techniques that promote fairness beyond complete demographics and highlight open research questions to encourage further progress in the field.",
    "published": "2025-11-17T15:59:25Z",
    "updated": "2025-11-17T15:59:25Z",
    "link": "http://arxiv.org/pdf/2511.13525v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zichong Wang",
      "Zhipeng Yin",
      "Roland H. C. Yap",
      "Wenbin Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13524v1",
    "title": "FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI",
    "summary": "As embodied intelligence emerges as a core frontier in artificial intelligence research, simulation platforms must evolve beyond low-level physical interactions to capture complex, human-centered social behaviors. We introduce FreeAskWorld, an interactive simulation framework that integrates large language models (LLMs) for high-level behavior planning and semantically grounded interaction, informed by theories of intention and social cognition. Our framework supports scalable, realistic human-agent simulations and includes a modular data generation pipeline tailored for diverse embodied tasks.To validate the framework, we extend the classic Vision-and-Language Navigation (VLN) task into a interaction enriched Direction Inquiry setting, wherein agents can actively seek and interpret navigational guidance. We present and publicly release FreeAskWorld, a large-scale benchmark dataset comprising reconstructed environments, six diverse task types, 16 core object categories, 63,429 annotated sample frames, and more than 17 hours of interaction data to support training and evaluation of embodied AI systems. We benchmark VLN models, and human participants under both open-loop and closed-loop settings. Experimental results demonstrate that models fine-tuned on FreeAskWorld outperform their original counterparts, achieving enhanced semantic understanding and interaction competency. These findings underscore the efficacy of socially grounded simulation frameworks in advancing embodied AI systems toward sophisticated high-level planning and more naturalistic human-agent interaction. Importantly, our work underscores that interaction itself serves as an additional information modality.",
    "published": "2025-11-17T15:58:46Z",
    "updated": "2025-11-17T15:58:46Z",
    "link": "http://arxiv.org/pdf/2511.13524v1.pdf",
    "category": [
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Yuhang Peng",
      "Yizhou Pan",
      "Xinning He",
      "Jihaoyu Yang",
      "Xinyu Yin",
      "Han Wang",
      "Xiaoji Zheng",
      "Chao Gao",
      "Jiangtao Gong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13510v1",
    "title": "Naga: Vedic Encoding for Deep State Space Models",
    "summary": "This paper presents Naga, a deep State Space Model (SSM) encoding approach inspired by structural concepts from Vedic mathematics. The proposed method introduces a bidirectional representation for time series by jointly processing forward and time-reversed input sequences. These representations are then combined through an element-wise (Hadamard) interaction, resulting in a Vedic-inspired encoding that enhances the model's ability to capture temporal dependencies across distant time steps. We evaluate Naga on multiple long-term time series forecasting (LTSF) benchmarks, including ETTh1, ETTh2, ETTm1, ETTm2, Weather, Traffic, and ILI. The experimental results show that Naga outperforms 28 current state of the art models and demonstrates improved efficiency compared to existing deep SSM-based approaches. The findings suggest that incorporating structured, Vedic-inspired decomposition can provide an interpretable and computationally efficient alternative for long-range sequence modeling.",
    "published": "2025-11-17T15:43:49Z",
    "updated": "2025-11-17T15:43:49Z",
    "link": "http://arxiv.org/pdf/2511.13510v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "authors": [
      "Melanie Schaller",
      "Nick Janssen",
      "Bodo Rosenhahn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.11077v2",
    "title": "Deep deterministic policy gradient with symmetric data augmentation for lateral attitude tracking control of a fixed-wing aircraft",
    "summary": "The symmetry of dynamical systems can be exploited for state-transition prediction and to facilitate control policy optimization. This paper leverages system symmetry to develop sample-efficient offline reinforcement learning (RL) approaches. Under the symmetry assumption for a Markov Decision Process (MDP), a symmetric data augmentation method is proposed. The augmented samples are integrated into the dataset of Deep Deterministic Policy Gradient (DDPG) to enhance its coverage rate of the state-action space. Furthermore, sample utilization efficiency is improved by introducing a second critic trained on the augmented samples, resulting in a dual-critic structure. The aircraft's model is verified to be symmetric, and flight control simulations demonstrate accelerated policy convergence when augmented samples are employed.",
    "published": "2024-07-13T08:20:11Z",
    "updated": "2025-11-17T15:43:10Z",
    "link": "http://arxiv.org/pdf/2407.11077v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yifei Li",
      "Erik-Jan van Kampen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.00918v2",
    "title": "Dynamic and Distributed Routing in IoT Networks based on Multi-Objective Q-Learning",
    "summary": "IoT networks often face conflicting routing goals such as maximizing packet delivery, minimizing delay, and conserving limited battery energy. These priorities can also change dynamically: for example, an emergency alert requires high reliability, while routine monitoring prioritizes energy efficiency to prolong network lifetime. Existing works, including many deep reinforcement learning approaches, are typically centralized and assume static objectives, making them slow to adapt when preferences shift. We propose a dynamic and fully distributed multi-objective Q-learning routing algorithm that learns multiple per-preference Q-tables in parallel and introduces a novel greedy interpolation policy to act near-optimally for unseen preferences without retraining or central coordination. A theoretical analysis further shows that the optimal value function is Lipschitz-continuous in the preference parameter, ensuring that the proposed greedy interpolation policy yields provably near-optimal behavior. Simulations show that our approach adapts in real time to shifting priorities and achieves up to 80-90\\% lower energy consumption and more than 2-5x higher cumulative rewards and packet delivery compared to six baseline protocols. These results demonstrate significant gains in adaptability, delivery, and efficiency for dynamic IoT environments.",
    "published": "2025-05-01T23:34:35Z",
    "updated": "2025-11-17T15:29:32Z",
    "link": "http://arxiv.org/pdf/2505.00918v2.pdf",
    "category": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "authors": [
      "Shubham Vaishnav",
      "Praveen Kumar Donta",
      "Sindri Magnússon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.11647v3",
    "title": "Near-Optimal Reinforcement Learning with Shuffle Differential Privacy",
    "summary": "Reinforcement learning (RL) is a powerful tool for sequential decision-making, but its application is often hindered by privacy concerns arising from its interaction data. This challenge is particularly acute in advanced networked systems, where learning from operational and user data can expose systems to privacy inference attacks. Existing differential privacy (DP) models for RL are often inadequate: the centralized model requires a fully trusted server, creating a single point of failure risk, while the local model incurs significant performance degradation that is unsuitable for many networked applications. This paper addresses this gap by leveraging the emerging shuffle model of privacy, an intermediate trust model that provides strong privacy guarantees without a centralized trust assumption. We present Shuffle Differentially Private Policy Elimination (SDP-PE), the first generic policy elimination-based algorithm for episodic RL under the shuffle model. Our method introduces a novel exponential batching schedule and a ``forgetting'' mechanism to balance the competing demands of privacy and learning performance. Our analysis shows that SDP-PE achieves a near-optimal regret bound, demonstrating a superior privacy-regret trade-off with utility comparable to the centralized model while significantly outperforming the local model. The numerical experiments also corroborate our theoretical results and demonstrate the effectiveness of SDP-PE. This work establishes the viability of the shuffle model for secure data-driven decision-making in networked systems.",
    "published": "2024-11-18T15:24:11Z",
    "updated": "2025-11-17T15:22:52Z",
    "link": "http://arxiv.org/pdf/2411.11647v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "authors": [
      "Shaojie Bai",
      "Mohammad Sadegh Talebi",
      "Chengcheng Zhao",
      "Peng Cheng",
      "Jiming Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00210v2",
    "title": "REIC: RAG-Enhanced Intent Classification at Scale",
    "summary": "Accurate intent classification is critical for efficient routing in customer service, ensuring customers are connected with the most suitable agents while reducing handling times and operational costs. However, as companies expand their product lines, intent classification faces scalability challenges due to the increasing number of intents and variations in taxonomy across different verticals. In this paper, we introduce REIC, a Retrieval-augmented generation Enhanced Intent Classification approach, which addresses these challenges effectively. REIC leverages retrieval-augmented generation (RAG) to dynamically incorporate relevant knowledge, enabling precise classification without the need for frequent retraining. Through extensive experiments on real-world datasets, we demonstrate that REIC outperforms traditional fine-tuning, zero-shot, and few-shot methods in large-scale customer service settings. Our results highlight its effectiveness in both in-domain and out-of-domain scenarios, demonstrating its potential for real-world deployment in adaptive and large-scale intent classification systems.",
    "published": "2025-05-30T20:32:10Z",
    "updated": "2025-11-17T15:21:31Z",
    "link": "http://arxiv.org/pdf/2506.00210v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Ziji Zhang",
      "Michael Yang",
      "Zhiyu Chen",
      "Yingying Zhuang",
      "Shu-Ting Pi",
      "Qun Liu",
      "Rajashekar Maragoud",
      "Vy Nguyen",
      "Anurag Beniwal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13480v1",
    "title": "A Lexical Analysis of online Reviews on Human-AI Interactions",
    "summary": "This study focuses on understanding the complex dynamics between humans and AI systems by analyzing user reviews. While previous research has explored various aspects of human-AI interaction, such as user perceptions and ethical considerations, there remains a gap in understanding the specific concerns and challenges users face. By using a lexical approach to analyze 55,968 online reviews from G2.com, Producthunt.com, and Trustpilot.com, this preliminary research aims to analyze human-AI interaction. Initial results from factor analysis reveal key factors influencing these interactions. The study aims to provide deeper insights into these factors through content analysis, contributing to the development of more user-centric AI systems. The findings are expected to enhance our understanding of human-AI interaction and inform future AI technology and user experience improvements.",
    "published": "2025-11-17T15:17:36Z",
    "updated": "2025-11-17T15:17:36Z",
    "link": "http://arxiv.org/pdf/2511.13480v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "Parisa Arbab",
      "Xiaowen Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13478v1",
    "title": "Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling",
    "summary": "Multimedia documents such as slide presentations and posters are designed to be interactive and easy to modify. Yet, they are often distributed in a static raster format, which limits editing and customization. Restoring their editability requires converting these raster images back into structured vector formats. However, existing geometric raster-vectorization methods, which rely on low-level primitives like curves and polygons, fall short at this task. Specifically, when applied to complex documents like slides, they fail to preserve the high-level structure, resulting in a flat collection of shapes where the semantic distinction between image and text elements is lost. To overcome this limitation, we address the problem of semantic document derendering by introducing SliDer, a novel framework that uses Vision-Language Models (VLMs) to derender slide images as compact and editable Scalable Vector Graphic (SVG) representations. SliDer detects and extracts attributes from individual image and text elements in a raster input and organizes them into a coherent SVG format. Crucially, the model iteratively refines its predictions during inference in a process analogous to human design, generating SVG code that more faithfully reconstructs the original raster upon rendering. Furthermore, we introduce Slide2SVG, a novel dataset comprising raster-SVG pairs of slide documents curated from real-world scientific presentations, to facilitate future research in this domain. Our results demonstrate that SliDer achieves a reconstruction LPIPS of 0.069 and is favored by human evaluators in 82.9% of cases compared to the strongest zero-shot VLM baseline.",
    "published": "2025-11-17T15:16:13Z",
    "updated": "2025-11-17T15:16:13Z",
    "link": "http://arxiv.org/pdf/2511.13478v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Adam Hazimeh",
      "Ke Wang",
      "Mark Collier",
      "Gilles Baechler",
      "Efi Kokiopoulou",
      "Pascal Frossard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13476v1",
    "title": "Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation",
    "summary": "Enhancing fuel efficiency in public transportation requires the integration of complex multimodal data into interpretable, decision-relevant insights. However, traditional analytics and visualization methods often yield fragmented outputs that demand extensive human interpretation, limiting scalability and consistency. This study presents a multi-agent framework that leverages multimodal large language models (LLMs) to automate data narration and energy insight generation. The framework coordinates three specialized agents, including a data narration agent, an LLM-as-a-judge agent, and an optional human-in-the-loop evaluator, to iteratively transform analytical artifacts into coherent, stakeholder-oriented reports. The system is validated through a real-world case study on public bus transportation in Northern Jutland, Denmark, where fuel efficiency data from 4006 trips are analyzed using Gaussian Mixture Model clustering. Comparative experiments across five state-of-the-art LLMs and three prompting paradigms identify GPT-4.1 mini with Chain-of-Thought prompting as the optimal configuration, achieving 97.3% narrative accuracy while balancing interpretability and computational cost. The findings demonstrate that multi-agent orchestration significantly enhances factual precision, coherence, and scalability in LLM-based reporting. The proposed framework establishes a replicable and domain-adaptive methodology for AI-driven narrative generation and decision support in energy informatics.",
    "published": "2025-11-17T15:14:17Z",
    "updated": "2025-11-17T15:14:17Z",
    "link": "http://arxiv.org/pdf/2511.13476v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zhipeng Ma",
      "Ali Rida Bahja",
      "Andreas Burgdorf",
      "André Pomp",
      "Tobias Meisen",
      "Bo Nørregaard Jørgensen",
      "Zheng Grace Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.00032v2",
    "title": "Ken Utilization Layer: Hebbian Replay Within a Student's Ken for Adaptive Exercise Recommendation",
    "summary": "Adaptive exercise recommendation (ER) aims to choose the next activity that matches a learner's evolving Zone of Proximal Development (ZPD). We present KUL-Rec, a biologically inspired ER system that couples a fast Hebbian memory with slow replay-based consolidation to enable continual, few-shot personalization from sparse interactions. The model operates in an embedding space, allowing a single architecture to handle both tabular knowledge-tracing logs and open-ended short-answer text. We align evaluation with tutoring needs using bidirectional ranking and rank-sensitive metrics (nDCG, Recall@K). Across ten public datasets, KUL-Rec improves macro nDCG (0.316 vs. 0.265 for the strongest baseline) and Recall@10 (0.305 vs. 0.211), while achieving low inference latency and an $\\approx99$\\% reduction in peak GPU memory relative to a competitive graph-based model. In a 13-week graduate course, KUL-Rec personalized weekly short-answer quizzes generated by a retrieval-augmented pipeline and the personalized quizzes were associated with lower perceived difficulty and higher helpfulness (p < .05). An embedding robustness audit highlights that encoder choice affects semantic alignment, motivating routine audits when deploying open-response assessment. Together, these results indicate that Hebbian replay with bounded consolidation offers a practical path to real-time, interpretable ER that scales across data modalities and classroom settings.",
    "published": "2025-06-18T00:06:28Z",
    "updated": "2025-11-17T15:10:41Z",
    "link": "http://arxiv.org/pdf/2507.00032v2.pdf",
    "category": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "authors": [
      "Grey Kuling",
      "Marinka Zitnik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13466v1",
    "title": "The Quick Red Fox gets the best Data Driven Classroom Interviews: A manual for an interview app and its associated methodology",
    "summary": "Data Driven Classroom Interviews (DDCIs) are an interviewing technique that is facilitated by recent technological developments in the learning analytics community. DDCIs are short, targeted interviews that allow researchers to contextualize students' interactions with a digital learning environment (e.g., intelligent tutoring systems or educational games) while minimizing the amount of time that the researcher interrupts that learning experience, and focusing researcher time on the events they most want to focus on DDCIs are facilitated by a research tool called the Quick Red Fox (QRF)--an open-source server-client Android app that optimizes researcher time by directing interviewers to users that have just displayed an interesting behavior (previously defined by the research team). QRF integrates with existing student modeling technologies (e.g., behavior-sensing, affect-sensing, detection of self-regulated learning) to alert researchers to key moments in a learner's experience. This manual documents the tech while providing training on the processes involved in developing triggers and interview techniques; it also suggests methods of analyses.",
    "published": "2025-11-17T15:08:47Z",
    "updated": "2025-11-17T15:08:47Z",
    "link": "http://arxiv.org/pdf/2511.13466v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.ET"
    ],
    "authors": [
      "Jaclyn Ocumpaugh",
      "Luc Paquette",
      "Ryan S. Baker",
      "Amanda Barany",
      "Jeff Ginger",
      "Nathan Casano",
      "Andres F. Zambrano",
      "Xiner Liu",
      "Zhanlan Wei",
      "Yiqui Zhou",
      "Qianhui Liu",
      "Stephen Hutt",
      "Alexandra M. A. Andres",
      "Nidhi Nasiar",
      "Camille Giordano",
      "Martin van Velsen",
      "Micheal Mogessi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13463v1",
    "title": "Multi-task GINN-LP for Multi-target Symbolic Regression",
    "summary": "In the area of explainable artificial intelligence, Symbolic Regression (SR) has emerged as a promising approach by discovering interpretable mathematical expressions that fit data. However, SR faces two main challenges: most methods are evaluated on scientific datasets with well-understood relationships, limiting generalization, and SR primarily targets single-output regression, whereas many real-world problems involve multi-target outputs with interdependent variables. To address these issues, we propose multi-task regression GINN-LP (MTRGINN-LP), an interpretable neural network for multi-target symbolic regression. By integrating GINN-LP with a multi-task deep learning, the model combines a shared backbone including multiple power-term approximator blocks with task-specific output layers, capturing inter-target dependencies while preserving interpretability. We validate multi-task GINN-LP on practical multi-target applications, including energy efficiency prediction and sustainable agriculture. Experimental results demonstrate competitive predictive performance alongside high interpretability, effectively extending symbolic regression to broader real-world multi-output tasks.",
    "published": "2025-11-17T15:07:41Z",
    "updated": "2025-11-17T15:07:41Z",
    "link": "http://arxiv.org/pdf/2511.13463v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hussein Rajabu",
      "Lijun Qian",
      "Xishuang Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13458v1",
    "title": "Trust in Vision-Language Models: Insights from a Participatory User Workshop",
    "summary": "With the growing deployment of Vision-Language Models (VLMs), pre-trained on large image-text and video-text datasets, it is critical to equip users with the tools to discern when to trust these systems. However, examining how user trust in VLMs builds and evolves remains an open problem. This problem is exacerbated by the increasing reliance on AI models as judges for experimental validation, to bypass the cost and implications of running participatory design studies directly with users. Following a user-centred approach, this paper presents preliminary results from a workshop with prospective VLM users. Insights from this pilot workshop inform future studies aimed at contextualising trust metrics and strategies for participants' engagement to fit the case of user-VLM interaction.",
    "published": "2025-11-17T15:04:59Z",
    "updated": "2025-11-17T15:04:59Z",
    "link": "http://arxiv.org/pdf/2511.13458v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Agnese Chiatti",
      "Lara Piccolo",
      "Sara Bernardini",
      "Matteo Matteucci",
      "Viola Schiaffonati"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13457v1",
    "title": "Artificial Intelligence-Enabled Spirometry for Early Detection of Right Heart Failure",
    "summary": "Right heart failure (RHF) is a disease characterized by abnormalities in the structure or function of the right ventricle (RV), which is associated with high morbidity and mortality. Lung disease often causes increased right ventricular load, leading to RHF. Therefore, it is very important to screen out patients with cor pulmonale who develop RHF from people with underlying lung diseases. In this work, we propose a self-supervised representation learning method to early detecting RHF from patients with cor pulmonale, which uses spirogram time series to predict patients with RHF at an early stage. The proposed model is divided into two stages. The first stage is the self-supervised representation learning-based spirogram embedding (SLSE) network training process, where the encoder of the Variational autoencoder (VAE-encoder) learns a robust low-dimensional representation of the spirogram time series from the data-augmented unlabeled data. Second, this low-dimensional representation is fused with demographic information and fed into a CatBoost classifier for the downstream RHF prediction task. Trained and tested on a carefully selected subset of 26,617 individuals from the UK Biobank, our model achieved an AUROC of 0.7501 in detecting RHF, demonstrating strong population-level distinction ability. We further evaluated the model on high-risk clinical subgroups, achieving AUROC values of 0.8194 on a test set of 74 patients with chronic kidney disease (CKD) and 0.8413 on a set of 64 patients with valvular heart disease (VHD). These results highlight the model's potential utility in predicting RHF among clinically elevated-risk populations. In conclusion, this study presents a self-supervised representation learning approach combining spirogram time series and demographic data, demonstrating promising potential for early RHF detection in clinical practice.",
    "published": "2025-11-17T15:03:04Z",
    "updated": "2025-11-17T15:03:04Z",
    "link": "http://arxiv.org/pdf/2511.13457v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Bin Liu",
      "Qinghao Zhao",
      "Yuxi Zhou",
      "Zhejun Sun",
      "Kaijie Lei",
      "Deyun Zhang",
      "Shijia Geng",
      "Shenda Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.16124v3",
    "title": "Benchmarking LLM Privacy Recognition for Social Robot Decision Making",
    "summary": "While robots have previously utilized rule-based systems or probabilistic models for user interaction, the rapid evolution of large language models (LLMs) presents new opportunities to develop LLM-powered robots for enhanced human-robot interaction (HRI). To fully realize these capabilities, however, robots need to collect data such as audio, fine-grained images, video, and locations. As a result, LLMs often process sensitive personal information, particularly within private environments, such as homes. Given the tension between utility and privacy risks, evaluating how current LLMs manage sensitive data is critical. Specifically, we aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the context of household robots. In this work, we present a set of privacy-relevant scenarios developed using the Contextual Integrity (CI) framework. We first surveyed users' privacy preferences regarding in-home robot behaviors and then examined how their privacy orientations affected their choices of these behaviors (N = 450). We then provided the same set of scenarios and questions to state-of-the-art LLMs (N = 10) and found that the agreement between humans and LLMs was generally low. To further investigate the capabilities of LLMs as potential privacy controllers, we implemented four additional prompting strategies and compared their results. We discuss the performance of the evaluated models as well as the implications and potential of AI privacy awareness in human-robot interaction.",
    "published": "2025-07-22T00:36:59Z",
    "updated": "2025-11-17T15:01:43Z",
    "link": "http://arxiv.org/pdf/2507.16124v3.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Dakota Sullivan",
      "Shirley Zhang",
      "Jennica Li",
      "Heather Kirkorian",
      "Bilge Mutlu",
      "Kassem Fawaz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13444v1",
    "title": "Discovering Operational Patterns Using Image-Based Convolutional Clustering and Composite Evaluation: A Case Study in Foundry Melting Processes",
    "summary": "Industrial process monitoring increasingly relies on sensor-generated time-series data, yet the lack of labels, high variability, and operational noise make it difficult to extract meaningful patterns using conventional methods. Existing clustering techniques either rely on fixed distance metrics or deep models designed for static data, limiting their ability to handle dynamic, unstructured industrial sequences. Addressing this gap, this paper proposes a novel framework for unsupervised discovery of operational modes in univariate time-series data using image-based convolutional clustering with composite internal evaluation. The proposed framework improves upon existing approaches in three ways: (1) raw time-series sequences are transformed into grayscale matrix representations via overlapping sliding windows, allowing effective feature extraction using a deep convolutional autoencoder; (2) the framework integrates both soft and hard clustering outputs and refines the selection through a two-stage strategy; and (3) clustering performance is objectively evaluated by a newly developed composite score, S_eva, which combines normalized Silhouette, Calinski-Harabasz, and Davies-Bouldin indices. Applied to over 3900 furnace melting operations from a Nordic foundry, the method identifies seven explainable operational patterns, revealing significant differences in energy consumption, thermal dynamics, and production duration. Compared to classical and deep clustering baselines, the proposed approach achieves superior overall performance, greater robustness, and domain-aligned explainability. The framework addresses key challenges in unsupervised time-series analysis, such as sequence irregularity, overlapping modes, and metric inconsistency, and provides a generalizable solution for data-driven diagnostics and energy optimization in industrial systems.",
    "published": "2025-11-17T14:50:44Z",
    "updated": "2025-11-17T14:50:44Z",
    "link": "http://arxiv.org/pdf/2511.13444v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhipeng Ma",
      "Bo Nørregaard Jørgensen",
      "Zheng Grace Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13442v1",
    "title": "Unlocking the Forgery Detection Potential of Vanilla MLLMs: A Novel Training-Free Pipeline",
    "summary": "With the rapid advancement of artificial intelligence-generated content (AIGC) technologies, including multimodal large language models (MLLMs) and diffusion models, image generation and manipulation have become remarkably effortless. Existing image forgery detection and localization (IFDL) methods often struggle to generalize across diverse datasets and offer limited interpretability. Nowadays, MLLMs demonstrate strong generalization potential across diverse vision-language tasks, and some studies introduce this capability to IFDL via large-scale training. However, such approaches cost considerable computational resources, while failing to reveal the inherent generalization potential of vanilla MLLMs to address this problem. Inspired by this observation, we propose Foresee, a training-free MLLM-based pipeline tailored for image forgery analysis. It eliminates the need for additional training and enables a lightweight inference process, while surpassing existing MLLM-based methods in both tamper localization accuracy and the richness of textual explanations. Foresee employs a type-prior-driven strategy and utilizes a Flexible Feature Detector (FFD) module to specifically handle copy-move manipulations, thereby effectively unleashing the potential of vanilla MLLMs in the forensic domain. Extensive experiments demonstrate that our approach simultaneously achieves superior localization accuracy and provides more comprehensive textual explanations. Moreover, Foresee exhibits stronger generalization capability, outperforming existing IFDL methods across various tampering types, including copy-move, splicing, removal, local enhancement, deepfake, and AIGC-based editing. The code will be released in the final version.",
    "published": "2025-11-17T14:49:57Z",
    "updated": "2025-11-17T14:49:57Z",
    "link": "http://arxiv.org/pdf/2511.13442v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Rui Zuo",
      "Qinyue Tong",
      "Zhe-Ming Lu",
      "Ziqian Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.04663v2",
    "title": "HierarchicalPrune: Position-Aware Compression for Large-Scale Diffusion Models",
    "summary": "State-of-the-art text-to-image diffusion models (DMs) achieve remarkable quality, yet their massive parameter scale (8-11B) poses significant challenges for inferences on resource-constrained devices. In this paper, we present HierarchicalPrune, a novel compression framework grounded in a key observation: DM blocks exhibit distinct functional hierarchies, where early blocks establish semantic structures while later blocks handle texture refinements. HierarchicalPrune synergistically combines three techniques: (1) Hierarchical Position Pruning, which identifies and removes less essential later blocks based on position hierarchy; (2) Positional Weight Preservation, which systematically protects early model portions that are essential for semantic structural integrity; and (3) Sensitivity-Guided Distillation, which adjusts knowledge-transfer intensity based on our discovery of block-wise sensitivity variations. As a result, our framework brings billion-scale diffusion models into a range more suitable for on-device inference, while preserving the quality of the output images. Specifically, combined with INT4 weight quantisation, HierarchicalPrune achieves 77.5-80.4% memory footprint reduction (e.g., from 15.8 GB to 3.2 GB) and 27.9-38.0% latency reduction, measured on server and consumer grade GPUs, with the minimum drop of 2.6% in GenEval score and 7% in HPSv2 score compared to the original model. Finally, our comprehensive user study with 85 participants demonstrates that HierarchicalPrune maintains perceptual quality comparable to the original model while significantly outperforming prior works.",
    "published": "2025-08-06T17:30:44Z",
    "updated": "2025-11-17T14:38:19Z",
    "link": "http://arxiv.org/pdf/2508.04663v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Young D. Kwon",
      "Rui Li",
      "Sijia Li",
      "Da Li",
      "Sourav Bhattacharya",
      "Stylianos I. Venieris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08151v2",
    "title": "SciAgent: A Unified Multi-Agent System for Generalistic Scientific Reasoning",
    "summary": "Recent advances in large language models have enabled AI systems to achieve expert-level performance on domain-specific scientific tasks, yet these systems remain narrow and handcrafted. We introduce SciAgent, a unified multi-agent system designed for generalistic scientific reasoning-the ability to adapt reasoning strategies across disciplines and difficulty levels. SciAgent organizes problem solving as a hierarchical process: a Coordinator Agent interprets each problem's domain and complexity, dynamically orchestrating specialized Worker Systems, each composed of interacting reasoning Sub-agents for symbolic deduction, conceptual modeling, numerical computation, and verification. These agents collaboratively assemble and refine reasoning pipelines tailored to each task. Across mathematics and physics Olympiads (IMO, IMC, IPhO, CPhO), SciAgent consistently attains or surpasses human gold-medalist performance, demonstrating both domain generality and reasoning adaptability. Additionally, SciAgent has been tested on the International Chemistry Olympiad (IChO) and selected problems from the Humanity's Last Exam (HLE) benchmark, further confirming the system's ability to generalize across diverse scientific domains. This work establishes SciAgent as a concrete step toward generalistic scientific intelligence-AI systems capable of coherent, cross-disciplinary reasoning at expert levels.",
    "published": "2025-11-11T12:00:34Z",
    "updated": "2025-11-17T14:32:09Z",
    "link": "http://arxiv.org/pdf/2511.08151v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "authors": [
      "Xuchen Li",
      "Ruitao Wu",
      "Xuanbo Liu",
      "Xukai Wang",
      "Jinbo Hu",
      "Zhixin Bai",
      "Bohan Zeng",
      "Hao Liang",
      "Leheng Chen",
      "Mingrui Chen",
      "Haitian Zhong",
      "Xuanlin Yang",
      "Xu-Yao Zhang",
      "Liu Liu",
      "Jia Li",
      "Kaiqi Huang",
      "Jiahao Xu",
      "Haitao Mi",
      "Wentao Zhang",
      "Bin Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13418v1",
    "title": "Exploring Multi-Table Retrieval Through Iterative Search",
    "summary": "Open-domain question answering over datalakes requires retrieving and composing information from multiple tables, a challenging subtask that demands semantic relevance and structural coherence (e.g., joinability). While exact optimization methods like Mixed-Integer Programming (MIP) can ensure coherence, their computational complexity is often prohibitive. Conversely, simpler greedy heuristics that optimize for query coverage alone often fail to find these coherent, joinable sets. This paper frames multi-table retrieval as an iterative search process, arguing this approach offers advantages in scalability, interpretability, and flexibility. We propose a general framework and a concrete instantiation: a fast, effective Greedy Join-Aware Retrieval algorithm that holistically balances relevance, coverage, and joinability. Experiments across 5 NL2SQL benchmarks demonstrate that our iterative method achieves competitive retrieval performance compared to the MIP-based approach while being 4-400x faster depending on the benchmark and search space settings. This work highlights the potential of iterative heuristics for practical, scalable, and composition-aware retrieval.",
    "published": "2025-11-17T14:31:33Z",
    "updated": "2025-11-17T14:31:33Z",
    "link": "http://arxiv.org/pdf/2511.13418v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.LG"
    ],
    "authors": [
      "Allaa Boutaleb",
      "Bernd Amann",
      "Rafael Angarita",
      "Hubert Naacke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13414v1",
    "title": "PAST: A Primary-Auxiliary Spatio-Temporal Network for Traffic Time Series Imputation",
    "summary": "Traffic time series imputation is crucial for the safety and reliability of intelligent transportation systems, while diverse types of missing data, including random, fiber, and block missing make the imputation task challenging. Existing models often focus on disentangling and separately modeling spatial and temporal patterns based on relationships between data points. However, these approaches struggle to adapt to the random missing positions, and fail to learn long-term and large-scale dependencies, which are essential in extensive missing conditions. In this paper, patterns are categorized into two types to handle various missing data conditions: primary patterns, which originate from internal relationships between data points, and auxiliary patterns, influenced by external factors like timestamps and node attributes. Accordingly, we propose the Primary-Auxiliary Spatio-Temporal network (PAST). It comprises a graph-integrated module (GIM) and a cross-gated module (CGM). GIM captures primary patterns via dynamic graphs with interval-aware dropout and multi-order convolutions, and CGM extracts auxiliary patterns through bidirectional gating on embedded external features. The two modules interact via shared hidden vectors and are trained under an ensemble self-supervised framework. Experiments on three datasets under 27 missing data conditions demonstrate that the imputation accuracy of PAST outperforms seven state-of-the-art baselines by up to 26.2% in RMSE and 31.6% in MAE.",
    "published": "2025-11-17T14:28:29Z",
    "updated": "2025-11-17T14:28:29Z",
    "link": "http://arxiv.org/pdf/2511.13414v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Hanwen Hu",
      "Zimo Wen",
      "Shiyou Qian",
      "Jian Co"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13411v1",
    "title": "An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence",
    "summary": "We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing \"baby AGI\" becomes Superintelligence intuition.",
    "published": "2025-11-17T14:24:27Z",
    "updated": "2025-11-17T14:24:27Z",
    "link": "http://arxiv.org/pdf/2511.13411v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Przemyslaw Chojecki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.16136v3",
    "title": "Modeling Dynamic Neural Activity by combining Naturalistic Video Stimuli and Stimulus-independent Latent Factors",
    "summary": "The neural activity in the visual processing is influenced by both external stimuli and internal brain states. Ideally, a neural predictive model should account for both of them. Currently, there are no dynamic encoding models that explicitly model a latent state and the entire neuronal response distribution. We address this gap by proposing a probabilistic model that predicts the joint distribution of the neuronal responses from video stimuli and stimulus-independent latent factors. After training and testing our model on mouse V1 neuronal responses, we find that it outperforms video-only models in terms of log-likelihood and achieves improvements in likelihood and correlation when conditioned on responses from other neurons. Furthermore, we find that the learned latent factors strongly correlate with mouse behavior and that they exhibit patterns related to the neurons' position on the visual cortex, although the model was trained without behavior and cortical coordinates. Our findings demonstrate that unsupervised learning of latent factors from population responses can reveal biologically meaningful structure that bridges sensory processing and behavior, without requiring explicit behavioral annotations during training.",
    "published": "2024-10-21T16:01:39Z",
    "updated": "2025-11-17T14:19:49Z",
    "link": "http://arxiv.org/pdf/2410.16136v3.pdf",
    "category": [
      "q-bio.NC",
      "cs.AI"
    ],
    "authors": [
      "Finn Schmidt",
      "Polina Turishcheva",
      "Suhas Shrinivasan",
      "Fabian H. Sinz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13399v1",
    "title": "TripleFDS: Triple Feature Disentanglement and Synthesis for Scene Text Editing",
    "summary": "Scene Text Editing (STE) aims to naturally modify text in images while preserving visual consistency, the decisive factors of which can be divided into three parts, i.e., text style, text content, and background. Previous methods have struggled with incomplete disentanglement of editable attributes, typically addressing only one aspect - such as editing text content - thus limiting controllability and visual consistency. To overcome these limitations, we propose TripleFDS, a novel framework for STE with disentangled modular attributes, and an accompanying dataset called SCB Synthesis. SCB Synthesis provides robust training data for triple feature disentanglement by utilizing the \"SCB Group\", a novel construct that combines three attributes per image to generate diverse, disentangled training groups. Leveraging this construct as a basic training unit, TripleFDS first disentangles triple features, ensuring semantic accuracy through inter-group contrastive regularization and reducing redundancy through intra-sample multi-feature orthogonality. In the synthesis phase, TripleFDS performs feature remapping to prevent \"shortcut\" phenomena during reconstruction and mitigate potential feature leakage. Trained on 125,000 SCB Groups, TripleFDS achieves state-of-the-art image fidelity (SSIM of 44.54) and text accuracy (ACC of 93.58%) on the mainstream STE benchmarks. Besides superior performance, the more flexible editing of TripleFDS supports new operations such as style replacement and background transfer. Code: https://github.com/yusenbao01/TripleFDS",
    "published": "2025-11-17T14:15:03Z",
    "updated": "2025-11-17T14:15:03Z",
    "link": "http://arxiv.org/pdf/2511.13399v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuchen Bao",
      "Yiting Wang",
      "Wenjian Huang",
      "Haowei Wang",
      "Shen Chen",
      "Taiping Yao",
      "Shouhong Ding",
      "Jianguo Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09829v2",
    "title": "Thermally Activated Dual-Modal Adversarial Clothing against AI Surveillance Systems",
    "summary": "Adversarial patches have emerged as a popular privacy-preserving approach for resisting AI-driven surveillance systems. However, their conspicuous appearance makes them difficult to deploy in real-world scenarios. In this paper, we propose a thermally activated adversarial wearable designed to ensure adaptability and effectiveness in complex real-world environments. The system integrates thermochromic dyes with flexible heating units to induce visually dynamic adversarial patterns on clothing surfaces. In its default state, the clothing appears as an ordinary black T-shirt. Upon heating via an embedded thermal unit, hidden adversarial patterns on the fabric are activated, allowing the wearer to effectively evade detection across both visible and infrared modalities. Physical experiments demonstrate that the adversarial wearable achieves rapid texture activation within 50 seconds and maintains an adversarial success rate above 80\\% across diverse real-world surveillance environments. This work demonstrates a new pathway toward physically grounded, user-controllable anti-AI systems, highlighting the growing importance of proactive adversarial techniques for privacy protection in the age of ubiquitous AI surveillance.",
    "published": "2025-11-13T00:23:15Z",
    "updated": "2025-11-17T14:14:26Z",
    "link": "http://arxiv.org/pdf/2511.09829v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Jiahuan Long",
      "Tingsong Jiang",
      "Hanqing Liu",
      "Chao Ma",
      "Wen Yao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13397v1",
    "title": "Descriptor: Distance-Annotated Traffic Perception Question Answering (DTPQA)",
    "summary": "The remarkable progress of Vision-Language Models (VLMs) on a variety of tasks has raised interest in their application to automated driving. However, for these models to be trusted in such a safety-critical domain, they must first possess robust perception capabilities, i.e., they must be capable of understanding a traffic scene, which can often be highly complex, with many things happening simultaneously. Moreover, since critical objects and agents in traffic scenes are often at long distances, we require systems with not only strong perception capabilities at close distances (up to 20 meters), but also at long (30+ meters) range. Therefore, it is important to evaluate the perception capabilities of these models in isolation from other skills like reasoning or advanced world knowledge. Distance-Annotated Traffic Perception Question Answering (DTPQA) is a Visual Question Answering (VQA) benchmark designed specifically for this purpose: it can be used to evaluate the perception systems of VLMs in traffic scenarios using trivial yet crucial questions relevant to driving decisions. It consists of two parts: a synthetic benchmark (DTP-Synthetic) created using a simulator, and a real-world benchmark (DTP-Real) built on top of existing images of real traffic scenes. Additionally, DTPQA includes distance annotations, i.e., how far the object in question is from the camera. More specifically, each DTPQA sample consists of (at least): (a) an image, (b) a question, (c) the ground truth answer, and (d) the distance of the object in question, enabling analysis of how VLM performance degrades with increasing object distance. In this article, we provide the dataset itself along with the Python scripts used to create it, which can be used to generate additional data of the same kind.",
    "published": "2025-11-17T14:12:22Z",
    "updated": "2025-11-17T14:12:22Z",
    "link": "http://arxiv.org/pdf/2511.13397v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Nikos Theodoridis",
      "Tim Brophy",
      "Reenu Mohandas",
      "Ganesh Sistu",
      "Fiachra Collins",
      "Anthony Scanlan",
      "Ciaran Eising"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13391v1",
    "title": "Finding Kissing Numbers with Game-theoretic Reinforcement Learning",
    "summary": "Since Isaac Newton first studied the Kissing Number Problem in 1694, determining the maximal number of non-overlapping spheres around a central sphere has remained a fundamental challenge. This problem represents the local analogue of Hilbert's 18th problem on sphere packing, bridging geometry, number theory, and information theory. Although significant progress has been made through lattices and codes, the irregularities of high-dimensional geometry and exponentially growing combinatorial complexity beyond 8 dimensions, which exceeds the complexity of Go game, limit the scalability of existing methods. Here we model this problem as a two-player matrix completion game and train the game-theoretic reinforcement learning system, PackingStar, to efficiently explore high-dimensional spaces. The matrix entries represent pairwise cosines of sphere center vectors; one player fills entries while another corrects suboptimal ones, jointly maximizing the matrix size, corresponding to the kissing number. This cooperative dynamics substantially improves sample quality, making the extremely large spaces tractable. PackingStar reproduces previous configurations and surpasses all human-known records from dimensions 25 to 31, with the configuration in 25 dimensions geometrically corresponding to the Leech lattice and suggesting possible optimality. It achieves the first breakthrough beyond rational structures from 1971 in 13 dimensions and discovers over 6000 new structures in 14 and other dimensions. These results demonstrate AI's power to explore high-dimensional spaces beyond human intuition and open new pathways for the Kissing Number Problem and broader geometry problems.",
    "published": "2025-11-17T14:02:00Z",
    "updated": "2025-11-17T14:02:00Z",
    "link": "http://arxiv.org/pdf/2511.13391v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Chengdong Ma",
      "Théo Tao Zhaowei",
      "Pengyu Li",
      "Minghao Liu",
      "Haojun Chen",
      "Zihao Mao",
      "Yuan Cheng",
      "Yuan Qi",
      "Yaodong Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13387v1",
    "title": "Generalized Denoising Diffusion Codebook Models (gDDCM): Tokenizing images using a pre-trained diffusion model",
    "summary": "Recently, the Denoising Diffusion Codebook Models (DDCM) was proposed. DDCM leverages the Denoising Diffusion Probabilistic Model (DDPM) and replaces the random noise in the backward process with noise sampled from specific sets according to a predefined rule, thereby enabling image compression. However, DDCM cannot be applied to methods other than DDPM. In this paper, we propose the generalized Denoising Diffusion Compression Model (gDDCM), which extends DDCM to mainstream diffusion models and their variants, including DDPM, Score-Based Models, Consistency Models, and Rectified Flow. We evaluate our method on CIFAR-10 and LSUN Bedroom datasets. Experimental results demonstrate that our approach successfully generalizes DDCM to the aforementioned models and achieves improved performance.",
    "published": "2025-11-17T13:58:49Z",
    "updated": "2025-11-17T13:58:49Z",
    "link": "http://arxiv.org/pdf/2511.13387v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Fei Kong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.19730v3",
    "title": "CamSAM2: Segment Anything Accurately in Camouflaged Videos",
    "summary": "Video camouflaged object segmentation (VCOS), aiming at segmenting camouflaged objects that seamlessly blend into their environment, is a fundamental vision task with various real-world applications. With the release of SAM2, video segmentation has witnessed significant progress. However, SAM2's capability of segmenting camouflaged videos is suboptimal, especially when given simple prompts such as point and box. To address the problem, we propose Camouflaged SAM2 (CamSAM2), which enhances SAM2's ability to handle camouflaged scenes without modifying SAM2's parameters. Specifically, we introduce a decamouflaged token to provide the flexibility of feature adjustment for VCOS. To make full use of fine-grained and high-resolution features from the current frame and previous frames, we propose implicit object-aware fusion (IOF) and explicit object-aware fusion (EOF) modules, respectively. Object prototype generation (OPG) is introduced to abstract and memorize object prototypes with informative details using high-quality features from previous frames. Extensive experiments are conducted to validate the effectiveness of our approach. While CamSAM2 only adds negligible learnable parameters to SAM2, it substantially outperforms SAM2 on three VCOS datasets, especially achieving 12.2 mDice gains with click prompt on MoCA-Mask and 19.6 mDice gains with mask prompt on SUN-SEG-Hard, with Hiera-T as the backbone. The code is available at https://github.com/zhoustan/CamSAM2.",
    "published": "2025-03-25T14:58:52Z",
    "updated": "2025-11-17T13:56:24Z",
    "link": "http://arxiv.org/pdf/2503.19730v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuli Zhou",
      "Yawei Li",
      "Yuqian Fu",
      "Luca Benini",
      "Ender Konukoglu",
      "Guolei Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.15979v2",
    "title": "Dream, Lift, Animate: From Single Images to Animatable Gaussian Avatars",
    "summary": "We introduce Dream, Lift, Animate (DLA), a novel framework that reconstructs animatable 3D human avatars from a single image. This is achieved by leveraging multi-view generation, 3D Gaussian lifting, and pose-aware UV-space mapping of 3D Gaussians. Given an image, we first dream plausible multi-views using a video diffusion model, capturing rich geometric and appearance details. These views are then lifted into unstructured 3D Gaussians. To enable animation, we propose a transformer-based encoder that models global spatial relationships and projects these Gaussians into a structured latent representation aligned with the UV space of a parametric body model. This latent code is decoded into UV-space Gaussians that can be animated via body-driven deformation and rendered conditioned on pose and viewpoint. By anchoring Gaussians to the UV manifold, our method ensures consistency during animation while preserving fine visual details. DLA enables real-time rendering and intuitive editing without requiring post-processing. Our method outperforms state-of-the-art approaches on the ActorsHQ and 4D-Dress datasets in both perceptual quality and photometric accuracy. By combining the generative strengths of video diffusion models with a pose-aware UV-space Gaussian mapping, DLA bridges the gap between unstructured 3D representations and high-fidelity, animation-ready avatars.",
    "published": "2025-07-21T18:20:09Z",
    "updated": "2025-11-17T13:55:41Z",
    "link": "http://arxiv.org/pdf/2507.15979v2.pdf",
    "category": [
      "cs.GR",
      "cs.AI"
    ],
    "authors": [
      "Marcel C. Bühler",
      "Ye Yuan",
      "Xueting Li",
      "Yangyi Huang",
      "Koki Nagano",
      "Umar Iqbal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13378v1",
    "title": "Moving Pictures of Thought: Extracting Visual Knowledge in Charles S. Peirce's Manuscripts with Vision-Language Models",
    "summary": "Diagrams are crucial yet underexplored tools in many disciplines, demonstrating the close connection between visual representation and scholarly reasoning. However, their iconic form poses obstacles to visual studies, intermedial analysis, and text-based digital workflows. In particular, Charles S. Peirce consistently advocated the use of diagrams as essential for reasoning and explanation. His manuscripts, often combining textual content with complex visual artifacts, provide a challenging case for studying documents involving heterogeneous materials. In this preliminary study, we investigate whether Visual Language Models (VLMs) can effectively help us identify and interpret such hybrid pages in context. First, we propose a workflow that (i) segments manuscript page layouts, (ii) reconnects each segment to IIIF-compliant annotations, and (iii) submits fragments containing diagrams to a VLM. In addition, by adopting Peirce's semiotic framework, we designed prompts to extract key knowledge about diagrams and produce concise captions. Finally, we integrated these captions into knowledge graphs, enabling structured representations of diagrammatic content within composite sources.",
    "published": "2025-11-17T13:52:23Z",
    "updated": "2025-11-17T13:52:23Z",
    "link": "http://arxiv.org/pdf/2511.13378v1.pdf",
    "category": [
      "cs.DL",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "authors": [
      "Carlo Teo Pedretti",
      "Davide Picca",
      "Dario Rodighiero"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13373v1",
    "title": "A Novel Hierarchical Integration Method for Efficient Model Merging in Medical LLMs",
    "summary": "Large Language Models (LLMs) face significant challenges in distributed healthcare, including consolidating specialized domain knowledge across institutions while maintaining privacy, reducing computational overhead, and preventing catastrophic forgetting during model updates.This paper presents a systematic evaluation of six parameter-space merging techniques applied to two architecturally compatible medical LLMs derived from the Mistral-7B base model. We introduce a novel hierarchical method that combines selective Optimal Transport (OT) alignment for attention layers with cosine similarity-weighted interpolation, designed to address permutation variance while minimizing computational overhead for edge deployment scenarios. Our study evaluates Task Arithmetic, Linear Averaging, DARE-TIES, DELLA, Breadcrumbs, and our Hierarchical approach across five medical benchmarks. Results demonstrate that architecturally compatible models benefit significantly from simple averaging methods, with Task Arithmetic achieving 45.80% accuracy on MedQA, outperforming complex pruning-based approaches. These findings offer critical insights for the deployment of distributed medical AI in resource-constrained IoT environments, where computational efficiency and model compatibility are paramount. Our work establishes that for architecturally compatible models, simple averaging provides a robust and computationally efficient baseline for knowledge consolidation, offering a pragmatic path forward for scalable medical AI systems.",
    "published": "2025-11-17T13:47:27Z",
    "updated": "2025-11-17T13:47:27Z",
    "link": "http://arxiv.org/pdf/2511.13373v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Prakrit Timilsina",
      "Anuj Nepal",
      "Rajan Kadel",
      "Robin Doss"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.07046v3",
    "title": "Learning Quantized Continuous Controllers for Integer Hardware",
    "summary": "Deploying continuous-control reinforcement learning policies on embedded hardware requires meeting tight latency and power budgets. Small FPGAs can deliver these, but only if costly floating point pipelines are avoided. We study quantization-aware training (QAT) of policies for integer inference and we present a learning-to-hardware pipeline that automatically selects low-bit policies and synthesizes them to an Artix-7 FPGA. Across five MuJoCo tasks, we obtain policy networks that are competitive with full precision (FP32) policies but require as few as 3 or even only 2 bits per weight, and per internal activation value, as long as input precision is chosen carefully. On the target hardware, the selected policies achieve inference latencies on the order of microseconds and consume microjoules per action, favorably comparing to a quantized reference. Last, we observe that the quantized policies exhibit increased input noise robustness compared to the floating-point baseline.",
    "published": "2025-11-10T12:39:14Z",
    "updated": "2025-11-17T13:47:04Z",
    "link": "http://arxiv.org/pdf/2511.07046v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Fabian Kresse",
      "Christoph H. Lampert"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13371v1",
    "title": "Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning",
    "summary": "How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.",
    "published": "2025-11-17T13:46:19Z",
    "updated": "2025-11-17T13:46:19Z",
    "link": "http://arxiv.org/pdf/2511.13371v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Caroline Baumgartner",
      "Eleanor Spens",
      "Neil Burgess",
      "Petru Manescu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11560v2",
    "title": "A Unified Convergence Analysis for Semi-Decentralized Learning: Sampled-to-Sampled vs. Sampled-to-All Communication",
    "summary": "In semi-decentralized federated learning, devices primarily rely on device-to-device communication but occasionally interact with a central server. Periodically, a sampled subset of devices uploads their local models to the server, which computes an aggregate model. The server can then either (i) share this aggregate model only with the sampled clients (sampled-to-sampled, S2S) or (ii) broadcast it to all clients (sampled-to-all, S2A). Despite their practical significance, a rigorous theoretical and empirical comparison of these two strategies remains absent. We address this gap by analyzing S2S and S2A within a unified convergence framework that accounts for key system parameters: sampling rate, server aggregation frequency, and network connectivity. Our results, both analytical and experimental, reveal distinct regimes where one strategy outperforms the other, depending primarily on the degree of data heterogeneity across devices. These insights lead to concrete design guidelines for practical semi-decentralized FL deployments.",
    "published": "2025-11-14T18:53:37Z",
    "updated": "2025-11-17T13:43:56Z",
    "link": "http://arxiv.org/pdf/2511.11560v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "authors": [
      "Angelo Rodio",
      "Giovanni Neglia",
      "Zheng Chen",
      "Erik G. Larsson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13368v1",
    "title": "Donors and Recipients: On Asymmetric Transfer Across Tasks and Languages with Parameter-Efficient Fine-Tuning",
    "summary": "Large language models (LLMs) perform strongly across tasks and languages, yet how improvements in one task or language affect other tasks and languages and their combinations remains poorly understood. We conduct a controlled PEFT/LoRA study across multiple open-weight LLM families and sizes, treating task and language as transfer axes while conditioning on model family and size; we fine-tune each model on a single task-language source and measure transfer as the percentage-point change versus its baseline score when evaluated on all other task-language target pairs. We decompose transfer into (i) Matched-Task (Cross-Language), (ii) Matched-Language (Cross-Task), and (iii) Cross-Task (Cross-Language) regimes. We uncover two consistent general patterns. First, a pronounced on-task vs. off-task asymmetry: Matched-Task (Cross-Language) transfer is reliably positive, whereas off-task transfer often incurs collateral degradation. Second, a stable donor-recipient structure across languages and tasks (hub donors vs. brittle recipients). We outline implications for risk-aware fine-tuning and model specialisation.",
    "published": "2025-11-17T13:41:31Z",
    "updated": "2025-11-17T13:41:31Z",
    "link": "http://arxiv.org/pdf/2511.13368v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Kajetan Dymkiewicz",
      "Ivan Vulic",
      "Helen Yannakoudakis",
      "Eilam Shapira",
      "Roi Reichart",
      "Anna Korhonen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.03294v2",
    "title": "NLP Methods May Actually Be Better Than Professors at Estimating Question Difficulty",
    "summary": "Estimating the difficulty of exam questions is essential for developing good exams, but professors are not always good at this task. We compare various Large Language Model-based methods with three professors in their ability to estimate what percentage of students will give correct answers on True/False exam questions in the areas of Neural Networks and Machine Learning. Our results show that the professors have limited ability to distinguish between easy and difficult questions and that they are outperformed by directly asking Gemini 2.5 to solve this task. Yet, we obtained even better results using uncertainties of the LLMs solving the questions in a supervised learning setting, using only 42 training samples. We conclude that supervised learning using LLM uncertainty can help professors better estimate the difficulty of exam questions, improving the quality of assessment.",
    "published": "2025-08-05T10:12:38Z",
    "updated": "2025-11-17T13:37:20Z",
    "link": "http://arxiv.org/pdf/2508.03294v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Leonidas Zotos",
      "Ivo Pascal de Jong",
      "Matias Valdenegro-Toro",
      "Andreea Ioana Sburlea",
      "Malvina Nissim",
      "Hedderik van Rijn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13365v1",
    "title": "InfoDecom: Decomposing Information for Defending against Privacy Leakage in Split Inference",
    "summary": "Split inference (SI) enables users to access deep learning (DL) services without directly transmitting raw data. However, recent studies reveal that data reconstruction attacks (DRAs) can recover the original inputs from the smashed data sent from the client to the server, leading to significant privacy leakage. While various defenses have been proposed, they often result in substantial utility degradation, particularly when the client-side model is shallow. We identify a key cause of this trade-off: existing defenses apply excessive perturbation to redundant information in the smashed data. To address this issue in computer vision tasks, we propose InfoDecom, a defense framework that first decomposes and removes redundant information and then injects noise calibrated to provide theoretically guaranteed privacy. Experiments demonstrate that InfoDecom achieves a superior utility-privacy trade-off compared to existing baselines. The code and the appendix are available at https://github.com/SASA-cloud/InfoDecom.",
    "published": "2025-11-17T13:36:40Z",
    "updated": "2025-11-17T13:36:40Z",
    "link": "http://arxiv.org/pdf/2511.13365v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "authors": [
      "Ruijun Deng",
      "Zhihui Lu",
      "Qiang Duan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13361v1",
    "title": "MedDCR: Learning to Design Agentic Workflows for Medical Coding",
    "summary": "Medical coding converts free-text clinical notes into standardized diagnostic and procedural codes, which are essential for billing, hospital operations, and medical research. Unlike ordinary text classification, it requires multi-step reasoning: extracting diagnostic concepts, applying guideline constraints, mapping to hierarchical codebooks, and ensuring cross-document consistency. Recent advances leverage agentic LLMs, but most rely on rigid, manually crafted workflows that fail to capture the nuance and variability of real-world documentation, leaving open the question of how to systematically learn effective workflows. We present MedDCR, a closed-loop framework that treats workflow design as a learning problem. A Designer proposes workflows, a Coder executes them, and a Reflector evaluates predictions and provides constructive feedback, while a memory archive preserves prior designs for reuse and iterative refinement. On benchmark datasets, MedDCR outperforms state-of-the-art baselines and produces interpretable, adaptable workflows that better reflect real coding practice, improving both the reliability and trustworthiness of automated systems.",
    "published": "2025-11-17T13:30:51Z",
    "updated": "2025-11-17T13:30:51Z",
    "link": "http://arxiv.org/pdf/2511.13361v1.pdf",
    "category": [
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Jiyang Zheng",
      "Islam Nassar",
      "Thanh Vu",
      "Xu Zhong",
      "Yang Lin",
      "Tongliang Liu",
      "Long Duong",
      "Yuan-Fang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20334v2",
    "title": "Lookahead Q-Cache: Achieving More Consistent KV Cache Eviction via Pseudo Query",
    "summary": "Large language models (LLMs) rely on key-value cache (KV cache) to accelerate decoding by reducing redundant computations. However, the KV cache memory usage grows substantially with longer text sequences, posing challenges for efficient deployment. Existing KV cache eviction methods prune tokens using prefilling-stage attention scores, causing inconsistency with actual inference queries, especially under tight memory budgets. In this paper, we propose Lookahead Q-Cache (LAQ), a novel eviction framework that generates low-cost pseudo lookahead queries to better approximate the true decoding-stage queries. By using these lookahead queries as the observation window for importance estimation, LAQ achieves more consistent and accurate KV cache eviction aligned with real inference scenarios. Experimental results on LongBench and Needle-in-a-Haystack benchmarks show that LAQ outperforms existing methods across various budget levels, achieving a 1 $\\sim$ 4 point improvement on LongBench under limited cache budget. Moreover, LAQ is complementary to existing approaches and can be flexibly combined to yield further improvements.",
    "published": "2025-05-24T10:34:38Z",
    "updated": "2025-11-17T13:29:25Z",
    "link": "http://arxiv.org/pdf/2505.20334v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yixuan Wang",
      "Shiyu Ji",
      "Yijun Liu",
      "Yuzhuang Xu",
      "Yang Xu",
      "Qingfu Zhu",
      "Wanxiang Che"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13359v1",
    "title": "Reasoning Shapes Alignment: Investigating Cultural Alignment in Large Reasoning Models with Cultural Norms",
    "summary": "The advanced reasoning capabilities of Large Reasoning Models enable them to thoroughly understand and apply safety policies through deliberate thought processes, thereby improving the models' safety. Beyond safety, these models must also be able to reflect the diverse range of human values across various cultures. This paper presents the Cultural Norm-based Cultural Alignment (CNCA) framework, which enables models to leverage their powerful reasoning ability to align with cultural norms. Specifically, we propose three methods to automatically mine cultural norms from limited survey data and explore ways to effectively utilize these norms for improving cultural alignment. Two alignment paradigms are examined: an in-context alignment method, where cultural norms are explicitly integrated into the user context, and a fine-tuning-based method, which internalizes norms through enhanced Chain-of-Thought training data. Comprehensive experiments demonstrate the effectiveness of these methods, highlighting that models with stronger reasoning capabilities benefit more from cultural norm mining and utilization. Our findings emphasize the potential for reasoning models to better reflect diverse human values through culturally informed alignment strategies.",
    "published": "2025-11-17T13:29:22Z",
    "updated": "2025-11-17T13:29:22Z",
    "link": "http://arxiv.org/pdf/2511.13359v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yuhang Wang",
      "Yanxu Zhu",
      "Jitao Sang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13356v1",
    "title": "Enhancing All-to-X Backdoor Attacks with Optimized Target Class Mapping",
    "summary": "Backdoor attacks pose severe threats to machine learning systems, prompting extensive research in this area. However, most existing work focuses on single-target All-to-One (A2O) attacks, overlooking the more complex All-to-X (A2X) attacks with multiple target classes, which are often assumed to have low attack success rates. In this paper, we first demonstrate that A2X attacks are robust against state-of-the-art defenses. We then propose a novel attack strategy that enhances the success rate of A2X attacks while maintaining robustness by optimizing grouping and target class assignment mechanisms. Our method improves the attack success rate by up to 28%, with average improvements of 6.7%, 16.4%, 14.1% on CIFAR10, CIFAR100, and Tiny-ImageNet, respectively. We anticipate that this study will raise awareness of A2X attacks and stimulate further research in this under-explored area. Our code is available at https://github.com/kazefjj/A2X-backdoor .",
    "published": "2025-11-17T13:22:44Z",
    "updated": "2025-11-17T13:22:44Z",
    "link": "http://arxiv.org/pdf/2511.13356v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Lei Wang",
      "Yulong Tian",
      "Hao Han",
      "Fengyuan Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.11947v2",
    "title": "A GPU-Accelerated RAG-Based Telegram Assistant for Supporting Parallel Processing Students",
    "summary": "This project addresses a critical pedagogical need: offering students continuous, on-demand academic assistance beyond conventional reception hours. I present a domain-specific Retrieval-Augmented Generation (RAG) system powered by a quantized Mistral-7B Instruct model and deployed as a Telegram bot. The assistant enhances learning by delivering real-time, personalized responses aligned with the \"Introduction to Parallel Processing\" course materials. GPU acceleration significantly improves inference latency, enabling practical deployment on consumer hardware. This approach demonstrates how consumer GPUs can enable affordable, private, and effective AI tutoring for HPC education.",
    "published": "2025-09-15T14:06:09Z",
    "updated": "2025-11-17T13:19:12Z",
    "link": "http://arxiv.org/pdf/2509.11947v2.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Guy Tel-Zur"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13353v1",
    "title": "Semi-Supervised Multi-Task Learning for Interpretable Quality As- sessment of Fundus Images",
    "summary": "Retinal image quality assessment (RIQA) supports computer-aided diagnosis of eye diseases. However, most tools classify only overall image quality, without indicating acquisition defects to guide recapture. This gap is mainly due to the high cost of detailed annotations. In this paper, we aim to mitigate this limitation by introducing a hybrid semi-supervised learning approach that combines manual labels for overall quality with pseudo-labels of quality details within a multi-task framework. Our objective is to obtain more interpretable RIQA models without requiring extensive manual labeling. Pseudo-labels are generated by a Teacher model trained on a small dataset and then used to fine-tune a pre-trained model in a multi-task setting. Using a ResNet-18 backbone, we show that these weak annotations improve quality assessment over single-task baselines (F1: 0.875 vs. 0.863 on EyeQ, and 0.778 vs. 0.763 on DeepDRiD), matching or surpassing existing methods. The multi-task model achieved performance statistically comparable to the Teacher for most detail prediction tasks (p > 0.05). In a newly annotated EyeQ subset released with this paper, our model performed similarly to experts, suggesting that pseudo-label noise aligns with expert variability. Our main finding is that the proposed semi-supervised approach not only improves overall quality assessment but also provides interpretable feedback on capture conditions (illumination, clarity, contrast). This enhances interpretability at no extra manual labeling cost and offers clinically actionable outputs to guide image recapture.",
    "published": "2025-11-17T13:17:42Z",
    "updated": "2025-11-17T13:17:42Z",
    "link": "http://arxiv.org/pdf/2511.13353v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Lucas Gabriel Telesco",
      "Danila Nejamkin",
      "Estefanía Mata",
      "Francisco Filizzola",
      "Kevin Wignall",
      "Lucía Franco Troilo",
      "María de los Angeles Cenoz",
      "Melissa Thompson",
      "Mercedes Leguía",
      "Ignacio Larrabide",
      "José Ignacio Orlando"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13351v1",
    "title": "Dual-LoRA and Quality-Enhanced Pseudo Replay for Multimodal Continual Food Learning",
    "summary": "Food analysis has become increasingly critical for health-related tasks such as personalized nutrition and chronic disease prevention. However, existing large multimodal models (LMMs) in food analysis suffer from catastrophic forgetting when learning new tasks, requiring costly retraining from scratch. To address this, we propose a novel continual learning framework for multimodal food learning, integrating a Dual-LoRA architecture with Quality-Enhanced Pseudo Replay. We introduce two complementary low-rank adapters for each task: a specialized LoRA that learns task-specific knowledge with orthogonal constraints to previous tasks' subspaces, and a cooperative LoRA that consolidates shared knowledge across tasks via pseudo replay. To improve the reliability of replay data, our Quality-Enhanced Pseudo Replay strategy leverages self-consistency and semantic similarity to reduce hallucinations in generated samples. Experiments on the comprehensive Uni-Food dataset show superior performance in mitigating forgetting, representing the first effective continual learning approach for complex food tasks.",
    "published": "2025-11-17T13:16:48Z",
    "updated": "2025-11-17T13:16:48Z",
    "link": "http://arxiv.org/pdf/2511.13351v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xinlan Wu",
      "Bin Zhu",
      "Feng Han",
      "Pengkun Jiao",
      "Jingjing Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13191v2",
    "title": "Emergence of Fixational and Saccadic Movements in a Multi-Level Recurrent Attention Model for Vision",
    "summary": "Inspired by foveal vision, hard attention models promise interpretability and parameter economy. However, existing models like the Recurrent Model of Visual Attention (RAM) and Deep Recurrent Attention Model (DRAM) failed to model the hierarchy of human vision system, that compromise on the visual exploration dynamics. As a result, they tend to produce attention that are either overly fixational or excessively saccadic, diverging from human eye movement behavior. In this paper, we propose a Multi-Level Recurrent Attention Model (MRAM), a novel hard attention framework that explicitly models the neural hierarchy of human visual processing. By decoupling the function of glimpse location generation and task execution in two recurrent layers, MRAM emergent a balanced behavior between fixation and saccadic movement. Our results show that MRAM not only achieves more human-like attention dynamics, but also consistently outperforms CNN, RAM and DRAM baselines on standard image classification benchmarks.",
    "published": "2025-05-19T14:48:36Z",
    "updated": "2025-11-17T13:11:41Z",
    "link": "http://arxiv.org/pdf/2505.13191v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Pengcheng Pan",
      "Yonekura Shogo",
      "Yasuo Kuniyoshi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13341v1",
    "title": "An LLM-based Quantitative Framework for Evaluating High-Stealthy Backdoor Risks in OSS Supply Chains",
    "summary": "In modern software development workflows, the open-source software supply chain contributes significantly to efficient and convenient engineering practices. With increasing system complexity, using open-source software as third-party dependencies has become a common practice. However, the lack of maintenance for underlying dependencies and insufficient community auditing create challenges in ensuring source code security and the legitimacy of repository maintainers, especially under high-stealthy backdoor attacks exemplified by the XZ-Util incident. To address these problems, we propose a fine-grained project evaluation framework for backdoor risk assessment in open-source software. The framework models stealthy backdoor attacks from the viewpoint of the attacker and defines targeted metrics for each attack stage. In addition, to overcome the limitations of static analysis in assessing the reliability of repository maintenance activities such as irregular committer privilege escalation and limited participation in reviews, the framework uses large language models (LLMs) to conduct semantic evaluation of code repositories without relying on manually crafted patterns. The framework is evaluated on sixty six high-priority packages in the Debian ecosystem. The experimental results indicate that the current open-source software supply chain is exposed to various security risks.",
    "published": "2025-11-17T13:10:36Z",
    "updated": "2025-11-17T13:10:36Z",
    "link": "http://arxiv.org/pdf/2511.13341v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Zihe Yan",
      "Kai Luo",
      "Haoyu Yang",
      "Yang Yu",
      "Zhuosheng Zhang",
      "Guancheng Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.02760v2",
    "title": "Hierarchical Generalized Category Discovery for Brain Tumor Classification in Digital Pathology",
    "summary": "Accurate brain tumor classification is critical for intra-operative decision making in neuro-oncological surgery. However, existing approaches are restricted to a fixed set of predefined classes and are therefore unable to capture patterns of tumor types not available during training. Unsupervised learning can extract general-purpose features, but it lacks the ability to incorporate prior knowledge from labelled data, and semi-supervised methods often assume that all potential classes are represented in the labelled data. Generalized Category Discovery (GCD) aims to bridge this gap by categorizing both known and unknown classes within unlabelled data. To reflect the hierarchical structure of brain tumor taxonomies, in this work, we introduce Hierarchical Generalized Category Discovery for Brain Tumor Classification (HGCD-BT), a novel approach that integrates hierarchical clustering with contrastive learning. Our method extends contrastive learning based GCD by incorporating a novel semi-supervised hierarchical clustering loss. We evaluate HGCD-BT on OpenSRH, a dataset of stimulated Raman histology brain tumor images, achieving a +28% improvement in accuracy over state-of-the-art GCD methods for patch-level classification, particularly in identifying previously unseen tumor categories. Furthermore, we demonstrate the generalizability of HGCD-BT on slide-level classification of hematoxylin and eosin stained whole-slide images from the Digital Brain Tumor Atlas, confirming its utility across imaging modalities.",
    "published": "2025-10-03T06:46:55Z",
    "updated": "2025-11-17T13:07:53Z",
    "link": "http://arxiv.org/pdf/2510.02760v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Matthias Perkonigg",
      "Patrick Rockenschaub",
      "Georg Göbel",
      "Adelheid Wöhrer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13335v1",
    "title": "AHaSIS: Shared Task on Sentiment Analysis for Arabic Dialects",
    "summary": "The hospitality industry in the Arab world increasingly relies on customer feedback to shape services, driving the need for advanced Arabic sentiment analysis tools. To address this challenge, the Sentiment Analysis on Arabic Dialects in the Hospitality Domain shared task focuses on Sentiment Detection in Arabic Dialects. This task leverages a multi-dialect, manually curated dataset derived from hotel reviews originally written in Modern Standard Arabic (MSA) and translated into Saudi and Moroccan (Darija) dialects. The dataset consists of 538 sentiment-balanced reviews spanning positive, neutral, and negative categories. Translations were validated by native speakers to ensure dialectal accuracy and sentiment preservation. This resource supports the development of dialect-aware NLP systems for real-world applications in customer experience analysis. More than 40 teams have registered for the shared task, with 12 submitting systems during the evaluation phase. The top-performing system achieved an F1 score of 0.81, demonstrating the feasibility and ongoing challenges of sentiment analysis across Arabic dialects.",
    "published": "2025-11-17T13:06:55Z",
    "updated": "2025-11-17T13:06:55Z",
    "link": "http://arxiv.org/pdf/2511.13335v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Maram Alharbi",
      "Salmane Chafik",
      "Saad Ezzini",
      "Ruslan Mitkov",
      "Tharindu Ranasinghe",
      "Hansi Hettiarachchi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13333v1",
    "title": "AutoMalDesc: Large-Scale Script Analysis for Cyber Threat Research",
    "summary": "Generating thorough natural language explanations for threat detections remains an open problem in cybersecurity research, despite significant advances in automated malware detection systems. In this work, we present AutoMalDesc, an automated static analysis summarization framework that, following initial training on a small set of expert-curated examples, operates independently at scale. This approach leverages an iterative self-paced learning pipeline to progressively enhance output quality through synthetic data generation and validation cycles, eliminating the need for extensive manual data annotation. Evaluation across 3,600 diverse samples in five scripting languages demonstrates statistically significant improvements between iterations, showing consistent gains in both summary quality and classification accuracy. Our comprehensive validation approach combines quantitative metrics based on established malware labels with qualitative assessment from both human experts and LLM-based judges, confirming both technical precision and linguistic coherence of generated summaries. To facilitate reproducibility and advance research in this domain, we publish our complete dataset of more than 100K script samples, including annotated seed (0.9K) and test (3.6K) datasets, along with our methodology and evaluation framework.",
    "published": "2025-11-17T13:05:25Z",
    "updated": "2025-11-17T13:05:25Z",
    "link": "http://arxiv.org/pdf/2511.13333v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Alexandru-Mihai Apostu",
      "Andrei Preda",
      "Alexandra Daniela Damir",
      "Diana Bolocan",
      "Radu Tudor Ionescu",
      "Ioana Croitoru",
      "Mihaela Gaman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11030v2",
    "title": "Algorithms Trained on Normal Chest X-rays Can Predict Health Insurance Types",
    "summary": "Artificial intelligence is revealing what medicine never intended to encode. Deep vision models, trained on chest X-rays, can now detect not only disease but also invisible traces of social inequality. In this study, we show that state-of-the-art architectures (DenseNet121, SwinV2-B, MedMamba) can predict a patient's health insurance type, a strong proxy for socioeconomic status, from normal chest X-rays with significant accuracy (AUC around 0.67 on MIMIC-CXR-JPG, 0.68 on CheXpert). The signal persists even when age, race, and sex are controlled for, and remains detectable when the model is trained exclusively on a single racial group. Patch-based occlusion reveals that the signal is diffuse rather than localized, embedded in the upper and mid-thoracic regions. This suggests that deep networks may be internalizing subtle traces of clinical environments, equipment differences, or care pathways; learning socioeconomic segregation itself. These findings challenge the assumption that medical images are neutral biological data. By uncovering how models perceive and exploit these hidden social signatures, this work reframes fairness in medical AI: the goal is no longer only to balance datasets or adjust thresholds, but to interrogate and disentangle the social fingerprints embedded in clinical data itself.",
    "published": "2025-11-14T07:34:29Z",
    "updated": "2025-11-17T13:02:28Z",
    "link": "http://arxiv.org/pdf/2511.11030v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Chi-Yu Chen",
      "Rawan Abulibdeh",
      "Arash Asgari",
      "Leo Anthony Celi",
      "Deirdre Goode",
      "Hassan Hamidi",
      "Laleh Seyyed-Kalantari",
      "Ned McCague",
      "Thomas Sounack",
      "Po-Chih Kuo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13322v1",
    "title": "Explainable RL Policies by Distilling to Locally-Specialized Linear Policies with Voronoi State Partitioning",
    "summary": "Deep Reinforcement Learning is one of the state-of-the-art methods for producing near-optimal system controllers. However, deep RL algorithms train a deep neural network, that lacks transparency, which poses challenges when the controller has to meet regulations, or foster trust. To alleviate this, one could transfer the learned behaviour into a model that is human-readable by design using knowledge distilla- tion. Often this is done with a single model which mimics the original model on average but could struggle in more dynamic situations. A key challenge is that this simpler model should have the right balance be- tween flexibility and complexity or right balance between balance bias and accuracy. We propose a new model-agnostic method to divide the state space into regions where a simplified, human-understandable model can operate in. In this paper, we use Voronoi partitioning to find regions where linear models can achieve similar performance to the original con- troller. We evaluate our approach on a gridworld environment and a classic control task. We observe that our proposed distillation to locally- specialized linear models produces policies that are explainable and show that the distillation matches or even slightly outperforms the black-box policy they are distilled from.",
    "published": "2025-11-17T12:58:38Z",
    "updated": "2025-11-17T12:58:38Z",
    "link": "http://arxiv.org/pdf/2511.13322v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Senne Deproost",
      "Dennis Steckelmacher",
      "Ann Nowé"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13319v1",
    "title": "Whistledown: Combining User-Level Privacy with Conversational Coherence in LLMs",
    "summary": "Users increasingly rely on large language models (LLMs) for personal, emotionally charged, and socially sensitive conversations. However, prompts sent to cloud-hosted models can contain personally identifiable information (PII) that users do not want logged, retained, or leaked. We observe this to be especially acute when users discuss friends, coworkers, or adversaries, i.e., when they spill the tea. Enterprises face the same challenge when they want to use LLMs for internal communication and decision-making.\n  In this whitepaper, we present Whistledown, a best-effort privacy layer that modifies prompts before they are sent to the LLM. Whistledown combines pseudonymization and $ε$-local differential privacy ($ε$-LDP) with transformation caching to provide best-effort privacy protection without sacrificing conversational utility. Whistledown is designed to have low compute and memory overhead, allowing it to be deployed directly on a client's device in the case of individual users. For enterprise users, Whistledown is deployed centrally within a zero-trust gateway that runs on an enterprise's trusted infrastructure. Whistledown requires no changes to the existing APIs of popular LLM providers.",
    "published": "2025-11-17T12:56:33Z",
    "updated": "2025-11-17T12:56:33Z",
    "link": "http://arxiv.org/pdf/2511.13319v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Chelsea McMurray",
      "Hayder Tirmazi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13315v1",
    "title": "Computer Vision based group activity detection and action spotting",
    "summary": "Group activity detection in multi-person scenes is challenging due to complex human interactions, occlusions, and variations in appearance over time. This work presents a computer vision based framework for group activity recognition and action spotting using a combination of deep learning models and graph based relational reasoning. The system first applies Mask R-CNN to obtain accurate actor localization through bounding boxes and instance masks. Multiple backbone networks, including Inception V3, MobileNet, and VGG16, are used to extract feature maps, and RoIAlign is applied to preserve spatial alignment when generating actor specific features. The mask information is then fused with the feature maps to obtain refined masked feature representations for each actor. To model interactions between individuals, we construct Actor Relation Graphs that encode appearance similarity and positional relations using methods such as normalized cross correlation, sum of absolute differences, and dot product. Graph Convolutional Networks operate on these graphs to reason about relationships and predict both individual actions and group level activities. Experiments on the Collective Activity dataset demonstrate that the combination of mask based feature refinement, robust similarity search, and graph neural network reasoning leads to improved recognition performance across both crowded and non crowded scenarios. This approach highlights the potential of integrating segmentation, feature extraction, and relational graph reasoning for complex video understanding tasks.",
    "published": "2025-11-17T12:52:22Z",
    "updated": "2025-11-17T12:52:22Z",
    "link": "http://arxiv.org/pdf/2511.13315v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Narthana Sivalingam",
      "Santhirarajah Sivasthigan",
      "Thamayanthi Mahendranathan",
      "G. M. R. I. Godaliyadda",
      "M. P. B. Ekanayake",
      "H. M. V. R. Herath"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13312v1",
    "title": "EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation",
    "summary": "Acting in human environments is a crucial capability for general-purpose robots, necessitating a robust understanding of natural language and its application to physical tasks. This paper seeks to harness the capabilities of diffusion models within a visuomotor policy framework that merges visual and textual inputs to generate precise robotic trajectories. By employing reference demonstrations during training, the model learns to execute manipulation tasks specified through textual commands within the robot's immediate environment. The proposed research aims to extend an existing model by leveraging improved embeddings, and adapting techniques from diffusion models for image generation. We evaluate our methods on the CALVIN dataset, proving enhanced performance on various manipulation tasks and an increased long-horizon success rate when multiple tasks are executed in sequence. Our approach reinforces the usefulness of diffusion models and contributes towards general multitask manipulation.",
    "published": "2025-11-17T12:47:18Z",
    "updated": "2025-11-17T12:47:18Z",
    "link": "http://arxiv.org/pdf/2511.13312v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jonas Bode",
      "Raphael Memmesheimer",
      "Sven Behnke"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13306v1",
    "title": "DAP: A Discrete-token Autoregressive Planner for Autonomous Driving",
    "summary": "Gaining sustainable performance improvement with scaling data and model budget remains a pivotal yet unresolved challenge in autonomous driving. While autoregressive models exhibited promising data-scaling efficiency in planning tasks, predicting ego trajectories alone suffers sparse supervision and weakly constrains how scene evolution should shape ego motion. Therefore, we introduce DAP, a discrete-token autoregressive planner that jointly forecasts BEV semantics and ego trajectories, thereby enforcing comprehensive representation learning and allowing predicted dynamics to directly condition ego motion. In addition, we incorporate a reinforcement-learning-based fine-tuning, which preserves supervised behavior cloning priors while injecting reward-guided improvements. Despite a compact 160M parameter budget, DAP achieves state-of-the-art performance on open-loop metrics and delivers competitive closed-loop results on the NAVSIM benchmark. Overall, the fully discrete-token autoregressive formulation operating on both rasterized BEV and ego actions provides a compact yet scalable planning paradigm for autonomous driving.",
    "published": "2025-11-17T12:31:33Z",
    "updated": "2025-11-17T12:31:33Z",
    "link": "http://arxiv.org/pdf/2511.13306v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Bowen Ye",
      "Bin Zhang",
      "Hang Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.02962v5",
    "title": "RAG-R1: Incentivizing the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism",
    "summary": "Large Language Models (LLMs), despite their remarkable capabilities, are prone to generating hallucinated or outdated content due to their static internal knowledge. While Retrieval-Augmented Generation (RAG) integrated with Reinforcement Learning (RL) offers a solution, these methods are fundamentally constrained by a single-query mode, leading to prohibitive latency and inherent brittleness. To overcome these limitations, we introduce RAG-R1, a novel two-stage training framework centered around multi-query parallelism. Our framework enables LLMs to adaptively leverage internal and external knowledge during the reasoning process while transitioning from the single-query mode to multi-query parallelism. This architectural shift bolsters reasoning robustness while significantly reducing inference latency. Extensive experiments on seven question-answering benchmarks confirm the superiority of our method, which outperforms the strongest baseline by up to 13.7% and decreases inference time by 11.1%.",
    "published": "2025-06-30T09:02:45Z",
    "updated": "2025-11-17T12:23:38Z",
    "link": "http://arxiv.org/pdf/2507.02962v5.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Zhiwen Tan",
      "Jiaming Huang",
      "Qintong Wu",
      "Hongxuan Zhang",
      "Chenyi Zhuang",
      "Jinjie Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13293v1",
    "title": "Grounded by Experience: Generative Healthcare Prediction Augmented with Hierarchical Agentic Retrieval",
    "summary": "Accurate healthcare prediction is critical for improving patient outcomes and reducing operational costs. Bolstered by growing reasoning capabilities, large language models (LLMs) offer a promising path to enhance healthcare predictions by drawing on their rich parametric knowledge. However, LLMs are prone to factual inaccuracies due to limitations in the reliability and coverage of their embedded knowledge. While retrieval-augmented generation (RAG) frameworks, such as GraphRAG and its variants, have been proposed to mitigate these issues by incorporating external knowledge, they face two key challenges in the healthcare scenario: (1) identifying the clinical necessity to activate the retrieval mechanism, and (2) achieving synergy between the retriever and the generator to craft contextually appropriate retrievals. To address these challenges, we propose GHAR, a \\underline{g}enerative \\underline{h}ierarchical \\underline{a}gentic \\underline{R}AG framework that simultaneously resolves when to retrieve and how to optimize the collaboration between submodules in healthcare. Specifically, for the first challenge, we design a dual-agent architecture comprising Agent-Top and Agent-Low. Agent-Top acts as the primary physician, iteratively deciding whether to rely on parametric knowledge or to initiate retrieval, while Agent-Low acts as the consulting service, summarising all task-relevant knowledge once retrieval was triggered. To tackle the second challenge, we innovatively unify the optimization of both agents within a formal Markov Decision Process, designing diverse rewards to align their shared goal of accurate prediction while preserving their distinct roles. Extensive experiments on three benchmark datasets across three popular tasks demonstrate our superiority over state-of-the-art baselines, highlighting the potential of hierarchical agentic RAG in advancing healthcare systems.",
    "published": "2025-11-17T12:15:46Z",
    "updated": "2025-11-17T12:15:46Z",
    "link": "http://arxiv.org/pdf/2511.13293v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Chuang Zhao",
      "Hui Tang",
      "Hongke Zhao",
      "Xiaofang Zhou",
      "Xiaomeng Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13290v1",
    "title": "Dropouts in Confidence: Moral Uncertainty in Human-LLM Alignment",
    "summary": "Humans display significant uncertainty when confronted with moral dilemmas, yet the extent of such uncertainty in machines and AI agents remains underexplored. Recent studies have confirmed the overly confident tendencies of machine-generated responses, particularly in large language models (LLMs). As these systems are increasingly embedded in ethical decision-making scenarios, it is important to understand their moral reasoning and the inherent uncertainties in building reliable AI systems. This work examines how uncertainty influences moral decisions in the classical trolley problem, analyzing responses from 32 open-source models and 9 distinct moral dimensions. We first find that variance in model confidence is greater across models than within moral dimensions, suggesting that moral uncertainty is predominantly shaped by model architecture and training method. To quantify uncertainty, we measure binary entropy as a linear combination of total entropy, conditional entropy, and mutual information. To examine its effects, we introduce stochasticity into models via \"dropout\" at inference time. Our findings show that our mechanism increases total entropy, mainly through a rise in mutual information, while conditional entropy remains largely unchanged. Moreover, this mechanism significantly improves human-LLM moral alignment, with correlations in mutual information and alignment score shifts. Our results highlight the potential to better align model-generated decisions and human preferences by deliberately modulating uncertainty and reducing LLMs' confidence in morally complex scenarios.",
    "published": "2025-11-17T12:13:15Z",
    "updated": "2025-11-17T12:13:15Z",
    "link": "http://arxiv.org/pdf/2511.13290v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "authors": [
      "Jea Kwon",
      "Luiz Felipe Vecchietti",
      "Sungwon Park",
      "Meeyoung Cha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25506v3",
    "title": "Reflections on the Reproducibility of Commercial LLM Performance in Empirical Software Engineering Studies",
    "summary": "Large Language Models have gained remarkable interest in industry and academia. The increasing interest in LLMs in academia is also reflected in the number of publications on this topic over the last years. For instance, alone 78 of the around 425 publications at ICSE 2024 performed experiments with LLMs. Conducting empirical studies with LLMs remains challenging and raises questions on how to achieve reproducible results, for both researchers and practitioners. One important step towards excelling in empirical research on LLM and their application is to first understand to what extent current research results are eventually reproducible and what factors may impede reproducibility. This investigation is within the scope of our work. We contribute an analysis of the reproducibility of LLM-centric studies, provide insights into the factors impeding reproducibility, and discuss suggestions on how to improve the current state. In particular, we studied the 85 articles describing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 85 articles, 18 provided research artefacts and used OpenAI models. We attempted to replicate those 18 studies. Of the 18 studies, only five were sufficiently complete and executable. For none of the five studies, we were able to fully reproduce the results. Two studies seemed to be partially reproducible, and three studies did not seem to be reproducible. Our results highlight not only the need for stricter research artefact evaluations but also for more robust study designs to ensure the reproducible value of future publications.",
    "published": "2025-10-29T13:31:32Z",
    "updated": "2025-11-17T12:06:48Z",
    "link": "http://arxiv.org/pdf/2510.25506v3.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Florian Angermeir",
      "Maximilian Amougou",
      "Mark Kreitz",
      "Andreas Bauer",
      "Matthias Linhuber",
      "Davide Fucci",
      "Fabiola Moyón C.",
      "Daniel Mendez",
      "Tony Gorschek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13288v1",
    "title": "Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO",
    "summary": "Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions underlying for different agents. Therefore, training multi-agent systems with distinct LLMs should be the next step to solve. However, this approach introduces optimization challenges. For example, agents operate at different frequencies, rollouts involve varying sub-agent invocations, and agents are often deployed across separate servers, disrupting end-to-end gradient flow. To address these issues, we propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical Multi-agent systems with a main agent (planner) and multiple sub-agents (multi-turn tool executors). M-GRPO computes group-relative advantages for both main and sub-agents, maintaining hierarchical credit assignment. It also introduces a trajectory-alignment scheme that generates fixed-size batches despite variable sub-agent invocations. We deploy a decoupled training pipeline in which agents run on separate servers and exchange minimal statistics via a shared store. This enables scalable training without cross-server backpropagation. In experiments on real-world benchmarks (e.g., GAIA, XBench-DeepSearch, and WebWalkerQA), M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency. These results show that aligning heterogeneous trajectories and decoupling optimization across specialized agents enhances tool-augmented reasoning tasks.",
    "published": "2025-11-17T12:06:30Z",
    "updated": "2025-11-17T12:06:30Z",
    "link": "http://arxiv.org/pdf/2511.13288v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Haoyang Hong",
      "Jiajun Yin",
      "Yuan Wang",
      "Jingnan Liu",
      "Zhe Chen",
      "Ailing Yu",
      "Ji Li",
      "Zhiling Ye",
      "Hansong Xiao",
      "Yefei Chen",
      "Hualei Zhou",
      "Yun Yue",
      "Minghui Yang",
      "Chunxiao Guo",
      "Junwei Liu",
      "Peng Wei",
      "Jinjie Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13274v1",
    "title": "KForge: Program Synthesis for Diverse AI Hardware Accelerators",
    "summary": "GPU kernels are critical for ML performance but difficult to optimize across diverse accelerators. We present KForge, a platform-agnostic framework built on two collaborative LLM-based agents: a generation agent that produces and iteratively refines programs through compilation and correctness feedback, and a performance analysis agent that interprets profiling data to guide optimization. This agent-based architecture requires only a single-shot example to target new platforms.\n  We make three key contributions: (1) introducing an iterative refinement system where the generation agent and performance analysis agent collaborate through functional and optimization passes, interpreting diverse profiling data (from programmatic APIs to GUI-based tools) to generate actionable recommendations that guide program synthesis for arbitrary accelerators; (2) demonstrating that the generation agent effectively leverages cross-platform knowledge transfer, where a reference implementation from one architecture substantially improves generation quality for different hardware targets; and (3) validating the platform-agnostic nature of our approach by demonstrating effective program synthesis across fundamentally different parallel computing platforms: NVIDIA CUDA and Apple Metal.",
    "published": "2025-11-17T11:46:43Z",
    "updated": "2025-11-17T11:46:43Z",
    "link": "http://arxiv.org/pdf/2511.13274v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.PF",
      "cs.SE"
    ],
    "authors": [
      "Taras Sereda",
      "Tom St. John",
      "Burak Bartan",
      "Natalie Serrino",
      "Sachin Katti",
      "Zain Asgar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13273v1",
    "title": "Spatial Blind Spot: Auditory Motion Perception Deficits in Audio LLMs",
    "summary": "Large Audio-Language Models (LALMs) have recently shown impressive progress in speech recognition, audio captioning, and auditory question answering. Yet, whether these models can perceive spatial dynamics, particularly the motion of sound sources, remains unclear. In this work, we uncover a systematic motion perception deficit in current ALLMs. To investigate this issue, we introduce AMPBench, the first benchmark explicitly designed to evaluate auditory motion understanding. AMPBench introduces a controlled question-answering benchmark designed to evaluate whether Audio-Language Models (LALMs) can infer the direction and trajectory of moving sound sources from binaural audio. Comprehensive quantitative and qualitative analyses reveal that current models struggle to reliably recognize motion cues or distinguish directional patterns. The average accuracy remains below 50%, underscoring a fundamental limitation in auditory spatial reasoning. Our study highlights a fundamental gap between human and model auditory spatial reasoning, providing both a diagnostic tool and new insight for enhancing spatial cognition in future Audio-Language Models.",
    "published": "2025-11-17T11:45:41Z",
    "updated": "2025-11-17T11:45:41Z",
    "link": "http://arxiv.org/pdf/2511.13273v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI"
    ],
    "authors": [
      "Zhe Sun",
      "Yujun Cai",
      "Jiayu Yao",
      "Yiwei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13271v1",
    "title": "Examining the Usage of Generative AI Models in Student Learning Activities for Software Programming",
    "summary": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, intermediate) to examine how students interact with ChatGPT while solving programming tasks. We analyzed task performance, conceptual understanding, and interaction behaviors. Our findings reveal that generating complete solutions with GenAI significantly improves task performance, especially for beginners, but does not consistently result in knowledge gains. Importantly, usage strategies differ by experience: beginners tend to rely heavily on GenAI toward task completion often without knowledge gain in the process, while intermediates adopt more selective approaches. We find that both over-reliance and minimal use result in weaker knowledge gains overall. Based on our results, we call on students and educators to adopt GenAI as a learning rather than a problem solving tool. Our study highlights the urgent need for guidance when integrating GenAI into programming education to foster deeper understanding.",
    "published": "2025-11-17T11:42:24Z",
    "updated": "2025-11-17T11:42:24Z",
    "link": "http://arxiv.org/pdf/2511.13271v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Rufeng Chen",
      "Shuaishuai Jiang",
      "Jiyun Shen",
      "AJung Moon",
      "Lili Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.12845v2",
    "title": "CAMAR: Continuous Actions Multi-Agent Routing",
    "summary": "Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving cooperative and competitive decision-making problems. While many MARL benchmarks have been proposed, few combine continuous state and action spaces with challenging coordination and planning tasks. We introduce CAMAR, a new MARL benchmark designed explicitly for multi-agent pathfinding in environments with continuous actions. CAMAR supports cooperative and competitive interactions between agents and runs efficiently at up to 100,000 environment steps per second. We also propose a three-tier evaluation protocol to better track algorithmic progress and enable deeper analysis of performance. In addition, CAMAR allows the integration of classical planning methods such as RRT and RRT* into MARL pipelines. We use them as standalone baselines and combine RRT* with popular MARL algorithms to create hybrid approaches. We provide a suite of test scenarios and benchmarking tools to ensure reproducibility and fair comparison. Experiments show that CAMAR presents a challenging and realistic testbed for the MARL community.",
    "published": "2025-08-18T11:32:26Z",
    "updated": "2025-11-17T11:37:40Z",
    "link": "http://arxiv.org/pdf/2508.12845v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      "Artem Pshenitsyn",
      "Aleksandr Panov",
      "Alexey Skrynnik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.13958v2",
    "title": "Toward Explainable Offline RL: Analyzing Representations in Intrinsically Motivated Decision Transformers",
    "summary": "Elastic Decision Transformers (EDTs) have proved to be particularly successful in offline reinforcement learning, offering a flexible framework that unifies sequence modeling with decision-making under uncertainty. Recent research has shown that incorporating intrinsic motivation mechanisms into EDTs improves performance across exploration tasks, yet the representational mechanisms underlying these improvements remain unexplored. In this paper, we introduce a systematic post-hoc explainability framework to analyze how intrinsic motivation shapes learned embeddings in EDTs. Through statistical analysis of embedding properties (including covariance structure, vector magnitudes, and orthogonality), we reveal that different intrinsic motivation variants create fundamentally different representational structures. Our analysis demonstrates environment-specific correlation patterns between embedding metrics and performance that explain why intrinsic motivation improves policy learning. These findings show that intrinsic motivation operates beyond simple exploration bonuses, acting as a representational prior that shapes embedding geometry in biologically plausible ways, creating environment-specific organizational structures that facilitate better decision-making.",
    "published": "2025-06-16T20:01:24Z",
    "updated": "2025-11-17T11:33:08Z",
    "link": "http://arxiv.org/pdf/2506.13958v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Leonardo Guiducci",
      "Antonio Rizzo",
      "Giovanna Maria Dimitri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13259v1",
    "title": "GeoX-Bench: Benchmarking Cross-View Geo-Localization and Pose Estimation Capabilities of Large Multimodal Models",
    "summary": "Large multimodal models (LMMs) have demonstrated remarkable capabilities across a wide range of tasks, however their knowledge and abilities in the cross-view geo-localization and pose estimation domains remain unexplored, despite potential benefits for navigation, autonomous driving, outdoor robotics, \\textit{etc}. To bridge this gap, we introduce \\textbf{GeoX-Bench}, a comprehensive \\underline{Bench}mark designed to explore and evaluate the capabilities of LMMs in \\underline{cross}-view \\underline{Geo}-localization and pose estimation. Specifically, GeoX-Bench contains 10,859 panoramic-satellite image pairs spanning 128 cities in 49 countries, along with corresponding 755,976 question-answering (QA) pairs. Among these, 42,900 QA pairs are designated for benchmarking, while the remaining are intended to enhance the capabilities of LMMs. Based on GeoX-Bench, we evaluate the capabilities of 25 state-of-the-art LMMs on cross-view geo-localization and pose estimation tasks, and further explore the empowered capabilities of instruction-tuning. Our benchmark demonstrate that while current LMMs achieve impressive performance in geo-localization tasks, their effectiveness declines significantly on the more complex pose estimation tasks, highlighting a critical area for future improvement, and instruction-tuning LMMs on the training data of GeoX-Bench can significantly improve the cross-view geo-sense abilities. The GeoX-Bench is available at \\textcolor{magenta}{https://github.com/IntMeGroup/GeoX-Bench}.",
    "published": "2025-11-17T11:19:07Z",
    "updated": "2025-11-17T11:19:07Z",
    "link": "http://arxiv.org/pdf/2511.13259v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yushuo Zheng",
      "Jiangyong Ying",
      "Huiyu Duan",
      "Chunyi Li",
      "Zicheng Zhang",
      "Jing Liu",
      "Xiaohong Liu",
      "Guangtao Zhai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.20630v2",
    "title": "TransPrune: Token Transition Pruning for Efficient Large Vision-Language Model",
    "summary": "Large Vision-Language Models (LVLMs) have advanced multimodal learning but face high computational costs due to the large number of visual tokens, motivating token pruning to improve inference efficiency. The key challenge lies in identifying which tokens are truly important. Most existing approaches rely on attention-based criteria to estimate token importance. However, they inherently suffer from certain limitations, such as positional bias. In this work, we explore a new perspective on token importance based on token transitions in LVLMs. We observe that the transition of token representations provides a meaningful signal of semantic information. Based on this insight, we propose TransPrune, a training-free and efficient token pruning method. Specifically, TransPrune progressively prunes tokens by assessing their importance through a combination of Token Transition Variation (TTV)-which measures changes in both the magnitude and direction of token representations-and Instruction-Guided Attention (IGA), which measures how strongly the instruction attends to image tokens via attention. Extensive experiments demonstrate that TransPrune achieves comparable multimodal performance to original LVLMs, such as LLaVA-v1.5 and LLaVA-Next, across eight benchmarks, while reducing inference TFLOPs by more than half. Moreover, TTV alone can serve as an effective criterion without relying on attention, achieving performance comparable to attention-based methods. The code will be made publicly available upon acceptance of the paper at https://github.com/liaolea/TransPrune.",
    "published": "2025-07-28T08:44:58Z",
    "updated": "2025-11-17T11:15:25Z",
    "link": "http://arxiv.org/pdf/2507.20630v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ao Li",
      "Yuxiang Duan",
      "Jinghui Zhang",
      "Congbo Ma",
      "Yutong Xie",
      "Gustavo Carneiro",
      "Mohammad Yaqub",
      "Hu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13245v1",
    "title": "Proceedings Seventh International Workshop on Formal Methods for Autonomous Systems",
    "summary": "This EPTCS volume contains the papers from the Seventh International Workshop on Formal Methods for Autonomous Systems (FMAS 2025), which was held between the 17th and 19th of November 2025. The goal of the FMAS workshop series is to bring together leading researchers who are using formal methods to tackle the unique challenges that autonomous systems present, so that they can publish and discuss their work with a growing community of researchers. FMAS 2025 was co-located with the 20th International Conference on integrated Formal Methods (iFM'25), hosted by Inria Paris, France at the Inria Paris Center. \n  In total, FMAS 2025 received 16 submissions from researchers at institutions in: Canada, China, France, Germany, Ireland, Italy, Japan, the Netherlands, Portugal, Sweden, the United States of America, and the United Kingdom. Though we received fewer submissions than last year, we are encouraged to see the submissions being sent from a wide range of countries. Submissions come from both past and new FMAS authors, which shows us that the existing community appreciates the network that FMAS has built over the past 7 years, while new authors also show the FMAS community's great potential of growth.",
    "published": "2025-11-17T11:07:57Z",
    "updated": "2025-11-17T11:07:57Z",
    "link": "http://arxiv.org/pdf/2511.13245v1.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Matt Luckcuck",
      "Maike Schwammberger",
      "Mengwei Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13244v1",
    "title": "Seek and You Shall Fold",
    "summary": "Accurate protein structures are essential for understanding biological function, yet incorporating experimental data into protein generative models remains a major challenge. Most predictors of experimental observables are non-differentiable, making them incompatible with gradient-based conditional sampling. This is especially limiting in nuclear magnetic resonance, where rich data such as chemical shifts are hard to directly integrate into generative modeling. We introduce a framework for non-differentiable guidance of protein generative models, coupling a continuous diffusion-based generator with any black-box objective via a tailored genetic algorithm. We demonstrate its effectiveness across three modalities: pairwise distance constraints, nuclear Overhauser effect restraints, and for the first time chemical shifts. These results establish chemical shift guided structure generation as feasible, expose key weaknesses in current predictors, and showcase a general strategy for incorporating diverse experimental signals. Our work points toward automated, data-conditioned protein modeling beyond the limits of differentiability.",
    "published": "2025-11-17T11:07:49Z",
    "updated": "2025-11-17T11:07:49Z",
    "link": "http://arxiv.org/pdf/2511.13244v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Nadav Bojan Sellam",
      "Meital Bojan",
      "Paul Schanda",
      "Alex Bronstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13243v1",
    "title": "Uncovering and Mitigating Transient Blindness in Multimodal Model Editing",
    "summary": "Multimodal Model Editing (MMED) aims to correct erroneous knowledge in multimodal models. Existing evaluation methods, adapted from textual model editing, overstate success by relying on low-similarity or random inputs, obscure overfitting. We propose a comprehensive locality evaluation framework, covering three key dimensions: random-image locality, no-image locality, and consistent-image locality, operationalized through seven distinct data types, enabling a detailed and structured analysis of multimodal edits. We introduce De-VQA, a dynamic evaluation for visual question answering, uncovering a phenomenon we term transient blindness, overfitting to edit-similar text while ignoring visuals. Token analysis shows edits disproportionately affect textual tokens. We propose locality-aware adversarial losses to balance cross-modal representations. Empirical results demonstrate that our approach consistently outperforms existing baselines, reducing transient blindness and improving locality by 17% on average.",
    "published": "2025-11-17T11:04:33Z",
    "updated": "2025-11-17T11:04:33Z",
    "link": "http://arxiv.org/pdf/2511.13243v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Xiaoqi Han",
      "Ru Li",
      "Ran Yi",
      "Hongye Tan",
      "Zhuomin Liang",
      "Víctor Gutiérrez-Basulto",
      "Jeff Z. Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.02781v3",
    "title": "Local Markov Equivalence for PC-style Local Causal Discovery and Identification of Controlled Direct Effects",
    "summary": "Understanding and identifying controlled direct effects (CDEs) is crucial across numerous scientific domains, including public health. While existing methods can identify these effects from causal directed acyclic graphs (DAGs), the true underlying structure is often unknown in practice. Essential graphs, which represent a Markov equivalence class of DAGs characterized by the same set of $d$-separations, provide a more practical and realistic alternative. However, learning the full essential graph is computationally intensive and typically depends on strong, untestable assumptions. In this work, we characterize a local class of graphs, defined relative to a target variable, that share a specific subset of $d$-separations, and introduce a graphical representation of this class, called the local essential graph (LEG). We then present LocPC, a novel algorithm designed to recover the LEG from an observed distribution using only local conditional independence tests. Building on LocPC, we propose LocPC-CDE, an algorithm that discovers the portion of the LEG that is both sufficient and necessary to identify a CDE, bypassing the need of retrieving the full essential graph. Compared to global methods, our algorithms require less conditional independence tests and operate under weaker assumptions while maintaining theoretical guarantees. We illustrate the effectiveness of our approach through simulation studies.",
    "published": "2025-05-05T16:47:29Z",
    "updated": "2025-11-17T11:01:56Z",
    "link": "http://arxiv.org/pdf/2505.02781v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Timothée Loranchet",
      "Charles K. Assaad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13238v1",
    "title": "Computational Measurement of Political Positions: A Review of Text-Based Ideal Point Estimation Algorithms",
    "summary": "This article presents the first systematic review of unsupervised and semi-supervised computational text-based ideal point estimation (CT-IPE) algorithms, methods designed to infer latent political positions from textual data. These algorithms are widely used in political science, communication, computational social science, and computer science to estimate ideological preferences from parliamentary speeches, party manifestos, and social media. Over the past two decades, their development has closely followed broader NLP trends -- beginning with word-frequency models and most recently turning to large language models (LLMs). While this trajectory has greatly expanded the methodological toolkit, it has also produced a fragmented field that lacks systematic comparison and clear guidance for applied use. To address this gap, we identified 25 CT-IPE algorithms through a systematic literature review and conducted a manual content analysis of their modeling assumptions and development contexts. To compare them meaningfully, we introduce a conceptual framework that distinguishes how algorithms generate, capture, and aggregate textual variance. On this basis, we identify four methodological families -- word-frequency, topic modeling, word embedding, and LLM-based approaches -- and critically assess their assumptions, interpretability, scalability, and limitations. Our review offers three contributions. First, it provides a structured synthesis of two decades of algorithm development, clarifying how diverse methods relate to one another. Second, it translates these insights into practical guidance for applied researchers, highlighting trade-offs in transparency, technical requirements, and validation strategies that shape algorithm choice. Third, it emphasizes that differences in estimation outcomes across algorithms are themselves informative, underscoring the need for systematic benchmarking.",
    "published": "2025-11-17T11:01:09Z",
    "updated": "2025-11-17T11:01:09Z",
    "link": "http://arxiv.org/pdf/2511.13238v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "authors": [
      "Patrick Parschan",
      "Charlott Jakob"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.14398v4",
    "title": "On the Limitations of Language Targeted Pruning: Investigating the Calibration Language Impact in Multilingual LLM Pruning",
    "summary": "Recent advances in large language model (LLM) pruning have shown state-of-the-art (SotA) compression results in post-training and retraining-free settings while maintaining high predictive performance. However, previous research mainly considered calibrating based on English text, despite the multilingual nature of modern LLMs and their frequent use in non-English languages. This analysis paper conducts an in-depth investigation of the performance and internal representation changes associated with pruning multilingual language models for monolingual applications. We present the first comprehensive empirical study, comparing different calibration languages for pruning multilingual models across diverse languages, tasks, models, and SotA pruning techniques. We further analyze the latent subspaces, pruning masks, and individual neurons within pruned models. Our results reveal that while calibration on the target language effectively retains perplexity and yields high signal-to-noise ratios, it does not consistently improve downstream task performance. Further analysis of internal representations at three different levels highlights broader limitations of current pruning approaches: While they effectively preserve dominant information like language-specific features, this is insufficient to counteract the loss of nuanced, language-agnostic features that are crucial for knowledge retention and reasoning.",
    "published": "2024-08-26T16:29:13Z",
    "updated": "2025-11-17T10:48:59Z",
    "link": "http://arxiv.org/pdf/2408.14398v4.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Simon Kurz",
      "Jian-Jia Chen",
      "Lucie Flek",
      "Zhixue Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11083v2",
    "title": "Efficient Reinforcement Learning for Zero-Shot Coordination in Evolving Games",
    "summary": "Zero-shot coordination(ZSC) has become a hot topic in reinforcement learning research recently. It focuses on the generalization ability of agents, requiring them to coordinate well with collaborators that are not seen before without any fine-tuning. Population-based training has been proven to provide good zero-shot coordination performance; nevertheless, existing methods are limited by computational resources, mainly focusing on optimizing diversity in small populations while neglecting the potential performance gains from scaling population size. To address this issue, this paper proposes the Scalable Population Training (ScaPT), an efficient training framework comprising two key components: a meta-agent that efficiently realizes a population by selectively sharing parameters across agents, and a mutual information regularizer that guarantees population diversity. To empirically validate the effectiveness of ScaPT, this paper evaluates it along with representational frameworks in Hanabi and confirms its superiority.",
    "published": "2025-11-14T08:59:22Z",
    "updated": "2025-11-17T10:48:54Z",
    "link": "http://arxiv.org/pdf/2511.11083v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Bingyu Hui",
      "Lebin Yu",
      "Quanming Yao",
      "Yunpeng Qu",
      "Xudong Zhang",
      "Jian Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.04511v2",
    "title": "Argumentative Debates for Transparent Bias Detection [Technical Report]",
    "summary": "As the use of AI in society grows, addressing emerging biases is essential to prevent systematic discrimination. Several bias detection methods have been proposed, but, with few exceptions, these tend to ignore transparency. Instead, interpretability and explainability are core requirements for algorithmic fairness, even more so than for other algorithmic solutions, given the human-oriented nature of fairness. We present ABIDE (Argumentative BIas detection by DEbate), a novel framework that structures bias detection transparently as debate, guided by an underlying argument graph as understood in (formal and computational) argumentation. The arguments are about the success chances of groups in local neighbourhoods and the significance of these neighbourhoods. We evaluate ABIDE experimentally and demonstrate its strengths in performance against an argumentative baseline.",
    "published": "2025-08-06T14:56:08Z",
    "updated": "2025-11-17T10:46:42Z",
    "link": "http://arxiv.org/pdf/2508.04511v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Hamed Ayoobi",
      "Nico Potyka",
      "Anna Rapberger",
      "Francesca Toni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13226v1",
    "title": "Informative Communication of Robot Plans",
    "summary": "When a robot is asked to verbalize its plan it can do it in many ways. For example, a seemingly natural strategy is incremental, where the robot verbalizes its planned actions in plan order. However, an important aspect of this type of strategy is that it misses considerations on what is effectively informative to communicate, because not considering what the user knows prior to explanations. In this paper we propose a verbalization strategy to communicate robot plans informatively, by measuring the information gain that verbalizations have against a second-order theory of mind of the user capturing his prior knowledge on the robot. As shown in our experiments, this strategy allows to understand the robot's goal much quicker than by using strategies such as increasing or decreasing plan order. In addition, following our formulation we hint to what is informative and why when a robot communicates its plan.",
    "published": "2025-11-17T10:44:25Z",
    "updated": "2025-11-17T10:44:25Z",
    "link": "http://arxiv.org/pdf/2511.13226v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Michele Persiani",
      "Thomas Hellstrom"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11569v2",
    "title": "Private Frequency Estimation Via Residue Number Systems",
    "summary": "We present \\textsf{ModularSubsetSelection} (MSS), a new algorithm for locally differentially private (LDP) frequency estimation. Given a universe of size $k$ and $n$ users, our $\\varepsilon$-LDP mechanism encodes each input via a Residue Number System (RNS) over $\\ell$ pairwise-coprime moduli $m_0, \\ldots, m_{\\ell-1}$, and reports a randomly chosen index $j \\in [\\ell]$ along with the perturbed residue using the statistically optimal \\textsf{SubsetSelection} (SS) (Wang et al. 2016). This design reduces the user communication cost from $Θ\\bigl(ω\\log_2(k/ω)\\bigr)$ bits required by standard SS (with $ω\\approx k/(e^\\varepsilon+1)$) down to $\\lceil \\log_2 \\ell \\rceil + \\lceil \\log_2 m_j \\rceil$ bits, where $m_j < k$. Server-side decoding runs in $Θ(n + r k \\ell)$ time, where $r$ is the number of LSMR (Fong and Saunders 2011) iterations. In practice, with well-conditioned moduli (\\textit{i.e.}, constant $r$ and $\\ell = Θ(\\log k)$), this becomes $Θ(n + k \\log k)$. We prove that MSS achieves worst-case MSE within a constant factor of state-of-the-art protocols such as SS and \\textsf{ProjectiveGeometryResponse} (PGR) (Feldman et al. 2022) while avoiding the algebraic prerequisites and dynamic-programming decoder required by PGR. Empirically, MSS matches the estimation accuracy of SS, PGR, and \\textsf{RAPPOR} (Erlingsson, Pihur, and Korolova 2014) across realistic $(k, \\varepsilon)$ settings, while offering faster decoding than PGR and shorter user messages than SS. Lastly, by sampling from multiple moduli and reporting only a single perturbed residue, MSS achieves the lowest reconstruction-attack success rate among all evaluated LDP protocols.",
    "published": "2025-11-14T18:58:41Z",
    "updated": "2025-11-17T10:42:09Z",
    "link": "http://arxiv.org/pdf/2511.11569v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Héber H. Arcolezi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13223v1",
    "title": "TokenSqueeze: Performance-Preserving Compression for Reasoning LLMs",
    "summary": "Emerging reasoning LLMs such as OpenAI-o1 and DeepSeek-R1 have achieved strong performance on complex reasoning tasks by generating long chain-of-thought (CoT) traces. However, these long CoTs result in increased token usage, leading to higher inference latency and memory consumption. As a result, balancing accuracy and reasoning efficiency has become essential for deploying reasoning LLMs in practical applications. Existing long-to-short (Long2Short) methods aim to reduce inference length but often sacrifice accuracy, revealing a need for an approach that maintains performance while lowering token costs. To address this efficiency-accuracy tradeoff, we propose TokenSqueeze, a novel Long2Short method that condenses reasoning paths while preserving performance and relying exclusively on self-generated data. First, to prevent performance degradation caused by excessive compression of reasoning depth, we propose to select self-generated samples whose reasoning depth is adaptively matched to the complexity of the problem. To further optimize the linguistic expression without altering the underlying reasoning paths, we introduce a distribution-aligned linguistic refinement method that enhances the clarity and conciseness of the reasoning path while preserving its logical integrity. Comprehensive experimental results demonstrate the effectiveness of TokenSqueeze in reducing token usage while maintaining accuracy. Notably, DeepSeek-R1-Distill-Qwen-7B fine-tuned using our proposed method achieved a 50\\% average token reduction while preserving accuracy on the MATH500 benchmark. TokenSqueeze exclusively utilizes the model's self-generated data, enabling efficient and high-fidelity reasoning without relying on manually curated short-answer datasets across diverse applications. Our code is available at https://github.com/zhangyx1122/TokenSqueeze.",
    "published": "2025-11-17T10:38:56Z",
    "updated": "2025-11-17T10:38:56Z",
    "link": "http://arxiv.org/pdf/2511.13223v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yuxiang Zhang",
      "Zhengxu Yu",
      "Weihang Pan",
      "Zhongming Jin",
      "Qiang Fu",
      "Deng Cai",
      "Binbin Lin",
      "Jieping Ye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13219v1",
    "title": "FoleyBench: A Benchmark For Video-to-Audio Models",
    "summary": "Video-to-audio generation (V2A) is of increasing importance in domains such as film post-production, AR/VR, and sound design, particularly for the creation of Foley sound effects synchronized with on-screen actions. Foley requires generating audio that is both semantically aligned with visible events and temporally aligned with their timing. Yet, there is a mismatch between evaluation and downstream applications due to the absence of a benchmark tailored to Foley-style scenarios. We find that 74% of videos from past evaluation datasets have poor audio-visual correspondence. Moreover, they are dominated by speech and music, domains that lie outside the use case for Foley. To address this gap, we introduce FoleyBench, the first large-scale benchmark explicitly designed for Foley-style V2A evaluation. FoleyBench contains 5,000 (video, ground-truth audio, text caption) triplets, each featuring visible sound sources with audio causally tied to on-screen events. The dataset is built using an automated, scalable pipeline applied to in-the-wild internet videos from YouTube-based and Vimeo-based sources. Compared to past datasets, we show that videos from FoleyBench have stronger coverage of sound categories from a taxonomy specifically designed for Foley sound. Each clip is further labeled with metadata capturing source complexity, UCS/AudioSet category, and video length, enabling fine-grained analysis of model performance and failure modes. We benchmark several state-of-the-art V2A models, evaluating them on audio quality, audio-video alignment, temporal synchronization, and audio-text consistency. Samples are available at: https://gclef-cmu.org/foleybench",
    "published": "2025-11-17T10:34:59Z",
    "updated": "2025-11-17T10:34:59Z",
    "link": "http://arxiv.org/pdf/2511.13219v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "authors": [
      "Satvik Dixit",
      "Koichi Saito",
      "Zhi Zhong",
      "Yuki Mitsufuji",
      "Chris Donahue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.06728v4",
    "title": "DeToNATION: Decoupled Torch Network-Aware Training on Interlinked Online Nodes",
    "summary": "Training large neural network models requires extensive computational resources, often distributed across several nodes and accelerators. Recent findings suggest that it may be sufficient to only exchange the fast moving components of the gradients, while accumulating momentum locally (Decoupled Momentum, or DeMo). However, DeMo assumes that models fit on a single accelerator. We relax this assumption and introduce FlexDeMo, whereby nodes fully shard model parameters locally between different accelerators, while inter-node communication is reduced by synchronizing only fast-moving components instead of the full gradients -- resulting in a hybrid sharded data parallel training strategy. We further introduce a framework, denoted as DeToNATION, that generalizes DeMo, FlexDeMo, and other popular distributed training schemes such as DiLoCo -- introducing new variations of replication schemes and challenging choices made in DeMo. Our results across language and vision domains show that FlexDeMo attains similar validation loss as hybrid sharded data parallel training employing AdamW and full gradient synchronization, while being substantially faster. FlexDeMo is thus a promising distributed training scheme for the largest machine learning models.",
    "published": "2025-02-10T17:55:59Z",
    "updated": "2025-11-17T10:34:58Z",
    "link": "http://arxiv.org/pdf/2502.06728v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mogens Henrik From",
      "Jacob Nielsen",
      "Lukas Galke Poech",
      "Peter Schneider-Kamp"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.08021v3",
    "title": "The Correspondence Between Bounded Graph Neural Networks and Fragments of First-Order Logic",
    "summary": "Graph Neural Networks (GNNs) address two key challenges in applying deep learning to graph-structured data: they handle varying size input graphs and ensure invariance under graph isomorphism. While GNNs have demonstrated broad applicability, understanding their expressive power remains an important question. In this paper, we propose GNN architectures that correspond precisely to prominent fragments of first-order logic (FO), including various modal logics as well as more expressive two-variable fragments. To establish these results, we apply methods from finite model theory of first-order and modal logics to the domain of graph representation learning. Our results provide a unifying framework for understanding the logical expressiveness of GNNs within FO.",
    "published": "2025-05-12T19:45:45Z",
    "updated": "2025-11-17T10:29:25Z",
    "link": "http://arxiv.org/pdf/2505.08021v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Bernardo Cuenca Grau",
      "Eva Feng",
      "Przemysław A. Wałęga"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13214v1",
    "title": "Learning to Solve Resource-Constrained Project Scheduling Problems with Duration Uncertainty using Graph Neural Networks",
    "summary": "The Resource-Constrained Project Scheduling Problem (RCPSP) is a classical scheduling problem that has received significant attention due to of its numerous applications in industry. However, in practice, task durations are subject to uncertainty that must be considered in order to propose resilient scheduling. In this paper, we address the RCPSP variant with uncertain tasks duration (modeled using known probabilities) and aim to minimize the overall expected project duration. Our objective is to produce a baseline schedule that can be reused multiple times in an industrial setting regardless of the actual duration scenario. We leverage Graph Neural Networks in conjunction with Deep Reinforcement Learning (DRL) to develop an effective policy for task scheduling. This policy operates similarly to a priority dispatch rule and is paired with a Serial Schedule Generation Scheme to produce a schedule. Our empirical evaluation on standard benchmarks demonstrates the approach's superiority in terms of performance and its ability to generalize. The developed framework, Wheatley, is made publicly available online to facilitate further research and reproducibility.",
    "published": "2025-11-17T10:27:35Z",
    "updated": "2025-11-17T10:27:35Z",
    "link": "http://arxiv.org/pdf/2511.13214v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Guillaume Infantes",
      "Stéphanie Roussel",
      "Antoine Jacquet",
      "Emmanuel Benazera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11275v2",
    "title": "A Workflow for Full Traceability of AI Decisions",
    "summary": "An ever increasing number of high-stake decisions are made or assisted by automated systems employing brittle artificial intelligence technology. There is a substantial risk that some of these decision induce harm to people, by infringing their well-being or their fundamental human rights. The state-of-the-art in AI systems makes little effort with respect to appropriate documentation of the decision process. This obstructs the ability to trace what went into a decision, which in turn is a prerequisite to any attempt of reconstructing a responsibility chain. Specifically, such traceability is linked to a documentation that will stand up in court when determining the cause of some AI-based decision that inadvertently or intentionally violates the law.\n  This paper takes a radical, yet practical, approach to this problem, by enforcing the documentation of each and every component that goes into the training or inference of an automated decision. As such, it presents the first running workflow supporting the generation of tamper-proof, verifiable and exhaustive traces of AI decisions. In doing so, we expand the DBOM concept into an effective running workflow leveraging confidential computing technology. We demonstrate the inner workings of the workflow in the development of an app to tell poisonous and edible mushrooms apart, meant as a playful example of high-stake decision support.",
    "published": "2025-11-14T13:10:45Z",
    "updated": "2025-11-17T10:24:15Z",
    "link": "http://arxiv.org/pdf/2511.11275v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Julius Wenzel",
      "Syeda Umaima Alam",
      "Andreas Schmidt",
      "Hanwei Zhang",
      "Holger Hermanns"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.09883v2",
    "title": "3D-Aware Vision-Language Models Fine-Tuning with Geometric Distillation",
    "summary": "Vision-Language Models (VLMs) have shown remarkable performance on diverse visual and linguistic tasks, yet they remain fundamentally limited in their understanding of 3D spatial structures. We propose Geometric Distillation, a lightweight, annotation-free fine-tuning framework that injects human-inspired geometric cues into pretrained VLMs without modifying their architecture. By distilling (1) sparse correspondences, (2) relative depth relations, and (3) dense cost volumes from off-the-shelf 3D foundation models (e.g., MASt3R, VGGT), our method shapes representations to be geometry-aware while remaining compatible with natural image-text inputs. Through extensive evaluations on 3D vision-language reasoning and 3D perception benchmarks, our method consistently outperforms prior approaches, achieving improved 3D spatial reasoning with significantly lower computational cost. Our work demonstrates a scalable and efficient path to bridge 2D-trained VLMs with 3D understanding, opening up wider use in spatially grounded multimodal tasks.",
    "published": "2025-06-11T15:56:59Z",
    "updated": "2025-11-17T10:19:22Z",
    "link": "http://arxiv.org/pdf/2506.09883v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Seonho Lee",
      "Jiho Choi",
      "Inha Kang",
      "Jiwook Kim",
      "Junsung Park",
      "Hyunjung Shim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.08098v3",
    "title": "What You See Is Not Always What You Get: Evaluating GPT's Comprehension of Source Code",
    "summary": "Recent studies have demonstrated outstanding capabilities of large language models (LLMs) in software engineering tasks, including code generation and comprehension. While LLMs have shown significant potential in assisting with coding, LLMs are vulnerable to adversarial attacks. In this paper, we investigate the vulnerability of LLMs to imperceptible attacks. This class of attacks manipulate source code at the character level, which renders the changes invisible to human reviewers yet effective in misleading LLMs' behaviour. We devise these attacks into four distinct categories and analyse their impacts on code analysis and comprehension tasks. These four types of imperceptible character attacks include coding reordering, invisible coding characters, code deletions, and code homoglyphs. To assess the robustness of state-of-the-art LLMs, we present a systematic evaluation across multiple models using both perturbed and clean code snippets. Two evaluation metrics, model confidence using log probabilities of response and response correctness, are introduced. The results reveal that LLMs are susceptible to imperceptible coding perturbations, with varying degrees of degradation highlighted across different LLMs. Furthermore, we observe a consistent negative correlation between perturbation magnitude and model performance. These results highlight the urgent need for robust LLMs capable of manoeuvring behaviours under imperceptible adversarial conditions.",
    "published": "2024-12-11T04:52:41Z",
    "updated": "2025-11-17T10:13:22Z",
    "link": "http://arxiv.org/pdf/2412.08098v3.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jiawen Wen",
      "Bangshuo Zhu",
      "Huaming Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13198v1",
    "title": "ParaDySe: A Parallel-Strategy Switching Framework for Dynamic Sequence Lengths in Transformer",
    "summary": "Dynamic sequences with varying lengths have been widely used in the training of Transformer-based large language models (LLMs). However, current training frameworks adopt a pre-defined static parallel strategy for these sequences, causing neither communication-parallelization cancellation on short sequences nor out-of-memory on long sequences. To mitigate these issues, we propose ParaDySe, a novel adaptive Parallel strategy switching framework for Dynamic Sequences. ParaDySe enables on-the-fly optimal strategy adoption according to the immediate input sequence. It first implements the modular function libraries for parallel strategies with unified tensor layout specifications, and then builds sequence-aware memory and time cost models with hybrid methods. Guided by cost models, ParaDySe selects optimal layer-wise strategies for dynamic sequences via an efficient heuristic algorithm. By integrating these techniques together, ParaDySe achieves seamless hot-switching of optimal strategies through its well-designed function libraries. We compare ParaDySe with baselines on representative LLMs under datasets with sequence lengths up to 624K. Experimental results indicate that ParaDySe addresses OOM and CPC bottlenecks in LLM training by systematically integrating long-sequence optimizations with existing frameworks.",
    "published": "2025-11-17T10:08:24Z",
    "updated": "2025-11-17T10:08:24Z",
    "link": "http://arxiv.org/pdf/2511.13198v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhixin Ou",
      "Peng Liang",
      "Jianchen Han",
      "Baihui Liu",
      "Linbo Qiao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13193v1",
    "title": "Cost-Effective Communication: An Auction-based Method for Language Agent Interaction",
    "summary": "Multi-agent systems (MAS) built on large language models (LLMs) often suffer from inefficient \"free-for-all\" communication, leading to exponential token costs and low signal-to-noise ratios that hinder their practical deployment. We challenge the notion that more communication is always beneficial, hypothesizing instead that the core issue is the absence of resource rationality. We argue that \"free\" communication, by ignoring the principle of scarcity, inherently breeds inefficiency and unnecessary expenses. To address this, we introduce the Dynamic Auction-based Language Agent (DALA), a novel framework that treats communication bandwidth as a scarce and tradable resource. Specifically, our DALA regards inter-agent communication as a centralized auction, where agents learn to bid for the opportunity to speak based on the predicted value density of their messages. Thus, our DALA intrinsically encourages agents to produce concise, informative messages while filtering out low-value communication. Extensive and comprehensive experiments demonstrate that our economically-driven DALA achieves new state-of-the-art performance across seven challenging reasoning benchmarks, including 84.32% on MMLU and a 91.21% pass@1 rate on HumanEval. Note that this is accomplished with remarkable efficiency, i.e., our DALA uses only 6.25 million tokens, a fraction of the resources consumed by current state-of-the-art methods on GSM8K. Further analysis reveals that our DALA cultivates the emergent skill of strategic silence, effectively adapting its communication strategies from verbosity to silence in a dynamical manner via resource constraints.",
    "published": "2025-11-17T10:00:20Z",
    "updated": "2025-11-17T10:00:20Z",
    "link": "http://arxiv.org/pdf/2511.13193v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yijia Fan",
      "Jusheng Zhang",
      "Kaitong Cai",
      "Jing Yang",
      "Chengpei Tang",
      "Jian Wang",
      "Keze Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.02036v2",
    "title": "Deep Clustering via Gradual Community Detection",
    "summary": "Deep clustering is an essential task in modern artificial intelligence, aiming to partition a set of data samples into a given number of homogeneous groups (i.e., clusters). Recent studies have proposed increasingly advanced deep neural networks and training strategies for deep clustering, effectively improving performance. However, deep clustering generally remains challenging due to the inadequacy of supervision signals. Building upon the existing representation learning backbones, this paper proposes a novel clustering strategy of gradual community detection. It initializes clustering by partitioning samples into many pseudo-communities and then gradually expands clusters by community merging. Compared with the existing clustering strategies, community detection factors in the new perspective of cluster network analysis in the clustering process. The new perspective can effectively leverage global structural characteristics to enhance cluster pseudo-label purity, which is critical to the performance of self-supervision. We have implemented the proposed approach based on the popular backbones and evaluated its efficacy on benchmark image datasets. Our extensive experiments have shown that the proposed clustering strategy can effectively improve the SOTA performance. Our ablation study also demonstrates that the new network perspective can effectively improve community pseudo-label purity, resulting in improved self-supervision.",
    "published": "2025-01-03T12:56:12Z",
    "updated": "2025-11-17T09:58:05Z",
    "link": "http://arxiv.org/pdf/2501.02036v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "authors": [
      "Tianyu Cheng",
      "Qun Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.19843v3",
    "title": "SoK: Large Language Model Copyright Auditing via Fingerprinting",
    "summary": "The broad capabilities and substantial resources required to train Large Language Models (LLMs) make them valuable intellectual property, yet they remain vulnerable to copyright infringement, such as unauthorized use and model theft. LLM fingerprinting, a non-intrusive technique that compares the distinctive features (i.e., fingerprint) of LLMs to identify whether an LLM is derived from another, offers a promising solution to copyright auditing. However, its reliability remains uncertain due to the prevalence of diverse model modifications and the lack of standardized evaluation. In this SoK, we present the first comprehensive study of the emerging LLM fingerprinting. We introduce a unified framework and taxonomy that structures the field: white-box methods are classified based on their feature source as static, forward-pass, or backward-pass fingerprinting, while black-box methods are distinguished by their query strategy as either untargeted or targeted. Furthermore, we propose LeaFBench, the first systematic benchmark for evaluating LLM fingerprinting under realistic deployment scenarios. Built upon 7 mainstream foundation models and comprising 149 distinct model instances, LeaFBench integrates 13 representative post-development techniques, spanning both parameter-altering methods (e.g., fine-tuning, quantization) and parameter-independent techniques (e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the strengths and weaknesses of existing methods, thereby outlining future research directions and critical open problems in this emerging field. The code is available at https://github.com/shaoshuo-ss/LeaFBench.",
    "published": "2025-08-27T12:56:57Z",
    "updated": "2025-11-17T09:34:10Z",
    "link": "http://arxiv.org/pdf/2508.19843v3.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Shuo Shao",
      "Yiming Li",
      "Yu He",
      "Hongwei Yao",
      "Wenyuan Yang",
      "Dacheng Tao",
      "Zhan Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.04789v3",
    "title": "Aligning Extraction and Generation for Robust Retrieval-Augmented Generation",
    "summary": "Retrieval-augmented generation (RAG) enhances LLMs with external knowledge, yet generation remains vulnerable to retrieval-induced noise and uncertain placement of relevant chunks, often causing hallucinations. We present Ext2Gen, an extract-then-generate framework that strengthens LLMs via joint evidence selection and answer generation, dynamically identifying query-relevant content while suppressing noise, thereby removing the need for any independent pre-generation compression module. Optimized through preference alignment with well-curated pairwise feedback, Ext2Gen produces accurate and faithful answers even under noisy or imprecise retrieval. Experiments demonstrate that it substantially enhances the robustness of the generation backbone and yields greater performance gains than methods relying on independent compression models, e.g., Recomp, CompAct, EXIT). It further benefits from improved retrieval techniques such as query rewriting, underscoring that generation-side enhancements address limitations that retrieval alone cannot overcome.",
    "published": "2025-02-28T06:46:53Z",
    "updated": "2025-11-17T09:25:49Z",
    "link": "http://arxiv.org/pdf/2503.04789v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Hwanjun Song",
      "Jeonghwan Choi",
      "Minseok Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.00626v6",
    "title": "Towards Methane Detection Onboard Satellites",
    "summary": "Methane is a potent greenhouse gas and a major driver of climate change, making its timely detection critical for effective mitigation. Machine learning (ML) deployed onboard satellites can enable rapid detection while reducing downlink costs, supporting faster response systems. Conventional methane detection methods often rely on image processing techniques, such as orthorectification to correct geometric distortions and matched filters to enhance plume signals. We introduce a novel approach that bypasses these preprocessing steps by using \\textit{unorthorectified} data (UnorthoDOS). We find that ML models trained on this dataset achieve performance comparable to those trained on orthorectified data. Moreover, we also train models on an orthorectified dataset, showing that they can outperform the matched filter baseline (mag1c). We release model checkpoints and two ML-ready datasets comprising orthorectified and unorthorectified hyperspectral images from the Earth Surface Mineral Dust Source Investigation (EMIT) sensor at https://huggingface.co/datasets/SpaceML/UnorthoDOS , along with code at https://github.com/spaceml-org/plume-hunter.",
    "published": "2025-08-30T22:54:00Z",
    "updated": "2025-11-17T09:23:12Z",
    "link": "http://arxiv.org/pdf/2509.00626v6.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Maggie Chen",
      "Hala Lambdouar",
      "Luca Marini",
      "Laura Martínez-Ferrer",
      "Chris Bridges",
      "Giacomo Acciarini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.00034v2",
    "title": "Is Our Chatbot Telling Lies? Assessing Correctness of an LLM-based Dutch Support Chatbot",
    "summary": "Companies support their customers using live chats and chatbots to gain their loyalty. AFAS is a Dutch company aiming to leverage the opportunity large language models (LLMs) offer to answer customer queries with minimal to no input from its customer support team. Adding to its complexity, it is unclear what makes a response correct, and that too in Dutch. Further, with minimal data available for training, the challenge is to identify whether an answer generated by a large language model is correct and do it on the fly.\n  This study is the first to define the correctness of a response based on how the support team at AFAS makes decisions. It leverages literature on natural language generation and automated answer grading systems to automate the decision-making of the customer support team. We investigated questions requiring a binary response (e.g., Would it be possible to adjust tax rates manually?) or instructions (e.g., How would I adjust tax rate manually?) to test how close our automated approach reaches support rating. Our approach can identify wrong messages in 55\\% of the cases. This work demonstrates the potential for automatically assessing when our chatbot may provide incorrect or misleading answers. Specifically, we contribute (1) a definition and metrics for assessing correctness, and (2) suggestions to improve correctness with respect to regional language and question type.",
    "published": "2024-10-29T12:02:14Z",
    "updated": "2025-11-17T09:20:23Z",
    "link": "http://arxiv.org/pdf/2411.00034v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Herman Lassche",
      "Michiel Overeem",
      "Ayushi Rastogi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13168v1",
    "title": "SOMA: Feature Gradient Enhanced Affine-Flow Matching for SAR-Optical Registration",
    "summary": "Achieving pixel-level registration between SAR and optical images remains a challenging task due to their fundamentally different imaging mechanisms and visual characteristics. Although deep learning has achieved great success in many cross-modal tasks, its performance on SAR-Optical registration tasks is still unsatisfactory. Gradient-based information has traditionally played a crucial role in handcrafted descriptors by highlighting structural differences. However, such gradient cues have not been effectively leveraged in deep learning frameworks for SAR-Optical image matching. To address this gap, we propose SOMA, a dense registration framework that integrates structural gradient priors into deep features and refines alignment through a hybrid matching strategy. Specifically, we introduce the Feature Gradient Enhancer (FGE), which embeds multi-scale, multi-directional gradient filters into the feature space using attention and reconstruction mechanisms to boost feature distinctiveness. Furthermore, we propose the Global-Local Affine-Flow Matcher (GLAM), which combines affine transformation and flow-based refinement within a coarse-to-fine architecture to ensure both structural consistency and local accuracy. Experimental results demonstrate that SOMA significantly improves registration precision, increasing the CMR@1px by 12.29% on the SEN1-2 dataset and 18.50% on the GFGE_SO dataset. In addition, SOMA exhibits strong robustness and generalizes well across diverse scenes and resolutions.",
    "published": "2025-11-17T09:14:56Z",
    "updated": "2025-11-17T09:14:56Z",
    "link": "http://arxiv.org/pdf/2511.13168v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Haodong Wang",
      "Tao Zhuo",
      "Xiuwei Zhang",
      "Hanlin Yin",
      "Wencong Wu",
      "Yanning Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.05440v3",
    "title": "EcoAgent: An Efficient Device-Cloud Collaborative Multi-Agent Framework for Mobile Automation",
    "summary": "To tackle increasingly complex tasks, recent research on mobile agents has shifted towards multi-agent collaboration. Current mobile multi-agent systems are primarily deployed in the cloud, leading to high latency and operational costs. A straightforward idea is to deploy a device-cloud collaborative multi-agent system, which is nontrivial, as directly extending existing systems introduces new challenges: (1) reliance on cloud-side verification requires uploading mobile screenshots, compromising user privacy; and (2) open-loop cooperation lacking device-to-cloud feedback, underutilizing device resources and increasing latency. To overcome these limitations, we propose EcoAgent, a closed-loop device-cloud collaborative multi-agent framework designed for privacy-aware, efficient, and responsive mobile automation. EcoAgent integrates a novel reasoning approach, Dual-ReACT, into the cloud-based Planning Agent, fully exploiting cloud reasoning to compensate for limited on-device capacity, thereby enabling device-side verification and lightweight feedback. Furthermore, the device-based Observation Agent leverages a Pre-understanding Module to summarize screen content into concise textual descriptions, significantly reducing token usage and device-cloud communication overhead while preserving privacy. Experiments on AndroidWorld demonstrate that EcoAgent matches the task success rates of fully cloud-based agents, while reducing resource consumption and response latency. Our project is available here: https://github.com/Yi-Biao/EcoAgent.",
    "published": "2025-05-08T17:31:20Z",
    "updated": "2025-11-17T09:12:00Z",
    "link": "http://arxiv.org/pdf/2505.05440v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Biao Yi",
      "Xavier Hu",
      "Yurun Chen",
      "Shengyu Zhang",
      "Hongxia Yang",
      "Fan Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.13746v3",
    "title": "CG-FedLLM: How to Compress Gradients in Federated Fune-tuning for Large Language Models",
    "summary": "The success of current Large-Language Models (LLMs) hinges on extensive training data that is collected and stored centrally, called Centralized Learning (CL). However, such a collection manner poses a privacy threat, and one potential solution is Federated Learning (FL), which transfers gradients, not raw data, among clients. Unlike traditional networks, FL for LLMs incurs significant communication costs due to their tremendous parameters. This study introduces an innovative approach to compress gradients to improve communication efficiency during LLM FL, formulating the new FL pipeline named CG-FedLLM. This approach integrates an encoder on the client side to acquire the compressed gradient features and a decoder on the server side to reconstruct the gradients. We also developed a novel training strategy that comprises Temporal-ensemble Gradient-Aware Pre-training (TGAP) to identify characteristic gradients of the target model and Federated AutoEncoder-Involved Fine-tuning (FAF) to compress gradients adaptively. Extensive experiments confirm that our approach reduces communication costs and improves performance (e.g., average 3 points increment compared with traditional CL- and FL-based fine-tuning with LlaMA on a well-recognized benchmark, C-Eval). This improvement is because our encoder-decoder, trained via TGAP and FAF, can filter gradients while selectively preserving critical features. Furthermore, we present a series of experimental analyses focusing on the signal-to-noise ratio, compression rate, and robustness within this privacy-centric framework, providing insight into developing more efficient and secure LLMs.",
    "published": "2024-05-22T15:32:38Z",
    "updated": "2025-11-17T09:11:39Z",
    "link": "http://arxiv.org/pdf/2405.13746v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "authors": [
      "Huiwen Wu",
      "Xiaogang Xu",
      "Deyi Zhang",
      "Xiaohan Li",
      "Jiafei Wu",
      "Zhe Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13166v1",
    "title": "Local Collaborative Filtering: A Collaborative Filtering Method that Utilizes Local Similarities among Users",
    "summary": "To leverage user behavior data from the Internet more effectively in recommender systems, this paper proposes a novel collaborative filtering (CF) method called Local Collaborative Filtering (LCF). LCF utilizes local similarities among users and integrates their data using the law of large numbers (LLN), thereby improving the utilization of user behavior data. Experiments are conducted on the Steam game dataset, and the results of LCF align with real-world needs.",
    "published": "2025-11-17T09:10:37Z",
    "updated": "2025-11-17T09:10:37Z",
    "link": "http://arxiv.org/pdf/2511.13166v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Zhaoxin Shen",
      "Dan Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17482v3",
    "title": "SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries",
    "summary": "Semantic occupancy has emerged as a powerful representation in world models for its ability to capture rich spatial semantics. However, most existing occupancy world models rely on static and fixed embeddings or grids, which inherently limit the flexibility of perception. Moreover, their ``in-place classification\" over grids exhibits a potential misalignment with the dynamic and continuous nature of real scenarios. In this paper, we propose SparseWorld, a novel 4D occupancy world model that is flexible, adaptive, and efficient, powered by sparse and dynamic queries. We propose a Range-Adaptive Perception module, in which learnable queries are modulated by the ego vehicle states and enriched with temporal-spatial associations to enable extended-range perception. To effectively capture the dynamics of the scene, we design a State-Conditioned Forecasting module, which replaces classification-based forecasting with regression-guided formulation, precisely aligning the dynamic queries with the continuity of the 4D environment. In addition, We specifically devise a Temporal-Aware Self-Scheduling training strategy to enable smooth and efficient training. Extensive experiments demonstrate that SparseWorld achieves state-of-the-art performance across perception, forecasting, and planning tasks. Comprehensive visualizations and ablation studies further validate the advantages of SparseWorld in terms of flexibility, adaptability, and efficiency.",
    "published": "2025-10-20T12:26:25Z",
    "updated": "2025-11-17T09:09:55Z",
    "link": "http://arxiv.org/pdf/2510.17482v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Chenxu Dang",
      "Haiyan Liu",
      "Jason Bao",
      "Pei An",
      "Xinyue Tang",
      " PanAn",
      "Jie Ma",
      "Bingchuan Sun",
      "Yan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13160v1",
    "title": "InteractiveGNNExplainer: A Visual Analytics Framework for Multi-Faceted Understanding and Probing of Graph Neural Network Predictions",
    "summary": "Graph Neural Networks (GNNs) excel in graph-based learning tasks, but their complex, non-linear operations often render them as opaque \"black boxes\". This opacity hinders user trust, complicates debugging, bias detection, and adoption in critical domains requiring explainability. This paper introduces InteractiveGNNExplainer, a visual analytics framework to enhance GNN explainability, focusing on node classification. Our system uniquely integrates coordinated interactive views (dynamic graph layouts, embedding projections, feature inspection, neighborhood analysis) with established post-hoc (GNNExplainer) and intrinsic (GAT attention) explanation techniques. Crucially, it incorporates interactive graph editing, allowing users to perform a \"what-if\" analysis by perturbing graph structures and observing immediate impacts on GNN predictions and explanations. We detail the system architecture and, through case studies on Cora and CiteSeer datasets, demonstrate how InteractiveGNNExplainer facilitates in-depth misclassification diagnosis, comparative analysis of GCN versus GAT behaviors, and rigorous probing of model sensitivity. These capabilities foster a deeper, multifaceted understanding of GNN predictions, contributing to more transparent, trustworthy, and robust graph analysis.",
    "published": "2025-11-17T09:08:31Z",
    "updated": "2025-11-17T09:08:31Z",
    "link": "http://arxiv.org/pdf/2511.13160v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "TC Singh",
      "Sougata Mukherjea"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.22564v2",
    "title": "Exploiting Synergistic Cognitive Biases to Bypass Safety in LLMs",
    "summary": "Large Language Models (LLMs) demonstrate impressive capabilities across a wide range of tasks, yet their safety mechanisms remain susceptible to adversarial attacks that exploit cognitive biases -- systematic deviations from rational judgment. Unlike prior jailbreaking approaches focused on prompt engineering or algorithmic manipulation, this work highlights the overlooked power of multi-bias interactions in undermining LLM safeguards. We propose CognitiveAttack, a novel red-teaming framework that systematically leverages both individual and combined cognitive biases. By integrating supervised fine-tuning and reinforcement learning, CognitiveAttack generates prompts that embed optimized bias combinations, effectively bypassing safety protocols while maintaining high attack success rates. Experimental results reveal significant vulnerabilities across 30 diverse LLMs, particularly in open-source models. CognitiveAttack achieves a substantially higher attack success rate compared to the SOTA black-box method PAP (60.1% vs. 31.6%), exposing critical limitations in current defense mechanisms. These findings highlight multi-bias interactions as a powerful yet underexplored attack vector. This work introduces a novel interdisciplinary perspective by bridging cognitive science and LLM safety, paving the way for more robust and human-aligned AI systems.",
    "published": "2025-07-30T10:40:53Z",
    "updated": "2025-11-17T09:00:14Z",
    "link": "http://arxiv.org/pdf/2507.22564v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Xikang Yang",
      "Biyu Zhou",
      "Xuehai Tang",
      "Jizhong Han",
      "Songlin Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13145v1",
    "title": "Automated Road Distress Detection Using Vision Transformersand Generative Adversarial Networks",
    "summary": "The American Society of Civil Engineers has graded Americas infrastructure condition as a C, with the road system receiving a dismal D. Roads are vital to regional economic viability, yet their management, maintenance, and repair processes remain inefficient, relying on outdated manual or laser-based inspection methods that are both costly and time-consuming. With the increasing availability of real-time visual data from autonomous vehicles, there is an opportunity to apply computer vision (CV) methods for advanced road monitoring, providing insights to guide infrastructure rehabilitation efforts. This project explores the use of state-of-the-art CV techniques for road distress segmentation. It begins by evaluating synthetic data generated with Generative Adversarial Networks (GANs) to assess its usefulness for model training. The study then applies Convolutional Neural Networks (CNNs) for road distress segmentation and subsequently examines the transformer-based model MaskFormer. Results show that GAN-generated data improves model performance and that MaskFormer outperforms the CNN model in two metrics: mAP50 and IoU.",
    "published": "2025-11-17T08:56:08Z",
    "updated": "2025-11-17T08:56:08Z",
    "link": "http://arxiv.org/pdf/2511.13145v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Cesar Portocarrero Rodriguez",
      "Laura Vandeweyen",
      "Yosuke Yamamoto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13143v1",
    "title": "SoK: The Last Line of Defense: On Backdoor Defense Evaluation",
    "summary": "Backdoor attacks pose a significant threat to deep learning models by implanting hidden vulnerabilities that can be activated by malicious inputs. While numerous defenses have been proposed to mitigate these attacks, the heterogeneous landscape of evaluation methodologies hinders fair comparison between defenses. This work presents a systematic (meta-)analysis of backdoor defenses through a comprehensive literature review and empirical evaluation. We analyzed 183 backdoor defense papers published between 2018 and 2025 across major AI and security venues, examining the properties and evaluation methodologies of these defenses.\n  Our analysis reveals significant inconsistencies in experimental setups, evaluation metrics, and threat model assumptions in the literature. Through extensive experiments involving three datasets (MNIST, CIFAR-100, ImageNet-1K), four model architectures (ResNet-18, VGG-19, ViT-B/16, DenseNet-121), 16 representative defenses, and five commonly used attacks, totaling over 3\\,000 experiments, we demonstrate that defense effectiveness varies substantially across different evaluation setups. We identify critical gaps in current evaluation practices, including insufficient reporting of computational overhead and behavior under benign conditions, bias in hyperparameter selection, and incomplete experimentation. Based on our findings, we provide concrete challenges and well-motivated recommendations to standardize and improve future defense evaluations. Our work aims to equip researchers and industry practitioners with actionable insights for developing, assessing, and deploying defenses to different systems.",
    "published": "2025-11-17T08:51:18Z",
    "updated": "2025-11-17T08:51:18Z",
    "link": "http://arxiv.org/pdf/2511.13143v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Gorka Abad",
      "Marina Krček",
      "Stefanos Koffas",
      "Behrad Tajalli",
      "Marco Arazzi",
      "Roberto Riaño",
      "Xiaoyun Xu",
      "Zhuoran Liu",
      "Antonino Nocera",
      "Stjepan Picek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.05337v2",
    "title": "Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression",
    "summary": "Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought reasoning with complex reflection behaviors, typically signaled by specific trigger words (e.g., \"Wait\" and \"Alternatively\") to enhance performance. However, these reflection behaviors can lead to the overthinking problem where the generation of redundant reasoning steps that unnecessarily increase token usage, raise inference costs, and reduce practical utility. In this paper, we propose Certainty-Guided Reflection Suppression (CGRS), a novel method that mitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS operates by dynamically suppressing the model's generation of reflection triggers when it exhibits high confidence in its current response, thereby preventing redundant reflection cycles without compromising output quality. Our approach is model-agnostic, requires no retraining or architectural modifications, and can be integrated seamlessly with existing autoregressive generation pipelines. Extensive experiments across four reasoning benchmarks (i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS's effectiveness: it reduces token usage by an average of 18.5% to 41.9% while preserving accuracy. It also achieves the optimal balance between length reduction and performance compared to state-of-the-art baselines. These results hold consistently across model architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3 family) and scales (4B to 32B parameters), highlighting CGRS's practical value for efficient reasoning.",
    "published": "2025-08-07T12:38:22Z",
    "updated": "2025-11-17T08:47:52Z",
    "link": "http://arxiv.org/pdf/2508.05337v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jiameng Huang",
      "Baijiong Lin",
      "Guhao Feng",
      "Jierun Chen",
      "Di He",
      "Lu Hou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13137v1",
    "title": "Conditional Diffusion Model for Multi-Agent Dynamic Task Decomposition",
    "summary": "Task decomposition has shown promise in complex cooperative multi-agent reinforcement learning (MARL) tasks, which enables efficient hierarchical learning for long-horizon tasks in dynamic and uncertain environments. However, learning dynamic task decomposition from scratch generally requires a large number of training samples, especially exploring the large joint action space under partial observability. In this paper, we present the Conditional Diffusion Model for Dynamic Task Decomposition (C$\\text{D}^\\text{3}$T), a novel two-level hierarchical MARL framework designed to automatically infer subtask and coordination patterns. The high-level policy learns subtask representation to generate a subtask selection strategy based on subtask effects. To capture the effects of subtasks on the environment, C$\\text{D}^\\text{3}$T predicts the next observation and reward using a conditional diffusion model. At the low level, agents collaboratively learn and share specialized skills within their assigned subtasks. Moreover, the learned subtask representation is also used as additional semantic information in a multi-head attention mixing network to enhance value decomposition and provide an efficient reasoning bridge between individual and joint value functions. Experimental results on various benchmarks demonstrate that C$\\text{D}^\\text{3}$T achieves better performance than existing baselines.",
    "published": "2025-11-17T08:46:31Z",
    "updated": "2025-11-17T08:46:31Z",
    "link": "http://arxiv.org/pdf/2511.13137v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yanda Zhu",
      "Yuanyang Zhu",
      "Daoyi Dong",
      "Caihua Chen",
      "Chunlin Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.22963v3",
    "title": "CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents",
    "summary": "LLM-powered agents often use prompt compression to reduce inference costs, but this introduces a new security risk. Compression modules, which are optimized for efficiency rather than safety, can be manipulated by adversarial inputs, causing semantic drift and altering LLM behavior. This work identifies prompt compression as a novel attack surface and presents CompressionAttack, the first framework to exploit it. CompressionAttack includes two strategies: HardCom, which uses discrete adversarial edits for hard compression, and SoftCom, which performs latent-space perturbations for soft compression. Experiments on multiple LLMs show up to an average ASR of 83% and 87% in two tasks, while remaining highly stealthy and transferable. Case studies in three practical scenarios confirm real-world impact, and current defenses prove ineffective, highlighting the need for stronger protections.",
    "published": "2025-10-27T03:37:41Z",
    "updated": "2025-11-17T08:45:43Z",
    "link": "http://arxiv.org/pdf/2510.22963v3.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Zesen Liu",
      "Zhixiang Zhang",
      "Yuchong Xie",
      "Dongdong She"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13133v1",
    "title": "Soft Conflict-Resolution Decision Transformer for Offline Multi-Task Reinforcement Learning",
    "summary": "Multi-task reinforcement learning (MTRL) seeks to learn a unified policy for diverse tasks, but often suffers from gradient conflicts across tasks. Existing masking-based methods attempt to mitigate such conflicts by assigning task-specific parameter masks. However, our empirical study shows that coarse-grained binary masks have the problem of over-suppressing key conflicting parameters, hindering knowledge sharing across tasks. Moreover, different tasks exhibit varying conflict levels, yet existing methods use a one-size-fits-all fixed sparsity strategy to keep training stability and performance, which proves inadequate. These limitations hinder the model's generalization and learning efficiency.\n  To address these issues, we propose SoCo-DT, a Soft Conflict-resolution method based by parameter importance. By leveraging Fisher information, mask values are dynamically adjusted to retain important parameters while suppressing conflicting ones. In addition, we introduce a dynamic sparsity adjustment strategy based on the Interquartile Range (IQR), which constructs task-specific thresholding schemes using the distribution of conflict and harmony scores during training. To enable adaptive sparsity evolution throughout training, we further incorporate an asymmetric cosine annealing schedule to continuously update the threshold. Experimental results on the Meta-World benchmark show that SoCo-DT outperforms the state-of-the-art method by 7.6% on MT50 and by 10.5% on the suboptimal dataset, demonstrating its effectiveness in mitigating gradient conflicts and improving overall multi-task performance.",
    "published": "2025-11-17T08:40:41Z",
    "updated": "2025-11-17T08:40:41Z",
    "link": "http://arxiv.org/pdf/2511.13133v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Shudong Wang",
      "Xinfei Wang",
      "Chenhao Zhang",
      "Shanchen Pang",
      "Haiyuan Gui",
      "Wenhao Ji",
      "Xiaojian Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13132v1",
    "title": "Shedding Light on VLN Robustness: A Black-box Framework for Indoor Lighting-based Adversarial Attack",
    "summary": "Vision-and-Language Navigation (VLN) agents have made remarkable progress, but their robustness remains insufficiently studied. Existing adversarial evaluations often rely on perturbations that manifest as unusual textures rarely encountered in everyday indoor environments. Errors under such contrived conditions have limited practical relevance, as real-world agents are unlikely to encounter such artificial patterns. In this work, we focus on indoor lighting, an intrinsic yet largely overlooked scene attribute that strongly influences navigation. We propose Indoor Lighting-based Adversarial Attack (ILA), a black-box framework that manipulates global illumination to disrupt VLN agents. Motivated by typical household lighting usage, we design two attack modes: Static Indoor Lighting-based Attack (SILA), where the lighting intensity remains constant throughout an episode, and Dynamic Indoor Lighting-based Attack (DILA), where lights are switched on or off at critical moments to induce abrupt illumination changes. We evaluate ILA on two state-of-the-art VLN models across three navigation tasks. Results show that ILA significantly increases failure rates while reducing trajectory efficiency, revealing previously unrecognized vulnerabilities of VLN agents to realistic indoor lighting variations.",
    "published": "2025-11-17T08:39:29Z",
    "updated": "2025-11-17T08:39:29Z",
    "link": "http://arxiv.org/pdf/2511.13132v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Chenyang Li",
      "Wenbing Tang",
      "Yihao Huang",
      "Sinong Simon Zhan",
      "Ming Hu",
      "Xiaojun Jia",
      "Yang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16742v2",
    "title": "Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration",
    "summary": "Complex systems are increasingly explored through simulation-driven engineering workflows that combine physics-based and empirical models with optimization and analytics. Despite their power, these workflows face two central obstacles: (1) high computational cost, since accurate exploration requires many expensive simulator runs; and (2) limited transparency and reliability when decisions rely on opaque blackbox components. We propose a workflow that addresses both challenges by training lightweight emulators on compact designs of experiments that (i) provide fast, low-latency approximations of expensive simulators, (ii) enable rigorous uncertainty quantification, and (iii) are adapted for global and local Explainable Artificial Intelligence (XAI) analyses. This workflow unifies every simulation-based complex-system analysis tool, ranging from engineering design to agent-based models for socio-environmental understanding. In this paper, we proposea comparative methodology and practical recommendations for using surrogate-based explainability tools within the proposed workflow. The methodology supports continuous and categorical inputs, combines global-effect and uncertainty analyses with local attribution, and evaluates the consistency of explanations across surrogate models, thereby diagnosing surrogate adequacy and guiding further data collection or model refinement. We demonstrate the approach on two contrasting case studies: a multidisciplinary design analysis of a hybrid-electric aircraft and an agent-based model of urban segregation. Results show that the surrogate model and XAI coupling enables large-scale exploration in seconds, uncovers nonlinear interactions and emergent behaviors, identifies key design and policy levers, and signals regions where surrogates require more data or alternative architectures.",
    "published": "2025-10-19T07:55:52Z",
    "updated": "2025-11-17T08:38:34Z",
    "link": "http://arxiv.org/pdf/2510.16742v2.pdf",
    "category": [
      "cs.AI",
      "cs.MA",
      "stat.ME"
    ],
    "authors": [
      "Paul Saves",
      "Pramudita Satria Palar",
      "Muhammad Daffa Robani",
      "Nicolas Verstaevel",
      "Moncef Garouani",
      "Julien Aligon",
      "Benoit Gaudou",
      "Koji Shimoyama",
      "Joseph Morlier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13131v1",
    "title": "MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications",
    "summary": "Large Language Models (LLMs) have emerged as powerful tools for automating complex reasoning and decision-making tasks. In telecommunications, they hold the potential to transform network optimization, automate troubleshooting, enhance customer support, and ensure regulatory compliance. However, their deployment in telecom is hindered by domain-specific challenges that demand specialized adaptation. To overcome these challenges and to accelerate the adaptation of LLMs for telecom, we propose MM-Telco, a comprehensive suite of multimodal benchmarks and models tailored for the telecom domain. The benchmark introduces various tasks (both text based and image based) that address various practical real-life use cases such as network operations, network management, improving documentation quality, and retrieval of relevant text and images. Further, we perform baseline experiments with various LLMs and VLMs. The models fine-tuned on our dataset exhibit a significant boost in performance. Our experiments also help analyze the weak areas in the working of current state-of-art multimodal LLMs, thus guiding towards further development and research.",
    "published": "2025-11-17T08:34:41Z",
    "updated": "2025-11-17T08:34:41Z",
    "link": "http://arxiv.org/pdf/2511.13131v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "cs.ET",
      "cs.NI"
    ],
    "authors": [
      "Gagan Raj Gupta",
      "Anshul Kumar",
      "Manish Rai",
      "Apu Chakraborty",
      "Ashutosh Modi",
      "Abdelaali Chaoub",
      "Soumajit Pramanik",
      "Moyank Giri",
      "Yashwanth Holla",
      "Sunny Kumar",
      "M. V. Kiran Sooraj"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.03138v4",
    "title": "DeepKnown-Guard: A Proprietary Model-Based Safety Response Framework for AI Agents",
    "summary": "With the widespread application of Large Language Models (LLMs), their associated security issues have become increasingly prominent, severely constraining their trustworthy deployment in critical domains. This paper proposes a novel safety response framework designed to systematically safeguard LLMs at both the input and output levels. At the input level, the framework employs a supervised fine-tuning-based safety classification model. Through a fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused Attention), it performs precise risk identification and differentiated handling of user queries, significantly enhancing risk coverage and business scenario adaptability, and achieving a risk recall rate of 99.3%. At the output level, the framework integrates Retrieval-Augmented Generation (RAG) with a specifically fine-tuned interpretation model, ensuring all responses are grounded in a real-time, trustworthy knowledge base. This approach eliminates information fabrication and enables result traceability. Experimental results demonstrate that our proposed safety control model achieves a significantly higher safety score on public safety evaluation benchmarks compared to the baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk test set, the framework's components attained a perfect 100% safety score, validating their exceptional protective capabilities in complex risk scenarios. This research provides an effective engineering pathway for building high-security, high-trust LLM applications.",
    "published": "2025-11-05T03:04:35Z",
    "updated": "2025-11-17T08:32:02Z",
    "link": "http://arxiv.org/pdf/2511.03138v4.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Qi Li",
      "Jianjun Xu",
      "Pingtao Wei",
      "Jiu Li",
      "Peiqiang Zhao",
      "Jiwei Shi",
      "Xuan Zhang",
      "Yanhui Yang",
      "Xiaodong Hui",
      "Peng Xu",
      "Wenqin Shao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.13537v2",
    "title": "Competence-Aware AI Agents with Metacognition for Unknown Situations and Environments (MUSE)",
    "summary": "Metacognition, defined as the awareness and regulation of one's cognitive processes, is central to human adaptability in unknown situations. In contrast, current autonomous agents often struggle in novel environments due to their limited capacity for adaptation. We hypothesize that metacognition is a critical missing ingredient in autonomous agents for the cognitive flexibility needed to tackle unfamiliar challenges. Given the broad scope of metacognitive abilities, we focus on competence awareness and strategy selection. To this end, we propose the Metacognition for Unknown Situations and Environments (MUSE) framework to integrate metacognitive processes of self-assessment and self-regulation into autonomous agents. We present two implementations of MUSE: one based on world modeling and another leveraging large language models (LLMs). Our system continually learns to assess its competence on a given task and uses this self-assessment to guide iterative cycles of strategy selection. MUSE agents demonstrate high competence awareness and significant improvements in self-regulation for solving novel, out-of-distribution tasks more effectively compared to model-based reinforcement learning and purely prompt-based LLM agent approaches. This work highlights the promise of approaches inspired by cognitive and neural systems in enabling autonomous agents to adapt to new environments while mitigating the heavy reliance on extensive training data and large models for the current models.",
    "published": "2024-11-20T18:41:03Z",
    "updated": "2025-11-17T08:25:53Z",
    "link": "http://arxiv.org/pdf/2411.13537v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Rodolfo Valiente",
      "Praveen K. Pilly"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13118v1",
    "title": "Extracting Events Like Code: A Multi-Agent Programming Framework for Zero-Shot Event Extraction",
    "summary": "Zero-shot event extraction (ZSEE) remains a significant challenge for large language models (LLMs) due to the need for complex reasoning and domain-specific understanding. Direct prompting often yields incomplete or structurally invalid outputs--such as misclassified triggers, missing arguments, and schema violations. To address these limitations, we present Agent-Event-Coder (AEC), a novel multi-agent framework that treats event extraction like software engineering: as a structured, iterative code-generation process. AEC decomposes ZSEE into specialized subtasks--retrieval, planning, coding, and verification--each handled by a dedicated LLM agent. Event schemas are represented as executable class definitions, enabling deterministic validation and precise feedback via a verification agent. This programming-inspired approach allows for systematic disambiguation and schema enforcement through iterative refinement. By leveraging collaborative agent workflows, AEC enables LLMs to produce precise, complete, and schema-consistent extractions in zero-shot settings. Experiments across five diverse domains and six LLMs demonstrate that AEC consistently outperforms prior zero-shot baselines, showcasing the power of treating event extraction like code generation. The code and data are released on https://github.com/UESTC-GQJ/Agent-Event-Coder.",
    "published": "2025-11-17T08:17:15Z",
    "updated": "2025-11-17T08:17:15Z",
    "link": "http://arxiv.org/pdf/2511.13118v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Quanjiang Guo",
      "Sijie Wang",
      "Jinchuan Zhang",
      "Ben Zhang",
      "Zhao Kang",
      "Ling Tian",
      "Ke Yan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13116v1",
    "title": "Synthetic Forgetting without Access: A Few-shot Zero-glance Framework for Machine Unlearning",
    "summary": "Machine unlearning aims to eliminate the influence of specific data from trained models to ensure privacy compliance. However, most existing methods assume full access to the original training dataset, which is often impractical. We address a more realistic yet challenging setting: few-shot zero-glance, where only a small subset of the retained data is available and the forget set is entirely inaccessible. We introduce GFOES, a novel framework comprising a Generative Feedback Network (GFN) and a two-phase fine-tuning procedure. GFN synthesises Optimal Erasure Samples (OES), which induce high loss on target classes, enabling the model to forget class-specific knowledge without access to the original forget data, while preserving performance on retained classes. The two-phase fine-tuning procedure enables aggressive forgetting in the first phase, followed by utility restoration in the second. Experiments on three image classification datasets demonstrate that GFOES achieves effective forgetting at both logit and representation levels, while maintaining strong performance using only 5% of the original data. Our framework offers a practical and scalable solution for privacy-preserving machine learning under data-constrained conditions.",
    "published": "2025-11-17T08:16:08Z",
    "updated": "2025-11-17T08:16:08Z",
    "link": "http://arxiv.org/pdf/2511.13116v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Qipeng Song",
      "Nan Yang",
      "Ziqi Xu",
      "Yue Li",
      "Wei Shao",
      "Feng Xia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.07015v2",
    "title": "Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach",
    "summary": "The implicit hitting set (IHS) approach offers a general framework for solving computationally hard combinatorial optimization problems declaratively. IHS iterates between a decision oracle used for extracting sources of inconsistency and an optimizer for computing so-called hitting sets (HSs) over the accumulated sources of inconsistency. While the decision oracle is language-specific, the optimizers is usually instantiated through integer programming.\n  We explore alternative algorithmic techniques for hitting set optimization based on different ways of employing pseudo-Boolean (PB) reasoning as well as stochastic local search. We extensively evaluate the practical feasibility of the alternatives in particular in the context of pseudo-Boolean (0-1 IP) optimization as one of the most recent instantiations of IHS. Highlighting a trade-off between efficiency and reliability, while a commercial IP solver turns out to remain the most effective way to instantiate HS computations, it can cause correctness issues due to numerical instability; in fact, we show that exact HS computations instantiated via PB reasoning can be made competitive with a numerically exact IP solver. Furthermore, the use of PB reasoning as a basis for HS computations allows for obtaining certificates for the correctness of IHS computations, generally applicable to any IHS instantiation in which reasoning in the declarative language at hand can be captured in the PB-based proof format we employ.",
    "published": "2025-08-09T15:27:36Z",
    "updated": "2025-11-17T08:14:51Z",
    "link": "http://arxiv.org/pdf/2508.07015v2.pdf",
    "category": [
      "cs.AI",
      "cs.DS"
    ],
    "authors": [
      "Hannes Ihalainen",
      "Dieter Vandesande",
      "André Schidler",
      "Jeremias Berg",
      "Bart Bogaerts",
      "Matti Järvisalo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13111v1",
    "title": "NuBench: An Open Benchmark for Deep Learning-Based Event Reconstruction in Neutrino Telescopes",
    "summary": "Neutrino telescopes are large-scale detectors designed to observe Cherenkov radiation produced from neutrino interactions in water or ice. They exist to identify extraterrestrial neutrino sources and to probe fundamental questions pertaining to the elusive neutrino itself. A central challenge common across neutrino telescopes is to solve a series of inverse problems known as event reconstruction, which seeks to resolve properties of the incident neutrino, based on the detected Cherenkov light. In recent times, significant efforts have been made in adapting advances from deep learning research to event reconstruction, as such techniques provide several benefits over traditional methods. While a large degree of similarity in reconstruction needs and low-level data exists, cross-experimental collaboration has been hindered by a lack of diverse open-source datasets for comparing methods.\n  We present NuBench, an open benchmark for deep learning-based event reconstruction in neutrino telescopes. NuBench comprises seven large-scale simulated datasets containing nearly 130 million charged- and neutral-current muon-neutrino interactions spanning 10 GeV to 100 TeV, generated across six detector geometries inspired by existing and proposed experiments. These datasets provide pulse- and event-level information suitable for developing and comparing machine-learning reconstruction methods in both water and ice environments. Using NuBench, we evaluate four reconstruction algorithms - ParticleNeT and DynEdge, both actively used within the KM3NeT and IceCube collaborations, respectively, along with GRIT and DeepIce - on up to five core tasks: energy and direction reconstruction, topology classification, interaction vertex prediction, and inelasticity estimation.",
    "published": "2025-11-17T08:08:01Z",
    "updated": "2025-11-17T08:08:01Z",
    "link": "http://arxiv.org/pdf/2511.13111v1.pdf",
    "category": [
      "hep-ex",
      "cs.AI",
      "cs.LG",
      "physics.data-an",
      "physics.ins-det"
    ],
    "authors": [
      "Rasmus F. Orsoe",
      "Stephan Meighen-Berger",
      "Jeffrey Lazar",
      "Jorge Prado",
      "Ivan Mozun-Mateo",
      "Aske Rosted",
      "Philip Weigel",
      "Arturo Llorente Anaya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09287v2",
    "title": "From Model Training to Model Raising",
    "summary": "Current AI training methods align models with human values only after their core capabilities have been established, resulting in models that are easily misaligned and lack deep-rooted value systems. We propose a paradigm shift from \"model training\" to \"model raising\", in which alignment is woven into a model's development from the start. We identify several key components for this paradigm, all centered around redesigning the training corpus: reframing training data from a first-person perspective, recontextualizing information as lived experience, simulating social interactions, and scaffolding the ordering of training data. We expect that this redesign of the training corpus will lead to an early commitment to values from the first training token onward, such that knowledge, skills, and values are intrinsically much harder to separate. In an ecosystem in which large language model capabilities start overtaking human capabilities in many tasks, this seems to us like a critical need.",
    "published": "2025-11-12T12:54:35Z",
    "updated": "2025-11-17T08:02:44Z",
    "link": "http://arxiv.org/pdf/2511.09287v2.pdf",
    "category": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "authors": [
      "Roland Aydin",
      "Christian Cyron",
      "Steve Bachelor",
      "Ashton Anderson",
      "Robert West"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25327v4",
    "title": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding",
    "summary": "Real-time multimodal inference on resource-constrained edge devices is essential for applications such as autonomous driving, human-computer interaction, and mobile health. However, prior work often overlooks the tight coupling between sensing dynamics and model execution, as well as the complex inter-modality dependencies. In this paper, we propose MMEdge, an new on-device multi-modal inference framework based on pipelined sensing and encoding. Instead of waiting for complete sensor inputs, MMEdge decomposes the entire inference process into a sequence of fine-grained sensing and encoding units, allowing computation to proceed incrementally as data arrive. MMEdge also introduces a lightweight but effective temporal aggregation module that captures rich temporal dynamics across different pipelined units to maintain accuracy performance. Such pipelined design also opens up opportunities for fine-grained cross-modal optimization and early decision-making during inference. To further enhance system performance under resource variability and input data complexity, MMEdge incorporates an adaptive multimodal configuration optimizer that dynamically selects optimal sensing and model configurations for each modality under latency constraints, and a cross-modal speculative skipping mechanism that bypasses future units of slower modalities when early predictions reach sufficient confidence. We evaluate MMEdge using two public multimodal datasets and deploy it on a real-world unmanned aerial vehicle (UAV)-based multimodal testbed. The results show that MMEdge significantly reduces end-to-end latency while maintaining high task accuracy across various system and data dynamics.",
    "published": "2025-10-29T09:41:03Z",
    "updated": "2025-11-17T08:01:11Z",
    "link": "http://arxiv.org/pdf/2510.25327v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Runxi Huang",
      "Mingxuan Yu",
      "Mingyu Tsoi",
      "Xiaomin Ouyang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.04614v2",
    "title": "Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error Diagnosis in GUI Automation",
    "summary": "In recent years, Multimodal Large Language Models (MLLMs) have been extensively utilized for multimodal reasoning tasks, including Graphical User Interface (GUI) automation. Unlike general offline multimodal tasks, GUI automation is executed in online interactive environments, necessitating step-by-step decision-making based on real-time status of the environment. This task has a lower tolerance for decision-making errors at each step, as any mistakes may cumulatively disrupt the process and potentially lead to irreversible outcomes like deletions or payments. To address these issues, we introduce a pre-operative critic mechanism that provides effective feedback prior to the actual execution, by reasoning about the potential outcome and correctness of actions. Specifically, we propose a Suggestion-aware Gradient Relative Policy Optimization (S-GRPO) strategy to construct our pre-operative critic model GUI-Critic-R1, incorporating a novel suggestion reward to enhance the reliability of the model's feedback. Furthermore, we develop a reasoning-bootstrapping based data collection pipeline to create a GUI-Critic-Train and a GUI-Critic-Test, filling existing gaps in GUI critic data. Static experiments on the GUI-Critic-Test across both mobile and web domains reveal that our GUI-Critic-R1 offers significant advantages in critic accuracy compared to current MLLMs. Dynamic evaluation on GUI automation benchmark further highlights the effectiveness and superiority of our model, as evidenced by improved success rates and operational efficiency.",
    "published": "2025-06-05T04:12:36Z",
    "updated": "2025-11-17T07:48:59Z",
    "link": "http://arxiv.org/pdf/2506.04614v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yuyang Wanyan",
      "Xi Zhang",
      "Haiyang Xu",
      "Haowei Liu",
      "Junyang Wang",
      "Jiabo Ye",
      "Yutong Kou",
      "Ming Yan",
      "Fei Huang",
      "Xiaoshan Yang",
      "Weiming Dong",
      "Changsheng Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13091v1",
    "title": "STEP: Success-Rate-Aware Trajectory-Efficient Policy Optimization",
    "summary": "Multi-turn interaction remains challenging for online reinforcement learning. A common solution is trajectory-level optimization, which treats each trajectory as a single training sample. However, this approach can be inefficient and yield misleading learning signals: it applies uniform sampling across tasks regardless of difficulty, penalizes correct intermediate actions in failed trajectories, and incurs high sample-collection costs. To address these issues, we propose STEP (Success-rate-aware Trajectory-Efficient Policy optimization), a framework that dynamically allocates sampling based on per-task success rates and performs step-level optimization. STEP maintains a smoothed success-rate record to guide adaptive trajectory resampling, allocating more effort to harder tasks. It then computes success-rate-weighted advantages and decomposes trajectories into step-level samples. Finally, it applies a step-level GRPO augmentation to refine updates for low-success tasks. Experiments on OSWorld and AndroidWorld show that STEP substantially improves sample efficiency and training stability over trajectory-level GRPO, converging faster and generalizing better under the same sampling budget.",
    "published": "2025-11-17T07:43:15Z",
    "updated": "2025-11-17T07:43:15Z",
    "link": "http://arxiv.org/pdf/2511.13091v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Yuhan Chen",
      "Yuxuan Liu",
      "Long Zhang",
      "Pengzhi Gao",
      "Jian Luan",
      "Wei Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.01891v2",
    "title": "Multi-Personality Generation of LLMs at Decoding-time",
    "summary": "Multi-personality generation for LLMs, enabling simultaneous embodiment of multiple personalization attributes, is a fundamental challenge. Existing retraining-based approaches are costly and poorly scalable, while decoding-time methods often rely on external models or heuristics, limiting flexibility and robustness. In this paper, we propose a novel Multi-Personality Generation (MPG) framework under the decoding-time combination paradigm. It flexibly controls multi-personality without relying on scarce multi-dimensional models or extra training, leveraging implicit density ratios in single-dimensional models as a \"free lunch\" to reformulate the task as sampling from a target strategy aggregating these ratios. To implement MPG efficiently, we design Speculative Chunk-level based Rejection sampling (SCR), which generates responses in chunks and parallelly validates them via estimated thresholds within a sliding window. This significantly reduces computational overhead while maintaining high-quality generation. Experiments on MBTI personality and Role-Playing demonstrate the effectiveness of MPG, showing improvements up to 16%-18%. Code and data are available at https://github.com/Libra117/MPG .",
    "published": "2025-10-27T09:45:11Z",
    "updated": "2025-11-17T07:41:03Z",
    "link": "http://arxiv.org/pdf/2511.01891v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Rongxin Chen",
      "Yunfan Li",
      "Yige Yuan",
      "Bingbing Xu",
      "Huawei Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13087v1",
    "title": "MEGA-GUI: Multi-stage Enhanced Grounding Agents for GUI Elements",
    "summary": "Graphical User Interface (GUI) grounding - the task of mapping natural language instructions to screen coordinates - is essential for autonomous agents and accessibility technologies. Existing systems rely on monolithic models or one-shot pipelines that lack modularity and fail under visual clutter and ambiguous instructions. We introduce MEGA-GUI, a multi-stage framework that separates grounding into coarse Region-of-Interest (ROI) selection and fine-grained element grounding, orchestrated by specialized vision-language agents. MEGA-GUI features a bidirectional ROI zoom algorithm that mitigates spatial dilution and a context-aware rewriting agent that reduces semantic ambiguity. Our analysis reveals complementary strengths and weaknesses across vision-language models at different visual scales, and we show that leveraging this modular structure achieves consistently higher accuracy than monolithic approaches. On the visually dense ScreenSpot-Pro benchmark, MEGA-GUI attains 73.18% accuracy, and on the semantically complex OSWorld-G benchmark it reaches 68.63%, surpassing previously reported results. Code and the Grounding Benchmark Toolkit (GBT) are available at https://github.com/samsungsds-research-papers/mega-gui.",
    "published": "2025-11-17T07:38:05Z",
    "updated": "2025-11-17T07:38:05Z",
    "link": "http://arxiv.org/pdf/2511.13087v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "SeokJoo Kwak",
      "Jihoon Kim",
      "Boyoun Kim",
      "Jung Jae Yoon",
      "Wooseok Jang",
      "Jeonghoon Hong",
      "Jaeho Yang",
      "Yeong-Dae Kwon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.14902v2",
    "title": "PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths",
    "summary": "Retrieval-augmented generation (RAG) improves the response quality of large language models (LLMs) by retrieving knowledge from external databases. Typical RAG approaches split the text database into chunks, organizing them in a flat structure for efficient searches. To better capture the inherent dependencies and structured relationships across the text database, researchers propose to organize textual information into an indexing graph, known asgraph-based RAG. However, we argue that the limitation of current graph-based RAG methods lies in the redundancy of the retrieved information, rather than its insufficiency. Moreover, previous methods use a flat structure to organize retrieved information within the prompts, leading to suboptimal performance. To overcome these limitations, we propose PathRAG, which retrieves key relational paths from the indexing graph, and converts these paths into textual form for prompting LLMs. Specifically, PathRAG effectively reduces redundant information with flow-based pruning, while guiding LLMs to generate more logical and coherent responses with path-based prompting. Experimental results show that PathRAG consistently outperforms state-of-the-art baselines across six datasets and five evaluation dimensions. The code is available at the following link: https://github.com/BUPT-GAMMA/PathRAG",
    "published": "2025-02-18T11:18:55Z",
    "updated": "2025-11-17T07:34:24Z",
    "link": "http://arxiv.org/pdf/2502.14902v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "authors": [
      "Boyu Chen",
      "Zirui Guo",
      "Zidan Yang",
      "Yuluo Chen",
      "Junze Chen",
      "Zhenghao Liu",
      "Chuan Shi",
      "Cheng Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21895v2",
    "title": "SineLoRA$Δ$: Sine-Activated Delta Compression",
    "summary": "Resource-constrained weight deployment is a task of immense practical importance. Recently, there has been interest in the specific task of \\textit{Delta Compression}, where parties each hold a common base model and only communicate compressed weight updates. However, popular parameter efficient updates such as Low Rank Adaptation (LoRA) face inherent representation limitations - which are especially pronounced when combined with aggressive quantization. To overcome this, we build on recent work that improves LoRA representation capacity by using fixed-frequency sinusoidal functions to increase stable rank without adding additional parameters. We extend this to the quantized setting and present the first theoretical analysis showing how stable rank evolves under quantization. From this, we introduce SineLoRA$Δ$, a principled and effective method for delta compression that improves the expressivity of quantized low-rank adapters by applying a sinusoidal activation. We validate SineLoRA$Δ$ across a diverse variety of domains - including language modeling, vision-language tasks, and text-to-image generation - achieving up to 66% memory reduction with similar performance. We additionally provide a novel application of the canonical Bjøntegaard Delta metric to consistently compare adapter compression changes across the rate-distortion curve.",
    "published": "2025-05-28T02:15:15Z",
    "updated": "2025-11-17T07:29:52Z",
    "link": "http://arxiv.org/pdf/2505.21895v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Cameron Gordon",
      "Yiping Ji",
      "Hemanth Saratchandran",
      "Paul Albert",
      "Simon Lucey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13081v1",
    "title": "Rethinking Saliency Maps: A Cognitive Human Aligned Taxonomy and Evaluation Framework for Explanations",
    "summary": "Saliency maps are widely used for visual explanations in deep learning, but a fundamental lack of consensus persists regarding their intended purpose and alignment with diverse user queries. This ambiguity hinders the effective evaluation and practical utility of explanation methods.We address this gap by introducing the Reference-Frame $\\times$ Granularity (RFxG) taxonomy, a principled conceptual framework that organizes saliency explanations along two essential axes:Reference-Frame: Distinguishing between pointwise (\"Why this prediction?\") and contrastive (\"Why this and not an alternative?\") explanations.Granularity: Ranging from fine-grained class-level (e.g., \"Why Husky?\") to coarse-grained group-level (e.g., \"Why Dog?\") interpretations.Using the RFxG lens, we demonstrate critical limitations in existing evaluation metrics, which overwhelmingly prioritize pointwise faithfulness while neglecting contrastive reasoning and semantic granularity. To systematically assess explanation quality across both RFxG dimensions, we propose four novel faithfulness metrics. Our comprehensive evaluation framework applies these metrics to ten state-of-the-art saliency methods, four model architectures, and three datasets.By advocating a shift toward user-intent-driven evaluation, our work provides both the conceptual foundation and the practical tools necessary to develop visual explanations that are not only faithful to the underlying model behavior but are also meaningfully aligned with the complexity of human understanding and inquiry.",
    "published": "2025-11-17T07:29:25Z",
    "updated": "2025-11-17T07:29:25Z",
    "link": "http://arxiv.org/pdf/2511.13081v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yehonatan Elisha",
      "Seffi Cohen",
      "Oren Barkan",
      "Noam Koenigstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.12440v2",
    "title": "MedFact: Benchmarking the Fact-Checking Capabilities of Large Language Models on Chinese Medical Texts",
    "summary": "Deploying Large Language Models (LLMs) in medical applications requires fact-checking capabilities to ensure patient safety and regulatory compliance. We introduce MedFact, a challenging Chinese medical fact-checking benchmark with 2,116 expert-annotated instances from diverse real-world texts, spanning 13 specialties, 8 error types, 4 writing styles, and 5 difficulty levels. Construction uses a hybrid AI-human framework where iterative expert feedback refines AI-driven, multi-criteria filtering to ensure high quality and difficulty. We evaluate 20 leading LLMs on veracity classification and error localization, and results show models often determine if text contains errors but struggle to localize them precisely, with top performers falling short of human performance. Our analysis reveals the \"over-criticism\" phenomenon, a tendency for models to misidentify correct information as erroneous, which can be exacerbated by advanced reasoning techniques such as multi-agent collaboration and inference-time scaling. MedFact highlights the challenges of deploying medical LLMs and provides resources to develop factually reliable medical AI systems.",
    "published": "2025-09-15T20:46:21Z",
    "updated": "2025-11-17T07:14:45Z",
    "link": "http://arxiv.org/pdf/2509.12440v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jiayi He",
      "Yangmin Huang",
      "Qianyun Du",
      "Xiangying Zhou",
      "Zhiyang He",
      "Jiaxue Hu",
      "Xiaodong Tao",
      "Lixian Lai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13062v1",
    "title": "Self-Adaptive Graph Mixture of Models",
    "summary": "Graph Neural Networks (GNNs) have emerged as powerful tools for learning over graph-structured data, yet recent studies have shown that their performance gains are beginning to plateau. In many cases, well-established models such as GCN and GAT, when appropriately tuned, can match or even exceed the performance of more complex, state-of-the-art architectures. This trend highlights a key limitation in the current landscape: the difficulty of selecting the most suitable model for a given graph task or dataset. To address this, we propose Self-Adaptive Graph Mixture of Models (SAGMM), a modular and practical framework that learns to automatically select and combine the most appropriate GNN models from a diverse pool of architectures. Unlike prior mixture-of-experts approaches that rely on variations of a single base model, SAGMM leverages architectural diversity and a topology-aware attention gating mechanism to adaptively assign experts to each node based on the structure of the input graph. To improve efficiency, SAGMM includes a pruning mechanism that reduces the number of active experts during training and inference without compromising performance. We also explore a training-efficient variant in which expert models are pretrained and frozen, and only the gating and task-specific layers are trained. We evaluate SAGMM on 16 benchmark datasets covering node classification, graph classification, regression, and link prediction tasks, and demonstrate that it consistently outperforms or matches leading GNN baselines and prior mixture-based methods, offering a robust and adaptive solution for real-world graph learning.",
    "published": "2025-11-17T07:11:06Z",
    "updated": "2025-11-17T07:11:06Z",
    "link": "http://arxiv.org/pdf/2511.13062v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mohit Meena",
      "Yash Punjabi",
      "Abhishek A",
      "Vishal Sharma",
      "Mahesh Chandran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13061v1",
    "title": "MACKO: Sparse Matrix-Vector Multiplication for Low Sparsity",
    "summary": "Sparse Matrix-Vector Multiplication (SpMV) is a fundamental operation in the inference of sparse Large Language Models (LLMs). Because existing SpMV methods perform poorly under the low and unstructured sparsity (30-90%) commonly observed in pruned LLMs, unstructured pruning provided only limited memory reduction and speedup. We propose MACKO-SpMV, a GPU-optimized format and kernel co-designed to reduce storage overhead while preserving compatibility with the GPU's execution model. This enables efficient SpMV for unstructured sparsity without specialized hardware units (e.g., tensor cores) or format-specific precomputation. Empirical results show that at sparsity 50%, MACKO is the first approach with significant 1.5x memory reduction and 1.2-1.5x speedup over dense representation. Speedups over other SpMV baselines: 2.8-13.0x over cuSPARSE, 1.9-2.6x over Sputnik, and 2.2-2.5x over DASP. Applied to Llama2-7B pruned with Wanda to sparsity 50%, it delivers 1.5x memory reduction and 1.5x faster inference at fp16 precision. Thanks to MACKO, unstructured pruning at 50% sparsity is now justified in real-world LLM workloads.",
    "published": "2025-11-17T07:10:37Z",
    "updated": "2025-11-17T07:10:37Z",
    "link": "http://arxiv.org/pdf/2511.13061v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.DS"
    ],
    "authors": [
      "Vladimír Macko",
      "Vladimír Boža"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13060v1",
    "title": "Latency and Ordering Effects in Online Decisions",
    "summary": "Online decision systems routinely operate under delayed feedback and order-sensitive (noncommutative) dynamics: actions affect which observations arrive, and in what sequence. Taking a Bregman divergence $D_Φ$ as the loss benchmark, we prove that the excess benchmark loss admits a structured lower bound $L \\ge L_{\\mathrm{ideal}} + g_1(λ) + g_2(\\varepsilon_\\star) + g_{12}(λ,\\varepsilon_\\star) - D_{\\mathrm{ncx}}$, where $g_1$ and $g_2$ are calibrated penalties for latency and order-sensitivity, $g_{12}$ captures their geometric interaction, and $D_{\\mathrm{ncx}}\\ge 0$ is a nonconvexity/approximation penalty that vanishes under convex Legendre assumptions. We extend this inequality to prox-regular and weakly convex settings, obtaining robust guarantees beyond the convex case. We also give an operational recipe for estimating and monitoring the four terms via simple $2\\times 2$ randomized experiments and streaming diagnostics (effective sample size, clipping rate, interaction heatmaps). The framework packages heterogeneous latency, noncommutativity, and implementation-gap effects into a single interpretable lower-bound statement that can be stress-tested and tuned in real-world systems.",
    "published": "2025-11-17T07:08:05Z",
    "updated": "2025-11-17T07:08:05Z",
    "link": "http://arxiv.org/pdf/2511.13060v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Duo Yi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.12638v2",
    "title": "edgeVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer",
    "summary": "Vision-Language Models (VLMs) are increasingly deployed in real-time applications such as autonomous driving and human-computer interaction, which demand fast and reliable responses based on accurate perception. To meet these requirements, existing systems commonly employ cloud-edge collaborative architectures, such as partitioned Large Vision-Language Models (LVLMs) or task offloading strategies between Large and Small Vision-Language Models (SVLMs). However, these methods fail to accommodate cloud latency fluctuations and overlook the full potential of delayed but accurate LVLM responses. In this work, we propose a novel cloud-edge collaborative paradigm for VLMs, termed Context Transfer, which treats the delayed outputs of LVLMs as historical context to provide real-time guidance for SVLMs inference. Based on this paradigm, we design edgeVLM, which incorporates both context replacement and visual focus modules to refine historical textual input and enhance visual grounding consistency. Extensive experiments on three real-time vision-lanuage reasoning tasks across four datasets demonstrate the effectiveness of the proposed framework. The new paradigm lays the groundwork for more effective and latency-aware collaboration strategies in future VLM systems.",
    "published": "2025-08-18T05:51:41Z",
    "updated": "2025-11-17T07:07:21Z",
    "link": "http://arxiv.org/pdf/2508.12638v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Chen Qian",
      "Xinran Yu",
      "Zewen Huang",
      "Danyang Li",
      "Qiang Ma",
      "Fan Dang",
      "Xuan Ding",
      "Guangyong Shang",
      "Zheng Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13057v1",
    "title": "Dimension vs. Precision: A Comparative Analysis of Autoencoders and Quantization for Efficient Vector Retrieval on BEIR SciFact",
    "summary": "Dense retrieval models have become a standard for state-of-the-art information retrieval. However, their high-dimensional, high-precision (float32) vector embeddings create significant storage and memory challenges for real-world deployment. To address this, we conduct a rigorous empirical study on the BEIR SciFact benchmark, evaluating the trade-offs between two primary compression strategies: (1) Dimensionality Reduction via deep Autoencoders (AE), reducing original 384-dim vectors to latent spaces from 384 down to 12, and (2) Precision Reduction via Quantization (float16, int8, and binary). We systematically compare each method by measuring the \"performance loss\" (or gain) relative to a float32 baseline across a full suite of retrieval metrics (NDCG, MAP, MRR, Recall, Precision) at various k cutoffs. Our results show that int8 scalar quantization provides the most effective \"sweet spot,\" achieving a 4x compression with a negligible [~1-2%] drop in nDCG@10. In contrast, Autoencoders show a graceful degradation but suffer a more significant performance loss at equivalent 4x compression ratios (AE-96). binary quantization was found to be unsuitable for this task due to catastrophic performance drops. This work provides a practical guide for deploying efficient, high-performance retrieval systems.",
    "published": "2025-11-17T07:02:11Z",
    "updated": "2025-11-17T07:02:11Z",
    "link": "http://arxiv.org/pdf/2511.13057v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Satyanarayan Pati"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.14830v2",
    "title": "Identify As A Human Does: A Pathfinder of Next-Generation Anti-Cheat Framework for First-Person Shooter Games",
    "summary": "The gaming industry has experienced substantial growth, but cheating in online games poses a significant threat to the integrity of the gaming experience. Cheating, particularly in first-person shooter (FPS) games, can lead to substantial losses for the game industry. Existing anti-cheat solutions have limitations, such as client-side hardware constraints, security risks, server-side unreliable methods, and both-sides suffer from a lack of comprehensive real-world datasets. To address these limitations, the paper proposes HAWK, a server-side FPS anti-cheat framework for the popular game CS:GO. HAWK utilizes machine learning techniques to mimic human experts' identification process, leverages novel multi-view features, and it is equipped with a well-defined workflow. The authors evaluate HAWK with the first large and real-world datasets containing multiple cheat types and cheating sophistication, and it exhibits promising efficiency and acceptable overheads, shorter ban times compared to the in-use anti-cheat, a significant reduction in manual labor, and the ability to capture cheaters who evaded official inspections.",
    "published": "2024-09-23T09:00:07Z",
    "updated": "2025-11-17T06:59:11Z",
    "link": "http://arxiv.org/pdf/2409.14830v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "authors": [
      "Jiayi Zhang",
      "Chenxin Sun",
      "Yue Gu",
      "Qingyu Zhang",
      "Jiayi Lin",
      "Xiaojiang Du",
      "Chenxiong Qian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13052v1",
    "title": "Learning from the Undesirable: Robust Adaptation of Language Models without Forgetting",
    "summary": "Language models (LMs) are often adapted through supervised fine-tuning (SFT) to specialize their capabilities for downstream tasks. However, in typical scenarios where the fine-tuning data is limited, e.g., compared to pre-training, SFT can lead LMs to overfit, causing them to rely on spurious patterns within the target task or to compromise other broadly useful capabilities as a side effect of narrow specialization. In this paper, we propose Learning-from-the-Undesirable (LfU), a simple yet effective regularization scheme for SFT to mitigate overfitting issues when fine-tuning LMs with limited data. Specifically, we aim to regularize the fine-tuning process to favor solutions that are resilient to \"undesirable\" model updates, e.g., gradient ascent steps that steer the model toward undesirable behaviors. To this end, we propose a novel form of consistency regularization that directly aligns internal representations of the model with those after an undesirable update. By leveraging representation-level data augmentation through undesirable updates, LfU effectively promotes generalization under limited data. Our experiments on diverse LM downstream tasks show that LfU serves as an effective prior that enhances adaptability while preserving pretrained knowledge. For example, our LM from LfU achieves a 16.8% average improvement on math tasks compared to vanilla SFT on the same dataset, where the latter even leads to degraded performance on those tasks. Furthermore, LfU exhibits improved robustness to prompt variations, e.g., yielding a 92.1% lower standard deviation in output performances compared to SFT, highlighting its versatile effects.",
    "published": "2025-11-17T06:57:44Z",
    "updated": "2025-11-17T06:57:44Z",
    "link": "http://arxiv.org/pdf/2511.13052v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yunhun Nam",
      "Jaehyung Kim",
      "Jongheon Jeong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13035v1",
    "title": "One-Step Generative Policies with Q-Learning: A Reformulation of MeanFlow",
    "summary": "We introduce a one-step generative policy for offline reinforcement learning that maps noise directly to actions via a residual reformulation of MeanFlow, making it compatible with Q-learning. While one-step Gaussian policies enable fast inference, they struggle to capture complex, multimodal action distributions. Existing flow-based methods improve expressivity but typically rely on distillation and two-stage training when trained with Q-learning. To overcome these limitations, we propose to reformulate MeanFlow to enable direct noise-to-action generation by integrating the velocity field and noise-to-action transformation into a single policy network-eliminating the need for separate velocity estimation. We explore several reformulation variants and identify an effective residual formulation that supports expressive and stable policy learning. Our method offers three key advantages: 1) efficient one-step noise-to-action generation, 2) expressive modelling of multimodal action distributions, and 3) efficient and stable policy learning via Q-learning in a single-stage training setup. Extensive experiments on 73 tasks across the OGBench and D4RL benchmarks demonstrate that our method achieves strong performance in both offline and offline-to-online reinforcement learning settings. Code is available at https://github.com/HiccupRL/MeanFlowQL.",
    "published": "2025-11-17T06:34:17Z",
    "updated": "2025-11-17T06:34:17Z",
    "link": "http://arxiv.org/pdf/2511.13035v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zeyuan Wang",
      "Da Li",
      "Yulin Chen",
      "Ye Shi",
      "Liang Bai",
      "Tianyuan Yu",
      "Yanwei Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.25230v2",
    "title": "Energy Guided Geometric Flow Matching",
    "summary": "A useful inductive bias for temporal data is that trajectories should stay close to the data manifold. Traditional flow matching relies on straight conditional paths, and flow matching methods which learn geodesics rely on RBF kernels or nearest neighbor graphs that suffer from the curse of dimensionality. We propose to use score matching and annealed energy distillation to learn a metric tensor that faithfully captures the underlying data geometry and informs more accurate flows. We demonstrate the efficacy of this strategy on synthetic manifolds with analytic geodesics, and interpolation of cell",
    "published": "2025-09-25T00:42:28Z",
    "updated": "2025-11-17T06:32:40Z",
    "link": "http://arxiv.org/pdf/2509.25230v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Aaron Zweig",
      "Mingxuan Zhang",
      "Elham Azizi",
      "David Knowles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13029v1",
    "title": "AA-Omniscience: Evaluating Cross-Domain Knowledge Reliability in Large Language Models",
    "summary": "Existing language model evaluations primarily measure general capabilities, yet reliable use of these models across a range of domains demands factual accuracy and recognition of knowledge gaps. We introduce AA-Omniscience, a benchmark designed to measure both factual recall and knowledge calibration across 6,000 questions. Questions are derived from authoritative academic and industry sources, and cover 42 economically relevant topics within six different domains. The evaluation measures a model's Omniscience Index, a bounded metric (-100 to 100) measuring factual recall that jointly penalizes hallucinations and rewards abstention when uncertain, with 0 equating to a model that answers questions correctly as much as it does incorrectly. Among evaluated models, Claude 4.1 Opus attains the highest score (4.8), making it one of only three models to score above zero. These results reveal persistent factuality and calibration weaknesses across frontier models. Performance also varies by domain, with the models from three different research labs leading across the six domains. This performance variability suggests models should be chosen according to the demands of the use case rather than general performance for tasks where knowledge is important.",
    "published": "2025-11-17T06:27:16Z",
    "updated": "2025-11-17T06:27:16Z",
    "link": "http://arxiv.org/pdf/2511.13029v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Declan Jackson",
      "William Keating",
      "George Cameron",
      "Micah Hill-Smith"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13027v1",
    "title": "Scaling Generative Verifiers For Natural Language Mathematical Proof Verification And Selection",
    "summary": "Large language models have achieved remarkable success on final-answer mathematical problems, largely due to the ease of applying reinforcement learning with verifiable rewards. However, the reasoning underlying these solutions is often flawed. Advancing to rigorous proof-based mathematics requires reliable proof verification capabilities. We begin by analyzing multiple evaluation setups and show that focusing on a single benchmark can lead to brittle or misleading conclusions. To address this, we evaluate both proof-based and final-answer reasoning to obtain a more reliable measure of model performance. We then scale two major generative verification methods (GenSelect and LLM-as-a-Judge) to millions of tokens and identify their combination as the most effective framework for solution verification and selection. We further show that the choice of prompt for LLM-as-a-Judge significantly affects the model's performance, but reinforcement learning can reduce this sensitivity. However, despite improving proof-level metrics, reinforcement learning does not enhance final-answer precision, indicating that current models often reward stylistic or procedural correctness rather than mathematical validity. Our results establish practical guidelines for designing and evaluating scalable proof-verification and selection systems.",
    "published": "2025-11-17T06:25:35Z",
    "updated": "2025-11-17T06:25:35Z",
    "link": "http://arxiv.org/pdf/2511.13027v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Sadegh Mahdavi",
      "Branislav Kisacanin",
      "Shubham Toshniwal",
      "Wei Du",
      "Ivan Moshkov",
      "George Armstrong",
      "Renjie Liao",
      "Christos Thrampoulidis",
      "Igor Gitman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13023v1",
    "title": "SLMQuant:Benchmarking Small Language Model Quantization for Practical Deployment",
    "summary": "Despite the growing interest in Small Language Models (SLMs) as resource-efficient alternatives to Large Language Models (LLMs), their deployment on edge devices remains challenging due to unresolved efficiency gaps in model compression. While quantization has proven effective for LLMs, its applicability to SLMs is significantly underexplored, with critical questions about differing quantization bottlenecks and efficiency profiles. This paper introduces SLMQuant, the first systematic benchmark for evaluating LLM compression techniques when applied to SLMs. Through comprehensive multi-track evaluations across diverse architectures and tasks, we analyze how state-of-the-art quantization methods perform on SLMs. Our findings reveal fundamental disparities between SLMs and LLMs in quantization sensitivity, demonstrating that direct transfer of LLM-optimized techniques leads to suboptimal results due to SLMs' unique architectural characteristics and training dynamics. We identify key factors governing effective SLM quantization and propose actionable design principles for SLM-tailored compression. SLMQuant establishes a foundational framework for advancing efficient SLM deployment on low-end devices in edge applications, and provides critical insights for deploying lightweight language models in resource-constrained scenarios.",
    "published": "2025-11-17T06:20:33Z",
    "updated": "2025-11-17T06:20:33Z",
    "link": "http://arxiv.org/pdf/2511.13023v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jiacheng Wang",
      "Yejun Zeng",
      "Jinyang Guo",
      "Yuqing Ma",
      "Aishan Liu",
      "Xianglong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13021v1",
    "title": "PragWorld: A Benchmark Evaluating LLMs' Local World Model under Minimal Linguistic Alterations and Conversational Dynamics",
    "summary": "Real-world conversations are rich with pragmatic elements, such as entity mentions, references, and implicatures. Understanding such nuances is a requirement for successful natural communication, and often requires building a local world model which encodes such elements and captures the dynamics of their evolving states. However, it is not well-understood whether language models (LMs) construct or maintain a robust implicit representation of conversations. In this work, we evaluate the ability of LMs to encode and update their internal world model in dyadic conversations and test their malleability under linguistic alterations. To facilitate this, we apply seven minimal linguistic alterations to conversations sourced from popular datasets and construct two benchmarks comprising yes-no questions. We evaluate a wide range of open and closed source LMs and observe that they struggle to maintain robust accuracy. Our analysis unveils that LMs struggle to memorize crucial details, such as tracking entities under linguistic alterations to conversations. We then propose a dual-perspective interpretability framework which identifies transformer layers that are useful or harmful and highlights linguistic alterations most influenced by harmful layers, typically due to encoding spurious signals or relying on shortcuts. Inspired by these insights, we propose two layer-regularization based fine-tuning strategies that suppress the effect of the harmful layers.",
    "published": "2025-11-17T06:17:17Z",
    "updated": "2025-11-17T06:17:17Z",
    "link": "http://arxiv.org/pdf/2511.13021v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Sachin Vashistha",
      "Aryan Bibhuti",
      "Atharva Naik",
      "Martin Tutek",
      "Somak Aditya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13020v1",
    "title": "SpectralAdapt: Semi-Supervised Domain Adaptation with Spectral Priors for Human-Centered Hyperspectral Image Reconstruction",
    "summary": "Hyperspectral imaging (HSI) holds great potential for healthcare due to its rich spectral information. However, acquiring HSI data remains costly and technically demanding. Hyperspectral image reconstruction offers a practical solution by recovering HSI data from accessible modalities, such as RGB. While general domain datasets are abundant, the scarcity of human HSI data limits progress in medical applications. To tackle this, we propose SpectralAdapt, a semi-supervised domain adaptation (SSDA) framework that bridges the domain gap between general and human-centered HSI datasets. To fully exploit limited labels and abundant unlabeled data, we enhance spectral reasoning by introducing Spectral Density Masking (SDM), which adaptively masks RGB channels based on their spectral complexity, encouraging recovery of informative regions from complementary cues during consistency training. Furthermore, we introduce Spectral Endmember Representation Alignment (SERA), which derives physically interpretable endmembers from valuable labeled pixels and employs them as domain-invariant anchors to guide unlabeled predictions, with momentum updates ensuring adaptability and stability. These components are seamlessly integrated into SpectralAdapt, a spectral prior-guided framework that effectively mitigates domain shift, spectral degradation, and data scarcity in HSI reconstruction. Experiments on benchmark datasets demonstrate consistent improvements in spectral fidelity, cross-domain generalization, and training stability, highlighting the promise of SSDA as an efficient solution for hyperspectral imaging in healthcare.",
    "published": "2025-11-17T06:17:13Z",
    "updated": "2025-11-17T06:17:13Z",
    "link": "http://arxiv.org/pdf/2511.13020v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yufei Wen",
      "Yuting Zhang",
      "Jingdan Kang",
      "Hao Ren",
      "Weibin Cheng",
      "Jintai Chen",
      "Kaishun Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13019v1",
    "title": "MeanFlow Transformers with Representation Autoencoders",
    "summary": "MeanFlow (MF) is a diffusion-motivated generative model that enables efficient few-step generation by learning long jumps directly from noise to data. In practice, it is often used as a latent MF by leveraging the pre-trained Stable Diffusion variational autoencoder (SD-VAE) for high-dimensional data modeling. However, MF training remains computationally demanding and is often unstable. During inference, the SD-VAE decoder dominates the generation cost, and MF depends on complex guidance hyperparameters for class-conditional generation. In this work, we develop an efficient training and sampling scheme for MF in the latent space of a Representation Autoencoder (RAE), where a pre-trained vision encoder (e.g., DINO) provides semantically rich latents paired with a lightweight decoder. We observe that naive MF training in the RAE latent space suffers from severe gradient explosion. To stabilize and accelerate training, we adopt Consistency Mid-Training for trajectory-aware initialization and use a two-stage scheme: distillation from a pre-trained flow matching teacher to speed convergence and reduce variance, followed by an optional bootstrapping stage with a one-point velocity estimator to further reduce deviation from the oracle mean flow. This design removes the need for guidance, simplifies training configurations, and reduces computation in both training and sampling. Empirically, our method achieves a 1-step FID of 2.03, outperforming vanilla MF's 3.43, while reducing sampling GFLOPS by 38% and total training cost by 83% on ImageNet 256. We further scale our approach to ImageNet 512, achieving a competitive 1-step FID of 3.23 with the lowest GFLOPS among all baselines. Code is available at https://github.com/sony/mf-rae.",
    "published": "2025-11-17T06:17:08Z",
    "updated": "2025-11-17T06:17:08Z",
    "link": "http://arxiv.org/pdf/2511.13019v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zheyuan Hu",
      "Chieh-Hsin Lai",
      "Ge Wu",
      "Yuki Mitsufuji",
      "Stefano Ermon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13010v1",
    "title": "Are Graph Transformers Necessary? Efficient Long-Range Message Passing with Fractal Nodes in MPNNs",
    "summary": "Graph Neural Networks (GNNs) have emerged as powerful tools for learning on graph-structured data, but often struggle to balance local and global information. While graph Transformers aim to address this by enabling long-range interactions, they often overlook the inherent locality and efficiency of Message Passing Neural Networks (MPNNs). We propose a new concept called fractal nodes, inspired by the fractal structure observed in real-world networks. Our approach is based on the intuition that graph partitioning naturally induces fractal structure, where subgraphs often reflect the connectivity patterns of the full graph. Fractal nodes are designed to coexist with the original nodes and adaptively aggregate subgraph-level feature representations, thereby enforcing feature similarity within each subgraph. We show that fractal nodes alleviate the over-squashing problem by providing direct shortcut connections that enable long-range propagation of subgraph-level representations. Experiment results show that our method improves the expressive power of MPNNs and achieves comparable or better performance to graph Transformers while maintaining the computational efficiency of MPNN by improving the long-range dependencies of MPNN.",
    "published": "2025-11-17T06:11:52Z",
    "updated": "2025-11-17T06:11:52Z",
    "link": "http://arxiv.org/pdf/2511.13010v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jeongwhan Choi",
      "Seungjun Park",
      "Sumin Park",
      "Sung-Bae Cho",
      "Noseong Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.13768v3",
    "title": "Evaluation-Driven Development and Operations of LLM Agents: A Process Model and Reference Architecture",
    "summary": "Large Language Models (LLMs) have enabled the emergence of LLM agents, systems capable of pursuing under-specified goals and adapting after deployment. Evaluating such agents is challenging because their behavior is open ended, probabilistic, and shaped by system-level interactions over time. Traditional evaluation methods, built around fixed benchmarks and static test suites, fail to capture emergent behaviors or support continuous adaptation across the lifecycle. To ground a more systematic approach, we conduct a multivocal literature review (MLR) synthesizing academic and industrial evaluation practices. The findings directly inform two empirically derived artifacts: a process model and a reference architecture that embed evaluation as a continuous, governing function rather than a terminal checkpoint. Together they constitute the evaluation-driven development and operations (EDDOps) approach, which unifies offline (development-time) and online (runtime) evaluation within a closed feedback loop. By making evaluation evidence drive both runtime adaptation and governed redevelopment, EDDOps supports safer, more traceable evolution of LLM agents aligned with changing objectives, user needs, and governance constraints.",
    "published": "2024-11-21T00:34:30Z",
    "updated": "2025-11-17T06:10:41Z",
    "link": "http://arxiv.org/pdf/2411.13768v3.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Boming Xia",
      "Qinghua Lu",
      "Liming Zhu",
      "Zhenchang Xing",
      "Dehai Zhao",
      "Hao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.07998v2",
    "title": "Self-Correction Distillation for Structured Data Question Answering",
    "summary": "Structured data question answering (QA), including table QA, Knowledge Graph (KG) QA, and temporal KG QA, is a pivotal research area. Advances in large language models (LLMs) have driven significant progress in unified structural QA frameworks like TrustUQA. However, these frameworks face challenges when applied to small-scale LLMs since small-scale LLMs are prone to errors in generating structured queries. To improve the structured data QA ability of small-scale LLMs, we propose a self-correction distillation (SCD) method. In SCD, an error prompt mechanism (EPM) is designed to detect errors and provide customized error messages during inference, and a two-stage distillation strategy is designed to transfer large-scale LLMs' query-generation and error-correction capabilities to small-scale LLM. Experiments across 5 benchmarks with 3 structured data types demonstrate that our SCD achieves the best performance and superior generalization on small-scale LLM (8B) compared to other distillation methods, and closely approaches the performance of GPT4 on some datasets. Furthermore, large-scale LLMs equipped with EPM surpass the state-of-the-art results on most datasets.",
    "published": "2025-11-11T09:01:51Z",
    "updated": "2025-11-17T06:08:41Z",
    "link": "http://arxiv.org/pdf/2511.07998v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yushan Zhu",
      "Wen Zhang",
      "Long Jin",
      "Mengshu Sun",
      "Ling Zhong",
      "Zhiqiang Liu",
      "Juan Li",
      "Lei Liang",
      "Chong Long",
      "Chao Deng",
      "Junlan Feng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13007v1",
    "title": "GEM: Generative Entropy-Guided Preference Modeling for Few-shot Alignment of LLMs",
    "summary": "Alignment of large language models (LLMs) with human preferences typically relies on supervised reward models or external judges that demand abundant annotations. However, in fields that rely on professional knowledge, such as medicine and law, such large-scale preference labels are often unachievable. In this paper, we propose a generative entropy-guided preference modeling approach named GEM for LLMs aligment at low-resource and domain-specific scenarios. Instead of training a discriminative reward model on preference data, we directly train the LLM to internalize a closed-loop optimization architecture that can extract and exploit the multi-dimensional, fine-grained cognitive signals implicit in human preferences. Specifically, our Cognitive Filtering module, based on entropy theory in decision making, first leverages Chain-of-Thought (CoT) prompting to generate diverse candidate reasoning chains (CoTs) from preference data. Subsequently, it introduces a token scoring mechanism to rank and weight the sampled CoTs, boosting the importance of high-confidence answers and strategically high-entropy tokens. Building on these filtered preferences, we fine-tune the LLM using a novel self-evaluated group advantage algorithm, SEGA, which effectively aggregates group-level cognitive signals and transforms the entropy-based scores into implicit rewards for policy optimization. In these ways, GEM empowers the LLM to rely on its own judgments and establishes an entropy-guided closed-loop cognitive optimization framework, enabling highly efficient few-shot alignment of LLMs. Experiments on general benchmarks and domain-specific tasks (such as mathematical reasoning and medical dialogues) demonstrate that our GEM achieves significant improvements with few-shot preference data.",
    "published": "2025-11-17T06:04:47Z",
    "updated": "2025-11-17T06:04:47Z",
    "link": "http://arxiv.org/pdf/2511.13007v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yiyang Zhao",
      "Huiyu Bai",
      "Xuejiao Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.10210v2",
    "title": "Advanced Black-Box Tuning of Large Language Models with Limited API Calls",
    "summary": "Black-box tuning is an emerging paradigm for adapting large language models (LLMs) to better achieve desired behaviors, particularly when direct access to model parameters is unavailable. Current strategies, however, often present a dilemma of suboptimal extremes: either separately train a small proxy model and then use it to shift the predictions of the foundation model, offering notable efficiency but often yielding limited improvement; or making API calls in each tuning iteration to the foundation model, which entails prohibitive computational costs. Therefore, we propose a novel advanced black-box tuning method for LLMs with limited API calls. Our core strategy involves training a Gaussian Process (GP) surrogate model with \"LogitMap Pairs\" derived from querying the foundation model on a minimal but highly informative training subset. This surrogate can approximate the outputs of the foundation model to guide the training of the proxy model, thereby effectively reducing the need for direct queries to the foundation model. Extensive experiments verify that our approach elevates pre-trained language model accuracy from 55.92% to 86.85%, reducing the frequency of API queries to merely 1.38%. This significantly outperforms offline approaches that operate entirely without API access. Notably, our method also achieves comparable or superior accuracy to query-intensive approaches, while significantly reducing API costs. This offers a robust and high-efficiency paradigm for language model adaptation.",
    "published": "2025-11-13T11:32:08Z",
    "updated": "2025-11-17T05:54:02Z",
    "link": "http://arxiv.org/pdf/2511.10210v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zhikang Xie",
      "Weilin Wan",
      "Peizhu Gong",
      "Weizhong Zhang",
      "Cheng Jin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13005v1",
    "title": "SAGE: Spuriousness-Aware Guided Prompt Exploration for Mitigating Multimodal Bias",
    "summary": "Large vision-language models, such as CLIP, have shown strong zero-shot classification performance by aligning images and text in a shared embedding space. However, CLIP models often develop multimodal spurious biases, which is the undesirable tendency to rely on spurious features. For example, CLIP may infer object types in images based on frequently co-occurring backgrounds rather than the object's core features. This bias significantly impairs the robustness of pre-trained CLIP models on out-of-distribution data, where such cross-modal associations no longer hold. Existing methods for mitigating multimodal spurious bias typically require fine-tuning on downstream data or prior knowledge of the bias, which undermines the out-of-the-box usability of CLIP. In this paper, we first theoretically analyze the impact of multimodal spurious bias in zero-shot classification. Based on this insight, we propose Spuriousness-Aware Guided Exploration (SAGE), a simple and effective method that mitigates spurious bias through guided prompt selection. SAGE requires no training, fine-tuning, or external annotations. It explores a space of prompt templates and selects the prompts that induce the largest semantic separation between classes, thereby improving worst-group robustness. Extensive experiments on four real-world benchmark datasets and five popular backbone models demonstrate that SAGE consistently improves zero-shot performance and generalization, outperforming previous zero-shot approaches without any external knowledge or model updates.",
    "published": "2025-11-17T05:52:32Z",
    "updated": "2025-11-17T05:52:32Z",
    "link": "http://arxiv.org/pdf/2511.13005v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Wenqian Ye",
      "Di Wang",
      "Guangtao Zheng",
      "Bohan Liu",
      "Aidong Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.03238v2",
    "title": "Rethinking Whole-Body CT Image Interpretation: An Abnormality-Centric Approach",
    "summary": "Automated interpretation of CT images-particularly localizing and describing abnormal findings across multi-plane and whole-body scans-remains a significant challenge in clinical radiology. This work aims to address this challenge through four key contributions: (i) On taxonomy, we collaborate with senior radiologists to propose a comprehensive hierarchical classification system, with 404 representative abnormal findings across all body regions; (ii) On data, we contribute a dataset containing over 14.5K CT images from multiple planes and all human body regions, and meticulously provide grounding annotations for over 19K abnormalities, each linked to the detailed description and cast into the taxonomy; (iii) On model development, we propose OmniAbnorm-CT, which can automatically ground and describe abnormal findings on multi-plane and whole-body CT images based on text queries, while also allowing flexible interaction through visual prompts; (iv) On evaluation, we establish three representative tasks based on real clinical scenarios, and introduce a clinically grounded metric to assess abnormality descriptions. Through extensive experiments, we show that OmniAbnorm-CT can significantly outperform existing methods in both internal and external validations, and across all the tasks.",
    "published": "2025-06-03T17:57:34Z",
    "updated": "2025-11-17T05:49:33Z",
    "link": "http://arxiv.org/pdf/2506.03238v2.pdf",
    "category": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Ziheng Zhao",
      "Lisong Dai",
      "Ya Zhang",
      "Yanfeng Wang",
      "Weidi Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16186v2",
    "title": "SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning",
    "summary": "Large Reasoning Models (LRMs) introduce a new generation paradigm of explicitly reasoning before answering, leading to remarkable improvements in complex tasks. However, they pose great safety risks against harmful queries and adversarial attacks. While recent mainstream safety efforts on LRMs, supervised fine-tuning (SFT), improve safety performance, we find that SFT-aligned models struggle to generalize to unseen jailbreak prompts. After thorough investigation of LRMs' generation, we identify a safety aha moment that can activate safety reasoning and lead to a safe response. This aha moment typically appears in the `key sentence', which follows models' query understanding process and can indicate whether the model will proceed safely. Based on these insights, we propose SafeKey, including two complementary objectives to better activate the safety aha moment in the key sentence: (1) a Dual-Path Safety Head to enhance the safety signal in the model's internal representations before the key sentence, and (2) a Query-Mask Modeling objective to improve the models' attention on its query understanding, which has important safety hints. Experiments across multiple safety benchmarks demonstrate that our methods significantly improve safety generalization to a wide range of jailbreak attacks and out-of-distribution harmful prompts, lowering the average harmfulness rate by 9.6\\%, while maintaining general abilities. Our analysis reveals how SafeKey enhances safety by reshaping internal attention and improving the quality of hidden representations.",
    "published": "2025-05-22T03:46:03Z",
    "updated": "2025-11-17T05:49:23Z",
    "link": "http://arxiv.org/pdf/2505.16186v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "authors": [
      "Kaiwen Zhou",
      "Xuandong Zhao",
      "Gaowen Liu",
      "Jayanth Srinivasa",
      "Aosong Feng",
      "Dawn Song",
      "Xin Eric Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.12659v4",
    "title": "The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1",
    "summary": "The rapid development of large reasoning models (LRMs), such as OpenAI-o3 and DeepSeek-R1, has led to significant improvements in complex reasoning over non-reasoning large language models~(LLMs). However, their enhanced capabilities, combined with the open-source access of models like DeepSeek-R1, raise serious safety concerns, particularly regarding their potential for misuse. In this work, we present a comprehensive safety assessment of these reasoning models, leveraging established safety benchmarks to evaluate their compliance with safety regulations. Furthermore, we investigate their susceptibility to adversarial attacks, such as jailbreaking and prompt injection, to assess their robustness in real-world applications. Through our multi-faceted analysis, we uncover four key findings: (1) There is a significant safety gap between the open-source reasoning models and the o3-mini model, on both safety benchmark and attack, suggesting more safety effort on open LRMs is needed. (2) The stronger the model's reasoning ability, the greater the potential harm it may cause when answering unsafe questions. (3) Safety thinking emerges in the reasoning process of LRMs, but fails frequently against adversarial attacks. (4) The thinking process in R1 models poses greater safety concerns than their final answers. Our study provides insights into the security implications of reasoning models and highlights the need for further advancements in R1 models' safety to close the gap.",
    "published": "2025-02-18T09:06:07Z",
    "updated": "2025-11-17T05:45:20Z",
    "link": "http://arxiv.org/pdf/2502.12659v4.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Kaiwen Zhou",
      "Chengzhi Liu",
      "Xuandong Zhao",
      "Shreedhar Jangam",
      "Jayanth Srinivasa",
      "Gaowen Liu",
      "Dawn Song",
      "Xin Eric Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.06852v3",
    "title": "Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment",
    "summary": "Safety alignment instills in Large Language Models (LLMs) a critical capacity to refuse malicious requests. Prior works have modeled this refusal mechanism as a single linear direction in the activation space. We posit that this is an oversimplification that conflates two functionally distinct neural processes: the detection of harm and the execution of a refusal. In this work, we deconstruct this single representation into a Harm Detection Direction and a Refusal Execution Direction. Leveraging this fine-grained model, we introduce Differentiated Bi-Directional Intervention (DBDI), a new white-box framework that precisely neutralizes the safety alignment at critical layer. DBDI applies adaptive projection nullification to the refusal execution direction while suppressing the harm detection direction via direct steering. Extensive experiments demonstrate that DBDI outperforms prominent jailbreaking methods, achieving up to a 97.88\\% attack success rate on models such as Llama-2. By providing a more granular and mechanistic framework, our work offers a new direction for the in-depth understanding of LLM safety alignment.",
    "published": "2025-11-10T08:52:34Z",
    "updated": "2025-11-17T05:42:17Z",
    "link": "http://arxiv.org/pdf/2511.06852v3.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "authors": [
      "Peng Zhang",
      "Peijie Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12997v1",
    "title": "WebCoach: Self-Evolving Web Agents with Cross-Session Memory Guidance",
    "summary": "Multimodal LLM-powered agents have recently demonstrated impressive capabilities in web navigation, enabling agents to complete complex browsing tasks across diverse domains. However, current agents struggle with repetitive errors and lack the ability to learn from past experiences across sessions, limiting their long-term robustness and sample efficiency. We introduce WebCoach, a model-agnostic self-evolving framework that equips web browsing agents with persistent cross-session memory, enabling improved long-term planning, reflection, and continual learning without retraining. WebCoach consists of three key components: (1) a WebCondenser, which standardizes raw navigation logs into concise summaries; (2) an External Memory Store, which organizes complete trajectories as episodic experiences; and (3) a Coach, which retrieves relevant experiences based on similarity and recency, and decides whether to inject task-specific advice into the agent via runtime hooks. This design empowers web agents to access long-term memory beyond their native context window, improving robustness in complex browsing tasks. Moreover, WebCoach achieves self-evolution by continuously curating episodic memory from new navigation trajectories, enabling agents to improve over time without retraining. Evaluations on the WebVoyager benchmark demonstrate that WebCoach consistently improves the performance of browser-use agents across three different LLM backbones. With a 38B model, it increases task success rates from 47% to 61% while reducing or maintaining the average number of steps. Notably, smaller base models with WebCoach achieve performance comparable to the same web agent using GPT-4o.",
    "published": "2025-11-17T05:38:50Z",
    "updated": "2025-11-17T05:38:50Z",
    "link": "http://arxiv.org/pdf/2511.12997v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Genglin Liu",
      "Shijie Geng",
      "Sha Li",
      "Hejie Cui",
      "Sarah Zhang",
      "Xin Liu",
      "Tianyi Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12988v1",
    "title": "UNSEEN: Enhancing Dataset Pruning from a Generalization Perspective",
    "summary": "The growing scale of datasets in deep learning has introduced significant computational challenges. Dataset pruning addresses this challenge by constructing a compact but informative coreset from the full dataset with comparable performance. Previous approaches typically establish scoring metrics based on specific criteria to identify representative samples. However, these methods predominantly rely on sample scores obtained from the model's performance during the training (i.e., fitting) phase. As scoring models achieve near-optimal performance on training data, such fitting-centric approaches induce a dense distribution of sample scores within a narrow numerical range. This concentration reduces the distinction between samples and hinders effective selection. To address this challenge, we conduct dataset pruning from the perspective of generalization, i.e., scoring samples based on models not exposed to them during training. We propose a plug-and-play framework, UNSEEN, which can be integrated into existing dataset pruning methods. Additionally, conventional score-based methods are single-step and rely on models trained solely on the complete dataset, providing limited perspective on the importance of samples. To address this limitation, we scale UNSEEN to multi-step scenarios and propose an incremental selection technique through scoring models trained on varying coresets, and optimize the quality of the coreset dynamically. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art (SOTA) methods on CIFAR-10, CIFAR-100, and ImageNet-1K. Notably, on ImageNet-1K, UNSEEN achieves lossless performance while reducing training data by 30\\%.",
    "published": "2025-11-17T05:17:39Z",
    "updated": "2025-11-17T05:17:39Z",
    "link": "http://arxiv.org/pdf/2511.12988v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Furui Xu",
      "Shaobo Wang",
      "Jiajun Zhang",
      "Chenghao Sun",
      "Haixiang Tang",
      "Linfeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12986v1",
    "title": "Learning Branching Policies for MILPs with Proximal Policy Optimization",
    "summary": "Branch-and-Bound (B\\&B) is the dominant exact solution method for Mixed Integer Linear Programs (MILP), yet its exponential time complexity poses significant challenges for large-scale instances. The growing capabilities of machine learning have spurred efforts to improve B\\&B by learning data-driven branching policies. However, most existing approaches rely on Imitation Learning (IL), which tends to overfit to expert demonstrations and struggles to generalize to structurally diverse or unseen instances. In this work, we propose Tree-Gate Proximal Policy Optimization (TGPPO), a novel framework that employs Proximal Policy Optimization (PPO), a Reinforcement Learning (RL) algorithm, to train a branching policy aimed at improving generalization across heterogeneous MILP instances. Our approach builds on a parameterized state space representation that dynamically captures the evolving context of the search tree. Empirical evaluations show that TGPPO often outperforms existing learning-based policies in terms of reducing the number of nodes explored and improving p-Primal-Dual Integrals (PDI), particularly in out-of-distribution instances. These results highlight the potential of RL to develop robust and adaptable branching strategies for MILP solvers.",
    "published": "2025-11-17T05:16:14Z",
    "updated": "2025-11-17T05:16:14Z",
    "link": "http://arxiv.org/pdf/2511.12986v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "authors": [
      "Abdelouahed Ben Mhamed",
      "Assia Kamal-Idrissi",
      "Amal El Fallah Seghrouchni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11551v2",
    "title": "Aligning Machiavellian Agents: Behavior Steering via Test-Time Policy Shaping",
    "summary": "The deployment of decision-making AI agents presents a critical challenge in maintaining alignment with human values or guidelines while operating in complex, dynamic environments. Agents trained solely to achieve their objectives may adopt harmful behavior, exposing a key trade-off between maximizing the reward function and maintaining alignment. For pre-trained agents, ensuring alignment is particularly challenging, as retraining can be a costly and slow process. This is further complicated by the diverse and potentially conflicting attributes representing the ethical values for alignment. To address these challenges, we propose a test-time alignment technique based on model-guided policy shaping. Our method allows precise control over individual behavioral attributes, generalizes across diverse reinforcement learning (RL) environments, and facilitates a principled trade-off between ethical alignment and reward maximization without requiring agent retraining. We evaluate our approach using the MACHIAVELLI benchmark, which comprises 134 text-based game environments and thousands of annotated scenarios involving ethical decisions. The RL agents are first trained to maximize the reward in their respective games. At test time, we apply policy shaping via scenario-action attribute classifiers to ensure decision alignment with ethical attributes. We compare our approach against prior training-time methods and general-purpose agents, as well as study several types of ethical violations and power-seeking behavior. Our results demonstrate that test-time policy shaping provides an effective and scalable solution for mitigating unethical behavior across diverse environments and alignment attributes.",
    "published": "2025-11-14T18:42:18Z",
    "updated": "2025-11-17T04:49:46Z",
    "link": "http://arxiv.org/pdf/2511.11551v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Dena Mujtaba",
      "Brian Hu",
      "Anthony Hoogs",
      "Arslan Basharat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12971v1",
    "title": "Esim: EVM Bytecode Similarity Detection Based on Stable-Semantic Graph",
    "summary": "Decentralized finance (DeFi) is experiencing rapid expansion. However, prevalent code reuse and limited open-source contributions have introduced significant challenges to the blockchain ecosystem, including plagiarism and the propagation of vulnerable code. Consequently, an effective and accurate similarity detection method for EVM bytecode is urgently needed to identify similar contracts. Traditional binary similarity detection methods are typically based on instruction stream or control flow graph (CFG), which have limitations on EVM bytecode due to specific features like low-level EVM bytecode and heavily-reused basic blocks. Moreover, the highly-diverse Solidity Compiler (Solc) versions further complicate accurate similarity detection.\n  Motivated by these challenges, we propose a novel EVM bytecode representation called Stable-Semantic Graph (SSG), which captures relationships between 'stable instructions' (special instructions identified by our study). Moreover, we implement a prototype, Esim, which embeds SSG into matrices for similarity detection using a heterogeneous graph neural network. Esim demonstrates high accuracy in SSG construction, achieving F1-scores of 100% for control flow and 95.16% for data flow, and its similarity detection performance reaches 96.3% AUC, surpassing traditional approaches. Our large-scale study, analyzing 2,675,573 smart contracts on six EVM-compatible chains over a one-year period, also demonstrates that Esim outperforms the SOTA tool Etherscan in vulnerability search.",
    "published": "2025-11-17T04:48:52Z",
    "updated": "2025-11-17T04:48:52Z",
    "link": "http://arxiv.org/pdf/2511.12971v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Zhuo Chen",
      "Gaoqiang Ji",
      "Yiling He",
      "Lei Wu",
      "Yajin Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12964v1",
    "title": "CalibrateMix: Guided-Mixup Calibration of Image Semi-Supervised Models",
    "summary": "Semi-supervised learning (SSL) has demonstrated high performance in image classification tasks by effectively utilizing both labeled and unlabeled data. However, existing SSL methods often suffer from poor calibration, with models yielding overconfident predictions that misrepresent actual prediction likelihoods. Recently, neural networks trained with {\\tt mixup} that linearly interpolates random examples from the training set have shown better calibration in supervised settings. However, calibration of neural models remains under-explored in semi-supervised settings. Although effective in supervised model calibration, random mixup of pseudolabels in SSL presents challenges due to the overconfidence and unreliability of pseudolabels. In this work, we introduce CalibrateMix, a targeted mixup-based approach that aims to improve the calibration of SSL models while maintaining or even improving their classification accuracy. Our method leverages training dynamics of labeled and unlabeled samples to identify ``easy-to-learn'' and ``hard-to-learn'' samples, which in turn are utilized in a targeted mixup of easy and hard samples. Experimental results across several benchmark image datasets show that our method achieves lower expected calibration error (ECE) and superior accuracy compared to existing SSL approaches.",
    "published": "2025-11-17T04:43:53Z",
    "updated": "2025-11-17T04:43:53Z",
    "link": "http://arxiv.org/pdf/2511.12964v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Mehrab Mustafy Rahman",
      "Jayanth Mohan",
      "Tiberiu Sosea",
      "Cornelia Caragea"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25015v2",
    "title": "VeriStruct: AI-assisted Automated Verification of Data-Structure Modules in Verus",
    "summary": "We introduce VeriStruct, a novel framework that extends AI-assisted automated verification from single functions to more complex data structure modules in Verus. VeriStruct employs a planner module to orchestrate the systematic generation of abstractions, type invariants, specifications, and proof code. To address the challenge that LLMs often misunderstand Verus' annotation syntax and verification-specific semantics, VeriStruct embeds syntax guidance within prompts and includes a repair stage to automatically correct annotation errors. In an evaluation on eleven Rust data structure modules, VeriStruct succeeds on ten of the eleven, successfully verifying 128 out of 129 functions (99.2%) in total. These results represent an important step toward the goal of automatic AI-assisted formal verification.",
    "published": "2025-10-28T22:28:37Z",
    "updated": "2025-11-17T04:43:41Z",
    "link": "http://arxiv.org/pdf/2510.25015v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Chuyue Sun",
      "Yican Sun",
      "Daneshvar Amrollahi",
      "Ethan Zhang",
      "Shuvendu Lahiri",
      "Shan Lu",
      "David Dill",
      "Clark Barrett"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12963v1",
    "title": "MedRule-KG: A Knowledge-Graph--Steered Scaffold for Reliable Mathematical and Biomedical Reasoning",
    "summary": "We study how to impose domain-consistent structure on large language models (LLMs) used for scientific reasoning and early-stage drug discovery. We present MedRule-KG, a compact knowledge-graph scaffold paired with a lightweight verifier that steers generation toward mathematically and biomedically valid outputs. The system injects curated symbolic facts into prompts and then enforces rule satisfaction with a deterministic checker. We formalize generation as constrained inference, introduce a soft guidance surrogate suitable for decoding, and perform a thorough statistical analysis with uncertainty quantification. Across 90 tasks spanning reaction feasibility, metabolic compatibility, and toxicity screening, MedRule-KG reduces violation counts by 83.2\\% relative to a strong chain-of-thought baseline while improving exact match. Results remain stable under stratification and scale with dataset size, and the verifier adds negligible latency, making the approach practical for interactive design.",
    "published": "2025-11-17T04:42:52Z",
    "updated": "2025-11-17T04:42:52Z",
    "link": "http://arxiv.org/pdf/2511.12963v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Crystal Su"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12962v1",
    "title": "EndoSight AI: Deep Learning-Driven Real-Time Gastrointestinal Polyp Detection and Segmentation for Enhanced Endoscopic Diagnostics",
    "summary": "Precise and real-time detection of gastrointestinal polyps during endoscopic procedures is crucial for early diagnosis and prevention of colorectal cancer. This work presents EndoSight AI, a deep learning architecture developed and evaluated independently to enable accurate polyp localization and detailed boundary delineation. Leveraging the publicly available Hyper-Kvasir dataset, the system achieves a mean Average Precision (mAP) of 88.3% for polyp detection and a Dice coefficient of up to 69% for segmentation, alongside real-time inference speeds exceeding 35 frames per second on GPU hardware. The training incorporates clinically relevant performance metrics and a novel thermal-aware procedure to ensure model robustness and efficiency. This integrated AI solution is designed for seamless deployment in endoscopy workflows, promising to advance diagnostic accuracy and clinical decision-making in gastrointestinal healthcare.",
    "published": "2025-11-17T04:40:38Z",
    "updated": "2025-11-17T04:40:38Z",
    "link": "http://arxiv.org/pdf/2511.12962v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Daniel Cavadia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12955v1",
    "title": "Global Cross-Time Attention Fusion for Enhanced Solar Flare Prediction from Multivariate Time Series",
    "summary": "Multivariate time series classification is increasingly investigated in space weather research as a means to predict intense solar flare events, which can cause widespread disruptions across modern technological systems. Magnetic field measurements of solar active regions are converted into structured multivariate time series, enabling predictive modeling across segmented observation windows. However, the inherently imbalanced nature of solar flare occurrences, where intense flares are rare compared to minor flare events, presents a significant barrier to effective learning. To address this challenge, we propose a novel Global Cross-Time Attention Fusion (GCTAF) architecture, a transformer-based model to enhance long-range temporal modeling. Unlike traditional self-attention mechanisms that rely solely on local interactions within time series, GCTAF injects a set of learnable cross-attentive global tokens that summarize salient temporal patterns across the entire sequence. These tokens are refined through cross-attention with the input sequence and fused back into the temporal representation, enabling the model to identify globally significant, non-contiguous time points that are critical for flare prediction. This mechanism functions as a dynamic attention-driven temporal summarizer that augments the model's capacity to capture discriminative flare-related dynamics. We evaluate our approach on the benchmark solar flare dataset and show that GCTAF effectively detects intense flares and improves predictive performance, demonstrating that refining transformer-based architectures presents a high-potential alternative for solar flare prediction tasks.",
    "published": "2025-11-17T04:26:56Z",
    "updated": "2025-11-17T04:26:56Z",
    "link": "http://arxiv.org/pdf/2511.12955v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Onur Vural",
      "Shah Muhammad Hamdi",
      "Soukaina Filali Boubrahimi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12937v1",
    "title": "Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models",
    "summary": "Automated operation in cross-platform strategy games demands agents with robust generalization across diverse user interfaces and dynamic battlefield conditions. While vision-language models (VLMs) have shown considerable promise in multimodal reasoning, their application to complex human-computer interaction scenarios--such as strategy gaming--remains largely unexplored. Here, we introduce Yanyun-3, a general-purpose agent framework that, for the first time, enables autonomous cross-platform operation across three heterogeneous strategy game environments. By integrating the vision-language reasoning of Qwen2.5-VL with the precise execution capabilities of UI-TARS, Yanyun-3 successfully performs core tasks including target localization, combat resource allocation, and area control. Through systematic ablation studies, we evaluate the effects of various multimodal data combinations--static images, multi-image sequences, and videos--and propose the concept of combination granularity to differentiate between intra-sample fusion and inter-sample mixing strategies. We find that a hybrid strategy, which fuses multi-image and video data while mixing in static images (MV+S), substantially outperforms full fusion: it reduces inference time by 63% and boosts the BLEU-4 score by a factor of 12 (from 4.81% to 62.41%, approximately 12.98x). Operating via a closed-loop pipeline of screen capture, model inference, and action execution, the agent demonstrates strong real-time performance and cross-platform generalization. Beyond providing an efficient solution for strategy game automation, our work establishes a general paradigm for enhancing VLM performance through structured multimodal data organization, offering new insights into the interplay between static perception and dynamic reasoning in embodied intelligence.",
    "published": "2025-11-17T03:45:15Z",
    "updated": "2025-11-17T03:45:15Z",
    "link": "http://arxiv.org/pdf/2511.12937v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Guoyan Wang",
      "Yanyan Huang",
      "Chunlin Chen",
      "Lifeng Wang",
      "Yuxiang Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12936v1",
    "title": "Privacy-Preserving Federated Learning from Partial Decryption Verifiable Threshold Multi-Client Functional Encryption",
    "summary": "In federated learning, multiple parties can cooperate to train the model without directly exchanging their own private data, but the gradient leakage problem still threatens the privacy security and model integrity. Although the existing scheme uses threshold cryptography to mitigate the inference attack, it can not guarantee the verifiability of the aggregation results, making the system vulnerable to the threat of poisoning attack. We construct a partial decryption verifiable threshold multi client function encryption scheme, and apply it to Federated learning to implement the federated learning verifiable threshold security aggregation protocol (VTSAFL). VTSAFL empowers clients to verify aggregation results, concurrently minimizing both computational and communication overhead. The size of the functional key and partial decryption results of the scheme are constant, which provides efficiency guarantee for large-scale deployment. The experimental results on MNIST dataset show that vtsafl can achieve the same accuracy as the existing scheme, while reducing the total training time by more than 40%, and reducing the communication overhead by up to 50%. This efficiency is critical for overcoming the resource constraints inherent in Internet of Things (IoT) devices.",
    "published": "2025-11-17T03:44:47Z",
    "updated": "2025-11-17T03:44:47Z",
    "link": "http://arxiv.org/pdf/2511.12936v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Minjie Wang",
      "Jinguang Han",
      "Weizhi Meng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12935v1",
    "title": "PFAvatar: Pose-Fusion 3D Personalized Avatar Reconstruction from Real-World Outfit-of-the-Day Photos",
    "summary": "We propose PFAvatar (Pose-Fusion Avatar), a new method that reconstructs high-quality 3D avatars from ``Outfit of the Day'' (OOTD) photos, which exhibit diverse poses, occlusions, and complex backgrounds. Our method consists of two stages: (1) fine-tuning a pose-aware diffusion model from few-shot OOTD examples and (2) distilling a 3D avatar represented by a neural radiance field (NeRF). In the first stage, unlike previous methods that segment images into assets (e.g., garments, accessories) for 3D assembly, which is prone to inconsistency, we avoid decomposition and directly model the full-body appearance. By integrating a pre-trained ControlNet for pose estimation and a novel Condition Prior Preservation Loss (CPPL), our method enables end-to-end learning of fine details while mitigating language drift in few-shot training. Our method completes personalization in just 5 minutes, achieving a 48$\\times$ speed-up compared to previous approaches. In the second stage, we introduce a NeRF-based avatar representation optimized by canonical SMPL-X space sampling and Multi-Resolution 3D-SDS. Compared to mesh-based representations that suffer from resolution-dependent discretization and erroneous occluded geometry, our continuous radiance field can preserve high-frequency textures (e.g., hair) and handle occlusions correctly through transmittance. Experiments demonstrate that PFAvatar outperforms state-of-the-art methods in terms of reconstruction fidelity, detail preservation, and robustness to occlusions/truncations, advancing practical 3D avatar generation from real-world OOTD albums. In addition, the reconstructed 3D avatar supports downstream applications such as virtual try-on, animation, and human video reenactment, further demonstrating the versatility and practical value of our approach.",
    "published": "2025-11-17T03:40:43Z",
    "updated": "2025-11-17T03:40:43Z",
    "link": "http://arxiv.org/pdf/2511.12935v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "authors": [
      "Dianbing Xi",
      "Guoyuan An",
      "Jingsen Zhu",
      "Zhijian Liu",
      "Yuan Liu",
      "Ruiyuan Zhang",
      "Jiayuan Lu",
      "Rui Wang",
      "Yuchi Huo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16826v2",
    "title": "KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning",
    "summary": "Recent advances have demonstrated that integrating reinforcement learning with rule-based rewards can significantly enhance the reasoning capabilities of large language models, even without supervised fine-tuning. However, prevalent reinforcement learning algorithms such as GRPO and its variants like DAPO, suffer from a coarse granularity issue when computing the advantage. Specifically, they compute rollout-level advantages that assign identical values to every token within a sequence, failing to capture token-specific contributions and hindering effective learning. To address this limitation, we propose Key-token Advantage Estimation (KTAE) - a novel algorithm that estimates fine-grained, token-level advantages without introducing additional models. KTAE leverages the correctness of sampled rollouts and applies statistical analysis to quantify the importance of individual tokens within a sequence to the final outcome. This quantified token-level importance is then combined with the rollout-level advantage to obtain a more fine-grained token-level advantage estimation. Empirical results show that models trained with GRPO+KTAE and DAPO+KTAE outperform baseline methods across five mathematical reasoning benchmarks. Notably, they achieve higher accuracy with shorter responses and even surpass R1-Distill-Qwen-1.5B using the same base model.",
    "published": "2025-05-22T16:00:33Z",
    "updated": "2025-11-17T03:28:32Z",
    "link": "http://arxiv.org/pdf/2505.16826v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Wei Sun",
      "Wen Yang",
      "Pu Jian",
      "Qianlong Du",
      "Fuwei Cui",
      "Shuo Ren",
      "Jiajun Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11347v2",
    "title": "Privacy Challenges and Solutions in Retrieval-Augmented Generation-Enhanced LLMs for Healthcare Chatbots: A Review of Applications, Risks, and Future Directions",
    "summary": "Retrieval-augmented generation (RAG) has rapidly emerged as a transformative approach for integrating large language models into clinical and biomedical workflows. However, privacy risks, such as protected health information (PHI) exposure, remain inconsistently mitigated. This review provides a thorough analysis of the current landscape of RAG applications in healthcare, including (i) sensitive data type across clinical scenarios, (ii) the associated privacy risks, (iii) current and emerging data-privacy protection mechanisms and (iv) future direction for patient data privacy protection. We synthesize 23 articles on RAG applications in healthcare and systematically analyze privacy challenges through a pipeline-structured framework encompassing data storage, transmission, retrieval and generation stages, delineating potential failure modes, their underlying causes in threat models and system mechanisms, and their practical implications. Building on this analysis, we critically review 17 articles on privacy-preserving strategies for RAG systems. Our evaluation reveals critical gaps, including insufficient clinical validation, absence of standardized evaluation frameworks, and lack of automated assessment tools. We propose actionable directions based on these limitations and conclude with a call to action. This review provides researchers and practitioners with a structured framework for understanding privacy vulnerabilities in healthcare RAG and offers a roadmap toward developing systems that achieve both clinical effectiveness and robust privacy preservation.",
    "published": "2025-11-14T14:33:58Z",
    "updated": "2025-11-17T03:23:50Z",
    "link": "http://arxiv.org/pdf/2511.11347v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Shaowei Guan",
      "Hin Chi Kwok",
      "Ngai Fong Law",
      "Gregor Stiglic",
      "Harry Qin",
      "Vivian Hui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12922v1",
    "title": "Tokenize Once, Recommend Anywhere: Unified Item Tokenization for Multi-domain LLM-based Recommendation",
    "summary": "Large language model (LLM)-based recommender systems have achieved high-quality performance by bridging the discrepancy between the item space and the language space through item tokenization. However, existing item tokenization methods typically require training separate models for each item domain, limiting generalization. Moreover, the diverse distributions and semantics across item domains make it difficult to construct a unified tokenization that preserves domain-specific information. To address these challenges, we propose UniTok, a Unified item Tokenization framework that integrates our own mixture-of-experts (MoE) architecture with a series of codebooks to convert items into discrete tokens, enabling scalable tokenization while preserving semantic information across multiple item domains. Specifically, items from different domains are first projected into a unified latent space through a shared encoder. They are then routed to domain-specific experts to capture the unique semantics, while a shared expert, which is always active, encodes common knowledge transferable across domains. Additionally, to mitigate semantic imbalance across domains, we present a mutual information calibration mechanism, which guides the model towards retaining similar levels of semantic information for each domain. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed UniTok framework is (a) highly effective: achieving up to 51.89% improvements over strong benchmarks, (b) theoretically sound: showing the analytical validity of our architectural design and optimization; and (c) highly generalizable: demonstrating robust performance across diverse domains without requiring per-domain retraining, a capability not supported by existing baselines.",
    "published": "2025-11-17T03:18:04Z",
    "updated": "2025-11-17T03:18:04Z",
    "link": "http://arxiv.org/pdf/2511.12922v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "cs.SI"
    ],
    "authors": [
      "Yu Hou",
      "Won-Yong Shin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12920v1",
    "title": "Auditing Google's AI Overviews and Featured Snippets: A Case Study on Baby Care and Pregnancy",
    "summary": "Google Search increasingly surfaces AI-generated content through features like AI Overviews (AIO) and Featured Snippets (FS), which users frequently rely on despite having no control over their presentation. Through a systematic algorithm audit of 1,508 real baby care and pregnancy-related queries, we evaluate the quality and consistency of these information displays. Our robust evaluation framework assesses multiple quality dimensions, including answer consistency, relevance, presence of medical safeguards, source categories, and sentiment alignment. Our results reveal concerning gaps in information consistency, with information in AIO and FS displayed on the same search result page being inconsistent with each other in 33% of cases. Despite high relevance scores, both features critically lack medical safeguards (present in just 11% of AIO and 7% of FS responses). While health and wellness websites dominate source categories for both, AIO and FS, FS also often link to commercial sources. These findings have important implications for public health information access and demonstrate the need for stronger quality controls in AI-mediated health information. Our methodology provides a transferable framework for auditing AI systems across high-stakes domains where information quality directly impacts user well-being.",
    "published": "2025-11-17T03:16:36Z",
    "updated": "2025-11-17T03:16:36Z",
    "link": "http://arxiv.org/pdf/2511.12920v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.IR"
    ],
    "authors": [
      "Desheng Hu",
      "Joachim Baumann",
      "Aleksandra Urman",
      "Elsa Lichtenegger",
      "Robin Forsberg",
      "Aniko Hannak",
      "Christo Wilson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11079v2",
    "title": "ARCTraj: A Dataset and Benchmark of Human Reasoning Trajectories for Abstract Problem Solving",
    "summary": "We present ARCTraj, a dataset and methodological framework for modeling human reasoning through complex visual tasks in the Abstraction and Reasoning Corpus (ARC). While ARC has inspired extensive research on abstract reasoning, most existing approaches rely on static input--output supervision, which limits insight into how reasoning unfolds over time. ARCTraj addresses this gap by recording temporally ordered, object-level actions that capture how humans iteratively transform inputs into outputs, revealing intermediate reasoning steps that conventional datasets overlook. Collected via the O2ARC web interface, it contains around 10,000 trajectories annotated with task identifiers, timestamps, and success labels across 400 training tasks from the ARC-AGI-1 benchmark. It further defines a unified reasoning pipeline encompassing data collection, action abstraction, Markov decision process (MDP) formulation, and downstream learning, enabling integration with reinforcement learning, generative modeling, and sequence modeling methods such as PPO, World Models, GFlowNets, Diffusion agents, and Decision Transformers. Analyses of spatial selection, color attribution, and strategic convergence highlight the structure and diversity of human reasoning. Together, these contributions position ARCTraj as a structured and interpretable foundation for studying human-like reasoning, advancing explainability, alignment, and generalizable intelligence.",
    "published": "2025-11-14T08:52:53Z",
    "updated": "2025-11-17T03:11:14Z",
    "link": "http://arxiv.org/pdf/2511.11079v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Sejin Kim",
      "Hayan Choi",
      "Seokki Lee",
      "Sundong Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12916v1",
    "title": "Fault2Flow: An AlphaEvolve-Optimized Human-in-the-Loop Multi-Agent System for Fault-to-Workflow Automation",
    "summary": "Power grid fault diagnosis is a critical process hindered by its reliance on manual, error-prone methods. Technicians must manually extract reasoning logic from dense regulations and attempt to combine it with tacit expert knowledge, which is inefficient, error-prone, and lacks maintainability as ragulations are updated and experience evolves. While Large Language Models (LLMs) have shown promise in parsing unstructured text, no existing framework integrates these two disparate knowledge sources into a single, verified, and executable workflow. To bridge this gap, we propose Fault2Flow, an LLM-based multi-agent system. Fault2Flow systematically: (1) extracts and structures regulatory logic into PASTA-formatted fault trees; (2) integrates expert knowledge via a human-in-the-loop interface for verification; (3) optimizes the reasoning logic using a novel AlphaEvolve module; and (4) synthesizes the final, verified logic into an n8n-executable workflow. Experimental validation on transformer fault diagnosis datasets confirms 100\\% topological consistency and high semantic fidelity. Fault2Flow establishes a reproducible path from fault analysis to operational automation, substantially reducing expert workload.",
    "published": "2025-11-17T03:07:40Z",
    "updated": "2025-11-17T03:07:40Z",
    "link": "http://arxiv.org/pdf/2511.12916v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yafang Wang",
      "Yangjie Tian",
      "Xiaoyu Shen",
      "Gaoyang Zhang",
      "Jiaze Sun",
      "He Zhang",
      "Ruohua Xu",
      "Feng Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12913v1",
    "title": "CoS: Towards Optimal Event Scheduling via Chain-of-Scheduling",
    "summary": "Recommending event schedules is a key issue in Event-based Social Networks (EBSNs) in order to maintain user activity. An effective recommendation is required to maximize the user's preference, subjecting to both time and geographical constraints. Existing methods face an inherent trade-off among efficiency, effectiveness, and generalization, due to the NP-hard nature of the problem. This paper proposes the Chain-of-Scheduling (CoS) framework, which activates the event scheduling capability of Large Language Models (LLMs) through a guided, efficient scheduling process. CoS enhances LLM by formulating the schedule task into three atomic stages, i.e., exploration, verification and integration. Then we enable the LLMs to generate CoS autonomously via Knowledge Distillation (KD). Experimental results show that CoS achieves near-theoretical optimal effectiveness with high efficiency on three real-world datasets in a interpretable manner. Moreover, it demonstrates strong zero-shot learning ability on out-of-domain data.",
    "published": "2025-11-17T03:01:47Z",
    "updated": "2025-11-17T03:01:47Z",
    "link": "http://arxiv.org/pdf/2511.12913v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yiming Zhao",
      "Jiwei Tang",
      "Shimin Di",
      "Libin Zheng",
      "Jianxing Yu",
      "Jian Yin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.08956v2",
    "title": "A Human Behavioral Baseline for Collective Governance in Software Projects",
    "summary": "We study how open source communities describe participation and control through version controlled governance documents. Using a corpus of 710 projects with paired snapshots, we parse text into actors, rules, actions, and objects, then group them and measure change with entropy for evenness, richness for diversity, and Jensen Shannon divergence for drift. Projects define more roles and more actions over time, and these are distributed more evenly, while the composition of rules remains stable. These findings indicate that governance grows by expanding and balancing categories of participation without major shifts in prescriptive force. The analysis provides a reproducible baseline for evaluating whether future AI mediated workflows concentrate or redistribute authority.",
    "published": "2025-10-10T03:04:46Z",
    "updated": "2025-11-17T02:57:26Z",
    "link": "http://arxiv.org/pdf/2510.08956v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Mobina Noori",
      "Mahasweta Chakraborti",
      "Amy X Zhang",
      "Seth Frey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12908v1",
    "title": "DeepSport: A Multimodal Large Language Model for Comprehensive Sports Video Reasoning via Agentic Reinforcement Learning",
    "summary": "Sports video understanding presents unique challenges, requiring models to perceive high-speed dynamics, comprehend complex rules, and reason over long temporal contexts. While Multimodal Large Language Models (MLLMs) have shown promise in genral domains, the current state of research in sports remains narrowly focused: existing approaches are either single-sport centric, limited to specific tasks, or rely on training-free paradigms that lack robust, learned reasoning process. To address this gap, we introduce DeepSport, the first end-to-end trained MLLM framework designed for multi-task, multi-sport video understanding. DeepSport shifts the paradigm from passive frame processing to active, iterative reasoning, empowering the model to ``think with videos'' by dynamically interrogating content via a specialized frame-extraction tool. To enable this, we propose a data distillation pipeline that synthesizes high-quality Chain-of-Thought (CoT) trajectories from 10 diverse data source, creating a unified resource of 78k training data. We then employ a two-stage training strategy, Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) with a novel gated tool-use reward, to optimize the model's reasoning process. Extensive experiments on the testing benchmark of 6.7k questions demonstrate that DeepSport achieves state-of-the-art performance, significantly outperforming baselines of both proprietary model and open-source models. Our work establishes a new foundation for domain-specific video reasoning to address the complexities of diverse sports.",
    "published": "2025-11-17T02:57:15Z",
    "updated": "2025-11-17T02:57:15Z",
    "link": "http://arxiv.org/pdf/2511.12908v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Junbo Zou",
      "Haotian Xia",
      "Zhen Ye",
      "Shengjie Zhang",
      "Christopher Lai",
      "Vicente Ordonez",
      "Weining Shen",
      "Hanjie Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.00090v2",
    "title": "LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video Generation",
    "summary": "We present LeMiCa, a training-free and efficient acceleration framework for diffusion-based video generation. While existing caching strategies primarily focus on reducing local heuristic errors, they often overlook the accumulation of global errors, leading to noticeable content degradation between accelerated and original videos. To address this issue, we formulate cache scheduling as a directed graph with error-weighted edges and introduce a Lexicographic Minimax Path Optimization strategy that explicitly bounds the worst-case path error. This approach substantially improves the consistency of global content and style across generated frames. Extensive experiments on multiple text-to-video benchmarks demonstrate that LeMiCa delivers dual improvements in both inference speed and generation quality. Notably, our method achieves a 2.9x speedup on the Latte model and reaches an LPIPS score of 0.05 on Open-Sora, outperforming prior caching techniques. Importantly, these gains come with minimal perceptual quality degradation, making LeMiCa a robust and generalizable paradigm for accelerating diffusion-based video generation. We believe this approach can serve as a strong foundation for future research on efficient and reliable video synthesis. Our code is available at :https://github.com/UnicomAI/LeMiCa",
    "published": "2025-10-30T04:57:26Z",
    "updated": "2025-11-17T02:55:48Z",
    "link": "http://arxiv.org/pdf/2511.00090v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Huanlin Gao",
      "Ping Chen",
      "Fuyuan Shi",
      "Chao Tan",
      "Zhaoxiang Liu",
      "Fang Zhao",
      "Kai Wang",
      "Shiguo Lian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12905v1",
    "title": "LinkedIn Profile Characteristics and Professional Success Indicators",
    "summary": "This study explores the relationship between LinkedIn profile characteristics and professional success, focusing on the indicators of promotions, follower count, and career progression rate. By leveraging a dataset of over 62,000 anonymized LinkedIn profiles, we developed predictive models using machine learning techniques to identify the most influential factors driving professional success. Results indicate that while promotions are highly predictable, follower growth exhibits greater complexity. This research provides actionable insights for professionals seeking to optimize their LinkedIn presence and career strategies.",
    "published": "2025-11-17T02:54:12Z",
    "updated": "2025-11-17T02:54:12Z",
    "link": "http://arxiv.org/pdf/2511.12905v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tania-Amanda Fredrick Eneye",
      "Ashlesha Malla",
      "Pawan Paudel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12903v1",
    "title": "Contrastive Entropy Bounds for Density and Conditional Density Decomposition",
    "summary": "This paper studies the interpretability of neural network features from a Bayesian Gaussian view, where optimizing a cost is reaching a probabilistic bound; learning a model approximates a density that makes the bound tight and the cost optimal, often with a Gaussian mixture density. The two examples are Mixture Density Networks (MDNs) using the bound for the marginal and autoencoders using the conditional bound. It is a known result, not only for autoencoders, that minimizing the error between inputs and outputs maximizes the dependence between inputs and the middle.\n  We use Hilbert space and decomposition to address cases where a multiple-output network produces multiple centers defining a Gaussian mixture. Our first finding is that an autoencoder's objective is equivalent to maximizing the trace of a Gaussian operator, the sum of eigenvalues under bases orthonormal w.r.t. the data and model distributions. This suggests that, when a one-to-one correspondence as needed in autoencoders is unnecessary, we can instead maximize the nuclear norm of this operator, the sum of singular values, to maximize overall rank rather than trace. Thus the trace of a Gaussian operator can be used to train autoencoders, and its nuclear norm can be used as divergence to train MDNs.\n  Our second test uses inner products and norms in a Hilbert space to define bounds and costs. Such bounds often have an extra norm compared to KL-based bounds, which increases sample diversity and prevents the trivial solution where a multiple-output network produces the same constant, at the cost of requiring a sample batch to estimate and optimize. We propose an encoder-mixture-decoder architecture whose decoder is multiple-output, producing multiple centers per sample, potentially tightening the bound. Assuming the data are small-variance Gaussian mixtures, this upper bound can be tracked and analyzed quantitatively.",
    "published": "2025-11-17T02:49:08Z",
    "updated": "2025-11-17T02:49:08Z",
    "link": "http://arxiv.org/pdf/2511.12903v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Bo Hu",
      "Jose C. Principe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11000v2",
    "title": "DialogGraph-LLM: Graph-Informed LLMs for End-to-End Audio Dialogue Intent Recognition",
    "summary": "Recognizing speaker intent in long audio dialogues among speakers has a wide range of applications, but is a non-trivial AI task due to complex inter-dependencies in speaker utterances and scarce annotated data. To address these challenges, an end-to-end framework, namely DialogGraph-LLM, is proposed in the current work. DialogGraph-LLM combines a novel Multi-Relational Dialogue Attention Network (MR-DAN) architecture with multimodal foundation models (e.g., Qwen2.5-Omni-7B) for direct acoustic-to-intent inference. An adaptive semi-supervised learning strategy is designed using LLM with a confidence-aware pseudo-label generation mechanism based on dual-threshold filtering using both global and class confidences, and an entropy-based sample selection process that prioritizes high-information unlabeled instances. Extensive evaluations on the proprietary MarketCalls corpus and the publicly available MIntRec 2.0 benchmark demonstrate DialogGraph-LLM's superiority over strong audio and text-driven baselines. The framework demonstrates strong performance and efficiency in intent recognition in real world scenario audio dialogues, proving its practical value for audio-rich domains with limited supervision. Our code is available at https://github.com/david188888/DialogGraph-LLM.",
    "published": "2025-11-14T06:42:04Z",
    "updated": "2025-11-17T02:49:01Z",
    "link": "http://arxiv.org/pdf/2511.11000v2.pdf",
    "category": [
      "cs.SD",
      "cs.AI"
    ],
    "authors": [
      "HongYu Liu",
      "Junxin Li",
      "Changxi Guo",
      "Hao Chen",
      "Yaqian Huang",
      "Yifu Guo",
      "Huan Yang",
      "Lihua Cai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12901v1",
    "title": "Online Learning of HTN Methods for integrated LLM-HTN Planning",
    "summary": "We present online learning of Hierarchical Task Network (HTN) methods in the context of integrated HTN planning and LLM-based chatbots. Methods indicate when and how to decompose tasks into subtasks. Our method learner is built on top of the ChatHTN planner. ChatHTN queries ChatGPT to generate a decomposition of a task into primitive tasks when no applicable method for the task is available. In this work, we extend ChatHTN. Namely, when ChatGPT generates a task decomposition, ChatHTN learns from it, akin to memoization. However, unlike memoization, it learns a generalized method that applies not only to the specific instance encountered, but to other instances of the same task. We conduct experiments on two domains and demonstrate that our online learning procedure reduces the number of calls to ChatGPT while solving at least as many problems, and in some cases, even more.",
    "published": "2025-11-17T02:46:04Z",
    "updated": "2025-11-17T02:46:04Z",
    "link": "http://arxiv.org/pdf/2511.12901v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Yuesheng Xu",
      "Hector Munoz-Avila"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21341v2",
    "title": "Magellan: Guided MCTS for Latent Space Exploration and Novelty Generation",
    "summary": "Large Language Models (LLMs) often struggle with generating truly innovative ideas, typically defaulting to high-probability, familiar concepts within their training data's \"gravity wells.\" While advanced search-based methods like Tree of Thoughts (ToT) attempt to mitigate this, they are fundamentally limited by their reliance on unprincipled, inconsistent self-evaluation heuristics to guide exploration. To address this gap, we introduce \\textbf{Magellan}, a novel framework that reframes creative generation as a principled, guided exploration of an LLM's latent conceptual space. At its core, Magellan employs Monte Carlo Tree Search (MCTS) governed by a hierarchical guidance system. For long-range direction, a \"semantic compass\" vector, formulated via orthogonal projection, steers the search towards relevant novelty. For local, step-by-step decisions, a landscape-aware value function replaces flawed self-evaluation with an explicit reward structure that balances intrinsic coherence, extrinsic novelty, and narrative progress. Extensive experiments demonstrate that Magellan significantly outperforms strong baselines, including ReAct and ToT, in generating scientific ideas with superior plausibility and innovation. Our work shows that for creative discovery, a principled, guided search is more effective than unconstrained agency, paving the way for LLMs to become more capable partners in innovation.",
    "published": "2025-10-24T11:09:59Z",
    "updated": "2025-11-17T02:33:41Z",
    "link": "http://arxiv.org/pdf/2510.21341v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Lufan Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12882v1",
    "title": "Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos",
    "summary": "Embodied world models aim to predict and interact with the physical world through visual observations and actions. However, existing models struggle to accurately translate low-level actions (e.g., joint positions) into precise robotic movements in predicted frames, leading to inconsistencies with real-world physical interactions. To address these limitations, we propose MTV-World, an embodied world model that introduces Multi-view Trajectory-Video control for precise visuomotor prediction. Specifically, instead of directly using low-level actions for control, we employ trajectory videos obtained through camera intrinsic and extrinsic parameters and Cartesian-space transformation as control signals. However, projecting 3D raw actions onto 2D images inevitably causes a loss of spatial information, making a single view insufficient for accurate interaction modeling. To overcome this, we introduce a multi-view framework that compensates for spatial information loss and ensures high-consistency with physical world. MTV-World forecasts future frames based on multi-view trajectory videos as input and conditioning on an initial frame per view. Furthermore, to systematically evaluate both robotic motion precision and object interaction accuracy, we develop an auto-evaluation pipeline leveraging multimodal large models and referring video object segmentation models. To measure spatial consistency, we formulate it as an object location matching problem and adopt the Jaccard Index as the evaluation metric. Extensive experiments demonstrate that MTV-World achieves precise control execution and accurate physical interaction modeling in complex dual-arm scenarios.",
    "published": "2025-11-17T02:17:04Z",
    "updated": "2025-11-17T02:17:04Z",
    "link": "http://arxiv.org/pdf/2511.12882v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Taiyi Su",
      "Jian Zhu",
      "Yaxuan Li",
      "Chong Ma",
      "Zitai Huang",
      "Yichen Zhu",
      "Hanli Wang",
      "Yi Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.13981v3",
    "title": "On the Learn-to-Optimize Capabilities of Transformers in In-Context Sparse Recovery",
    "summary": "An intriguing property of the Transformer is its ability to perform in-context learning (ICL), where the Transformer can solve different inference tasks without parameter updating based on the contextual information provided by the corresponding input-output demonstration pairs. It has been theoretically proved that ICL is enabled by the capability of Transformers to perform gradient-descent algorithms (Von Oswald et al., 2023a; Bai et al., 2024). This work takes a step further and shows that Transformers can perform learning-to-optimize (L2O) algorithms. Specifically, for the ICL sparse recovery (formulated as LASSO) tasks, we show that a K-layer Transformer can perform an L2O algorithm with a provable convergence rate linear in K. This provides a new perspective explaining the superior ICL capability of Transformers, even with only a few layers, which cannot be achieved by the standard gradient-descent algorithms. Moreover, unlike the conventional L2O algorithms that require the measurement matrix involved in training to match that in testing, the trained Transformer is able to solve sparse recovery problems generated with different measurement matrices. Besides, Transformers as an L2O algorithm can leverage structural information embedded in the training tasks to accelerate its convergence during ICL, and generalize across different lengths of demonstration pairs, where conventional L2O algorithms typically struggle or fail. Such theoretical findings are supported by our experimental results.",
    "published": "2024-10-17T19:18:28Z",
    "updated": "2025-11-17T02:12:11Z",
    "link": "http://arxiv.org/pdf/2410.13981v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Renpu Liu",
      "Ruida Zhou",
      "Cong Shen",
      "Jing Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12876v1",
    "title": "Think, Speak, Decide: Language-Augmented Multi-Agent Reinforcement Learning for Economic Decision-Making",
    "summary": "Economic decision-making depends not only on structured signals such as prices and taxes, but also on unstructured language, including peer dialogue and media narratives. While multi-agent reinforcement learning (MARL) has shown promise in optimizing economic decisions, it struggles with the semantic ambiguity and contextual richness of language. We propose LAMP (Language-Augmented Multi-Agent Policy), a framework that integrates language into economic decision-making and narrows the gap to real-world settings. LAMP follows a Think-Speak-Decide pipeline: (1) Think interprets numerical observations to extract short-term shocks and long-term trends, caching high-value reasoning trajectories; (2) Speak crafts and exchanges strategic messages based on reasoning, updating beliefs by parsing peer communications; and (3) Decide fuses numerical data, reasoning, and reflections into a MARL policy to optimize language-augmented decision-making. Experiments in economic simulation show that LAMP outperforms both MARL and LLM-only baselines in cumulative return (+63.5%, +34.0%), robustness (+18.8%, +59.4%), and interpretability. These results demonstrate the potential of language-augmented policies to deliver more effective and robust economic strategies.",
    "published": "2025-11-17T02:09:18Z",
    "updated": "2025-11-17T02:09:18Z",
    "link": "http://arxiv.org/pdf/2511.12876v1.pdf",
    "category": [
      "cs.AI",
      "econ.GN"
    ],
    "authors": [
      "Heyang Ma",
      "Qirui Mi",
      "Qipeng Yang",
      "Zijun Fan",
      "Bo Li",
      "Haifeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.22805v3",
    "title": "MoCHA: Advanced Vision-Language Reasoning with MoE Connector and Hierarchical Group Attention",
    "summary": "Vision large language models (VLLMs) are focusing primarily on handling complex and fine-grained visual information by incorporating advanced vision encoders and scaling up visual models. However, these approaches face high training and inference costs, as well as challenges in extracting visual details, effectively bridging across modalities. In this work, we propose a novel visual framework, MoCHA, to address these issues. Our framework integrates four vision backbones (i.e., CLIP, SigLIP, DINOv2 and ConvNeXt) to extract complementary visual features and is equipped with a sparse Mixture of Experts Connectors (MoECs) module to dynamically select experts tailored to different visual dimensions. To mitigate redundant or insufficient use of the visual information encoded by the MoECs module, we further design a Hierarchical Group Attention (HGA) with intra- and inter-group operations and an adaptive gating strategy for encoded visual features. We train MoCHA on two mainstream LLMs (e.g., Phi2-2.7B and Vicuna-7B) and evaluate their performance across various benchmarks. Notably, MoCHA outperforms state-of-the-art open-weight models on various tasks. For example, compared to CuMo (Mistral-7B), our MoCHA (Phi2-2.7B) presents outstanding abilities to mitigate hallucination by showing improvements of 3.25% in POPE and to follow visual instructions by raising 153 points on MME. Finally, ablation studies further confirm the effectiveness and robustness of the proposed MoECs and HGA in improving the overall performance of MoCHA.",
    "published": "2025-07-30T16:15:22Z",
    "updated": "2025-11-17T02:08:29Z",
    "link": "http://arxiv.org/pdf/2507.22805v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuqi Pang",
      "Bowen Yang",
      "Yun Cao",
      "Rong Fan",
      "Xiaoyu Li",
      "Chen He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12874v1",
    "title": "Classification of Hope in Textual Data using Transformer-Based Models",
    "summary": "This paper presents a transformer-based approach for classifying hope expressions in text. We developed and compared three architectures (BERT, GPT-2, and DeBERTa) for both binary classification (Hope vs. Not Hope) and multiclass categorization (five hope-related categories). Our initial BERT implementation achieved 83.65% binary and 74.87% multiclass accuracy. In the extended comparison, BERT demonstrated superior performance (84.49% binary, 72.03% multiclass accuracy) while requiring significantly fewer computational resources (443s vs. 704s training time) than newer architectures. GPT-2 showed lowest overall accuracy (79.34% binary, 71.29% multiclass), while DeBERTa achieved moderate results (80.70% binary, 71.56% multiclass) but at substantially higher computational cost (947s for multiclass training). Error analysis revealed architecture-specific strengths in detecting nuanced hope expressions, with GPT-2 excelling at sarcasm detection (92.46% recall). This study provides a framework for computational analysis of hope, with applications in mental health and social media analysis, while demonstrating that architectural suitability may outweigh model size for specialized emotion detection tasks.",
    "published": "2025-11-17T02:07:24Z",
    "updated": "2025-11-17T02:07:24Z",
    "link": "http://arxiv.org/pdf/2511.12874v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Chukwuebuka Fortunate Ijezue",
      "Tania-Amanda Fredrick Eneye",
      "Maaz Amjad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.10218v2",
    "title": "MTP: Exploring Multimodal Urban Traffic Profiling with Modality Augmentation and Spectrum Fusion",
    "summary": "With rapid urbanization in the modern era, traffic signals from various sensors have been playing a significant role in monitoring the states of cities, which provides a strong foundation in ensuring safe travel, reducing traffic congestion and optimizing urban mobility. Most existing methods for traffic signal modeling often rely on the original data modality, i.e., numerical direct readings from the sensors in cities. However, this unimodal approach overlooks the semantic information existing in multimodal heterogeneous urban data in different perspectives, which hinders a comprehensive understanding of traffic signals and limits the accurate prediction of complex traffic dynamics. To address this problem, we propose a novel Multimodal framework, MTP, for urban Traffic Profiling, which learns multimodal features through numeric, visual, and textual perspectives. The three branches drive for a multimodal perspective of urban traffic signal learning in the frequency domain, while the frequency learning strategies delicately refine the information for extraction. Specifically, we first conduct the visual augmentation for the traffic signals, which transforms the original modality into frequency images and periodicity images for visual learning. Also, we augment descriptive texts for the traffic signals based on the specific topic, background information and item description for textual learning. To complement the numeric information, we utilize frequency multilayer perceptrons for learning on the original modality. We design a hierarchical contrastive learning on the three branches to fuse the spectrum of three modalities. Finally, extensive experiments on six real-world datasets demonstrate superior performance compared with the state-of-the-art approaches.",
    "published": "2025-11-13T11:47:01Z",
    "updated": "2025-11-17T01:59:07Z",
    "link": "http://arxiv.org/pdf/2511.10218v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Haolong Xiang",
      "Peisi Wang",
      "Xiaolong Xu",
      "Kun Yi",
      "Xuyun Zhang",
      "Quanzheng Sheng",
      "Amin Beheshti",
      "Wei Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12869v1",
    "title": "On the Fundamental Limits of LLMs at Scale",
    "summary": "Large Language Models (LLMs) have benefited enormously from scaling, yet these gains are bounded by five fundamental limitations: (1) hallucination, (2) context compression, (3) reasoning degradation, (4) retrieval fragility, and (5) multimodal misalignment. While existing surveys describe these phenomena empirically, they lack a rigorous theoretical synthesis connecting them to the foundational limits of computation, information, and learning. This work closes that gap by presenting a unified, proof-informed framework that formalizes the innate theoretical ceilings of LLM scaling. First, computability and uncomputability imply an irreducible residue of error: for any computably enumerable model family, diagonalization guarantees inputs on which some model must fail, and undecidable queries (e.g., halting-style tasks) induce infinite failure sets for all computable predictors. Second, information-theoretic and statistical constraints bound attainable accuracy even on decidable tasks, finite description length enforces compression error, and long-tail factual knowledge requires prohibitive sample complexity. Third, geometric and computational effects compress long contexts far below their nominal size due to positional under-training, encoding attenuation, and softmax crowding. We further show how likelihood-based training favors pattern completion over inference, how retrieval under token limits suffers from semantic drift and coupling noise, and how multimodal scaling inherits shallow cross-modal alignment. Across sections, we pair theorems and empirical evidence to outline where scaling helps, where it saturates, and where it cannot progress, providing both theoretical foundations and practical mitigation paths like bounded-oracle retrieval, positional curricula, and sparse or hierarchical attention.",
    "published": "2025-11-17T01:55:33Z",
    "updated": "2025-11-17T01:55:33Z",
    "link": "http://arxiv.org/pdf/2511.12869v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.IT",
      "cs.MA"
    ],
    "authors": [
      "Muhammad Ahmed Mohsin",
      "Muhammad Umer",
      "Ahsan Bilal",
      "Zeeshan Memon",
      "Muhammad Ibtsaam Qadir",
      "Sagnik Bhattacharya",
      "Hassan Rizwan",
      "Abhiram R. Gorle",
      "Maahe Zehra Kazmi",
      "Ayesha Mohsin",
      "Muhammad Usman Rafique",
      "Zihao He",
      "Pulkit Mehta",
      "Muhammad Ali Jamshed",
      "John M. Cioffi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12868v1",
    "title": "Video Finetuning Improves Reasoning Between Frames",
    "summary": "Multimodal large language models (LLMs) have made rapid progress in visual understanding, yet their extension from images to videos often reduces to a naive concatenation of frame tokens. In this work, we investigate what video finetuning brings to multimodal LLMs. We propose Visual Chain-of-Thought (vCoT), an explicit reasoning process that generates transitional event descriptions between consecutive frames. Using vCoT, we systematically compare image-only LVLMs with their video-finetuned counterparts, both with and without access to these transitional cues. Our experiments show that vCoT significantly improves the performance of image-only models on long-form video question answering, while yielding only marginal gains for video-finetuned models. This suggests that the latter already capture frame-to-frame transitions implicitly. Moreover, we find that video models transfer this temporal reasoning ability to purely static settings, outperforming image models' baselines on relational visual reasoning tasks.",
    "published": "2025-11-17T01:51:57Z",
    "updated": "2025-11-17T01:51:57Z",
    "link": "http://arxiv.org/pdf/2511.12868v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ruiqi Yang",
      "Tian Yun",
      "Zihan Wang",
      "Ellie Pavlick"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25522v2",
    "title": "Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography",
    "summary": "Segmentation of liver structures in multi-phase contrast-enhanced computed tomography (CECT) plays a crucial role in computer-aided diagnosis and treatment planning for liver diseases, including tumor detection. In this study, we investigate the performance of UNet-based architectures for liver tumor segmentation, starting from the original UNet and extending to UNet3+ with various backbone networks. We evaluate ResNet, Transformer-based, and State-space (Mamba) backbones, all initialized with pretrained weights. Surprisingly, despite the advances in modern architecture, ResNet-based models consistently outperform Transformer- and Mamba-based alternatives across multiple evaluation metrics. To further improve segmentation quality, we introduce attention mechanisms into the backbone and observe that incorporating the Convolutional Block Attention Module (CBAM) yields the best performance. ResNetUNet3+ with CBAM module not only produced the best overlap metrics with a Dice score of 0.755 and IoU of 0.662, but also achieved the most precise boundary delineation, evidenced by the lowest HD95 distance of 77.911. The model's superiority was further cemented by its leading overall accuracy of 0.925 and specificity of 0.926, showcasing its robust capability in accurately identifying both lesion and healthy tissue. To further enhance interpretability, Grad-CAM visualizations were employed to highlight the region's most influential predictions, providing insights into its decision-making process. These findings demonstrate that classical ResNet architecture, when combined with modern attention modules, remain highly competitive for medical image segmentation tasks, offering a promising direction for liver tumor detection in clinical practice.",
    "published": "2025-10-29T13:46:19Z",
    "updated": "2025-11-17T01:51:10Z",
    "link": "http://arxiv.org/pdf/2510.25522v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Doan-Van-Anh Ly",
      "Thi-Thu-Hien Pham",
      "Thanh-Hai Le"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12867v1",
    "title": "Bootstrapping LLMs via Preference-Based Policy Optimization",
    "summary": "Bootstrapping large language models (LLMs) through preference-based policy optimization offers a promising direction for aligning model behavior with human preferences without relying on extensive manual annotations. In this work, we propose a novel preference-based policy optimization (PbPO) framework that formulates the learning process as a min-max game between the main policy and a reward model (RM). The RM is constrained within a confidence set derived from preference data to ensure reliable exploitation. Our iterative online algorithm actively collects preference data through guided exploration of the evolving policy, enabling continual self-improvement of both the policy and the RM. We provide theoretical guarantees for our method, establishing high-probability regret bounds for both settings with sequence-level RM and token-level RM, demonstrating its effectiveness in bootstrapping LLMs. Extensive experiments on five benchmarks show that our approach consistently outperforms existing state-of-the-art preference optimization techniques.",
    "published": "2025-11-17T01:41:14Z",
    "updated": "2025-11-17T01:41:14Z",
    "link": "http://arxiv.org/pdf/2511.12867v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Chen Jia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12865v1",
    "title": "An approach of deep reinforcement learning for maximizing the net present value of stochastic projects",
    "summary": "This paper investigates a project with stochastic activity durations and cash flows under discrete scenarios, where activities must satisfy precedence constraints generating cash inflows and outflows. The objective is to maximize expected net present value (NPV) by accelerating inflows and deferring outflows. We formulate the problem as a discrete-time Markov Decision Process (MDP) and propose a Double Deep Q-Network (DDQN) approach. Comparative experiments demonstrate that DDQN outperforms traditional rigid and dynamic strategies, particularly in large-scale or highly uncertain environments, exhibiting superior computational capability, policy reliability, and adaptability. Ablation studies further reveal that the dual-network architecture mitigates overestimation of action values, while the target network substantially improves training convergence and robustness. These results indicate that DDQN not only achieves higher expected NPV in complex project optimization but also provides a reliable framework for stable and effective policy implementation.",
    "published": "2025-11-17T01:32:08Z",
    "updated": "2025-11-17T01:32:08Z",
    "link": "http://arxiv.org/pdf/2511.12865v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Wei Xu",
      "Fan Yang",
      "Qinyuan Cui",
      "Zhi Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12852v1",
    "title": "From Black-Box to White-Box: Control-Theoretic Neural Network Interpretability",
    "summary": "Deep neural networks achieve state of the art performance but remain difficult to interpret mechanistically. In this work, we propose a control theoretic framework that treats a trained neural network as a nonlinear state space system and uses local linearization, controllability and observability Gramians, and Hankel singular values to analyze its internal computation. For a given input, we linearize the network around the corresponding hidden activation pattern and construct a state space model whose state consists of hidden neuron activations. The input state and state output Jacobians define local controllability and observability Gramians, from which we compute Hankel singular values and associated modes. These quantities provide a principled notion of neuron and pathway importance: controllability measures how easily each neuron can be excited by input perturbations, observability measures how strongly each neuron influences the output, and Hankel singular values rank internal modes that carry input output energy. We illustrate the framework on simple feedforward networks, including a 1 2 2 1 SwiGLU network and a 2 3 3 2 GELU network. By comparing different operating points, we show how activation saturation reduces controllability, shrinks the dominant Hankel singular value, and shifts the dominant internal mode to a different subset of neurons. The proposed method turns a neural network into a collection of local white box dynamical models and suggests which internal directions are natural candidates for pruning or constraints to improve interpretability.",
    "published": "2025-11-17T00:47:33Z",
    "updated": "2025-11-17T00:47:33Z",
    "link": "http://arxiv.org/pdf/2511.12852v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "authors": [
      "Jihoon Moon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12851v1",
    "title": "NeuroLex: A Lightweight Domain Language Model for EEG Report Understanding and Generation",
    "summary": "Clinical electroencephalogram (EEG) reports encode domain-specific linguistic conventions that general-purpose language models (LMs) fail to capture. We introduce NeuroLex, a lightweight domain-adaptive language model trained purely on EEG report text from the Harvard Electroencephalography Database. Unlike existing biomedical LMs, NeuroLex is tailored to the linguistic and diagnostic characteristics of EEG reporting, enabling it to serve as both an independent textual model and a decoder backbone for multimodal EEG-language systems. Using span-corruption pretraining and instruction-style fine-tuning on report polishing, paragraph summarization, and terminology question answering, NeuroLex learns the syntax and reasoning patterns characteristic of EEG interpretation. Comprehensive evaluations show that it achieves lower perplexity, higher extraction and summarization accuracy, better label efficiency, and improved robustness to negation and factual hallucination compared with general models of the same scale. With an EEG-aware linguistic backbone, NeuroLex bridges biomedical text modeling and brain-computer interface applications, offering a foundation for interpretable and language-driven neural decoding.",
    "published": "2025-11-17T00:44:35Z",
    "updated": "2025-11-17T00:44:35Z",
    "link": "http://arxiv.org/pdf/2511.12851v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Kang Yin",
      "Hye-Bin Shin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12846v1",
    "title": "RoS-Guard: Robust and Scalable Online Change Detection with Delay-Optimal Guarantees",
    "summary": "Online change detection (OCD) aims to rapidly identify change points in streaming data and is critical in applications such as power system monitoring, wireless network sensing, and financial anomaly detection. Existing OCD methods typically assume precise system knowledge, which is unrealistic due to estimation errors and environmental variations. Moreover, existing OCD methods often struggle with efficiency in large-scale systems. To overcome these challenges, we propose RoS-Guard, a robust and optimal OCD algorithm tailored for linear systems with uncertainty. Through a tight relaxation and reformulation of the OCD optimization problem, RoS-Guard employs neural unrolling to enable efficient parallel computation via GPU acceleration. The algorithm provides theoretical guarantees on performance, including expected false alarm rate and worst-case average detection delay. Extensive experiments validate the effectiveness of RoS-Guard and demonstrate significant computational speedup in large-scale system scenarios.",
    "published": "2025-11-17T00:30:36Z",
    "updated": "2025-11-17T00:30:36Z",
    "link": "http://arxiv.org/pdf/2511.12846v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zelin Zhu",
      "Yancheng Huang",
      "Kai Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12844v1",
    "title": "Mapping fNIRS Signals to Agent Performance: Toward Reinforcement Learning from Neural Feedback",
    "summary": "Reinforcement Learning from Human Feedback (RLHF) is a methodology that aligns agent behavior with human preferences by integrating human feedback into the agent's training process. We introduce a possible framework that employs passive Brain-Computer Interfaces (BCI) to guide agent training from implicit neural signals. We present and release a novel dataset of functional near-infrared spectroscopy (fNIRS) recordings collected from 25 human participants across three domains: a Pick-and-Place Robot, Lunar Lander, and Flappy Bird. We train classifiers to predict levels of agent performance (optimal, sub-optimal, or worst-case) from windows of preprocessed fNIRS feature vectors, achieving an average F1 score of 67% for binary classification and 46% for multi-class models averaged across conditions and domains. We also train regressors to predict the degree of deviation between an agent's chosen action and a set of near-optimal policies, providing a continuous measure of performance. We evaluate cross-subject generalization and demonstrate that fine-tuning pre-trained models with a small sample of subject-specific data increases average F1 scores by 17% and 41% for binary and multi-class models, respectively. Our work demonstrates that mapping implicit fNIRS signals to agent performance is feasible and can be improved, laying the foundation for future brain-driven RLHF systems.",
    "published": "2025-11-17T00:21:46Z",
    "updated": "2025-11-17T00:21:46Z",
    "link": "http://arxiv.org/pdf/2511.12844v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Julia Santaniello",
      "Matthew Russell",
      "Benson Jiang",
      "Donatello Sassaroli",
      "Robert Jacob",
      "Jivko SInapov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12838v1",
    "title": "Connectivity-Guided Sparsification of 2-FWL GNNs: Preserving Full Expressivity with Improved Efficiency",
    "summary": "Higher-order Graph Neural Networks (HOGNNs) based on the 2-FWL test achieve superior expressivity by modeling 2- and 3-node interactions, but at $\\mathcal{O}(n^3)$ computational cost. However, this computational burden is typically mitigated by existing efficiency methods at the cost of reduced expressivity. We propose \\textbf{Co-Sparsify}, a connectivity-aware sparsification framework that eliminates \\emph{provably redundant} computations while preserving full 2-FWL expressive power. Our key insight is that 3-node interactions are expressively necessary only within \\emph{biconnected components} -- maximal subgraphs where every pair of nodes lies on a cycle. Outside these components, structural relationships can be fully captured via 2-node message passing or global readout, rendering higher-order modeling unnecessary. Co-Sparsify restricts 2-node message passing to connected components and 3-node interactions to biconnected ones, removing computation without approximation or sampling. We prove that Co-Sparsified GNNs are as expressive as the 2-FWL test. Empirically, on PPGN, Co-Sparsify matches or exceeds accuracy on synthetic substructure counting tasks and achieves state-of-the-art performance on real-world benchmarks (ZINC, QM9). This study demonstrates that high expressivity and scalability are not mutually exclusive: principled, topology-guided sparsification enables powerful, efficient GNNs with theoretical guarantees.",
    "published": "2025-11-16T23:46:54Z",
    "updated": "2025-11-16T23:46:54Z",
    "link": "http://arxiv.org/pdf/2511.12838v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Rongqin Chen",
      "Fan Mo",
      "Pak Lon Ip",
      "Shenghui Zhang",
      "Dan Wu",
      "Ye Li",
      "Leong Hou U"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12834v1",
    "title": "SAGA: Source Attribution of Generative AI Videos",
    "summary": "The proliferation of generative AI has led to hyper-realistic synthetic videos, escalating misuse risks and outstripping binary real/fake detectors. We introduce SAGA (Source Attribution of Generative AI videos), the first comprehensive framework to address the urgent need for AI-generated video source attribution at a large scale. Unlike traditional detection, SAGA identifies the specific generative model used. It uniquely provides multi-granular attribution across five levels: authenticity, generation task (e.g., T2V/I2V), model version, development team, and the precise generator, offering far richer forensic insights. Our novel video transformer architecture, leveraging features from a robust vision foundation model, effectively captures spatio-temporal artifacts. Critically, we introduce a data-efficient pretrain-and-attribute strategy, enabling SAGA to achieve state-of-the-art attribution using only 0.5\\% of source-labeled data per class, matching fully supervised performance. Furthermore, we propose Temporal Attention Signatures (T-Sigs), a novel interpretability method that visualizes learned temporal differences, offering the first explanation for why different video generators are distinguishable. Extensive experiments on public datasets, including cross-domain scenarios, demonstrate that SAGA sets a new benchmark for synthetic video provenance, providing crucial, interpretable insights for forensic and regulatory applications.",
    "published": "2025-11-16T23:39:54Z",
    "updated": "2025-11-16T23:39:54Z",
    "link": "http://arxiv.org/pdf/2511.12834v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Rohit Kundu",
      "Vishal Mohanty",
      "Hao Xiong",
      "Shan Jia",
      "Athula Balachandran",
      "Amit K. Roy-Chowdhury"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12832v1",
    "title": "From Passive to Persuasive: Steering Emotional Nuance in Human-AI Negotiation",
    "summary": "Large Language Models (LLMs) demonstrate increasing conversational fluency, yet instilling them with nuanced, human-like emotional expression remains a significant challenge. Current alignment techniques often address surface-level output or require extensive fine-tuning. This paper demonstrates that targeted activation engineering can steer LLaMA 3.1-8B to exhibit more human-like emotional nuances. We first employ attribution patching to identify causally influential components, to find a key intervention locus by observing activation patterns during diagnostic conversational tasks. We then derive emotional expression vectors from the difference in the activations generated by contrastive text pairs (positive vs. negative examples of target emotions). Applying these vectors to new conversational prompts significantly enhances emotional characteristics: steered responses show increased positive sentiment (e.g., joy, trust) and more frequent first-person pronoun usage, indicative of greater personal engagement. Our findings offer a precise and interpretable framework and new directions for the study of conversational AI.",
    "published": "2025-11-16T23:33:06Z",
    "updated": "2025-11-16T23:33:06Z",
    "link": "http://arxiv.org/pdf/2511.12832v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Niranjan Chebrolu",
      "Gerard Christopher Yeo",
      "Kokil Jaidka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12828v1",
    "title": "Catastrophic Forgetting in Kolmogorov-Arnold Networks",
    "summary": "Catastrophic forgetting is a longstanding challenge in continual learning, where models lose knowledge from earlier tasks when learning new ones. While various mitigation strategies have been proposed for Multi-Layer Perceptrons (MLPs), recent architectural advances like Kolmogorov-Arnold Networks (KANs) have been suggested to offer intrinsic resistance to forgetting by leveraging localized spline-based activations. However, the practical behavior of KANs under continual learning remains unclear, and their limitations are not well understood. To address this, we present a comprehensive study of catastrophic forgetting in KANs and develop a theoretical framework that links forgetting to activation support overlap and intrinsic data dimension. We validate these analyses through systematic experiments on synthetic and vision tasks, measuring forgetting dynamics under varying model configurations and data complexity. Further, we introduce KAN-LoRA, a novel adapter design for parameter-efficient continual fine-tuning of language models, and evaluate its effectiveness in knowledge editing tasks. Our findings reveal that while KANs exhibit promising retention in low-dimensional algorithmic settings, they remain vulnerable to forgetting in high-dimensional domains such as image classification and language modeling. These results advance the understanding of KANs' strengths and limitations, offering practical insights for continual learning system design.",
    "published": "2025-11-16T23:22:50Z",
    "updated": "2025-11-16T23:22:50Z",
    "link": "http://arxiv.org/pdf/2511.12828v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Mohammad Marufur Rahman",
      "Guanchu Wang",
      "Kaixiong Zhou",
      "Minghan Chen",
      "Fan Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.18988v4",
    "title": "Timely Clinical Diagnosis through Active Test Selection",
    "summary": "There is growing interest in using machine learning (ML) to support clinical diagnosis, but most approaches rely on static, fully observed datasets and fail to reflect the sequential, resource-aware reasoning clinicians use in practice. Diagnosis remains complex and error prone, especially in high-pressure or resource-limited settings, underscoring the need for frameworks that help clinicians make timely and cost-effective decisions. We propose ACTMED (Adaptive Clinical Test selection via Model-based Experimental Design), a diagnostic framework that integrates Bayesian Experimental Design (BED) with large language models (LLMs) to better emulate real-world diagnostic reasoning. At each step, ACTMED selects the test expected to yield the greatest reduction in diagnostic uncertainty for a given patient. LLMs act as flexible simulators, generating plausible patient state distributions and supporting belief updates without requiring structured, task-specific training data. Clinicians can remain in the loop; reviewing test suggestions, interpreting intermediate outputs, and applying clinical judgment throughout. We evaluate ACTMED on real-world datasets and show it can optimize test selection to improve diagnostic accuracy, interpretability, and resource use. This represents a step toward transparent, adaptive, and clinician-aligned diagnostic systems that generalize across settings with reduced reliance on domain-specific data.",
    "published": "2025-10-21T18:10:45Z",
    "updated": "2025-11-16T23:13:57Z",
    "link": "http://arxiv.org/pdf/2510.18988v4.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Silas Ruhrberg Estévez",
      "Nicolás Astorga",
      "Mihaela van der Schaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.01110v2",
    "title": "NoLBERT: A No Lookahead(back) Foundational Language Model",
    "summary": "We present NoLBERT, a lightweight, timestamped foundational language model for empirical research -- particularly for forecasting in economics, finance, and the social sciences. By pretraining exclusively on text from 1976 to 1995, NoLBERT avoids both lookback and lookahead biases (information leakage) that can undermine econometric inference. It exceeds domain-specific baselines on NLP benchmarks while maintaining temporal consistency. Applied to patent texts, NoLBERT enables the construction of firm-level innovation networks and shows that gains in innovation centrality predict higher long-run profit growth.",
    "published": "2025-09-01T04:07:10Z",
    "updated": "2025-11-16T23:13:08Z",
    "link": "http://arxiv.org/pdf/2509.01110v2.pdf",
    "category": [
      "econ.GN",
      "cs.AI",
      "cs.LG",
      "q-fin.GN"
    ],
    "authors": [
      "Ali Kakhbod",
      "Peiyao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.05810v2",
    "title": "DiagnoLLM: A Hybrid Bayesian Neural Language Framework for Interpretable Disease Diagnosis",
    "summary": "Building trustworthy clinical AI systems requires not only accurate predictions but also transparent, biologically grounded explanations. We present \\texttt{DiagnoLLM}, a hybrid framework that integrates Bayesian deconvolution, eQTL-guided deep learning, and LLM-based narrative generation for interpretable disease diagnosis. DiagnoLLM begins with GP-unmix, a Gaussian Process-based hierarchical model that infers cell-type-specific gene expression profiles from bulk and single-cell RNA-seq data while modeling biological uncertainty. These features, combined with regulatory priors from eQTL analysis, power a neural classifier that achieves high predictive performance in Alzheimer's Disease (AD) detection (88.0\\% accuracy). To support human understanding and trust, we introduce an LLM-based reasoning module that translates model outputs into audience-specific diagnostic reports, grounded in clinical features, attribution signals, and domain knowledge. Human evaluations confirm that these reports are accurate, actionable, and appropriately tailored for both physicians and patients. Our findings show that LLMs, when deployed as post-hoc reasoners rather than end-to-end predictors, can serve as effective communicators within hybrid diagnostic pipelines.",
    "published": "2025-11-08T02:51:21Z",
    "updated": "2025-11-16T22:54:36Z",
    "link": "http://arxiv.org/pdf/2511.05810v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Bowen Xu",
      "Xinyue Zeng",
      "Jiazhen Hu",
      "Tuo Wang",
      "Adithya Kulkarni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.17984v2",
    "title": "Machine Unlearning of Traffic State Estimation and Prediction",
    "summary": "Data-driven traffic state estimation and prediction (TSEP) relies heavily on data sources that contain sensitive information. While the abundance of data has fueled significant breakthroughs, particularly in machine learning-based methods, it also raises concerns regarding privacy, cybersecurity, and data freshness. These issues can erode public trust in intelligent transportation systems. Recently, regulations have introduced the \"right to be forgotten\", allowing users to request the removal of their private data from models. As machine learning models can remember old data, simply removing it from back-end databases is insufficient in such systems. To address these challenges, this study introduces a novel learning paradigm for TSEP-Machine Unlearning TSEP-which enables a trained TSEP model to selectively forget privacy-sensitive, poisoned, or outdated data. By empowering models to \"unlearn,\" we aim to enhance the trustworthiness and reliability of data-driven traffic TSEP.",
    "published": "2025-07-23T23:23:18Z",
    "updated": "2025-11-16T22:36:08Z",
    "link": "http://arxiv.org/pdf/2507.17984v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xin Wang",
      "R. Tyrrell Rockafellar",
      " Xuegang",
      " Ban"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12810v1",
    "title": "MSRNet: A Multi-Scale Recursive Network for Camouflaged Object Detection",
    "summary": "Camouflaged object detection is an emerging and challenging computer vision task that requires identifying and segmenting objects that blend seamlessly into their environments due to high similarity in color, texture, and size. This task is further complicated by low-light conditions, partial occlusion, small object size, intricate background patterns, and multiple objects. While many sophisticated methods have been proposed for this task, current methods still struggle to precisely detect camouflaged objects in complex scenarios, especially with small and multiple objects, indicating room for improvement. We propose a Multi-Scale Recursive Network that extracts multi-scale features via a Pyramid Vision Transformer backbone and combines them via specialized Attention-Based Scale Integration Units, enabling selective feature merging. For more precise object detection, our decoder recursively refines features by incorporating Multi-Granularity Fusion Units. A novel recursive-feedback decoding strategy is developed to enhance global context understanding, helping the model overcome the challenges in this task. By jointly leveraging multi-scale learning and recursive feature optimization, our proposed method achieves performance gains, successfully detecting small and multiple camouflaged objects. Our model achieves state-of-the-art results on two benchmark datasets for camouflaged object detection and ranks second on the remaining two. Our codes, model weights, and results are available at \\href{https://github.com/linaagh98/MSRNet}{https://github.com/linaagh98/MSRNet}.",
    "published": "2025-11-16T22:29:06Z",
    "updated": "2025-11-16T22:29:06Z",
    "link": "http://arxiv.org/pdf/2511.12810v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "authors": [
      "Leena Alghamdi",
      "Muhammad Usman",
      "Hafeez Anwar",
      "Abdul Bais",
      "Saeed Anwar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12808v1",
    "title": "Expressive Temporal Specifications for Reward Monitoring",
    "summary": "Specifying informative and dense reward functions remains a pivotal challenge in Reinforcement Learning, as it directly affects the efficiency of agent training. In this work, we harness the expressive power of quantitative Linear Temporal Logic on finite traces (($\\text{LTL}_f[\\mathcal{F}]$)) to synthesize reward monitors that generate a dense stream of rewards for runtime-observable state trajectories. By providing nuanced feedback during training, these monitors guide agents toward optimal behaviour and help mitigate the well-known issue of sparse rewards under long-horizon decision making, which arises under the Boolean semantics dominating the current literature. Our framework is algorithm-agnostic and only relies on a state labelling function, and naturally accommodates specifying non-Markovian properties. Empirical results show that our quantitative monitors consistently subsume and, depending on the environment, outperform Boolean monitors in maximizing a quantitative measure of task completion and in reducing convergence time.",
    "published": "2025-11-16T22:28:30Z",
    "updated": "2025-11-16T22:28:30Z",
    "link": "http://arxiv.org/pdf/2511.12808v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "authors": [
      "Omar Adalat",
      "Francesco Belardinelli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12804v1",
    "title": "The Alignment Game: A Theory of Long-Horizon Alignment Through Recursive Curation",
    "summary": "In self-consuming generative models that train on their own outputs, alignment with user preferences becomes a recursive rather than one-time process. We provide the first formal foundation for analyzing the long-term effects of such recursive retraining on alignment. Under a two-stage curation mechanism based on the Bradley-Terry (BT) model, we model alignment as an interaction between two factions: the Model Owner, who filters which outputs should be learned by the model, and the Public User, who determines which outputs are ultimately shared and retained through interactions with the model. Our analysis reveals three structural convergence regimes depending on the degree of preference alignment: consensus collapse, compromise on shared optima, and asymmetric refinement. We prove a fundamental impossibility theorem: no recursive BT-based curation mechanism can simultaneously preserve diversity, ensure symmetric influence, and eliminate dependence on initialization. Framing the process as dynamic social choice, we show that alignment is not a static goal but an evolving equilibrium, shaped both by power asymmetries and path dependence.",
    "published": "2025-11-16T22:17:16Z",
    "updated": "2025-11-16T22:17:16Z",
    "link": "http://arxiv.org/pdf/2511.12804v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ali Falahati",
      "Mohammad Mohammadi Amiri",
      "Kate Larson",
      "Lukasz Golab"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.12155v6",
    "title": "Coarse-to-fine Q-Network with Action Sequence for Data-Efficient Reinforcement Learning",
    "summary": "Predicting a sequence of actions has been crucial in the success of recent behavior cloning algorithms in robotics. Can similar ideas improve reinforcement learning (RL)? We answer affirmatively by observing that incorporating action sequences when predicting ground-truth return-to-go leads to lower validation loss. Motivated by this, we introduce Coarse-to-fine Q-Network with Action Sequence (CQN-AS), a novel value-based RL algorithm that learns a critic network that outputs Q-values over a sequence of actions, i.e., explicitly training the value function to learn the consequence of executing action sequences. Our experiments show that CQN-AS outperforms several baselines on a variety of sparse-reward humanoid control and tabletop manipulation tasks from BiGym and RLBench.",
    "published": "2024-11-19T01:23:52Z",
    "updated": "2025-11-16T22:06:44Z",
    "link": "http://arxiv.org/pdf/2411.12155v6.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Younggyo Seo",
      "Pieter Abbeel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12797v1",
    "title": "Genomic Next-Token Predictors are In-Context Learners",
    "summary": "In-context learning (ICL) -- the capacity of a model to infer and apply abstract patterns from examples provided within its input -- has been extensively studied in large language models trained for next-token prediction on human text. In fact, prior work often attributes this emergent behavior to distinctive statistical properties in human language. This raises a fundamental question: can ICL arise organically in other sequence domains purely through large-scale predictive training?\n  To explore this, we turn to genomic sequences, an alternative symbolic domain rich in statistical structure. Specifically, we study the Evo2 genomic model, trained predominantly on next-nucleotide (A/T/C/G) prediction, at a scale comparable to mid-sized LLMs. We develop a controlled experimental framework comprising symbolic reasoning tasks instantiated in both linguistic and genomic forms, enabling direct comparison of ICL across genomic and linguistic models. Our results show that genomic models, like their linguistic counterparts, exhibit log-linear gains in pattern induction as the number of in-context demonstrations increases. To the best of our knowledge, this is the first evidence of organically emergent ICL in genomic sequences, supporting the hypothesis that ICL arises as a consequence of large-scale predictive modeling over rich data. These findings extend emergent meta-learning beyond language, pointing toward a unified, modality-agnostic view of in-context learning.",
    "published": "2025-11-16T21:56:39Z",
    "updated": "2025-11-16T21:56:39Z",
    "link": "http://arxiv.org/pdf/2511.12797v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "authors": [
      "Nathan Breslow",
      "Aayush Mishra",
      "Mahler Revsine",
      "Michael C. Schatz",
      "Anqi Liu",
      "Daniel Khashabi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12796v1",
    "title": "Maximizing the efficiency of human feedback in AI alignment: a comparative analysis",
    "summary": "Reinforcement Learning from Human Feedback (RLHF) relies on preference modeling to align machine learning systems with human values, yet the popular approach of random pair sampling with Bradley-Terry modeling is statistically limited and inefficient under constrained annotation budgets. In this work, we explore alternative sampling and evaluation strategies for preference inference in RLHF, drawing inspiration from areas such as game theory, statistics, and social choice theory. Our best-performing method, Swiss InfoGain, employs a Swiss tournament system with a proxy mutual-information-gain pairing rule, which significantly outperforms all other methods in constrained annotation budgets while also being more sample-efficient. Even in high-resource settings, we can identify superior alternatives to the Bradley-Terry baseline. Our experiments demonstrate that adaptive, resource-aware strategies reduce redundancy, enhance robustness, and yield statistically significant improvements in preference learning, highlighting the importance of balancing alignment quality with human workload in RLHF pipelines.",
    "published": "2025-11-16T21:55:59Z",
    "updated": "2025-11-16T21:55:59Z",
    "link": "http://arxiv.org/pdf/2511.12796v1.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "Andreas Chouliaras",
      "Dimitris Chatzopoulos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12793v1",
    "title": "Neuro-Logic Lifelong Learning",
    "summary": "Solving Inductive Logic Programming (ILP) problems with neural networks is a key challenge in Neural-Symbolic Ar- tificial Intelligence (AI). While most research has focused on designing novel network architectures for individual prob- lems, less effort has been devoted to exploring new learning paradigms involving a sequence of problems. In this work, we investigate lifelong learning ILP, which leverages the com- positional and transferable nature of logic rules for efficient learning of new problems. We introduce a compositional framework, demonstrating how logic rules acquired from ear- lier tasks can be efficiently reused in subsequent ones, leading to improved scalability and performance. We formalize our approach and empirically evaluate it on sequences of tasks. Experimental results validate the feasibility and advantages of this paradigm, opening new directions for continual learn- ing in Neural-Symbolic AI.",
    "published": "2025-11-16T21:51:18Z",
    "updated": "2025-11-16T21:51:18Z",
    "link": "http://arxiv.org/pdf/2511.12793v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Bowen He",
      "Xiaoan Xu",
      "Alper Kamil Bozkurt",
      "Vahid Tarokh",
      "Juncheng Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12792v1",
    "title": "Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization",
    "summary": "This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.",
    "published": "2025-11-16T21:47:04Z",
    "updated": "2025-11-16T21:47:04Z",
    "link": "http://arxiv.org/pdf/2511.12792v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Mohamad A. Hady",
      "Siyi Hu",
      "Mahardhika Pratama",
      "Zehong Cao",
      "Ryszard Kowalczyk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12791v1",
    "title": "Optimal Look-back Horizon for Time Series Forecasting in Federated Learning",
    "summary": "Selecting an appropriate look-back horizon remains a fundamental challenge in time series forecasting (TSF), particularly in the federated learning scenarios where data is decentralized, heterogeneous, and often non-independent. While recent work has explored horizon selection by preserving forecasting-relevant information in an intrinsic space, these approaches are primarily restricted to centralized and independently distributed settings. This paper presents a principled framework for adaptive horizon selection in federated time series forecasting through an intrinsic space formulation. We introduce a synthetic data generator (SDG) that captures essential temporal structures in client data, including autoregressive dependencies, seasonality, and trend, while incorporating client-specific heterogeneity. Building on this model, we define a transformation that maps time series windows into an intrinsic representation space with well-defined geometric and statistical properties. We then derive a decomposition of the forecasting loss into a Bayesian term, which reflects irreducible uncertainty, and an approximation term, which accounts for finite-sample effects and limited model capacity. Our analysis shows that while increasing the look-back horizon improves the identifiability of deterministic patterns, it also increases approximation error due to higher model complexity and reduced sample efficiency. We prove that the total forecasting loss is minimized at the smallest horizon where the irreducible loss starts to saturate, while the approximation loss continues to rise. This work provides a rigorous theoretical foundation for adaptive horizon selection for time series forecasting in federated learning.",
    "published": "2025-11-16T21:46:54Z",
    "updated": "2025-11-16T21:46:54Z",
    "link": "http://arxiv.org/pdf/2511.12791v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Dahao Tang",
      "Nan Yang",
      "Yanli Li",
      "Zhiyu Zhu",
      "Zhibo Jin",
      "Dong Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.16785v2",
    "title": "Interpreting the Effects of Quantization on LLMs",
    "summary": "Quantization offers a practical solution to deploy LLMs in resource-constraint environments. However, its impact on internal representations remains understudied, raising questions about the reliability of quantized models. In this study, we employ a range of interpretability techniques to investigate how quantization affects model and neuron behavior. We analyze multiple LLMs under 4-bit and 8-bit quantization. Our findings reveal that the impact of quantization on model calibration is generally minor. Analysis of neuron activations indicates that the number of dead neurons, i.e., those with activation values close to 0 across the dataset, remains consistent regardless of quantization. In terms of neuron contribution to predictions, we observe that smaller full precision models exhibit fewer salient neurons, whereas larger models tend to have more, with the exception of Llama-2-7B. The effect of quantization on neuron redundancy varies across models. Overall, our findings suggest that effect of quantization may vary by model and tasks, however, we did not observe any drastic change which may discourage the use of quantization as a reliable model compression technique.",
    "published": "2025-08-22T20:36:53Z",
    "updated": "2025-11-16T21:36:06Z",
    "link": "http://arxiv.org/pdf/2508.16785v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Manpreet Singh",
      "Hassan Sajjad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12785v1",
    "title": "Lightweight Optimal-Transport Harmonization on Edge Devices",
    "summary": "Color harmonization adjusts the colors of an inserted object so that it perceptually matches the surrounding image, resulting in a seamless composite. The harmonization problem naturally arises in augmented reality (AR), yet harmonization algorithms are not currently integrated into AR pipelines because real-time solutions are scarce. In this work, we address color harmonization for AR by proposing a lightweight approach that supports on-device inference. For this, we leverage classical optimal transport theory by training a compact encoder to predict the Monge-Kantorovich transport map. We benchmark our MKL-Harmonizer algorithm against state-of-the-art methods and demonstrate that for real composite AR images our method achieves the best aggregated score. We release our dedicated AR dataset of composite images with pixel-accurate masks and data-gathering toolkit to support further data acquisition by researchers.",
    "published": "2025-11-16T21:29:46Z",
    "updated": "2025-11-16T21:29:46Z",
    "link": "http://arxiv.org/pdf/2511.12785v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "authors": [
      "Maria Larchenko",
      "Dmitry Guskov",
      "Alexander Lobashev",
      "Georgy Derevyanko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12779v1",
    "title": "Scalable Multi-Objective and Meta Reinforcement Learning via Gradient Estimation",
    "summary": "We study the problem of efficiently estimating policies that simultaneously optimize multiple objectives in reinforcement learning (RL). Given $n$ objectives (or tasks), we seek the optimal partition of these objectives into $k \\ll n$ groups, where each group comprises related objectives that can be trained together. This problem arises in applications such as robotics, control, and preference optimization in language models, where learning a single policy for all $n$ objectives is suboptimal as $n$ grows. We introduce a two-stage procedure -- meta-training followed by fine-tuning -- to address this problem. We first learn a meta-policy for all objectives using multitask learning. Then, we adapt the meta-policy to multiple randomly sampled subsets of objectives. The adaptation step leverages a first-order approximation property of well-trained policy networks, which is empirically verified to be accurate within a $2\\%$ error margin across various RL environments. The resulting algorithm, PolicyGradEx, efficiently estimates an aggregate task-affinity score matrix given a policy evaluation algorithm. Based on the estimated affinity score matrix, we cluster the $n$ objectives into $k$ groups by maximizing the intra-cluster affinity scores. Experiments on three robotic control and the Meta-World benchmarks demonstrate that our approach outperforms state-of-the-art baselines by $16\\%$ on average, while delivering up to $26\\times$ faster speedup relative to performing full training to obtain the clusters. Ablation studies validate each component of our approach. For instance, compared with random grouping and gradient-similarity-based grouping, our loss-based clustering yields an improvement of $19\\%$. Finally, we analyze the generalization error of policy networks by measuring the Hessian trace of the loss surface, which gives non-vacuous measures relative to the observed generalization errors.",
    "published": "2025-11-16T21:05:21Z",
    "updated": "2025-11-16T21:05:21Z",
    "link": "http://arxiv.org/pdf/2511.12779v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zhenshuo Zhang",
      "Minxuan Duan",
      "Youran Ye",
      "Hongyang R. Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08234v2",
    "title": "On Geometric Structures for Policy Parameterization in Continuous Control",
    "summary": "Standard stochastic policies for continuous control often rely on ad-hoc boundary-enforcing transformations (e.g., tanh) which can distort the underlying optimization landscape and introduce gradient pathologies. While alternative parameterizations on the unit manifold (e.g., directional distributions) are theoretically appealing, their computational complexity (often requiring special functions or rejection sampling) has limited their practical use. We propose a novel, computationally efficient action generation paradigm that preserves the structural benefits of operating on a unit manifold. Our method decomposes the action into a deterministic directional vector and a learnable concentration scalar, enabling efficient interpolation between the target direction and uniform noise on the unit manifold. This design can reduce policy head parameters by nearly 50\\% (from $2d$ to $d+1$) and maintains a simple $O(d)$ sampling complexity, avoiding costly sampling procedures. Empirically, our method matches or exceeds state-of-the-art methods on standard continuous control benchmarks, with significant improvements (e.g., +37.6\\% and +112\\%) on high-dimensional locomotion tasks. Ablation studies confirm that both the unit-norm normalization and the adaptive concentration mechanism are essential to the method's success. These findings suggest that robust, efficient control can be achieved by explicitly respecting the structure of bounded action spaces, rather than relying on complex, unbounded distributions. Code is available in supplementary materials.",
    "published": "2025-11-11T13:32:38Z",
    "updated": "2025-11-16T21:02:53Z",
    "link": "http://arxiv.org/pdf/2511.08234v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Zhihao Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2401.06925v3",
    "title": "Foundations of Structural Causal Models with Latent Selection",
    "summary": "Three distinct phenomena complicate statistical causal analysis: latent common causes, causal cycles, and latent selection. Foundational works on Structural Causal Models (SCMs), e.g., Bongers et al. (2021, Ann. Stat., 49(5): 2885-2915), treat cycles and latent variables, while an analogous account of latent selection is missing. The goal of this article is to develop a theoretical foundation for modeling latent selection with SCMs. To achieve that, we introduce a conditioning operation for SCMs: it maps an SCM with explicit selection mechanisms to one without them while preserving the causal semantics of the selected subpopulation. Graphically, in Directed Mixed Graphs we extend bidirected edge--beyond latent common cause--to also encode latent selection. We prove that the conditioning operation preserves simplicity, acyclicity, and linearity of SCMs, and interacts well with marginalization, conditioning, and interventions. These properties make those three operations valuable tools for causal modeling, reasoning, and learning after abstracting away latent details (latent common causes and selection). Examples show how this abstraction streamlines analysis and clarifies when standard tools (e.g., adjustment, causal calculus, instrumental variables) remain valid under selection bias. We hope that these results deepen the SCM-based understanding of selection bias and become part of the standard causal modeling toolbox to build more reliable causal analysis.",
    "published": "2024-01-12T23:14:34Z",
    "updated": "2025-11-16T21:02:09Z",
    "link": "http://arxiv.org/pdf/2401.06925v3.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.ML"
    ],
    "authors": [
      "Leihao Chen",
      "Onno Zoeter",
      "Joris M. Mooij"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.03060v2",
    "title": "Efficiently Computing Compact Formal Explanations",
    "summary": "Building on VeriX (Verified eXplainability, arXiv:2212.01051), a system for producing optimal verified explanations for machine learning models, we present VeriX+, which significantly improves both the size and the generation time of formal explanations. We introduce a bound propagation-based sensitivity technique to improve the size, and a binary search-based traversal with confidence ranking for improving time -- the two techniques are orthogonal and can be used independently or together. We also show how to adapt the QuickXplain algorithm to our setting to provide a trade-off between size and time. Experimental evaluations on standard benchmarks demonstrate significant improvements on both metrics, e.g., a size reduction of $38\\%$ on the GTSRB dataset and a time reduction of $90\\%$ on MNIST. We demonstrate that our approach is scalable to transformers and real-world scenarios such as autonomous aircraft taxiing and sentiment analysis. We conclude by showcasing several novel applications of formal explanations.",
    "published": "2024-09-04T20:20:37Z",
    "updated": "2025-11-16T20:54:48Z",
    "link": "http://arxiv.org/pdf/2409.03060v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Min Wu",
      "Xiaofu Li",
      "Haoze Wu",
      "Clark Barrett"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12769v1",
    "title": "Event-CausNet: Unlocking Causal Knowledge from Text with Large Language Models for Reliable Spatio-Temporal Forecasting",
    "summary": "While spatio-temporal Graph Neural Networks (GNNs) excel at modeling recurring traffic patterns, their reliability plummets during non-recurring events like accidents. This failure occurs because GNNs are fundamentally correlational models, learning historical patterns that are invalidated by the new causal factors introduced during disruptions. To address this, we propose Event-CausNet, a framework that uses a Large Language Model to quantify unstructured event reports, builds a causal knowledge base by estimating average treatment effects, and injects this knowledge into a dual-stream GNN-LSTM network using a novel causal attention mechanism to adjust and enhance the forecast. Experiments on a real-world dataset demonstrate that Event-CausNet achieves robust performance, reducing prediction error (MAE) by up to 35.87%, significantly outperforming state-of-the-art baselines. Our framework bridges the gap between correlational models and causal reasoning, providing a solution that is more accurate and transferable, while also offering crucial interpretability, providing a more reliable foundation for real-world traffic management during critical disruptions.",
    "published": "2025-11-16T20:45:23Z",
    "updated": "2025-11-16T20:45:23Z",
    "link": "http://arxiv.org/pdf/2511.12769v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Luyao Niu",
      "Zepu Wang",
      "Shuyi Guan",
      "Yang Liu",
      "Peng Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12768v1",
    "title": "Evidence of Phase Transitions in Small Transformer-Based Language Models",
    "summary": "Phase transitions have been proposed as the origin of emergent abilities in large language models (LLMs), where new capabilities appear abruptly once models surpass critical thresholds of scale. Prior work, such as that of Wei et al., demonstrated these phenomena under model and data scaling, with transitions revealed after applying a log scale to training compute. In this work, we ask three complementary questions: (1) Are phase transitions unique to large models, or can they also be observed in small transformer-based language models? (2) Can such transitions be detected directly in linear training space, rather than only after log rescaling? and (3) Can these transitions emerge at early stages of training? To investigate, we train a small GPT-style transformer on a character-level corpus and analyze the evolution of vocabulary usage throughout training. We track the average word length, the number of correct versus incorrect words, and shifts in vocabulary diversity. Building on these measures, we apply Poisson and sub-Poisson statistics to quantify how words connect and reorganize. This combined analysis reveals a distinct transition point during training. Notably, these transitions are not apparent in standard loss or validation curves, but become visible through our vocabulary- and statistics-based probes. Our findings suggest that phase-transition reorganizations are a general feature of language model training, observable even in modest models, detectable directly in linear training space, and occurring surprisingly early as coherence emerges. This perspective provides new insight into the nonlinear dynamics of language model training and underscores the importance of tailored metrics for uncovering phase transition behaviors",
    "published": "2025-11-16T20:37:12Z",
    "updated": "2025-11-16T20:37:12Z",
    "link": "http://arxiv.org/pdf/2511.12768v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Noah Hong",
      "Tao Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14741v2",
    "title": "DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models",
    "summary": "Understanding and explaining the behavior of machine learning models is essential for building transparent and trustworthy AI systems. We introduce DEXTER, a data-free framework that employs diffusion models and large language models to generate global, textual explanations of visual classifiers. DEXTER operates by optimizing text prompts to synthesize class-conditional images that strongly activate a target classifier. These synthetic samples are then used to elicit detailed natural language reports that describe class-specific decision patterns and biases. Unlike prior work, DEXTER enables natural language explanation about a classifier's decision process without access to training data or ground-truth labels. We demonstrate DEXTER's flexibility across three tasks-activation maximization, slice discovery and debiasing, and bias explanation-each illustrating its ability to uncover the internal mechanisms of visual classifiers. Quantitative and qualitative evaluations, including a user study, show that DEXTER produces accurate, interpretable outputs. Experiments on ImageNet, Waterbirds, CelebA, and FairFaces confirm that DEXTER outperforms existing approaches in global model explanation and class-level bias reporting. Code is available at https://github.com/perceivelab/dexter.",
    "published": "2025-10-16T14:43:25Z",
    "updated": "2025-11-16T20:16:19Z",
    "link": "http://arxiv.org/pdf/2510.14741v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Simone Carnemolla",
      "Matteo Pennisi",
      "Sarinda Samarasinghe",
      "Giovanni Bellitto",
      "Simone Palazzo",
      "Daniela Giordano",
      "Mubarak Shah",
      "Concetto Spampinato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12759v1",
    "title": "Optimal Foraging in Memory Retrieval: Evaluating Random Walks and Metropolis-Hastings Sampling in Modern Semantic Spaces",
    "summary": "Human memory retrieval often resembles ecological foraging where animals search for food in a patchy environment. Optimal foraging means following the Marginal Value Theorem (MVT), in which individuals exploit a patch of semantically related concepts until it becomes less rewarding and then switch to a new cluster. While human behavioral data suggests foraging-like patterns in semantic fluency tasks, it remains unclear whether modern high-dimensional embedding spaces provide representations that allow algorithms to match observed human behavior. Using state-of-the-art embeddings and prior semantic fluency data, I find that random walks on these embedding spaces produce results consistent with optimal foraging and the MVT. Surprisingly, introducing Metropolis-Hastings sampling, an adaptive algorithm expected to model strategic acceptance and rejection of new clusters, does not produce results consistent with human behavior. These findings challenge the assumption that more complex sampling mechanisms inherently lead to better cognitive models of memory retrieval. Instead, they show that appropriately structured embeddings, even with simple sampling, can produce near-optimal foraging dynamics. This supports the perspective of Hills (2012) rather than Abbott (2015), demonstrating that modern embeddings can approximate human memory foraging without relying on complex acceptance criteria.",
    "published": "2025-11-16T20:08:29Z",
    "updated": "2025-11-16T20:08:29Z",
    "link": "http://arxiv.org/pdf/2511.12759v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "James Moore"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12757v1",
    "title": "Which Way from B to A: The role of embedding geometry in image interpolation for Stable Diffusion",
    "summary": "It can be shown that Stable Diffusion has a permutation-invariance property with respect to the rows of Contrastive Language-Image Pretraining (CLIP) embedding matrices. This inspired the novel observation that these embeddings can naturally be interpreted as point clouds in a Wasserstein space rather than as matrices in a Euclidean space. This perspective opens up new possibilities for understanding the geometry of embedding space. For example, when interpolating between embeddings of two distinct prompts, we propose reframing the interpolation problem as an optimal transport problem. By solving this optimal transport problem, we compute a shortest path (or geodesic) between embeddings that captures a more natural and geometrically smooth transition through the embedding space. This results in smoother and more coherent intermediate (interpolated) images when rendered by the Stable Diffusion generative model. We conduct experiments to investigate this effect, comparing the quality of interpolated images produced using optimal transport to those generated by other standard interpolation methods. The novel optimal transport--based approach presented indeed gives smoother image interpolations, suggesting that viewing the embeddings as point clouds (rather than as matrices) better reflects and leverages the geometry of the embedding space.",
    "published": "2025-11-16T19:58:48Z",
    "updated": "2025-11-16T19:58:48Z",
    "link": "http://arxiv.org/pdf/2511.12757v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Nicholas Karris",
      "Luke Durell",
      "Javier Flores",
      "Tegan Emerson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.12492v3",
    "title": "Temporal Test-Time Adaptation with State-Space Models",
    "summary": "Distribution shifts between training and test data are inevitable over the lifecycle of a deployed model, leading to performance decay. Adapting a model on test samples can help mitigate this drop in performance. However, most test-time adaptation methods have focused on synthetic corruption shifts, leaving a variety of distribution shifts underexplored. In this paper, we focus on distribution shifts that evolve gradually over time, which are common in the wild but challenging for existing methods, as we show. To address this, we propose STAD, a Bayesian filtering method that adapts a deployed model to temporal distribution shifts by learning the time-varying dynamics in the last set of hidden features. Without requiring labels, our model infers time-evolving class prototypes that act as a dynamic classification head. Through experiments on real-world temporal distribution shifts, we show that our method excels in handling small batch sizes and label shift.",
    "published": "2024-07-17T11:18:49Z",
    "updated": "2025-11-16T19:55:38Z",
    "link": "http://arxiv.org/pdf/2407.12492v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "authors": [
      "Mona Schirmer",
      "Dan Zhang",
      "Eric Nalisnick"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12754v1",
    "title": "Adaptively Coordinating with Novel Partners via Learned Latent Strategies",
    "summary": "Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult. In this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. Our approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type. For online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction. We evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space. Through these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.",
    "published": "2025-11-16T19:45:35Z",
    "updated": "2025-11-16T19:45:35Z",
    "link": "http://arxiv.org/pdf/2511.12754v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      "Benjamin Li",
      "Shuyang Shi",
      "Lucia Romero",
      "Huao Li",
      "Yaqi Xie",
      "Woojun Kim",
      "Stefanos Nikolaidis",
      "Michael Lewis",
      "Katia Sycara",
      "Simon Stepputtis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12752v1",
    "title": "Whose Narrative is it Anyway? A KV Cache Manipulation Attack",
    "summary": "The Key Value(KV) cache is an important component for efficient inference in autoregressive Large Language Models (LLMs), but its role as a representation of the model's internal state makes it a potential target for integrity attacks. This paper introduces \"History Swapping,\" a novel block-level attack that manipulates the KV cache to steer model generation without altering the user-facing prompt. The attack involves overwriting a contiguous segment of the active generation's cache with a precomputed cache from a different topic. We empirically evaluate this method across 324 configurations on the Qwen 3 family of models, analyzing the impact of timing, magnitude, and layer depth of the cache overwrite. Our findings reveal that only full-layer overwrites can successfully hijack the conversation's topic, leading to three distinct behaviors: immediate and persistent topic shift, partial recovery, or a delayed hijack. Furthermore, we observe that high-level structural plans are encoded early in the generation process and local discourse structure is maintained by the final layers of the model. This work demonstrates that the KV cache is a significant vector for security analysis, as it encodes not just context but also topic trajectory and structural planning, making it a powerful interface for manipulating model behavior.",
    "published": "2025-11-16T19:38:28Z",
    "updated": "2025-11-16T19:38:28Z",
    "link": "http://arxiv.org/pdf/2511.12752v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Mukkesh Ganesh",
      "Kaushik Iyer",
      "Arun Baalaaji Sankar Ananthan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.00833v2",
    "title": "HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning",
    "summary": "For robotic manipulation, existing robotics datasets and simulation benchmarks predominantly cater to robot-arm platforms. However, for humanoid robots equipped with dual arms and dexterous hands, simulation tasks and high-quality demonstrations are notably lacking. Bimanual dexterous manipulation is inherently more complex, as it requires coordinated arm movements and hand operations, making autonomous data collection challenging. This paper presents HumanoidGen, an automated task creation and demonstration collection framework that leverages atomic dexterous operations and LLM reasoning to generate relational constraints. Specifically, we provide spatial annotations for both assets and dexterous hands based on the atomic operations, and perform an LLM planner to generate a chain of actionable spatial constraints for arm movements based on object affordances and scenes. To further improve planning ability, we employ a variant of Monte Carlo tree search to enhance LLM reasoning for long-horizon tasks and insufficient annotation. In experiments, we create a novel benchmark with augmented scenarios to evaluate the quality of the collected data. The results show that the performance of the 2D and 3D diffusion policies can scale with the generated dataset. Project page is https://openhumanoidgen.github.io.",
    "published": "2025-07-01T15:04:38Z",
    "updated": "2025-11-16T19:36:16Z",
    "link": "http://arxiv.org/pdf/2507.00833v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Zhi Jing",
      "Siyuan Yang",
      "Jicong Ao",
      "Ting Xiao",
      "Yu-Gang Jiang",
      "Chenjia Bai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12751v1",
    "title": "Are LLMs The Way Forward? A Case Study on LLM-Guided Reinforcement Learning for Decentralized Autonomous Driving",
    "summary": "Autonomous vehicle navigation in complex environments such as dense and fast-moving highways and merging scenarios remains an active area of research. A key limitation of RL is its reliance on well-specified reward functions, which often fail to capture the full semantic and social complexity of diverse, out-of-distribution situations. As a result, a rapidly growing line of research explores using Large Language Models (LLMs) to replace or supplement RL for direct planning and control, on account of their ability to reason about rich semantic context. However, LLMs present significant drawbacks: they can be unstable in zero-shot safety-critical settings, produce inconsistent outputs, and often depend on expensive API calls with network latency. This motivates our investigation into whether small, locally deployed LLMs (< 14B parameters) can meaningfully support autonomous highway driving through reward shaping rather than direct control. We present a case study comparing RL-only, LLM-only, and hybrid approaches, where LLMs augment RL rewards by scoring state-action transitions during training, while standard RL policies execute at test time. Our findings reveal that RL-only agents achieve moderate success rates (73-89%) with reasonable efficiency, LLM-only agents can reach higher success rates (up to 94%) but with severely degraded speed performance, and hybrid approaches consistently fall between these extremes. Critically, despite explicit efficiency instructions, LLM-influenced approaches exhibit systematic conservative bias with substantial model-dependent variability, highlighting important limitations of current small LLMs for safety-critical control tasks.",
    "published": "2025-11-16T19:31:42Z",
    "updated": "2025-11-16T19:31:42Z",
    "link": "http://arxiv.org/pdf/2511.12751v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Timur Anvar",
      "Jeffrey Chen",
      "Yuyan Wang",
      "Rohan Chandra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.06568v2",
    "title": "Breaking the Dyadic Barrier: Rethinking Fairness in Link Prediction Beyond Demographic Parity",
    "summary": "Link prediction is a fundamental task in graph machine learning with applications, ranging from social recommendation to knowledge graph completion. Fairness in this setting is critical, as biased predictions can exacerbate societal inequalities. Prior work adopts a dyadic definition of fairness, enforcing fairness through demographic parity between intra-group and inter-group link predictions. However, we show that this dyadic framing can obscure underlying disparities across subgroups, allowing systemic biases to go undetected. Moreover, we argue that demographic parity does not meet desired properties for fairness assessment in ranking-based tasks such as link prediction. We formalize the limitations of existing fairness evaluations and propose a framework that enables a more expressive assessment. Additionally, we propose a lightweight post-processing method combined with decoupled link predictors that effectively mitigates bias and achieves state-of-the-art fairness-utility trade-offs.",
    "published": "2025-11-09T22:58:29Z",
    "updated": "2025-11-16T19:26:28Z",
    "link": "http://arxiv.org/pdf/2511.06568v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "stat.ML"
    ],
    "authors": [
      "João Mattos",
      "Debolina Halder Lina",
      "Arlei Silva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10680v4",
    "title": "Saturation Self-Organizing Map",
    "summary": "Continual learning poses a fundamental challenge for neural systems, which often suffer from catastrophic forgetting when exposed to sequential tasks. Self-Organizing Maps (SOMs), despite their interpretability and efficiency, are not immune to this issue. In this paper, we introduce Saturation Self-Organizing Maps (SatSOM)-an extension of SOMs designed to improve knowledge retention in continual learning scenarios. SatSOM incorporates a novel saturation mechanism that gradually reduces the learning rate and neighborhood radius of neurons as they accumulate information. This effectively freezes well-trained neurons and redirects learning to underutilized areas of the map.",
    "published": "2025-06-12T13:18:26Z",
    "updated": "2025-11-16T19:22:26Z",
    "link": "http://arxiv.org/pdf/2506.10680v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Igor Urbanik",
      "Paweł Gajewski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08206v2",
    "title": "EHRStruct: A Comprehensive Benchmark Framework for Evaluating Large Language Models on Structured Electronic Health Record Tasks",
    "summary": "Structured Electronic Health Record (EHR) data stores patient information in relational tables and plays a central role in clinical decision-making. Recent advances have explored the use of large language models (LLMs) to process such data, showing promise across various clinical tasks.However, the absence of standardized evaluation frameworks and clearly defined tasks makes it difficult to systematically assess and compare LLM performance on structured EHR data.To address these evaluation challenges, we introduce EHRStruct, a benchmark specifically designed to evaluate LLMs on structured EHR tasks.EHRStruct defines 11 representative tasks spanning diverse clinical needs and includes 2,200 task-specific evaluation samples derived from two widely used EHR datasets.We use EHRStruct to evaluate 20 advanced and representative LLMs, covering both general and medical models.We further analyze key factors influencing model performance, including input formats, few-shot generalisation, and finetuning strategies, and compare results with 11 state-of-the-art LLM-based enhancement methods for structured data reasoning. Our results indicate that many structured EHR tasks place high demands on the understanding and reasoning capabilities of LLMs.In response, we propose EHRMaster, a code-augmented method that achieves state-of-the-art performance and offers practical",
    "published": "2025-11-11T13:10:13Z",
    "updated": "2025-11-16T19:04:56Z",
    "link": "http://arxiv.org/pdf/2511.08206v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Xiao Yang",
      "Xuejiao Zhao",
      "Zhiqi Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13505v1",
    "title": "Applying Large Language Models to Characterize Public Narratives",
    "summary": "Public Narratives (PNs) are key tools for leadership development and civic mobilization, yet their systematic analysis remains challenging due to their subjective interpretation and the high cost of expert annotation. In this work, we propose a novel computational framework that leverages large language models (LLMs) to automate the qualitative annotation of public narratives. Using a codebook we co-developed with subject-matter experts, we evaluate LLM performance against that of expert annotators. Our work reveals that LLMs can achieve near-human-expert performance, achieving an average F1 score of 0.80 across 8 narratives and 14 codes. We then extend our analysis to empirically explore how PN framework elements manifest across a larger dataset of 22 stories. Lastly, we extrapolate our analysis to a set of political speeches, establishing a novel lens in which to analyze political rhetoric in civic spaces. This study demonstrates the potential of LLM-assisted annotation for scalable narrative analysis and highlights key limitations and directions for future research in computational civic storytelling.",
    "published": "2025-11-17T15:41:55Z",
    "updated": "2025-11-17T15:41:55Z",
    "link": "http://arxiv.org/pdf/2511.13505v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Elinor Poole-Dayan",
      "Daniel T Kessler",
      "Hannah Chiou",
      "Margaret Hughes",
      "Emily S Lin",
      "Marshall Ganz",
      "Deb Roy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.14011v3",
    "title": "QuanTaxo: A Quantum Approach to Self-Supervised Taxonomy Expansion",
    "summary": "A taxonomy is a hierarchical graph containing knowledge to provide valuable insights for various web applications. However, the manual construction of taxonomies requires significant human effort. As web content continues to expand at an unprecedented pace, existing taxonomies risk becoming outdated, struggling to incorporate new and emerging information effectively. As a consequence, there is a growing need for dynamic taxonomy expansion to keep them relevant and up-to-date. Existing taxonomy expansion methods often rely on classical word embeddings to represent entities. However, these embeddings fall short of capturing hierarchical polysemy, where an entity's meaning can vary based on its position in the hierarchy and its surrounding context. To address this challenge, we introduce QuanTaxo, a quantum-inspired framework for taxonomy expansion that encodes entities in a Hilbert space and models interference effects between them, yielding richer, context-sensitive representations. Comprehensive experiments on five real-world benchmark datasets show that QuanTaxo significantly outperforms classical embedding models, achieving substantial improvements of 12.3% in accuracy, 11.2% in Mean Reciprocal Rank (MRR), and 6.9% in Wu & Palmer (Wu&P) metrics across nine classical embedding-based baselines.",
    "published": "2025-01-23T18:40:02Z",
    "updated": "2025-11-17T15:18:18Z",
    "link": "http://arxiv.org/pdf/2501.14011v3.pdf",
    "category": [
      "cs.SI",
      "cs.CL"
    ],
    "authors": [
      "Sahil Mishra",
      "Avi Patni",
      "Niladri Chatterjee",
      "Tanmoy Chakraborty"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13481v1",
    "title": "Aspect-Level Obfuscated Sentiment in Thai Financial Disclosures and Its Impact on Abnormal Returns",
    "summary": "Understanding sentiment in financial documents is crucial for gaining insights into market behavior. These reports often contain obfuscated language designed to present a positive or neutral outlook, even when underlying conditions may be less favorable. This paper presents a novel approach using Aspect-Based Sentiment Analysis (ABSA) to decode obfuscated sentiment in Thai financial annual reports. We develop specific guidelines for annotating obfuscated sentiment in these texts and annotate more than one hundred financial reports. We then benchmark various text classification models on this annotated dataset, demonstrating strong performance in sentiment classification. Additionally, we conduct an event study to evaluate the real-world implications of our sentiment analysis on stock prices. Our results suggest that market reactions are selectively influenced by specific aspects within the reports. Our findings underscore the complexity of sentiment analysis in financial texts and highlight the importance of addressing obfuscated language to accurately assess market sentiment.",
    "published": "2025-11-17T15:17:46Z",
    "updated": "2025-11-17T15:17:46Z",
    "link": "http://arxiv.org/pdf/2511.13481v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Attapol T. Rutherford",
      "Sirisak Chueykamhang",
      "Thachaparn Bunditlurdruk",
      "Nanthicha Angsuwichitkul"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13467v1",
    "title": "Non-Linear Scoring Model for Translation Quality Evaluation",
    "summary": "Analytic Translation Quality Evaluation (TQE), based on Multidimensional Quality Metrics (MQM), traditionally uses a linear error-to-penalty scale calibrated to a reference sample of 1000-2000 words. However, linear extrapolation biases judgment on samples of different sizes, over-penalizing short samples and under-penalizing long ones, producing misalignment with expert intuition.\n  Building on the Multi-Range framework, this paper presents a calibrated, non-linear scoring model that better reflects how human content consumers perceive translation quality across samples of varying length. Empirical data from three large-scale enterprise environments shows that acceptable error counts grow logarithmically, not linearly, with sample size.\n  Psychophysical and cognitive evidence, including the Weber-Fechner law and Cognitive Load Theory, supports this premise by explaining why the perceptual impact of additional errors diminishes while the cognitive burden grows with scale. We propose a two-parameter model\n  E(x) = a * ln(1 + b * x), a, b > 0,\n  anchored to a reference tolerance and calibrated from two tolerance points using a one-dimensional root-finding step. The model yields an explicit interval within which the linear approximation stays within +/-20 percent relative error and integrates into existing evaluation workflows with only a dynamic tolerance function added.\n  The approach improves interpretability, fairness, and inter-rater reliability across both human and AI-generated translations. By operationalizing a perceptually valid scoring paradigm, it advances translation quality evaluation toward more accurate and scalable assessment. The model also provides a stronger basis for AI-based document-level evaluation aligned with human judgment. Implementation considerations for CAT/LQA systems and implications for human and AI-generated text evaluation are discussed.",
    "published": "2025-11-17T15:09:22Z",
    "updated": "2025-11-17T15:09:22Z",
    "link": "http://arxiv.org/pdf/2511.13467v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Serge Gladkoff",
      "Lifeng Han",
      "Katerina Gasova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.14128v2",
    "title": "Building a Macedonian Recipe Dataset: Collection, Parsing, and Comparative Analysis",
    "summary": "Computational gastronomy increasingly relies on diverse, high-quality recipe datasets to capture regional culinary traditions. Although there are large-scale collections for major languages, Macedonian recipes remain under-represented in digital research. In this work, we present the first systematic effort to construct a Macedonian recipe dataset through web scraping and structured parsing. We address challenges in processing heterogeneous ingredient descriptions, including unit, quantity, and descriptor normalization. An exploratory analysis of ingredient frequency and co-occurrence patterns, using measures such as Pointwise Mutual Information and Lift score, highlights distinctive ingredient combinations that characterize Macedonian cuisine. The resulting dataset contributes a new resource for studying food culture in underrepresented languages and offers insights into the unique patterns of Macedonian culinary tradition.",
    "published": "2025-10-15T21:54:23Z",
    "updated": "2025-11-17T14:50:31Z",
    "link": "http://arxiv.org/pdf/2510.14128v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Darko Sasanski",
      "Dimitar Peshevski",
      "Riste Stojanov",
      "Dimitar Trajanov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13415v1",
    "title": "Attention Grounded Enhancement for Visual Document Retrieval",
    "summary": "Visual document retrieval requires understanding heterogeneous and multi-modal content to satisfy information needs. Recent advances use screenshot-based document encoding with fine-grained late interaction, significantly improving retrieval performance. However, retrievers are still trained with coarse global relevance labels, without revealing which regions support the match. As a result, retrievers tend to rely on surface-level cues and struggle to capture implicit semantic connections, hindering their ability to handle non-extractive queries. To alleviate this problem, we propose a \\textbf{A}ttention-\\textbf{G}rounded \\textbf{RE}triever \\textbf{E}nhancement (AGREE) framework. AGREE leverages cross-modal attention from multimodal large language models as proxy local supervision to guide the identification of relevant document regions. During training, AGREE combines local signals with the global signals to jointly optimize the retriever, enabling it to learn not only whether documents match, but also which content drives relevance. Experiments on the challenging ViDoRe V2 benchmark show that AGREE significantly outperforms the global-supervision-only baseline. Quantitative and qualitative analyses further demonstrate that AGREE promotes deeper alignment between query terms and document regions, moving beyond surface-level matching toward more accurate and interpretable retrieval. Our code is available at: https://anonymous.4open.science/r/AGREE-2025.",
    "published": "2025-11-17T14:28:41Z",
    "updated": "2025-11-17T14:28:41Z",
    "link": "http://arxiv.org/pdf/2511.13415v1.pdf",
    "category": [
      "cs.IR",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Wanqing Cui",
      "Wei Huang",
      "Yazhi Guo",
      "Yibo Hu",
      "Meiguang Jin",
      "Junfeng Ma",
      "Keping Bi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13410v1",
    "title": "Mem-PAL: Towards Memory-based Personalized Dialogue Assistants for Long-term User-Agent Interaction",
    "summary": "With the rise of smart personal devices, service-oriented human-agent interactions have become increasingly prevalent. This trend highlights the need for personalized dialogue assistants that can understand user-specific traits to accurately interpret requirements and tailor responses to individual preferences. However, existing approaches often overlook the complexities of long-term interactions and fail to capture users' subjective characteristics. To address these gaps, we present PAL-Bench, a new benchmark designed to evaluate the personalization capabilities of service-oriented assistants in long-term user-agent interactions. In the absence of available real-world data, we develop a multi-step LLM-based synthesis pipeline, which is further verified and refined by human annotators. This process yields PAL-Set, the first Chinese dataset comprising multi-session user logs and dialogue histories, which serves as the foundation for PAL-Bench. Furthermore, to improve personalized service-oriented interactions, we propose H$^2$Memory, a hierarchical and heterogeneous memory framework that incorporates retrieval-augmented generation to improve personalized response generation. Comprehensive experiments on both our PAL-Bench and an external dataset demonstrate the effectiveness of the proposed memory framework.",
    "published": "2025-11-17T14:22:32Z",
    "updated": "2025-11-17T14:22:32Z",
    "link": "http://arxiv.org/pdf/2511.13410v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zhaopei Huang",
      "Qifeng Dai",
      "Guozheng Wu",
      "Xiaopeng Wu",
      "Kehan Chen",
      "Chuan Yu",
      "Xubin Li",
      "Tiezheng Ge",
      "Wenxuan Wang",
      "Qin Jin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13381v1",
    "title": "Can Large Language Models Function as Qualified Pediatricians? A Systematic Evaluation in Real-World Clinical Contexts",
    "summary": "With the rapid rise of large language models (LLMs) in medicine, a key question is whether they can function as competent pediatricians in real-world clinical settings. We developed PEDIASBench, a systematic evaluation framework centered on a knowledge-system framework and tailored to realistic clinical environments. PEDIASBench assesses LLMs across three dimensions: application of basic knowledge, dynamic diagnosis and treatment capability, and pediatric medical safety and medical ethics. We evaluated 12 representative models released over the past two years, including GPT-4o, Qwen3-235B-A22B, and DeepSeek-V3, covering 19 pediatric subspecialties and 211 prototypical diseases. State-of-the-art models performed well on foundational knowledge, with Qwen3-235B-A22B achieving over 90% accuracy on licensing-level questions, but performance declined ~15% as task complexity increased, revealing limitations in complex reasoning. Multiple-choice assessments highlighted weaknesses in integrative reasoning and knowledge recall. In dynamic diagnosis and treatment scenarios, DeepSeek-R1 scored highest in case reasoning (mean 0.58), yet most models struggled to adapt to real-time patient changes. On pediatric medical ethics and safety tasks, Qwen2.5-72B performed best (accuracy 92.05%), though humanistic sensitivity remained limited. These findings indicate that pediatric LLMs are constrained by limited dynamic decision-making and underdeveloped humanistic care. Future development should focus on multimodal integration and a clinical feedback-model iteration loop to enhance safety, interpretability, and human-AI collaboration. While current LLMs cannot independently perform pediatric care, they hold promise for decision support, medical education, and patient communication, laying the groundwork for a safe, trustworthy, and collaborative intelligent pediatric healthcare system.",
    "published": "2025-11-17T13:54:00Z",
    "updated": "2025-11-17T13:54:00Z",
    "link": "http://arxiv.org/pdf/2511.13381v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Siyu Zhu",
      "Mouxiao Bian",
      "Yue Xie",
      "Yongyu Tang",
      "Zhikang Yu",
      "Tianbin Li",
      "Pengcheng Chen",
      "Bing Han",
      "Jie Xu",
      "Xiaoyan Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2309.06706v3",
    "title": "Simultaneous Machine Translation with Large Language Models",
    "summary": "Real-world simultaneous machine translation (SimulMT) systems face more challenges than just the quality-latency trade-off. They also need to address issues related to robustness with noisy input, processing long contexts, and flexibility for knowledge injection. These challenges demand models with strong language understanding and generation capabilities which may not often equipped by dedicated MT models. In this paper, we investigate the possibility of applying Large Language Models (LLM) to SimulMT tasks by using existing incremental-decoding methods with a newly proposed RALCP algorithm for latency reduction. We conducted experiments using the \\texttt{Llama2-7b-chat} model on nine different languages from the MUST-C dataset. The results show that LLM outperforms dedicated MT models in terms of BLEU and LAAL metrics. Further analysis indicates that LLM has advantages in terms of tuning efficiency and robustness. However, it is important to note that the computational cost of LLM remains a significant obstacle to its application in SimulMT.",
    "published": "2023-09-13T04:06:47Z",
    "updated": "2025-11-17T13:41:30Z",
    "link": "http://arxiv.org/pdf/2309.06706v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Minghan Wang",
      "Jinming Zhao",
      "Thuy-Trang Vu",
      "Fatemeh Shiri",
      "Ehsan Shareghi",
      "Gholamreza Haffari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2402.10552v4",
    "title": "Conversational SimulMT: Efficient Simultaneous Translation with Large Language Models",
    "summary": "Simultaneous machine translation (SimulMT) presents a challenging trade-off between translation quality and latency. Recent studies have shown that LLMs can achieve good performance in SimulMT tasks. However, this often comes at the expense of high inference cost and latency. In this paper, we propose a conversational SimulMT framework to enhance the inference efficiency of LLM-based SimulMT through multi-turn-dialogue-based decoding. Our experiments with Llama2-7b-chat on two SimulMT benchmarks demonstrate the superiority of LLM in translation quality while achieving comparable computational latency to specialized SimulMT models.",
    "published": "2024-02-16T10:32:16Z",
    "updated": "2025-11-17T13:33:37Z",
    "link": "http://arxiv.org/pdf/2402.10552v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Minghan Wang",
      "Thuy-Trang Vu",
      "Yuxia Wang",
      "Ehsan Shareghi",
      "Gholamreza Haffari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13329v1",
    "title": "RegionMarker: A Region-Triggered Semantic Watermarking Framework for Embedding-as-a-Service Copyright Protection",
    "summary": "Embedding-as-a-Service (EaaS) is an effective and convenient deployment solution for addressing various NLP tasks. Nevertheless, recent research has shown that EaaS is vulnerable to model extraction attacks, which could lead to significant economic losses for model providers. For copyright protection, existing methods inject watermark embeddings into text embeddings and use them to detect copyright infringement. However, current watermarking methods often resist only a subset of attacks and fail to provide \\textit{comprehensive} protection. To this end, we present the region-triggered semantic watermarking framework called RegionMarker, which defines trigger regions within a low-dimensional space and injects watermarks into text embeddings associated with these regions. By utilizing a secret dimensionality reduction matrix to project onto this subspace and randomly selecting trigger regions, RegionMarker makes it difficult for watermark removal attacks to evade detection. Furthermore, by embedding watermarks across the entire trigger region and using the text embedding as the watermark, RegionMarker is resilient to both paraphrasing and dimension-perturbation attacks. Extensive experiments on various datasets show that RegionMarker is effective in resisting different attack methods, thereby protecting the copyright of EaaS.",
    "published": "2025-11-17T13:04:36Z",
    "updated": "2025-11-17T13:04:36Z",
    "link": "http://arxiv.org/pdf/2511.13329v1.pdf",
    "category": [
      "cs.CL",
      "cs.CR"
    ],
    "authors": [
      "Shufan Yang",
      "Zifeng Cheng",
      "Zhiwei Jiang",
      "Yafeng Yin",
      "Cong Wang",
      "Shiping Ge",
      "Yuchen Fu",
      "Qing Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12560v3",
    "title": "The taggedPBC: Annotating a massive parallel corpus for crosslinguistic investigations",
    "summary": "Existing datasets available for crosslinguistic investigations have tended to focus on large amounts of data for a small group of languages or a small amount of data for a large number of languages. This means that claims based on these datasets are limited in what they reveal about universal properties of the human language faculty. While this has begun to change through the efforts of projects seeking to develop tagged corpora for a large number of languages, such efforts are still constrained by limits on resources. The current paper reports on a large tagged parallel dataset which has been developed to partially address this issue. The taggedPBC contains POS-tagged parallel text data from more than 1,940 languages, representing 155 language families and 78 isolates, dwarfing previously available resources. The accuracy of particular tags in this dataset is shown to correlate well with both existing SOTA taggers for high-resource languages (SpaCy, Trankit) as well as hand-tagged corpora (Universal Dependencies Treebanks). Additionally, a novel measure derived from this dataset, the N1 ratio, correlates with expert determinations of intransitive word order in three typological databases (WALS, Grambank, Autotyp) such that a Gaussian Naive Bayes classifier trained on this feature can accurately identify basic intransitive word order for languages not in those databases. While much work is still needed to expand and develop this dataset, the taggedPBC is an important step to enable corpus-based crosslinguistic investigations, and is made available for research and collaboration via GitHub.",
    "published": "2025-05-18T22:13:32Z",
    "updated": "2025-11-17T12:47:15Z",
    "link": "http://arxiv.org/pdf/2505.12560v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hiram Ring"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.01215v2",
    "title": "Compress, Gather, and Recompute: REFORMing Long-Context Processing in Transformers",
    "summary": "As large language models increasingly gain popularity in real-world applications, processing extremely long contexts, often exceeding the model's pre-trained context limits, has emerged as a critical challenge. While existing approaches to efficient long-context processing show promise, recurrent compression-based methods struggle with information preservation, whereas random access approaches require substantial memory resources. We introduce REFORM, a novel inference framework that efficiently handles long contexts through a two-phase approach. First, it incrementally processes input chunks while maintaining a compressed KV cache, constructs cross-layer context embeddings, and utilizes early exit strategy for improved efficiency. Second, it identifies and gathers essential tokens via similarity matching and selectively recomputes the KV cache. Compared to baselines, REFORM achieves over 52% and 34% performance gains on RULER and BABILong respectively at 1M context length. It also outperforms baselines on Infinite-Bench, RepoEval, and MM-NIAH, demonstrating flexibility across diverse tasks and domains. Additionally, REFORM reduces inference time by 30% and peak memory usage by 5%, achieving both efficiency and superior performance.",
    "published": "2025-06-01T23:49:14Z",
    "updated": "2025-11-17T12:29:07Z",
    "link": "http://arxiv.org/pdf/2506.01215v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Woomin Song",
      "Sai Muralidhar Jayanthi",
      "Srikanth Ronanki",
      "Kanthashree Mysore Sathyendra",
      "Jinwoo Shin",
      "Aram Galstyan",
      "Shubham Katiyar",
      "Sravan Babu Bodapati"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.01223v2",
    "title": "Jailbreaking LLMs via Semantically Relevant Nested Scenarios with Targeted Toxic Knowledge",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks. However, they remain exposed to jailbreak attacks, eliciting harmful responses. The nested scenario strategy has been increasingly adopted across various methods, demonstrating immense potential. Nevertheless, these methods are easily detectable due to their prominent malicious intentions. In this work, we are the first to find and systematically verify that LLMs' alignment defenses are not sensitive to nested scenarios, where these scenarios are highly semantically relevant to the queries and incorporate targeted toxic knowledge. This is a crucial yet insufficiently explored direction. Based on this, we propose RTS-Attack (Semantically Relevant Nested Scenarios with Targeted Toxic Knowledge), an adaptive and automated framework to examine LLMs' alignment. By building scenarios highly relevant to the queries and integrating targeted toxic knowledge, RTS-Attack bypasses the alignment defenses of LLMs. Moreover, the jailbreak prompts generated by RTS-Attack are free from harmful queries, leading to outstanding concealment. Extensive experiments demonstrate that RTS-Attack exhibits superior performance in both efficiency and universality compared to the baselines across diverse advanced LLMs, including GPT-4o, Llama3-70b, and Gemini-pro. Our complete code is available at https://github.com/nercode/Work. WARNING: THIS PAPER CONTAINS POTENTIALLY HARMFUL CONTENT.",
    "published": "2025-09-22T12:37:07Z",
    "updated": "2025-11-17T11:40:43Z",
    "link": "http://arxiv.org/pdf/2510.01223v2.pdf",
    "category": [
      "cs.CR",
      "cs.CL"
    ],
    "authors": [
      "Ning Xu",
      "Bo Gao",
      "Hui Dou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.04708v2",
    "title": "Accelerated Test-Time Scaling with Model-Free Speculative Sampling",
    "summary": "Language models have demonstrated remarkable capabilities in reasoning tasks through test-time scaling techniques like best-of-N sampling and tree search. However, these approaches often demand substantial computational resources, creating a critical trade-off between performance and efficiency. We introduce STAND (STochastic Adaptive N-gram Drafting), a novel model-free speculative decoding approach that exploits the inherent redundancy in reasoning trajectories to achieve significant acceleration without compromising accuracy. Our analysis shows that reasoning paths frequently reuse similar reasoning patterns, enabling efficient model-free token prediction without requiring separate draft models. By introducing stochastic drafting and preserving probabilistic information through a memory-efficient logit-based N-gram module, combined with optimized Gumbel-Top-K sampling and data-driven tree construction, STAND significantly improves token acceptance rates. Extensive evaluations across multiple models and reasoning tasks (AIME-2024, GPQA-Diamond, and LiveCodeBench) demonstrate that STAND reduces inference latency by 60-65% compared to standard autoregressive decoding while maintaining accuracy. Furthermore, STAND consistently outperforms state-of-the-art speculative decoding methods across diverse inference patterns, including single-trajectory decoding, batch decoding, and test-time tree search. As a model-free approach, STAND can be applied to any existing language model without additional training, making it a powerful plug-and-play solution for accelerating language model reasoning.",
    "published": "2025-06-05T07:31:18Z",
    "updated": "2025-11-17T11:39:56Z",
    "link": "http://arxiv.org/pdf/2506.04708v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Woomin Song",
      "Saket Dingliwal",
      "Sai Muralidhar Jayanthi",
      "Bhavana Ganesh",
      "Jinwoo Shin",
      "Aram Galstyan",
      "Sravan Babu Bodapati"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13254v1",
    "title": "Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, but their training remains resource- and time-intensive, requiring massive compute power and careful orchestration of training procedures. Model souping-the practice of averaging weights from multiple models of the same architecture-has emerged as a promising pre- and post-training technique that can enhance performance without expensive retraining. In this paper, we introduce Soup Of Category Experts (SoCE), a principled approach for model souping that utilizes benchmark composition to identify optimal model candidates and applies non-uniform weighted averaging to maximize performance. Contrary to previous uniform-averaging approaches, our method leverages the observation that benchmark categories often exhibit low inter-correlations in model performance. SoCE identifies \"expert\" models for each weakly-correlated category cluster and combines them using optimized weighted averaging rather than uniform weights. We demonstrate that the proposed method improves performance and robustness across multiple domains, including multilingual capabilities, tool calling, and math and achieves state-of-the-art results on the Berkeley Function Calling Leaderboard.",
    "published": "2025-11-17T11:13:34Z",
    "updated": "2025-11-17T11:13:34Z",
    "link": "http://arxiv.org/pdf/2511.13254v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shalini Maiti",
      "Amar Budhiraja",
      "Bhavul Gauri",
      "Gaurav Chaurasia",
      "Anton Protopopov",
      "Alexis Audran-Reiss",
      "Michael Slater",
      "Despoina Magka",
      "Tatiana Shavrina",
      "Roberta Raileanu",
      "Yoram Bachrach"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.06261v4",
    "title": "Hogwild! Inference: Parallel LLM Generation via Concurrent Attention",
    "summary": "Large Language Models (LLMs) have demonstrated the ability to tackle increasingly complex tasks through advanced reasoning, long-form content generation, and tool use. Solving these tasks often involves long inference-time computations. In human problem solving, a common strategy to expedite work is collaboration: by dividing the problem into sub-tasks, exploring different strategies concurrently, etc. Recent research has shown that LLMs can also operate in parallel by implementing explicit cooperation frameworks, such as voting mechanisms or the explicit creation of independent sub-tasks that can be executed in parallel. However, each of these frameworks may not be suitable for all types of tasks, which can hinder their applicability. In this work, we propose a different design approach: we run LLM \"workers\" in parallel , allowing them to synchronize via a concurrently-updated attention cache and prompt these workers to decide how best to collaborate. Our approach allows the LLM instances to come up with their own collaboration strategy for the problem at hand, all the while \"seeing\" each other's memory in the concurrent KV cache. We implement this approach via Hogwild! Inference: a parallel LLM inference engine where multiple instances of the same LLM run in parallel with the same attention cache, with \"instant\" access to each other's memory. Hogwild! Inference takes advantage of Rotary Position Embeddings (RoPE) to avoid recomputation while improving parallel hardware utilization. We find that modern reasoning-capable LLMs can perform inference with shared Key-Value cache out of the box, without additional fine-tuning.",
    "published": "2025-04-08T17:59:41Z",
    "updated": "2025-11-17T11:11:28Z",
    "link": "http://arxiv.org/pdf/2504.06261v4.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Gleb Rodionov",
      "Roman Garipov",
      "Alina Shutova",
      "George Yakushev",
      "Erik Schultheis",
      "Vage Egiazarian",
      "Anton Sinitsin",
      "Denis Kuznedelev",
      "Dan Alistarh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13225v1",
    "title": "Seeing isn't Hearing: Benchmarking Vision Language Models at Interpreting Spectrograms",
    "summary": "With the rise of Large Language Models (LLMs) and their vision-enabled counterparts (VLMs), numerous works have investigated their capabilities in tasks that fuse the modalities of vision and language. In this work, we benchmark the extent to which VLMs are able to act as highly-trained phoneticians, interpreting spectrograms and waveforms of speech. To do this, we synthesise a novel dataset containing 4k+ English words spoken in isolation alongside stylistically consistent spectrogram and waveform figures. We test the ability of VLMs to understand these representations of speech through a multiple-choice task whereby models must predict the correct phonemic or graphemic transcription of a spoken word when presented amongst 3 distractor transcriptions that have been selected based on their phonemic edit distance to the ground truth. We observe that both zero-shot and finetuned models rarely perform above chance, demonstrating the requirement for specific parametric knowledge of how to interpret such figures, rather than paired samples alone.",
    "published": "2025-11-17T10:41:07Z",
    "updated": "2025-11-17T10:41:07Z",
    "link": "http://arxiv.org/pdf/2511.13225v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Tyler Loakman",
      "Joseph James",
      "Chenghua Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13182v1",
    "title": "Evaluating Large Language Models for Diacritic Restoration in Romanian Texts: A Comparative Study",
    "summary": "Automatic diacritic restoration is crucial for text processing in languages with rich diacritical marks, such as Romanian. This study evaluates the performance of several large language models (LLMs) in restoring diacritics in Romanian texts. Using a comprehensive corpus, we tested models including OpenAI's GPT-3.5, GPT-4, GPT-4o, Google's Gemini 1.0 Pro, Meta's Llama 2 and Llama 3, MistralAI's Mixtral 8x7B Instruct, airoboros 70B, and OpenLLM-Ro's RoLlama 2 7B, under multiple prompt templates ranging from zero-shot to complex multi-shot instructions. Results show that models such as GPT-4o achieve high diacritic restoration accuracy, consistently surpassing a neutral echo baseline, while others, including Meta's Llama family, exhibit wider variability. These findings highlight the impact of model architecture, training data, and prompt design on diacritic restoration performance and outline promising directions for improving NLP tools for diacritic-rich languages.",
    "published": "2025-11-17T09:43:54Z",
    "updated": "2025-11-17T09:43:54Z",
    "link": "http://arxiv.org/pdf/2511.13182v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Mihai Dan Nadas",
      "Laura Diosan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13180v1",
    "title": "Translation Entropy: A Statistical Framework for Evaluating Translation Systems",
    "summary": "The translation of written language has been known since the 3rd century BC; however, its necessity has become increasingly common in the information age. Today, many translators exist, based on encoder-decoder deep architectures, nevertheless, no quantitative objective methods are available to assess their performance, likely because the entropy of even a single language remains unknown. This study presents a quantitative method for estimating translation entropy, with the following key finding. Given a translator, several sentences that differ by only one selected token of a given pivot sentence yield identical translations. Analyzing the statistics of this phenomenon across an ensemble of such sentences, consisting each of a pivot selected token, yields the probabilities of replacing this specific token with others while preserving the translation. These probabilities constitute the entropy of the selected token, and the average across all selected pivot tokens provides an estimate of the translator's overall translation entropy, which is enhanced along the decoder blocks. This entropic measure allows for the quantitative ranking of several publicly available translators and reveals whether mutual translation entropy is symmetric. Extending the proposed method to include the replacement of two tokens in a given pivot sentence demonstrates a multiplicative effect, where translation degeneracy is proportional to the product of the degeneracies of the two tokens. These findings establish translation entropy as a measurable property and objective benchmarking of artificial translators. Results are based on MarianMT, T5-Base and NLLB-200 translators.",
    "published": "2025-11-17T09:42:15Z",
    "updated": "2025-11-17T09:42:15Z",
    "link": "http://arxiv.org/pdf/2511.13180v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ronit D. Gross",
      "Yanir Harel",
      "Ido Kanter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13169v1",
    "title": "TCM-5CEval: Extended Deep Evaluation Benchmark for LLM's Comprehensive Clinical Research Competence in Traditional Chinese Medicine",
    "summary": "Large language models (LLMs) have demonstrated exceptional capabilities in general domains, yet their application in highly specialized and culturally-rich fields like Traditional Chinese Medicine (TCM) requires rigorous and nuanced evaluation. Building upon prior foundational work such as TCM-3CEval, which highlighted systemic knowledge gaps and the importance of cultural-contextual alignment, we introduce TCM-5CEval, a more granular and comprehensive benchmark. TCM-5CEval is designed to assess LLMs across five critical dimensions: (1) Core Knowledge (TCM-Exam), (2) Classical Literacy (TCM-LitQA), (3) Clinical Decision-making (TCM-MRCD), (4) Chinese Materia Medica (TCM-CMM), and (5) Clinical Non-pharmacological Therapy (TCM-ClinNPT). We conducted a thorough evaluation of fifteen prominent LLMs, revealing significant performance disparities and identifying top-performing models like deepseek\\_r1 and gemini\\_2\\_5\\_pro. Our findings show that while models exhibit proficiency in recalling foundational knowledge, they struggle with the interpretative complexities of classical texts. Critically, permutation-based consistency testing reveals widespread fragilities in model inference. All evaluated models, including the highest-scoring ones, displayed a substantial performance degradation when faced with varied question option ordering, indicating a pervasive sensitivity to positional bias and a lack of robust understanding. TCM-5CEval not only provides a more detailed diagnostic tool for LLM capabilities in TCM but aldso exposes fundamental weaknesses in their reasoning stability. To promote further research and standardized comparison, TCM-5CEval has been uploaded to the Medbench platform, joining its predecessor in the \"In-depth Challenge for Comprehensive TCM Abilities\" special track.",
    "published": "2025-11-17T09:15:41Z",
    "updated": "2025-11-17T09:15:41Z",
    "link": "http://arxiv.org/pdf/2511.13169v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Tianai Huang",
      "Jiayuan Chen",
      "Lu Lu",
      "Pengcheng Chen",
      "Tianbin Li",
      "Bing Han",
      "Wenchao Tang",
      "Jie Xu",
      "Ming Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13159v1",
    "title": "Distinguishing Repetition Disfluency from Morphological Reduplication in Bangla ASR Transcripts: A Novel Corpus and Benchmarking Analysis",
    "summary": "Automatic Speech Recognition (ASR) transcripts, especially in low-resource languages like Bangla, contain a critical ambiguity: word-word repetitions can be either Repetition Disfluency (unintentional ASR error/hesitation) or Morphological Reduplication (a deliberate grammatical construct). Standard disfluency correction fails by erroneously deleting valid linguistic information. To solve this, we introduce the first publicly available, 20,000-row Bangla corpus, manually annotated to explicitly distinguish between these two phenomena in noisy ASR transcripts. We benchmark this novel resource using two paradigms: state-of-the-art multilingual Large Language Models (LLMs) and task-specific fine-tuning of encoder models. LLMs achieve competitive performance (up to 82.68\\% accuracy) with few-shot prompting. However, fine-tuning proves superior, with the language-specific BanglaBERT model achieving the highest accuracy of 84.78\\% and an F1 score of 0.677. This establishes a strong, linguistically-informed baseline and provides essential data for developing sophisticated, semantic-preserving text normalization systems for Bangla.",
    "published": "2025-11-17T09:06:01Z",
    "updated": "2025-11-17T09:06:01Z",
    "link": "http://arxiv.org/pdf/2511.13159v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zaara Zabeen Arpa",
      "Sadnam Sakib Apurbo",
      "Nazia Karim Khan Oishee",
      "Ajwad Abrar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13152v1",
    "title": "Zero-Shot Grammar Competency Estimation Using Large Language Model Generated Pseudo Labels",
    "summary": "Grammar competency estimation is essential for assessing linguistic proficiency in both written and spoken language; however, the spoken modality presents additional challenges due to its spontaneous, unstructured, and disfluent nature. Developing accurate grammar scoring models further requires extensive expert annotation, making large-scale data creation impractical. To address these limitations, we propose a zero-shot grammar competency estimation framework that leverages unlabeled data and Large Language Models (LLMs) without relying on manual labels. During training, we employ LLM-generated predictions on unlabeled data by using grammar competency rubric-based prompts. These predictions, treated as pseudo labels, are utilized to train a transformer-based model through a novel training framework designed to handle label noise effectively. We show that the choice of LLM for pseudo-label generation critically affects model performance and that the ratio of clean-to-noisy samples during training strongly influences stability and accuracy. Finally, a qualitative analysis of error intensity and score prediction confirms the robustness and interpretability of our approach. Experimental results demonstrate the efficacy of our approach in estimating grammar competency scores with high accuracy, paving the way for scalable, low-resource grammar assessment systems.",
    "published": "2025-11-17T09:00:26Z",
    "updated": "2025-11-17T09:00:26Z",
    "link": "http://arxiv.org/pdf/2511.13152v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Sourya Dipta Das",
      "Shubham Kumar",
      "Kuldeep Yadav"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13126v1",
    "title": "A Comparative Analysis of Recurrent and Attention Architectures for Isolated Sign Language Recognition",
    "summary": "This study presents a systematic comparative analysis of recurrent and attention-based neural architectures for isolated sign language recognition. We implement and evaluate two representative models-ConvLSTM and Vanilla Transformer-on the Azerbaijani Sign Language Dataset (AzSLD) and the Word-Level American Sign Language (WLASL) dataset. Our results demonstrate that the attention-based Vanilla Transformer consistently outperforms the recurrent ConvLSTM in both Top-1 and Top-5 accuracy across datasets, achieving up to 76.8% Top-1 accuracy on AzSLD and 88.3% on WLASL. The ConvLSTM, while more computationally efficient, lags in recognition accuracy, particularly on smaller datasets. These findings highlight the complementary strengths of each paradigm: the Transformer excels in overall accuracy and signer independence, whereas the ConvLSTM offers advantages in computational efficiency and temporal modeling. The study provides a nuanced analysis of these trade-offs, offering guidance for architecture selection in sign language recognition systems depending on application requirements and resource constraints.",
    "published": "2025-11-17T08:28:35Z",
    "updated": "2025-11-17T08:28:35Z",
    "link": "http://arxiv.org/pdf/2511.13126v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Nigar Alishzade",
      "Gulchin Abdullayeva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13107v1",
    "title": "Evaluating the Ability of Large Language Models to Identify Adherence to CONSORT Reporting Guidelines in Randomized Controlled Trials: A Methodological Evaluation Study",
    "summary": "The Consolidated Standards of Reporting Trials statement is the global benchmark for transparent and high-quality reporting of randomized controlled trials. Manual verification of CONSORT adherence is a laborious, time-intensive process that constitutes a significant bottleneck in peer review and evidence synthesis. This study aimed to systematically evaluate the accuracy and reliability of contemporary LLMs in identifying the adherence of published RCTs to the CONSORT 2010 statement under a zero-shot setting. We constructed a golden standard dataset of 150 published RCTs spanning diverse medical specialties. The primary outcome was the macro-averaged F1-score for the three-class classification task, supplemented by item-wise performance metrics and qualitative error analysis. Overall model performance was modest. The top-performing models, Gemini-2.5-Flash and DeepSeek-R1, achieved nearly identical macro F1 scores of 0.634 and Cohen's Kappa coefficients of 0.280 and 0.282, respectively, indicating only fair agreement with expert consensus. A striking performance disparity was observed across classes: while most models could identify compliant items with high accuracy (F1 score > 0.850), they struggled profoundly with identifying non-compliant and not applicable items, where F1 scores rarely exceeded 0.400. Notably, some high-profile models like GPT-4o underperformed, achieving a macro F1-score of only 0.521. LLMs show potential as preliminary screening assistants for CONSORT checks, capably identifying well-reported items. However, their current inability to reliably detect reporting omissions or methodological flaws makes them unsuitable for replacing human expertise in the critical appraisal of trial quality.",
    "published": "2025-11-17T08:05:15Z",
    "updated": "2025-11-17T08:05:15Z",
    "link": "http://arxiv.org/pdf/2511.13107v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zhichao He",
      "Mouxiao Bian",
      "Jianhong Zhu",
      "Jiayuan Chen",
      "Yunqiu Wang",
      "Wenxia Zhao",
      "Tianbin Li",
      "Bing Han",
      "Jie Xu",
      "Junyan Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.22581v3",
    "title": "Unveiling the Influence of Amplifying Language-Specific Neurons",
    "summary": "Language-specific neurons in LLMs that strongly correlate with individual languages have been shown to influence model behavior by deactivating them. However, their role in amplification remains underexplored. This work investigates the effect of amplifying language-specific neurons through interventions across 18 languages, including low-resource ones, using three models primarily trained in different languages. We compare amplification factors by their effectiveness in steering to the target language using a proposed Language Steering Shift (LSS) evaluation score, then evaluate it on downstream tasks: commonsense reasoning (XCOPA, XWinograd), knowledge (Include), and translation (FLORES). The optimal amplification factors effectively steer output toward nearly all tested languages. Intervention using this factor on downstream tasks improves self-language performance in some cases but generally degrades cross-language results. These findings highlight the effect of language-specific neurons in multilingual behavior, where amplification can be beneficial especially for low-resource languages, but provides limited advantage for cross-lingual transfer.",
    "published": "2025-07-30T11:23:30Z",
    "updated": "2025-11-17T07:52:20Z",
    "link": "http://arxiv.org/pdf/2507.22581v3.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Inaya Rahmanisa",
      "Lyzander Marciano Andrylie",
      "Mahardika Krisna Ihsani",
      "Alfan Farizki Wicaksono",
      "Haryo Akbarianto Wibowo",
      "Alham Fikri Aji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13095v1",
    "title": "BeDiscovER: The Benchmark of Discourse Understanding in the Era of Reasoning Language Models",
    "summary": "We introduce BeDiscovER (Benchmark of Discourse Understanding in the Era of Reasoning Language Models), an up-to-date, comprehensive suite for evaluating the discourse-level knowledge of modern LLMs. BeDiscovER compiles 5 publicly available discourse tasks across discourse lexicon, (multi-)sentential, and documental levels, with in total 52 individual datasets. It covers both extensively studied tasks such as discourse parsing and temporal relation extraction, as well as some novel challenges such as discourse particle disambiguation (e.g., ``just''), and also aggregates a shared task on Discourse Relation Parsing and Treebanking for multilingual and multi-framework discourse relation classification. We evaluate open-source LLMs: Qwen3 series, DeepSeek-R1, and frontier model such as GPT-5-mini on BeDiscovER, and find that state-of-the-art models exhibit strong performance in arithmetic aspect of temporal reasoning, but they struggle with full document reasoning and some subtle semantic and discourse phenomena, such as rhetorical relation recognition.",
    "published": "2025-11-17T07:50:12Z",
    "updated": "2025-11-17T07:50:12Z",
    "link": "http://arxiv.org/pdf/2511.13095v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Chuyuan Li",
      "Giuseppe Carenini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.00829v2",
    "title": "Exposing the Cracks: Vulnerabilities of Retrieval-Augmented LLM-based Machine Translation",
    "summary": "\\textbf{RE}trieval-\\textbf{A}ugmented \\textbf{L}LM-based \\textbf{M}achine \\textbf{T}ranslation (REAL-MT) shows promise for knowledge-intensive tasks like idiomatic translation, but its reliability under noisy retrieval contexts remains poorly understood despite this being a common challenge in real-world deployment. To address this gap, we propose a noise synthesis framework and new metrics to evaluate the robustness of REAL-MT systematically. Using this framework, we instantiate REAL-MT with Qwen-series models, including standard LLMs and large reasoning models (LRMs) with enhanced reasoning, and evaluate their performance on idiomatic translation across high-, medium-, and low-resource language pairs under synthesized noise. Our results show that low-resource language pairs, which rely more heavily on retrieved context, degrade more severely under noise than high-resource ones and often produce nonsensical translations. Although LRMs possess enhanced reasoning capabilities, they show no improvement in error correction and are even more susceptible to noise, tending to rationalize incorrect contexts. We find that this stems from an attention shift away from the source idiom to noisy content, while confidence increases despite declining accuracy, indicating poor calibration. To mitigate these issues, we investigate training-free and fine-tuning strategies, which improve robustness at the cost of performance in clean contexts, revealing a fundamental trade-off. Our findings highlight the limitations of current approaches, underscoring the need for self-verifying integration mechanisms.",
    "published": "2025-10-01T12:43:55Z",
    "updated": "2025-11-17T07:35:01Z",
    "link": "http://arxiv.org/pdf/2510.00829v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yanming Sun",
      "Runzhe Zhan",
      "Chi Seng Cheang",
      "Han Wu",
      "Xuebo Liu",
      "Yuyao Niu",
      "Fengying Ye",
      "Kaixin Lan",
      "Lidia S. Chao",
      "Derek F. Wong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.06059v2",
    "title": "Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System",
    "summary": "State-of-the-art (SOTA) fact-checking systems combat misinformation by employing autonomous LLM-based agents to decompose complex claims into smaller sub-claims, verify each sub-claim individually, and aggregate the partial results to produce verdicts with justifications (explanations for the verdicts). The security of these systems is crucial, as compromised fact-checkers can amplify misinformation, but remains largely underexplored. To bridge this gap, this work introduces a novel threat model against such fact-checking systems and presents \\textsc{Fact2Fiction}, the first poisoning attack framework targeting SOTA agentic fact-checking systems. Fact2Fiction employs LLMs to mimic the decomposition strategy and exploit system-generated justifications to craft tailored malicious evidences that compromise sub-claim verification. Extensive experiments demonstrate that Fact2Fiction achieves 8.9\\%--21.2\\% higher attack success rates than SOTA attacks across various poisoning budgets and exposes security weaknesses in existing fact-checking systems, highlighting the need for defensive countermeasures.",
    "published": "2025-08-08T06:44:57Z",
    "updated": "2025-11-17T06:44:09Z",
    "link": "http://arxiv.org/pdf/2508.06059v2.pdf",
    "category": [
      "cs.CR",
      "cs.CL"
    ],
    "authors": [
      "Haorui He",
      "Yupeng Li",
      "Bin Benjamin Zhu",
      "Dacheng Wen",
      "Reynold Cheng",
      "Francis C. M. Lau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13043v1",
    "title": "Spark-Prover-X1: Formal Theorem Proving Through Diverse Data Training",
    "summary": "Large Language Models (LLMs) have shown significant promise in automated theorem proving, yet progress is often constrained by the scarcity of diverse and high-quality formal language data. To address this issue, we introduce Spark-Prover-X1, a 7B parameter model trained via an three-stage framework designed to unlock the reasoning potential of more accessible and moderately-sized LLMs. The first stage infuses deep knowledge through continuous pre-training on a broad mathematical corpus, enhanced by a suite of novel data tasks. Key innovation is a \"CoT-augmented state prediction\" task to achieve fine-grained reasoning. The second stage employs Supervised Fine-tuning (SFT) within an expert iteration loop to specialize both the Spark-Prover-X1-7B and Spark-Formalizer-X1-7B models. Finally, a targeted round of Group Relative Policy Optimization (GRPO) is applied to sharpen the prover's capabilities on the most challenging problems. To facilitate robust evaluation, particularly on problems from real-world examinations, we also introduce ExamFormal-Bench, a new benchmark dataset of 402 formal problems. Experimental results demonstrate that Spark-Prover-X1-7B achieves state-of-the-art performance among similarly-sized open-source models, attaining a 37.0\\% average pass rate (pass@32). It shows exceptional performance on difficult competition benchmarks, notably solving 27 problems on PutnamBench (pass@32) and achieving 24.0\\% on CombiBench (pass@32). Our work validates that this diverse training data and progressively refined training pipeline provides an effective path for enhancing the formal reasoning capabilities of lightweight LLMs. Both Spark-Prover-X1-7B and Spark-Formalizer-X1-7B, along with the ExamFormal-Bench dataset, are made publicly available at:https://www.modelscope.cn/organization/iflytek, https://gitcode.com/ifly_opensource.",
    "published": "2025-11-17T06:44:02Z",
    "updated": "2025-11-17T06:44:02Z",
    "link": "http://arxiv.org/pdf/2511.13043v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xinyuan Zhou",
      "Yi Lei",
      "Xiaoyu Zhou",
      "Jingyi Sun",
      "Yu Zhu",
      "Zhongyi Ye",
      "Weitai Zhang",
      "Quan Liu",
      "Si Wei",
      "Cong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13040v1",
    "title": "How Good is BLI as an Alignment Measure: A Study in Word Embedding Paradigm",
    "summary": "Sans a dwindling number of monolingual embedding studies originating predominantly from the low-resource domains, it is evident that multilingual embedding has become the de facto choice due to its adaptability to the usage of code-mixed languages, granting the ability to process multilingual documents in a language-agnostic manner, as well as removing the difficult task of aligning monolingual embeddings. But is this victory complete? Are the multilingual models better than aligned monolingual models in every aspect? Can the higher computational cost of multilingual models always be justified? Or is there a compromise between the two extremes? Bilingual Lexicon Induction is one of the most widely used metrics in terms of evaluating the degree of alignment between two embedding spaces. In this study, we explore the strengths and limitations of BLI as a measure to evaluate the degree of alignment of two embedding spaces. Further, we evaluate how well traditional embedding alignment techniques, novel multilingual models, and combined alignment techniques perform BLI tasks in the contexts of both high-resource and low-resource languages. In addition to that, we investigate the impact of the language families to which the pairs of languages belong. We identify that BLI does not measure the true degree of alignment in some cases and we propose solutions for them. We propose a novel stem-based BLI approach to evaluate two aligned embedding spaces that take into account the inflected nature of languages as opposed to the prevalent word-based BLI techniques. Further, we introduce a vocabulary pruning technique that is more informative in showing the degree of the alignment, especially performing BLI on multilingual embedding models. Often, combined embedding alignment techniques perform better while in certain cases multilingual embeddings perform better (mainly low-resource language cases).",
    "published": "2025-11-17T06:41:41Z",
    "updated": "2025-11-17T06:41:41Z",
    "link": "http://arxiv.org/pdf/2511.13040v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Kasun Wickramasinghe",
      "Nisansa de Silva"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.18434v3",
    "title": "Chain-of-Conceptual-Thought Elicits Daily Conversation in Large Language Models",
    "summary": "Chain-of-Thought (CoT) is widely applied to enhance the LLM capability in math, coding and reasoning tasks. However, its performance is limited for open-domain tasks, when there are no clearly defined reasoning steps or logical transitions. To mitigate such challenges, we propose a new prompt-based paradigm called Chain of Conceptual Thoughts (CoCT), which suggests the LLM first to produce the tag of concepts, then complete the detailed content following the concept. To encourage this hierarchical way of thinking, we implement the concepts with emotions, strategies and topics. We experiment with this paradigm in daily and emotional support conversations, covering tasks with both in-domain and out-of-domain concept settings. Automatic, human, and LLM-based evaluations reveal that CoCT surpasses several prompt-based baselines such as self-refine, ECoT, SoT and RAG, suggesting a potential solution of LLM prompting paradigm for a wider scope of tasks.",
    "published": "2025-10-21T09:08:21Z",
    "updated": "2025-11-17T06:18:03Z",
    "link": "http://arxiv.org/pdf/2510.18434v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Qingqing Gu",
      "Dan Wang",
      "Yue Zhao",
      "Xiaoyu Wang",
      "Zhonglin Jiang",
      "Yong Chen",
      "Hongyan Li",
      "Luo Ji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25117v2",
    "title": "A Survey on Unlearning in Large Language Models",
    "summary": "Large Language Models (LLMs) demonstrate remarkable capabilities, but their training on massive corpora poses significant risks from memorized sensitive information. To mitigate these issues and align with legal standards, unlearning has emerged as a critical technique to selectively erase specific knowledge from LLMs without compromising their overall performance. This survey provides a systematic review of over 180 papers on LLM unlearning published since 2021. First, it introduces a novel taxonomy that categorizes unlearning methods based on the phase in the LLM pipeline of the intervention. This framework further distinguishes between parameter modification and parameter selection strategies, thus enabling deeper insights and more informed comparative analysis. Second, it offers a multidimensional analysis of evaluation paradigms. For datasets, we compare 18 existing benchmarks from the perspectives of task format, content, and experimental paradigms to offer actionable guidance. For metrics, we move beyond mere enumeration by dividing knowledge memorization metrics into 10 categories to analyze their advantages and applicability, while also reviewing metrics for model utility, robustness, and efficiency. By discussing current challenges and future directions, this survey aims to advance the field of LLM unlearning and the development of secure AI systems.",
    "published": "2025-10-29T02:34:17Z",
    "updated": "2025-11-17T05:58:57Z",
    "link": "http://arxiv.org/pdf/2510.25117v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ruichen Qiu",
      "Jiajun Tan",
      "Jiayue Pu",
      "Honglin Wang",
      "Xiao-Shan Gao",
      "Fei Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12991v1",
    "title": "Fine-Tuned LLMs Know They Don't Know: A Parameter-Efficient Approach to Recovering Honesty",
    "summary": "The honesty of Large Language Models (LLMs) is increasingly important for safe deployment in high-stakes domains. However, this crucial trait is severely undermined by supervised fine-tuning (SFT), a common technique for model specialization. Existing recovery methods rely on data-intensive global parameter adjustments, implicitly assuming that SFT deeply corrupts the models' ability to recognize their knowledge boundaries. However, we observe that fine-tuned LLMs still preserve this ability; what is damaged is their capacity to faithfully express that awareness. Building on this, we propose Honesty-Critical Neurons Restoration (HCNR) to surgically repair this suppressed capacity. HCNR identifies and restores key expression-governing neurons to their pre-trained state while harmonizing them with task-oriented neurons via Hessian-guided compensation. Experiments on four QA tasks and five LLM families demonstrate that HCNR effectively recovers 33.25% of the compromised honesty while achieving at least 2.23x speedup with over 10x less data compared to baseline methods, offering a practical solution for trustworthy LLM deployment.",
    "published": "2025-11-17T05:30:48Z",
    "updated": "2025-11-17T05:30:48Z",
    "link": "http://arxiv.org/pdf/2511.12991v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zeyu Shi",
      "Ziming Wang",
      "Tianyu Chen",
      "Shiqi Gao",
      "Haoyi Zhou",
      "Qingyun Sun",
      "Jianxin Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08230v2",
    "title": "VocalBench-zh: Decomposing and Benchmarking the Speech Conversational Abilities in Mandarin Context",
    "summary": "The development of multi-modal large language models (LLMs) leads to intelligent approaches capable of speech interactions. As one of the most widely spoken languages globally, Mandarin is supported by most models to enhance their applicability and reach. However, the scarcity of comprehensive speech-to-speech (S2S) benchmarks in Mandarin contexts impedes systematic evaluation for developers and hinders fair model comparison for users. In this work, we propose VocalBench-zh, an ability-level divided evaluation suite adapted to Mandarin context consisting of 10 well-crafted subsets and over 10K high-quality instances, covering 12 user-oriented characters. The evaluation experiment on 14 mainstream models reveals the common challenges for current routes, and highlights the need for new insights into next-generation speech interactive systems. The evaluation codes and datasets will be available at https://github.com/SJTU-OmniAgent/VocalBench-zh.",
    "published": "2025-11-11T13:30:41Z",
    "updated": "2025-11-17T04:39:12Z",
    "link": "http://arxiv.org/pdf/2511.08230v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Heyang Liu",
      "Ziyang Cheng",
      "Yuhao Wang",
      "Hongcheng Liu",
      "Yiqi Li",
      "Ronghua Wu",
      "Qunshan Gu",
      "Yanfeng Wang",
      "Yu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19768v2",
    "title": "T^2Agent A Tool-augmented Multimodal Misinformation Detection Agent with Monte Carlo Tree Search",
    "summary": "Real-world multimodal misinformation often arises from mixed forgery sources, requiring dynamic reasoning and adaptive verification. However, existing methods mainly rely on static pipelines and limited tool usage, limiting their ability to handle such complexity and diversity. To address this challenge, we propose \\method, a novel misinformation detection agent that incorporates an extensible toolkit with Monte Carlo Tree Search (MCTS). The toolkit consists of modular tools such as web search, forgery detection, and consistency analysis. Each tool is described using standardized templates, enabling seamless integration and future expansion. To avoid inefficiency from using all tools simultaneously, a greedy search-based selector is proposed to identify a task-relevant subset. This subset then serves as the action space for MCTS to dynamically collect evidence and perform multi-source verification. To better align MCTS with the multi-source nature of misinformation detection, \\method~ extends traditional MCTS with multi-source verification, which decomposes the task into coordinated subtasks targeting different forgery sources. A dual reward mechanism containing a reasoning trajectory score and a confidence score is further proposed to encourage a balance between exploration across mixed forgery sources and exploitation for more reliable evidence. We conduct ablation studies to confirm the effectiveness of the tree search mechanism and tool usage. Extensive experiments further show that \\method~ consistently outperforms existing baselines on challenging mixed-source multimodal misinformation benchmarks, demonstrating its strong potential as a training-free detector.",
    "published": "2025-05-26T09:50:55Z",
    "updated": "2025-11-17T04:33:33Z",
    "link": "http://arxiv.org/pdf/2505.19768v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xing Cui",
      "Yueying Zou",
      "Zekun Li",
      "Peipei Li",
      "Xinyuan Xu",
      "Xuannan Liu",
      "Huaibo Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.14099v2",
    "title": "Beyond Chains: Bridging Large Language Models and Knowledge Bases in Complex Question Answering",
    "summary": "Knowledge Base Question Answering (KBQA) aims to answer natural language questions using structured knowledge from KBs. While LLM-only approaches offer generalization, they suffer from outdated knowledge, hallucinations, and lack of transparency. Chain-based KG-RAG methods address these issues by incorporating external KBs, but are limited to simple chain-structured questions due to the absence of planning and logical structuring. Inspired by semantic parsing methods, we propose PDRR: a four-stage framework consisting of Predict, Decompose, Retrieve, and Reason. Our method first predicts the question type and decomposes the question into structured triples. Then retrieves relevant information from KBs and guides the LLM as an agent to reason over and complete the decomposed triples. Experimental results demonstrate that PDRR consistently outperforms existing methods across various LLM backbones and achieves superior performance on both chain-structured and non-chain complex questions.",
    "published": "2025-05-20T09:01:52Z",
    "updated": "2025-11-17T04:03:57Z",
    "link": "http://arxiv.org/pdf/2505.14099v2.pdf",
    "category": [
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Yihua Zhu",
      "Qianying Liu",
      "Akiko Aizawa",
      "Hidetoshi Shimodaira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23188v2",
    "title": "Diagnose, Localize, Align: A Full-Stack Framework for Reliable LLM Multi-Agent Systems under Instruction Conflicts",
    "summary": "Large Language Model (LLM)-powered multi-agent systems (MAS) have rapidly advanced collaborative reasoning, tool use, and role-specialized coordination in complex tasks. However, reliability-critical deployment remains hindered by a systemic failure mode: hierarchical compliance under instruction conflicts (system-user, peer-peer), where agents misprioritize system-level rules in the presence of competing demands. Moreover, widely used macro-level metrics (e.g., pass@k) obscure these micro-level violations and offer little actionable guidance for remedy. In this work, we present a full-stack, three-stage framework: (1) Diagnose - Contextualized Role Adherence Score (CRAS), a query-wise, context-aware scoring metric that decomposes role adherence into four measurable dimensions; (2) Localize - attention drift analysis revealing that instruction conflicts are resolved by attention heads that are largely concentrated in middle layers; (3) Align - Surgical Alignment of Instruction Layers (SAIL), which installs LoRA only on the localized focal layers and optimizes a token-weighted DPO-style preference objective that credits tokens by their focal attentional contribution. Across standard benchmarks and MAS frameworks, our surgical approach improves instruction hierarchy compliance (e.g., +5.60% with AutoGen on MedQA) without full-model finetuning.",
    "published": "2025-09-27T08:43:34Z",
    "updated": "2025-11-17T04:00:52Z",
    "link": "http://arxiv.org/pdf/2509.23188v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Guancheng Wan",
      "Leixin Sun",
      "Longxu Dou",
      "Zitong Shi",
      "Fang Wu",
      "Eric Hanchen Jiang",
      "Wenke Huang",
      "Guibin Zhang",
      "Hejia Geng",
      "Xiangru Tang",
      "Zhenfei Yin",
      "Yizhou Sun",
      "Wei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24130v2",
    "title": "Beyond Magic Words: Sharpness-Aware Prompt Evolving for Robust Large Language Models with TARE",
    "summary": "The performance of Large Language Models (LLMs) hinges on carefully engineered prompts. However, prevailing prompt optimization methods, ranging from heuristic edits and reinforcement learning to evolutionary search, primarily target point-wise accuracy. They seldom enforce paraphrase invariance or searching stability, and therefore cannot remedy this brittleness in practice. Automated prompt search remains brittle: small, semantically preserving paraphrases often cause large performance swings. We identify this brittleness as the textual sharpness of the prompt landscape. In this work, we provide the first formal treatment of textual sharpness in the discrete, semantic space of prompts, together with an operational robustness criterion over a semantic neighborhood; the design is black-box or API-only, requiring no gradients to update the model's parameters. Then we introduce TARE (Textual Sharpness-Aware Evolving), a derivative-free framework that alternates between an inner, sampling-based adversarial search that stresses a prompt with hard paraphrases and an outer, robust selection that prefers candidates whose neighborhoods remain strong. We further propose ATARE, which learns anisotropic weights to shape the semantic neighborhood and adapts its radius over time to balance exploration and fidelity. Diverse tasks evaluate our methods, whose design for minimizing textual sharpness gap leads to prompts that preserve accuracy under paraphrasing, outperforming accuracy-only prompt search while remaining computationally practical.",
    "published": "2025-09-28T23:57:05Z",
    "updated": "2025-11-17T04:00:24Z",
    "link": "http://arxiv.org/pdf/2509.24130v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Guancheng Wan",
      "Lucheng Fu",
      "Haoxin Liu",
      "Yiqiao Jin",
      "Hui Yi Leong",
      "Eric Hanchen Jiang",
      "Hejia Geng",
      "Jinhe Bi",
      "Yunpu Ma",
      "Xiangru Tang",
      "B. Aditya Prakash",
      "Yizhou Sun",
      "Wei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12928v1",
    "title": "Visual Room 2.0: Seeing is Not Understanding for MLLMs",
    "summary": "Can multi-modal large language models (MLLMs) truly understand what they can see? Extending Searle's Chinese Room into the multi-modal domain, this paper proposes the Visual Room argument: MLLMs may describe every visual detail precisely yet fail to comprehend the underlying emotions and intentions, namely seeing is not understanding. Building on this, we introduce \\textit{Visual Room} 2.0, a hierarchical benchmark for evaluating perception-cognition alignment of MLLMs. We model human perceptive and cognitive processes across three levels: low, middle, and high, covering 17 representative tasks. The perception component ranges from attribute recognition to scene understanding, while the cognition component extends from textual entailment to causal and social reasoning. The dataset contains 350 multi-modal samples, each with six progressive questions (2,100 in total) spanning perception to cognition. Evaluating 10 state-of-the-art (SoTA) MLLMs, we highlight three key findings: (1) MLLMs exhibit stronger perceptual competence than cognitive ability (8.0\\%$\\uparrow$); (2) cognition appears not causally dependent on perception-based reasoning; and (3) cognition scales with model size, but perception does not consistently improve with larger variants. This work operationalizes Seeing $\\ne$ Understanding as a testable hypothesis, offering a new paradigm from perceptual processing to cognitive reasoning in MLLMs. Our dataset is available at https://huggingface.co/datasets/LHK2003/PCBench.",
    "published": "2025-11-17T03:34:52Z",
    "updated": "2025-11-17T03:34:52Z",
    "link": "http://arxiv.org/pdf/2511.12928v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Haokun Li",
      "Yazhou Zhang",
      "Jizhi Ding",
      "Qiuchi Li",
      "Peng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.06105v2",
    "title": "You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures",
    "summary": "Large language models (LLMs) often suffer from hallucination, generating factually incorrect statements when handling questions beyond their knowledge and perception. Retrieval-augmented generation (RAG) addresses this by retrieving query-relevant contexts from knowledge bases to support LLM reasoning. Recent advances leverage pre-constructed graphs to capture the relational connections among distributed documents, showing remarkable performance in complex tasks. However, existing Graph-based RAG (GraphRAG) methods rely on a costly process to transform the corpus into a graph, introducing overwhelming token cost and update latency. Moreover, real-world queries vary in type and complexity, requiring different logic structures for accurate reasoning. The pre-built graph may not align with these required structures, resulting in ineffective knowledge retrieval. To this end, we propose a $\\textbf{Logic}$-aware $\\textbf{R}etrieval$-$\\textbf{A}$ugmented $\\textbf{G}$eneration framework ($\\textbf{LogicRAG}$) that dynamically extracts reasoning structures at inference time to guide adaptive retrieval without any pre-built graph. LogicRAG begins by decomposing the input query into a set of subproblems and constructing a directed acyclic graph (DAG) to model the logical dependencies among them. To support coherent multi-step reasoning, LogicRAG then linearizes the graph using topological sort, so that subproblems can be addressed in a logically consistent order. Besides, LogicRAG applies graph pruning to reduce redundant retrieval and uses context pruning to filter irrelevant context, significantly reducing the overall token cost. Extensive experiments demonstrate that LogicRAG achieves both superior performance and efficiency compared to state-of-the-art baselines.",
    "published": "2025-08-08T08:07:40Z",
    "updated": "2025-11-17T02:52:04Z",
    "link": "http://arxiv.org/pdf/2508.06105v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shengyuan Chen",
      "Chuang Zhou",
      "Zheng Yuan",
      "Qinggang Zhang",
      "Zeyang Cui",
      "Hao Chen",
      "Yilin Xiao",
      "Jiannong Cao",
      "Xiao Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12861v1",
    "title": "From Perception to Reasoning: Deep Thinking Empowers Multimodal Large Language Models",
    "summary": "With the remarkable success of Multimodal Large Language Models (MLLMs) in perception tasks, enhancing their complex reasoning capabilities has emerged as a critical research focus. Existing models still suffer from challenges such as opaque reasoning paths and insufficient generalization ability. Chain-of-Thought (CoT) reasoning, which has demonstrated significant efficacy in language models by enhancing reasoning transparency and output interpretability, holds promise for improving model reasoning capabilities when extended to the multimodal domain. This paper provides a systematic review centered on \"Multimodal Chain-of-Thought\" (MCoT). First, it analyzes the background and theoretical motivations for its inception from the perspectives of technical evolution and task demands. Then, it introduces mainstream MCoT methods from three aspects: CoT paradigms, the post-training stage, and the inference stage, while also analyzing their underlying mechanisms. Furthermore, the paper summarizes existing evaluation benchmarks and metrics, and discusses the application scenarios of MCoT. Finally, it analyzes the challenges currently facing MCoT and provides an outlook on its future research directions.",
    "published": "2025-11-17T01:22:37Z",
    "updated": "2025-11-17T01:22:37Z",
    "link": "http://arxiv.org/pdf/2511.12861v1.pdf",
    "category": [
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Wenxin Zhu",
      "Andong Chen",
      "Yuchen Song",
      "Kehai Chen",
      "Conghui Zhu",
      "Ziyan Chen",
      "Tiejun Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12850v1",
    "title": "Quantifying consistency and accuracy of Latent Dirichlet Allocation",
    "summary": "Topic modelling in Natural Language Processing uncovers hidden topics in large, unlabelled text datasets. It is widely applied in fields such as information retrieval, content summarisation, and trend analysis across various disciplines. However, probabilistic topic models can produce different results when rerun due to their stochastic nature, leading to inconsistencies in latent topics. Factors like corpus shuffling, rare text removal, and document elimination contribute to these variations. This instability affects replicability, reliability, and interpretation, raising concerns about whether topic models capture meaningful topics or just noise. To address these problems, we defined a new stability measure that incorporates accuracy and consistency and uses the generative properties of LDA to generate a new corpus with ground truth. These generated corpora are run through LDA 50 times to determine the variability in the output. We show that LDA can correctly determine the underlying number of topics in the documents. We also find that LDA is more internally consistent, as the multiple reruns return similar topics; however, these topics are not the true topics.",
    "published": "2025-11-17T00:44:27Z",
    "updated": "2025-11-17T00:44:27Z",
    "link": "http://arxiv.org/pdf/2511.12850v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Saranzaya Magsarjav",
      "Melissa Humphries",
      "Jonathan Tuke",
      "Lewis Mitchell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12821v1",
    "title": "BioMedJImpact: A Comprehensive Dataset and LLM Pipeline for AI Engagement and Scientific Impact Analysis of Biomedical Journals",
    "summary": "Assessing journal impact is central to scholarly communication, yet existing open resources rarely capture how collaboration structures and artificial intelligence (AI) research jointly shape venue prestige in biomedicine. We present BioMedJImpact, a large-scale, biomedical-oriented dataset designed to advance journal-level analysis of scientific impact and AI engagement. Built from 1.74 million PubMed Central articles across 2,744 journals, BioMedJImpact integrates bibliometric indicators, collaboration features, and LLM-derived semantic indicators for AI engagement. Specifically, the AI engagement feature is extracted through a reproducible three-stage LLM pipeline that we propose. Using this dataset, we analyze how collaboration intensity and AI engagement jointly influence scientific impact across pre- and post-pandemic periods (2016-2019, 2020-2023). Two consistent trends emerge: journals with higher collaboration intensity, particularly those with larger and more diverse author teams, tend to achieve greater citation impact, and AI engagement has become an increasingly strong correlate of journal prestige, especially in quartile rankings. To further validate the three-stage LLM pipeline we proposed for deriving the AI engagement feature, we conduct human evaluation, confirming substantial agreement in AI relevance detection and consistent subfield classification. Together, these contributions demonstrate that BioMedJImpact serves as both a comprehensive dataset capturing the intersection of biomedicine and AI, and a validated methodological framework enabling scalable, content-aware scientometric analysis of scientific impact and innovation dynamics. Code is available at https://github.com/JonathanWry/BioMedJImpact.",
    "published": "2025-11-16T23:03:15Z",
    "updated": "2025-11-16T23:03:15Z",
    "link": "http://arxiv.org/pdf/2511.12821v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Ruiyu Wang",
      "Yuzhang Xie",
      "Xiao Hu",
      "Carl Yang",
      "Jiaying Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12784v1",
    "title": "Evaluating Autoformalization Robustness via Semantically Similar Paraphrasing",
    "summary": "Large Language Models (LLMs) have recently emerged as powerful tools for autoformalization. Despite their impressive performance, these models can still struggle to produce grounded and verifiable formalizations. Recent work in text-to-SQL, has revealed that LLMs can be sensitive to paraphrased natural language (NL) inputs, even when high degrees of semantic fidelity are preserved (Safarzadeh, Oroojlooyjadid, and Roth 2025). In this paper, we investigate this claim in the autoformalization domain. Specifically, we evaluate the robustness of LLMs generating formal proofs with semantically similar paraphrased NL statements by measuring semantic and compilation validity. Using the formal benchmarks MiniF2F (Zheng, Han, and Polu 2021) and Lean 4 version of ProofNet (Xin et al. 2024), and two modern LLMs, we generate paraphrased natural language statements and cross-evaluate these statements across both models. The results of this paper reveal performance variability across paraphrased inputs, demonstrating that minor shifts in NL statements can significantly impact model outputs.",
    "published": "2025-11-16T21:25:59Z",
    "updated": "2025-11-16T21:25:59Z",
    "link": "http://arxiv.org/pdf/2511.12784v1.pdf",
    "category": [
      "cs.CL",
      "cs.LO"
    ],
    "authors": [
      "Hayden Moore",
      "Asfahan Shah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12782v1",
    "title": "LLM Reinforcement in Context",
    "summary": "Current Large Language Model alignment research mostly focuses on improving model robustness against adversarial attacks and misbehavior by training on examples and prompting. Research has shown that LLM jailbreak probability increases with the size of the user input or conversation length. There is a lack of appropriate research into means of strengthening alignment which also scale with user input length. We propose interruptions as a possible solution to this problem. Interruptions are control sentences added to the user input approximately every x tokens for some arbitrary x. We suggest that this can be generalized to the Chain-of-Thought process to prevent scheming.",
    "published": "2025-11-16T21:24:42Z",
    "updated": "2025-11-16T21:24:42Z",
    "link": "http://arxiv.org/pdf/2511.12782v1.pdf",
    "category": [
      "cs.CL",
      "cs.CR"
    ],
    "authors": [
      "Thomas Rivasseau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13539v1",
    "title": "BootOOD: Self-Supervised Out-of-Distribution Detection via Synthetic Sample Exposure under Neural Collapse",
    "summary": "Out-of-distribution (OOD) detection is critical for deploying image classifiers in safety-sensitive environments, yet existing detectors often struggle when OOD samples are semantically similar to the in-distribution (ID) classes. We present BootOOD, a fully self-supervised OOD detection framework that bootstraps exclusively from ID data and is explicitly designed to handle semantically challenging OOD samples. BootOOD synthesizes pseudo-OOD features through simple transformations of ID representations and leverages Neural Collapse (NC), where ID features cluster tightly around class means with consistent feature norms. Unlike prior approaches that aim to constrain OOD features into subspaces orthogonal to the collapsed ID means, BootOOD introduces a lightweight auxiliary head that performs radius-based classification on feature norms. This design decouples OOD detection from the primary classifier and imposes a relaxed requirement: OOD samples are learned to have smaller feature norms than ID features, which is easier to satisfy when ID and OOD are semantically close. Experiments on CIFAR-10, CIFAR-100, and ImageNet-200 show that BootOOD outperforms prior post-hoc methods, surpasses training-based methods without outlier exposure, and is competitive with state-of-the-art outlier-exposure approaches while maintaining or improving ID accuracy.",
    "published": "2025-11-17T16:12:31Z",
    "updated": "2025-11-17T16:12:31Z",
    "link": "http://arxiv.org/pdf/2511.13539v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Yuanchao Wang",
      "Tian Qin",
      "Eduardo Valle",
      "Bruno Abrahao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13535v1",
    "title": "Accuracy is Not Enough: Poisoning Interpretability in Federated Learning via Color Skew",
    "summary": "As machine learning models are increasingly deployed in safety-critical domains, visual explanation techniques have become essential tools for supporting transparency. In this work, we reveal a new class of attacks that compromise model interpretability without affecting accuracy. Specifically, we show that small color perturbations applied by adversarial clients in a federated learning setting can shift a model's saliency maps away from semantically meaningful regions while keeping the prediction unchanged. The proposed saliency-aware attack framework, called Chromatic Perturbation Module, systematically crafts adversarial examples by altering the color contrast between foreground and background in a way that disrupts explanation fidelity. These perturbations accumulate across training rounds, poisoning the global model's internal feature attributions in a stealthy and persistent manner. Our findings challenge a common assumption in model auditing that correct predictions imply faithful explanations and demonstrate that interpretability itself can be an attack surface. We evaluate this vulnerability across multiple datasets and show that standard training pipelines are insufficient to detect or mitigate explanation degradation, especially in the federated learning setting, where subtle color perturbations are harder to discern. Our attack reduces peak activation overlap in Grad-CAM explanations by up to 35% while preserving classification accuracy above 96% on all evaluated datasets.",
    "published": "2025-11-17T16:07:54Z",
    "updated": "2025-11-17T16:07:54Z",
    "link": "http://arxiv.org/pdf/2511.13535v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Farhin Farhad Riya",
      "Shahinul Hoque",
      "Jinyuan Stella Sun",
      "Olivera Kotevska"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13533v1",
    "title": "Minimax Multi-Target Conformal Prediction with Applications to Imaging Inverse Problems",
    "summary": "In ill-posed imaging inverse problems, uncertainty quantification remains a fundamental challenge, especially in safety-critical applications. Recently, conformal prediction has been used to quantify the uncertainty that the inverse problem contributes to downstream tasks like image classification, image quality assessment, fat mass quantification, etc. While existing works handle only a scalar estimation target, practical applications often involve multiple targets. In response, we propose an asymptotically minimax approach to multi-target conformal prediction that provides tight prediction intervals while ensuring joint marginal coverage. We then outline how our minimax approach can be applied to multi-metric blind image quality assessment, multi-task uncertainty quantification, and multi-round measurement acquisition. Finally, we numerically demonstrate the benefits of our minimax method, relative to existing multi-target conformal prediction methods, using both synthetic and magnetic resonance imaging (MRI) data.",
    "published": "2025-11-17T16:06:37Z",
    "updated": "2025-11-17T16:06:37Z",
    "link": "http://arxiv.org/pdf/2511.13533v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jeffrey Wen",
      "Rizwan Ahmad",
      "Philip Schniter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.12180v2",
    "title": "Bench2FreeAD: A Benchmark for Vision-based End-to-end Navigation in Unstructured Robotic Environments",
    "summary": "Most current end-to-end (E2E) autonomous driving algorithms are built on standard vehicles in structured transportation scenarios, lacking exploration of robot navigation for unstructured scenarios such as auxiliary roads, campus roads, and indoor settings. This paper investigates E2E robot navigation in unstructured road environments. First, we introduce two data collection pipelines - one for real-world robot data and another for synthetic data generated using the Isaac Sim simulator, which together produce an unstructured robotics navigation dataset -- FreeWorld Dataset. Second, we fine-tuned an efficient E2E autonomous driving model -- VAD -- using our datasets to validate the performance and adaptability of E2E autonomous driving models in these environments. Results demonstrate that fine-tuning through our datasets significantly enhances the navigation potential of E2E autonomous driving models in unstructured robotic environments. Thus, this paper presents the first dataset targeting E2E robot navigation tasks in unstructured scenarios, and provides a benchmark based on vision-based E2E autonomous driving algorithms to facilitate the development of E2E navigation technology for logistics and service robots. The project is available on Github.",
    "published": "2025-03-15T15:46:49Z",
    "updated": "2025-11-17T16:05:04Z",
    "link": "http://arxiv.org/pdf/2503.12180v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Yuhang Peng",
      "Sidong Wang",
      "Jihaoyu Yang",
      "Shilong Li",
      "Han Wang",
      "Jiangtao Gong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.05534v2",
    "title": "S4M: 4-points to Segment Anything",
    "summary": "Purpose: The Segment Anything Model (SAM) promises to ease the annotation bottleneck in medical segmentation, but overlapping anatomy and blurred boundaries make its point prompts ambiguous, leading to cycles of manual refinement to achieve precise masks. Better prompting strategies are needed.\n  Methods: We propose a structured prompting strategy using 4 points as a compact instance-level shape description. We study two 4-point variants: extreme points and the proposed major/minor axis endpoints, inspired by ultrasound measurement practice. SAM cannot fully exploit such structured prompts because it treats all points identically and lacks geometry-aware reasoning. To address this, we introduce S4M (4-points to Segment Anything), which augments SAM to interpret 4 points as relational cues rather than isolated clicks. S4M expands the prompt space with role-specific embeddings and adds an auxiliary \"Canvas\" pretext task that sketches coarse masks directly from prompts, fostering geometry-aware reasoning.\n  Results: Across eight datasets in ultrasound and surgical endoscopy, S4M improves segmentation by +3.42 mIoU over a strong SAM baseline at equal prompt budget. An annotation study with three clinicians further shows that major/minor prompts enable faster annotation.\n  Conclusion: S4M increases performance, reduces annotation effort, and aligns prompting with clinical practice, enabling more scalable dataset development in medical imaging.",
    "published": "2025-03-07T16:02:11Z",
    "updated": "2025-11-17T16:03:51Z",
    "link": "http://arxiv.org/pdf/2503.05534v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Adrien Meyer",
      "Lorenzo Arboit",
      "Giuseppe Massimiani",
      "Shih-Min Yin",
      "Didier Mutter",
      "Nicolas Padoy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.10800v2",
    "title": "ThinkingViT: Matryoshka Thinking Vision Transformer for Elastic Inference",
    "summary": "ViTs deliver SOTA performance, yet their fixed computational budget prevents scalable deployment across heterogeneous hardware. Recent Matryoshka-style Transformer architectures mitigate this by embedding nested subnetworks within a single model to enable scalable inference. However, these models allocate the same amount of compute to all inputs, regardless of their complexity, which leads to inefficiencies. To address this, we introduce ThinkingViT, a nested ViT architecture that employs progressive thinking stages to dynamically adjust inference computation based on input difficulty. ThinkingViT first activates a small subset of the most important attention heads to produce an initial prediction. If the prediction confidence exceeds a predefined threshold, inference terminates early. Otherwise, within the same backbone, it activates a larger subset of attention heads and conducts a new forward pass. This process continues iteratively until the model reaches the predefined confidence level or exhausts its maximum capacity. To boost the performance of subsequent rounds, we introduce a Token Recycling approach that fuses the input embeddings with the embeddings from the previous stage. Experiments show that ThinkingViT surpasses nested baselines by up to 2.0 percentage points (p.p.) in accuracy at the same throughput and by up to 2.9 p.p. at equal GMACs on ImageNet-1K. We show that the backbone-preserving design of ThinkingViT allows it to serve as a plug-in upgrade for ViTs in downstream tasks such as semantic segmentation. We also demonstrate that ThinkingViT transfers effectively to other architectures such as Swin. The source code is available at https://github.com/ds-kiel/ThinkingViT.",
    "published": "2025-07-14T20:54:41Z",
    "updated": "2025-11-17T15:43:33Z",
    "link": "http://arxiv.org/pdf/2507.10800v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ali Hojjat",
      "Janek Haberer",
      "Soren Pirk",
      "Olaf Landsiedel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13507v1",
    "title": "Mapping the Vanishing and Transformation of Urban Villages in China",
    "summary": "Urban villages (UVs), informal settlements embedded within China's urban fabric, have undergone widespread demolition and redevelopment in recent decades. However, there remains a lack of systematic evaluation of whether the demolished land has been effectively reused, raising concerns about the efficacy and sustainability of current redevelopment practices. To address the gap, this study proposes a deep learning-based framework to monitor the spatiotemporal changes of UVs in China. Specifically, semantic segmentation of multi-temporal remote sensing imagery is first used to map evolving UV boundaries, and then post-demolition land use is classified into six categories based on the \"remained-demolished-redeveloped\" phase: incomplete demolition, vacant land, construction sites, buildings, green spaces, and others. Four representative cities from China's four economic regions were selected as the study areas, i.e., Guangzhou (East), Zhengzhou (Central), Xi'an (West), and Harbin (Northeast). The results indicate: 1) UV redevelopment processes were frequently prolonged; 2) redevelopment transitions primarily occurred in peripheral areas, whereas urban cores remained relatively stable; and 3) three spatiotemporal transformation pathways, i.e., synchronized redevelopment, delayed redevelopment, and gradual optimization, were revealed. This study highlights the fragmented, complex and nonlinear nature of UV redevelopment, underscoring the need for tiered and context-sensitive planning strategies. By linking spatial dynamics with the context of redevelopment policies, the findings offer valuable empirical insights that support more inclusive, efficient, and sustainable urban renewal, while also contributing to a broader global understanding of informal settlement transformations.",
    "published": "2025-11-17T15:42:41Z",
    "updated": "2025-11-17T15:42:41Z",
    "link": "http://arxiv.org/pdf/2511.13507v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wenyu Zhang",
      "Yao Tong",
      "Yiqiu Liu",
      "Rui Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13494v1",
    "title": "Language-Guided Invariance Probing of Vision-Language Models",
    "summary": "Recent vision-language models (VLMs) such as CLIP, OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they respond to controlled linguistic perturbations. We introduce Language-Guided Invariance Probing (LGIP), a benchmark that measures (i) invariance to meaning-preserving paraphrases and (ii) sensitivity to meaning-changing semantic flips in image-text matching. Using 40k MS COCO images with five human captions each, we automatically generate paraphrases and rule-based flips that alter object category, color or count, and summarize model behavior with an invariance error, a semantic sensitivity gap and a positive-rate statistic.\n  Across nine VLMs, EVA02-CLIP and large OpenCLIP variants lie on a favorable invariance-sensitivity frontier, combining low paraphrase-induced variance with consistently higher scores for original captions than for their flipped counterparts. In contrast, SigLIP and SigLIP2 show much larger invariance error and often prefer flipped captions to the human descriptions, especially for object and color edits. These failures are largely invisible to standard retrieval metrics, indicating that LGIP provides a model-agnostic diagnostic for the linguistic robustness of VLMs beyond conventional accuracy scores.",
    "published": "2025-11-17T15:35:49Z",
    "updated": "2025-11-17T15:35:49Z",
    "link": "http://arxiv.org/pdf/2511.13494v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jae Joong Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13488v1",
    "title": "InterMoE: Individual-Specific 3D Human Interaction Generation via Dynamic Temporal-Selective MoE",
    "summary": "Generating high-quality human interactions holds significant value for applications like virtual reality and robotics. However, existing methods often fail to preserve unique individual characteristics or fully adhere to textual descriptions. To address these challenges, we introduce InterMoE, a novel framework built on a Dynamic Temporal-Selective Mixture of Experts. The core of InterMoE is a routing mechanism that synergistically uses both high-level text semantics and low-level motion context to dispatch temporal motion features to specialized experts. This allows experts to dynamically determine the selection capacity and focus on critical temporal features, thereby preserving specific individual characteristic identities while ensuring high semantic fidelity. Extensive experiments show that InterMoE achieves state-of-the-art performance in individual-specific high-fidelity 3D human interaction generation, reducing FID scores by 9% on the InterHuman dataset and 22% on InterX.",
    "published": "2025-11-17T15:26:10Z",
    "updated": "2025-11-17T15:26:10Z",
    "link": "http://arxiv.org/pdf/2511.13488v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Lipeng Wang",
      "Hongxing Fan",
      "Haohua Chen",
      "Zehuan Huang",
      "Lu Sheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.12197v2",
    "title": "Beyond Patches: Mining Interpretable Part-Prototypes for Explainable AI",
    "summary": "As AI systems grow more capable, it becomes increasingly important that their decisions remain understandable and aligned with human expectations. A key challenge is the limited interpretability of deep models. Post-hoc methods like GradCAM offer heatmaps but provide limited conceptual insight, while prototype-based approaches offer example-based explanations but often rely on rigid region selection and lack semantic consistency.\n  To address these limitations, we propose PCMNet, a part-prototypical concept mining network that learns human-comprehensible prototypes from meaningful image regions without additional supervision. By clustering these prototypes into concept groups and extracting concept activation vectors, PCMNet provides structured, concept-level explanations and enhances robustness to occlusion and challenging conditions, which are both critical for building reliable and aligned AI systems.\n  Experiments across multiple image classification benchmarks show that PCMNet outperforms state-of-the-art methods in interpretability, stability, and robustness. This work contributes to AI alignment by enhancing transparency, controllability, and trustworthiness in AI systems. Our code is available at: https://github.com/alehdaghi/PCMNet.",
    "published": "2025-04-16T15:48:21Z",
    "updated": "2025-11-17T15:12:15Z",
    "link": "http://arxiv.org/pdf/2504.12197v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mahdi Alehdaghi",
      "Rajarshi Bhattacharya",
      "Pourya Shamsolmoali",
      "Rafael M. O. Cruz",
      "Eric Granger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21501v2",
    "title": "Vision Transformers with Self-Distilled Registers",
    "summary": "Vision Transformers (ViTs) have emerged as the dominant architecture for visual processing tasks, demonstrating excellent scalability with increased training data and model size. However, recent work has identified the emergence of artifact tokens in ViTs that are incongruous with local semantics. These anomalous tokens degrade ViT performance in tasks that require fine-grained localization or structural coherence. An effective mitigation of this issue is the addition of register tokens to ViTs, which implicitly \"absorb\" the artifact term during training.Given the availability of existing large-scale pre-trained ViTs, in this paper we seek add register tokens to existing models without needing to re-train from scratch, which is infeasible considering their size. Specifically, we propose Post Hoc Registers (PH-Reg), an efficient self-distillation method that integrates registers into an existing ViT without requiring additional labeled data and full retraining. PH-Reg initializes both teacher and student networks from the same pre-trained ViT. The teacher remains frozen and unmodified, while the student is augmented with randomly initialized register tokens. By applying test-time augmentation to the teacher's inputs, we generate denoised dense embeddings free of artifacts, which are then used to optimize only a small subset of unlocked student weights. We show that our approach can effectively reduce the number of artifact tokens, improving the segmentation and depth prediction of the student ViT under zero-shot and linear probing.",
    "published": "2025-05-27T17:59:41Z",
    "updated": "2025-11-17T15:02:58Z",
    "link": "http://arxiv.org/pdf/2505.21501v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yinjie Chen",
      "Zipeng Yan",
      "Chong Zhou",
      "Bo Dai",
      "Andrew F. Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20782v2",
    "title": "Towards Cross-Domain Multi-Targeted Adversarial Attacks",
    "summary": "Multi-targeted adversarial attacks aim to mislead classifiers toward specific target classes using a single perturbation generator with a conditional input specifying the desired target class. Existing methods face two key limitations: (1) a single generator supports only a limited number of predefined target classes, and (2) it requires access to the victim model's training data to learn target class semantics. This dependency raises data leakage concerns in practical black-box scenarios where the training data is typically private. To address these limitations, we propose a novel Cross-Domain Multi-Targeted Attack (CD-MTA) that can generate perturbations toward arbitrary target classes, even those that do not exist in the attacker's training data. CD-MTA is trained on a single public dataset but can perform targeted attacks on black-box models trained on different datasets with disjoint and unknown class sets. Our method requires only a single example image that visually represents the desired target class, without relying its label, class distribution or pretrained embeddings. We achieve this through a Feature Injection Module (FIM) and class-agnostic objectives which guide the generator to extract transferable, fine-grained features from the target image without inferring class semantics. Experiments on ImageNet and seven additional datasets show that CD-MTA outperforms existing multi-targeted attack methods on unseen target classes in black-box and cross-domain scenarios. The code is available at https://github.com/tgoncalv/CD-MTA.",
    "published": "2025-05-27T06:39:29Z",
    "updated": "2025-11-17T14:56:37Z",
    "link": "http://arxiv.org/pdf/2505.20782v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Taïga Gonçalves",
      "Tomo Miyazaki",
      "Shinichiro Omachi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13431v1",
    "title": "FUSE: A Flow-based Mapping Between Shapes",
    "summary": "We introduce a novel neural representation for maps between 3D shapes based on flow-matching models, which is computationally efficient and supports cross-representation shape matching without large-scale training or data-driven procedures. 3D shapes are represented as the probability distribution induced by a continuous and invertible flow mapping from a fixed anchor distribution. Given a source and a target shape, the composition of the inverse flow (source to anchor) with the forward flow (anchor to target), we continuously map points between the two surfaces. By encoding the shapes with a pointwise task-tailored embedding, this construction provides an invertible and modality-agnostic representation of maps between shapes across point clouds, meshes, signed distance fields (SDFs), and volumetric data. The resulting representation consistently achieves high coverage and accuracy across diverse benchmarks and challenging settings in shape matching. Beyond shape matching, our framework shows promising results in other tasks, including UV mapping and registration of raw point cloud scans of human bodies.",
    "published": "2025-11-17T14:42:45Z",
    "updated": "2025-11-17T14:42:45Z",
    "link": "http://arxiv.org/pdf/2511.13431v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Lorenzo Olearo",
      "Giulio Viganò",
      "Daniele Baieri",
      "Filippo Maggioli",
      "Simone Melzi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.02043v3",
    "title": "Point2Primitive: CAD Reconstruction from Point Cloud by Direct Primitive Prediction",
    "summary": "Recovering CAD models from point clouds requires reconstructing their topology and sketch-based extrusion primitives. A dominant paradigm for representing sketches involves implicit neural representations such as Signed Distance Fields (SDFs). However, this indirect approach inherently struggles with precision, leading to unintended curved edges and models that are difficult to edit. In this paper, we propose Point2Primitive, a framework that learns to directly predict the explicit, parametric primitives of CAD models. Our method treats sketch reconstruction as a set prediction problem, employing a improved transformer-based decoder with explicit position queries to directly detect and predict the fundamental sketch curves (i.e., type and parameter) from the point cloud. Instead of approximating a continuous field, we formulate curve parameters as explicit position queries, which are optimized autoregressively to achieve high accuracy. The overall topology is rebuilt via extrusion segmentation. Extensive experiments demonstrate that this direct prediction paradigm significantly outperforms implicit methods in both primitive accuracy and overall geometric fidelity.",
    "published": "2025-05-04T09:42:03Z",
    "updated": "2025-11-17T14:42:42Z",
    "link": "http://arxiv.org/pdf/2505.02043v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xinzhu Ma",
      "Cheng Wang",
      "Chen Tang",
      "Bin Wang",
      "Shixiang Tang",
      "Yuan Meng",
      "Yunhong Wang",
      "Di Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13420v1",
    "title": "VOPE: Revisiting Hallucination of Vision-Language Models in Voluntary Imagination Task",
    "summary": "Most research on hallucinations in Large Vision-Language Models (LVLMs) focuses on factual description tasks that prohibit any output absent from the image. However, little attention has been paid to hallucinations in voluntary imagination tasks, e.g., story writing, where the models are expected to generate novel content beyond the given image. In these tasks, it is inappropriate to simply regard such imagined novel content as hallucinations. To address this limitation, we introduce Voluntary-imagined Object Presence Evaluation (VOPE)-a novel method to assess LVLMs' hallucinations in voluntary imagination tasks via presence evaluation. Specifically, VOPE poses recheck-based questions to evaluate how an LVLM interprets the presence of the imagined objects in its own response. The consistency between the model's interpretation and the object's presence in the image is then used to determine whether the model hallucinates when generating the response. We apply VOPE to several mainstream LVLMs and hallucination mitigation methods, revealing two key findings: (1) most LVLMs hallucinate heavily during voluntary imagination, and their performance in presence evaluation is notably poor on imagined objects; (2) existing hallucination mitigation methods show limited effect in voluntary imagination tasks, making this an important direction for future research.",
    "published": "2025-11-17T14:32:06Z",
    "updated": "2025-11-17T14:32:06Z",
    "link": "http://arxiv.org/pdf/2511.13420v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xingming Long",
      "Jie Zhang",
      "Shiguang Shan",
      "Xilin Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13417v1",
    "title": "Delineate Anything Flow: Fast, Country-Level Field Boundary Detection from Any Source",
    "summary": "Accurate delineation of agricultural field boundaries from satellite imagery is essential for land management and crop monitoring, yet existing methods often produce incomplete boundaries, merge adjacent fields, and struggle to scale. We present the Delineate Anything Flow (DelAnyFlow) methodology, a resolution-agnostic approach for large-scale field boundary mapping. DelAnyFlow combines the DelAny instance segmentation model, based on a YOLOv11 backbone and trained on the large-scale Field Boundary Instance Segmentation-22M (FBIS 22M) dataset, with a structured post-processing, merging, and vectorization sequence to generate topologically consistent vector boundaries. FBIS 22M, the largest dataset of its kind, contains 672,909 multi-resolution image patches (0.25-10m) and 22.9million validated field instances. The DelAny model delivers state-of-the-art accuracy with over 100% higher mAP and 400x faster inference than SAM2. DelAny demonstrates strong zero-shot generalization and supports national-scale applications: using Sentinel 2 data for 2024, DelAnyFlow generated a complete field boundary layer for Ukraine (603,000km2) in under six hours on a single workstation. DelAnyFlow outputs significantly improve boundary completeness relative to operational products from Sinergise Solutions and NASA Harvest, particularly in smallholder and fragmented systems (0.25-1ha). For Ukraine, DelAnyFlow delineated 3.75M fields at 5m and 5.15M at 2.5m, compared to 2.66M detected by Sinergise Solutions and 1.69M by NASA Harvest. This work delivers a scalable, cost-effective methodology for field delineation in regions lacking digital cadastral data. A project landing page with links to model weights, code, national-scale vector outputs, and dataset is available at https://lavreniuk.github.io/Delineate-Anything/.",
    "published": "2025-11-17T14:30:43Z",
    "updated": "2025-11-17T14:30:43Z",
    "link": "http://arxiv.org/pdf/2511.13417v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mykola Lavreniuk",
      "Nataliia Kussul",
      "Andrii Shelestov",
      "Yevhenii Salii",
      "Volodymyr Kuzin",
      "Sergii Skakun",
      "Zoltan Szantoi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13400v1",
    "title": "What Color Is It? A Text-Interference Multimodal Hallucination Benchmark",
    "summary": "With the rapid advancement of Large Models, numerous text-and-vision-fused Multimodal Large Models (MLMs) have emerged. However, these MLMs remain susceptible to informational interference in visual perception, particularly in color perception, which introduces an additional risk of hallucination. To validate this hypothesis, we introduce the \"What Color Is It\" dataset, a novel benchmark constructed using a simple method to trigger single-modality visual hallucination in MLMs. Based on this dataset, we further investigate the underlying causes of hallucination in the visual modality of MLMs and propose potential solutions to enhance their robustness.",
    "published": "2025-11-17T14:15:41Z",
    "updated": "2025-11-17T14:15:41Z",
    "link": "http://arxiv.org/pdf/2511.13400v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jinkun Zhao",
      "Lei Huang",
      "Wenjun Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23734v4",
    "title": "ZPressor: Bottleneck-Aware Compression for Scalable Feed-Forward 3DGS",
    "summary": "Feed-forward 3D Gaussian Splatting (3DGS) models have recently emerged as a promising solution for novel view synthesis, enabling one-pass inference without the need for per-scene 3DGS optimization. However, their scalability is fundamentally constrained by the limited capacity of their models, leading to degraded performance or excessive memory consumption as the number of input views increases. In this work, we analyze feed-forward 3DGS frameworks through the lens of the Information Bottleneck principle and introduce ZPressor, a lightweight architecture-agnostic module that enables efficient compression of multi-view inputs into a compact latent state $Z$ that retains essential scene information while discarding redundancy. Concretely, ZPressor enables existing feed-forward 3DGS models to scale to over 100 input views at 480P resolution on an 80GB GPU, by partitioning the views into anchor and support sets and using cross attention to compress the information from the support views into anchor views, forming the compressed latent state $Z$. We show that integrating ZPressor into several state-of-the-art feed-forward 3DGS models consistently improves performance under moderate input views and enhances robustness under dense view settings on two large-scale benchmarks DL3DV-10K and RealEstate10K. The video results, code and trained models are available on our project page: https://lhmd.top/zpressor.",
    "published": "2025-05-29T17:57:04Z",
    "updated": "2025-11-17T14:03:46Z",
    "link": "http://arxiv.org/pdf/2505.23734v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Weijie Wang",
      "Donny Y. Chen",
      "Zeyu Zhang",
      "Duochao Shi",
      "Akide Liu",
      "Bohan Zhuang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.09095v2",
    "title": "Backdooring CLIP through Concept Confusion",
    "summary": "Backdoor attacks pose a serious threat to deep learning models by allowing adversaries to implant hidden behaviors that remain dormant on clean inputs but are maliciously triggered at inference. Existing backdoor attack methods typically rely on explicit triggers such as image patches or pixel perturbations, which makes them easier to detect and limits their applicability in complex settings. To address this limitation, we take a different perspective by analyzing backdoor attacks through the lens of concept-level reasoning, drawing on insights from interpretable AI. We show that traditional attacks can be viewed as implicitly manipulating the concepts activated within a model's latent space. This motivates a natural question: can backdoors be built by directly manipulating concepts? To answer this, we propose the Concept Confusion Attack (CCA), a novel framework that designates human-understandable concepts as internal triggers, eliminating the need for explicit input modifications. By relabeling images that strongly exhibit a chosen concept and fine-tuning on this mixed dataset, CCA teaches the model to associate the concept itself with the attacker's target label. Consequently, the presence of the concept alone is sufficient to activate the backdoor, making the attack stealthier and more resistant to existing defenses. Using CLIP as a case study, we show that CCA achieves high attack success rates while preserving clean-task accuracy and evading state-of-the-art defenses.",
    "published": "2025-03-12T06:17:12Z",
    "updated": "2025-11-17T13:57:04Z",
    "link": "http://arxiv.org/pdf/2503.09095v2.pdf",
    "category": [
      "cs.CR",
      "cs.CV"
    ],
    "authors": [
      "Lijie Hu",
      "Junchi Liao",
      "Weimin Lyu",
      "Shaopeng Fu",
      "Tianhao Huang",
      "Shu Yang",
      "Guimin Hu",
      "Di Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.07864v2",
    "title": "Tracing and Mitigating Hallucinations in Multimodal LLMs via Dynamic Attention Localization",
    "summary": "Multimodal Large Language Models (MLLMs) achieve strong performance on tasks like image captioning and visual question answering, but remain prone to hallucinations, where generated text conflicts with the visual input. Prior work links this partly to insufficient visual attention, but existing attention-based detectors and mitigation typically apply uniform adjustments across layers and heads, obscuring where errors originate. In this paper, we first show these methods fail to accurately localize problematic layers. Then, we introduce two diagnostics: Layer Image Attention Entropy (LIAE) which flags anomalous layers, and Image Attention Focus (IAF) which scores attention heads within those layers. Analysis shows that LIAE pinpoints faulty layers and IAF reliably ranks heads that warrant correction. Guided by these signals, we propose Dynamic Layer-wise Entropy and Attention Fusion (D-LEAF), a task-agnostic, attention-guided method that dynamically localizes and corrects errors during inference with negligible overhead. Furthermore, by establishing a connection between D-LEAF and DPO, we provide theoretical justification for the effectiveness of D-LEAF. Results show our D-LEAF delivers a 53\\% relative improvement on standard captioning benchmarks, and on VQA both accuracy and F1-score improve by approximately 4\\%, substantially suppressing hallucinations while preserving efficiency.",
    "published": "2025-09-09T15:51:15Z",
    "updated": "2025-11-17T13:57:04Z",
    "link": "http://arxiv.org/pdf/2509.07864v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tiancheng Yang",
      "Lin Zhang",
      "Jiaye Lin",
      "Guimin Hu",
      "Di Wang",
      "Lijie Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2404.16000v2",
    "title": "A comprehensive and easy-to-use multi-domain multi-task medical imaging meta-dataset",
    "summary": "While the field of medical image analysis has undergone a transformative shift with the integration of machine learning techniques, the main challenge of these techniques is often the scarcity of large, diverse, and well-annotated datasets. Medical images vary in format, size, and other parameters and therefore require extensive preprocessing and standardization, for usage in machine learning. Addressing these challenges, we introduce the Medical Imaging Meta-Dataset (MedIMeta), a novel multi-domain, multi-task meta-dataset. MedIMeta contains 19 medical imaging datasets spanning 10 different domains and encompassing 54 distinct medical tasks, all of which are standardized to the same format and readily usable in PyTorch or other ML frameworks. We perform a technical validation of MedIMeta, demonstrating its utility through fully supervised and cross-domain few-shot learning baselines.",
    "published": "2024-04-24T17:27:57Z",
    "updated": "2025-11-17T13:28:40Z",
    "link": "http://arxiv.org/pdf/2404.16000v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Stefano Woerner",
      "Arthur Jaques",
      "Christian F. Baumgartner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.09981v2",
    "title": "LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit",
    "summary": "Large Vision-Language Models (VLMs) exhibit impressive multi-modal capabilities but suffer from prohibitive computational and memory demands, due to their long visual token sequences and massive parameter sizes. To address these issues, recent works have proposed training-free compression methods. However, existing efforts often suffer from three major limitations: (1) Current approaches do not decompose techniques into comparable modules, hindering fair evaluation across spatial and temporal redundancy. (2) Evaluation confined to simple single-turn tasks, failing to reflect performance in realistic scenarios. (3) Isolated use of individual compression techniques, without exploring their joint potential. To overcome these gaps, we introduce LLMC+, a comprehensive VLM compression benchmark with a versatile, plug-and-play toolkit. LLMC+ supports over 20 algorithms across five representative VLM families and enables systematic study of token-level and model-level compression. Our benchmark reveals that: (1) Spatial and temporal redundancies demand distinct technical strategies. (2) Token reduction methods degrade significantly in multi-turn dialogue and detail-sensitive tasks. (3) Combining token and model compression achieves extreme compression with minimal performance loss. We believe LLMC+ will facilitate fair evaluation and inspire future research in efficient VLM. Our code is available at https://github.com/ModelTC/LightCompress.",
    "published": "2025-08-13T17:54:49Z",
    "updated": "2025-11-17T13:22:24Z",
    "link": "http://arxiv.org/pdf/2508.09981v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chengtao Lv",
      "Bilang Zhang",
      "Yang Yong",
      "Ruihao Gong",
      "Yushi Huang",
      "Shiqiao Gu",
      "Jiajun Wu",
      "Yumeng Shi",
      "Jinyang Guo",
      "Wenya Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.21262v2",
    "title": "vGamba: Attentive State Space Bottleneck for efficient Long-range Dependencies in Visual Recognition",
    "summary": "Capturing long-range dependencies efficiently is essential for visual recognition tasks, yet existing methods face limitations. Convolutional neural networks (CNNs) struggle with restricted receptive fields, while Vision Transformers (ViTs) achieve global context and long-range modeling at a high computational cost. State-space models (SSMs) offer an alternative, but their application in vision remains underexplored. This work introduces vGamba, a hybrid vision backbone that integrates SSMs with attention mechanisms to enhance efficiency and expressiveness. At its core, the Gamba bottleneck block that includes, Gamba Cell, an adaptation of Mamba for 2D spatial structures, alongside a Multi-Head Self-Attention (MHSA) mechanism and a Gated Fusion Module for effective feature representation. The interplay of these components ensures that vGamba leverages the low computational demands of SSMs while maintaining the accuracy of attention mechanisms for modeling long-range dependencies in vision tasks. Additionally, the Fusion module enables seamless interaction between these components. Extensive experiments on classification, detection, and segmentation tasks demonstrate that vGamba achieves a superior trade-off between accuracy and computational efficiency, outperforming several existing models.",
    "published": "2025-03-27T08:39:58Z",
    "updated": "2025-11-17T13:12:41Z",
    "link": "http://arxiv.org/pdf/2503.21262v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yunusa Haruna",
      "Adamu Lawan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13344v1",
    "title": "YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection",
    "summary": "This paper presents a novel Mixture-of-Experts framework for object detection, incorporating adaptive routing among multiple YOLOv9-T experts to enable dynamic feature specialization and achieve higher mean Average Precision (mAP) and Average Recall (AR) compared to a single YOLOv9-T model.",
    "published": "2025-11-17T13:11:11Z",
    "updated": "2025-11-17T13:11:11Z",
    "link": "http://arxiv.org/pdf/2511.13344v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ori Meiraz",
      "Sharon Shalev",
      "Avishai Weizman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13309v1",
    "title": "DriveLiDAR4D: Sequential and Controllable LiDAR Scene Generation for Autonomous Driving",
    "summary": "The generation of realistic LiDAR point clouds plays a crucial role in the development and evaluation of autonomous driving systems. Although recent methods for 3D LiDAR point cloud generation have shown significant improvements, they still face notable limitations, including the lack of sequential generation capabilities and the inability to produce accurately positioned foreground objects and realistic backgrounds. These shortcomings hinder their practical applicability. In this paper, we introduce DriveLiDAR4D, a novel LiDAR generation pipeline consisting of multimodal conditions and a novel sequential noise prediction model LiDAR4DNet, capable of producing temporally consistent LiDAR scenes with highly controllable foreground objects and realistic backgrounds. To the best of our knowledge, this is the first work to address the sequential generation of LiDAR scenes with full scene manipulation capability in an end-to-end manner. We evaluated DriveLiDAR4D on the nuScenes and KITTI datasets, where we achieved an FRD score of 743.13 and an FVD score of 16.96 on the nuScenes dataset, surpassing the current state-of-the-art (SOTA) method, UniScene, with an performance boost of 37.2% in FRD and 24.1% in FVD, respectively.",
    "published": "2025-11-17T12:43:26Z",
    "updated": "2025-11-17T12:43:26Z",
    "link": "http://arxiv.org/pdf/2511.13309v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kaiwen Cai",
      "Xinze Liu",
      "Xia Zhou",
      "Hengtong Hu",
      "Jie Xiang",
      "Luyao Zhang",
      "Xueyang Zhang",
      "Kun Zhan",
      "Yifei Zhan",
      "Xianpeng Lang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.07673v3",
    "title": "Nearest Neighbor Projection Removal Adversarial Training",
    "summary": "Deep neural networks have exhibited impressive performance in image classification tasks but remain vulnerable to adversarial examples. Standard adversarial training enhances robustness but typically fails to explicitly address inter-class feature overlap, a significant contributor to adversarial susceptibility. In this work, we introduce a novel adversarial training framework that actively mitigates inter-class proximity by projecting out inter-class dependencies from adversarial and clean samples in the feature space. Specifically, our approach first identifies the nearest inter-class neighbors for each adversarial sample and subsequently removes projections onto these neighbors to enforce stronger feature separability. Theoretically, we demonstrate that our proposed logits correction reduces the Lipschitz constant of neural networks, thereby lowering the Rademacher complexity, which directly contributes to improved generalization and robustness. Extensive experiments across standard benchmarks including CIFAR-10, CIFAR-100, and SVHN show that our method demonstrates strong performance that is competitive with leading adversarial training techniques, highlighting significant achievements in both robust and clean accuracy. Our findings reveal the importance of addressing inter-class feature proximity explicitly to bolster adversarial robustness in DNNs.",
    "published": "2025-09-09T12:38:41Z",
    "updated": "2025-11-17T12:30:33Z",
    "link": "http://arxiv.org/pdf/2509.07673v3.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Himanshu Singh",
      "A. V. Subramanyam",
      "Shivank Rajput",
      "Mohan Kankanhalli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13297v1",
    "title": "CorrectAD: A Self-Correcting Agentic System to Improve End-to-end Planning in Autonomous Driving",
    "summary": "End-to-end planning methods are the de facto standard of the current autonomous driving system, while the robustness of the data-driven approaches suffers due to the notorious long-tail problem (i.e., rare but safety-critical failure cases). In this work, we explore whether recent diffusion-based video generation methods (a.k.a. world models), paired with structured 3D layouts, can enable a fully automated pipeline to self-correct such failure cases. We first introduce an agent to simulate the role of product manager, dubbed PM-Agent, which formulates data requirements to collect data similar to the failure cases. Then, we use a generative model that can simulate both data collection and annotation. However, existing generative models struggle to generate high-fidelity data conditioned on 3D layouts. To address this, we propose DriveSora, which can generate spatiotemporally consistent videos aligned with the 3D annotations requested by PM-Agent. We integrate these components into our self-correcting agentic system, CorrectAD. Importantly, our pipeline is an end-to-end model-agnostic and can be applied to improve any end-to-end planner. Evaluated on both nuScenes and a more challenging in-house dataset across multiple end-to-end planners, CorrectAD corrects 62.5% and 49.8% of failure cases, reducing collision rates by 39% and 27%, respectively.",
    "published": "2025-11-17T12:21:03Z",
    "updated": "2025-11-17T12:21:03Z",
    "link": "http://arxiv.org/pdf/2511.13297v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Enhui Ma",
      "Lijun Zhou",
      "Tao Tang",
      "Jiahuan Zhang",
      "Junpeng Jiang",
      "Zhan Zhang",
      "Dong Han",
      "Kun Zhan",
      "Xueyang Zhang",
      "XianPeng Lang",
      "Haiyang Sun",
      "Xia Zhou",
      "Di Lin",
      "Kaicheng Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13285v1",
    "title": "SkyReels-Text: Fine-grained Font-Controllable Text Editing for Poster Design",
    "summary": "Artistic design such as poster design often demands rapid yet precise modification of textual content while preserving visual harmony and typographic intent, especially across diverse font styles. Although modern image editing models have grown increasingly powerful, they still fall short in fine-grained, font-aware text manipulation, limiting their utility in professional design workflows such as poster editing. To address this issue, we present SkyReels-Text, a novel font-controllable framework for precise poster text editing. Our method enables simultaneous editing of multiple text regions, each rendered in distinct typographic styles, while preserving the visual appearance of non-edited regions. Notably, our model requires neither font labels nor fine-tuning during inference: users can simply provide cropped glyph patches corresponding to their desired typography, even if the font is not included in any standard library. Extensive experiments on multiple datasets, including handwrittent text benchmarks, SkyReels-Text achieves state-of-the-art performance in both text fidelity and visual realism, offering unprecedented control over font families, and stylistic nuances. This work bridges the gap between general-purpose image editing and professional-grade typographic design.",
    "published": "2025-11-17T12:02:52Z",
    "updated": "2025-11-17T12:02:52Z",
    "link": "http://arxiv.org/pdf/2511.13285v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yunjie Yu",
      "Jingchen Wu",
      "Junchen Zhu",
      "Chunze Lin",
      "Guibin Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.23752v3",
    "title": "StrokeFusion: Vector Sketch Generation via Joint Stroke-UDF Encoding and Latent Sequence Diffusion",
    "summary": "In the field of sketch generation, raster-format trained models often produce non-stroke artifacts, while vector-format trained models typically lack a holistic understanding of sketches, leading to compromised recognizability. Moreover, existing methods struggle to extract common features from similar elements (e.g., eyes of animals) appearing at varying positions across sketches. To address these challenges, we propose StrokeFusion, a two-stage framework for vector sketch generation. It contains a dual-modal sketch feature learning network that maps strokes into a high-quality latent space. This network decomposes sketches into normalized strokes and jointly encodes stroke sequences with Unsigned Distance Function (UDF) maps, representing sketches as sets of stroke feature vectors. Building upon this representation, our framework exploits a stroke-level latent diffusion model that simultaneously adjusts stroke position, scale, and trajectory during generation. This enables high-fidelity sketch generation while supporting stroke interpolation editing. Extensive experiments on the QuickDraw dataset demonstrate that our framework outperforms state-of-the-art techniques, validating its effectiveness in preserving structural integrity and semantic features. Code and models will be made publicly available upon publication.",
    "published": "2025-03-31T06:03:03Z",
    "updated": "2025-11-17T12:02:04Z",
    "link": "http://arxiv.org/pdf/2503.23752v3.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Jin Zhou",
      "Yi Zhou",
      "Hongliang Yang",
      "Pengfei Xu",
      "Hui Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13283v1",
    "title": "TabFlash: Efficient Table Understanding with Progressive Question Conditioning and Token Focusing",
    "summary": "Table images present unique challenges for effective and efficient understanding due to the need for question-specific focus and the presence of redundant background regions. Existing Multimodal Large Language Model (MLLM) approaches often overlook these characteristics, resulting in uninformative and redundant visual representations. To address these issues, we aim to generate visual features that are both informative and compact to improve table understanding. We first propose progressive question conditioning, which injects the question into Vision Transformer layers with gradually increasing frequency, considering each layer's capacity to handle additional information, to generate question-aware visual features. To reduce redundancy, we introduce a pruning strategy that discards background tokens, thereby improving efficiency. To mitigate information loss from pruning, we further propose token focusing, a training strategy that encourages the model to concentrate essential information in the retained tokens. By combining these approaches, we present TabFlash, an efficient and effective MLLM for table understanding. TabFlash achieves state-of-the-art performance, outperforming both open-source and proprietary MLLMs, while requiring 27% less FLOPs and 30% less memory usage compared to the second-best MLLM.",
    "published": "2025-11-17T12:00:23Z",
    "updated": "2025-11-17T12:00:23Z",
    "link": "http://arxiv.org/pdf/2511.13283v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jongha Kim",
      "Minseong Bae",
      "Sanghyeok Lee",
      "Jinsung Yoon",
      "Hyunwoo J. Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13282v1",
    "title": "Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space",
    "summary": "Multi-person human mesh recovery from a single image is a challenging task, hindered by the scarcity of in-the-wild training data. Prevailing in-the-wild human mesh pseudo-ground-truth (pGT) generation pipelines are single-person-centric, where each human is processed individually without joint optimization. This oversight leads to a lack of scene-level consistency, producing individuals with conflicting depths and scales within the same image. To address this, we introduce Depth-conditioned Translation Optimization (DTO), a novel optimization-based method that jointly refines the camera-space translations of all individuals in a crowd. By leveraging anthropometric priors on human height and depth cues from a monocular depth estimator, DTO solves for a scene-consistent placement of all subjects within a principled Maximum a posteriori (MAP) framework. Applying DTO to the 4D-Humans dataset, we construct DTO-Humans, a new large-scale pGT dataset of 0.56M high-quality, scene-consistent multi-person images, featuring dense crowds with an average of 4.8 persons per image. Furthermore, we propose Metric-Aware HMR, an end-to-end network that directly estimates human mesh and camera parameters in metric scale. This is enabled by a camera branch and a novel relative metric loss that enforces plausible relative scales. Extensive experiments demonstrate that our method achieves state-of-the-art performance on relative depth reasoning and human mesh recovery. Code and data will be released publicly.",
    "published": "2025-11-17T12:00:13Z",
    "updated": "2025-11-17T12:00:13Z",
    "link": "http://arxiv.org/pdf/2511.13282v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kaiwen Wang",
      "Kaili Zheng",
      "Yiming Shi",
      "Chenyi Guo",
      "Ji Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13278v1",
    "title": "SF-Recon: Simplification-Free Lightweight Building Reconstruction via 3D Gaussian Splatting",
    "summary": "Lightweight building surface models are crucial for digital city, navigation, and fast geospatial analytics, yet conventional multi-view geometry pipelines remain cumbersome and quality-sensitive due to their reliance on dense reconstruction, meshing, and subsequent simplification. This work presents SF-Recon, a method that directly reconstructs lightweight building surfaces from multi-view images without post-hoc mesh simplification. We first train an initial 3D Gaussian Splatting (3DGS) field to obtain a view-consistent representation. Building structure is then distilled by a normal-gradient-guided Gaussian optimization that selects primitives aligned with roof and wall boundaries, followed by multi-view edge-consistency pruning to enhance structural sharpness and suppress non-structural artifacts without external supervision. Finally, a multi-view depth-constrained Delaunay triangulation converts the structured Gaussian field into a lightweight, structurally faithful building mesh. Based on a proposed SF dataset, the experimental results demonstrate that our SF-Recon can directly reconstruct lightweight building models from multi-view imagery, achieving substantially fewer faces and vertices while maintaining computational efficiency. Website:https://lzh282140127-cell.github.io/SF-Recon-project/",
    "published": "2025-11-17T11:50:52Z",
    "updated": "2025-11-17T11:50:52Z",
    "link": "http://arxiv.org/pdf/2511.13278v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zihan Li",
      "Tengfei Wang",
      "Wentian Gan",
      "Hao Zhan",
      "Xin Wang",
      "Zongqian Zhan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13276v1",
    "title": "Recognition of Abnormal Events in Surveillance Videos using Weakly Supervised Dual-Encoder Models",
    "summary": "We address the challenge of detecting rare and diverse anomalies in surveillance videos using only video-level supervision. Our dual-backbone framework combines convolutional and transformer representations through top-k pooling, achieving 90.7% area under the curve (AUC) on the UCF-Crime dataset.",
    "published": "2025-11-17T11:47:28Z",
    "updated": "2025-11-17T11:47:28Z",
    "link": "http://arxiv.org/pdf/2511.13276v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Noam Tsfaty",
      "Avishai Weizman",
      "Liav Cohen",
      "Moshe Tshuva",
      "Yehudit Aperstein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.12644v2",
    "title": "Use as Many Surrogates as You Want: Selective Ensemble Attack to Unleash Transferability without Sacrificing Resource Efficiency",
    "summary": "In surrogate ensemble attacks, using more surrogate models yields higher transferability but lower resource efficiency. This practical trade-off between transferability and efficiency has largely limited existing attacks despite many pre-trained models are easily accessible online. In this paper, we argue that such a trade-off is caused by an unnecessary common assumption, i.e., all models should be \\textit{identical} across iterations. By lifting this assumption, we can use as many surrogates as we want to unleash transferability without sacrificing efficiency. Concretely, we propose Selective Ensemble Attack (SEA), which dynamically selects diverse models (from easily accessible pre-trained models) across iterations based on our new interpretation of decoupling within-iteration and cross-iteration model diversity. In this way, the number of within-iteration models is fixed for maintaining efficiency, while only cross-iteration model diversity is increased for higher transferability. Experiments on ImageNet demonstrate the superiority of SEA in various scenarios. For example, when dynamically selecting 4 from 20 accessible models, SEA yields 8.5% higher transferability than existing attacks under the same efficiency. The superiority of SEA also generalizes to real-world systems, such as commercial vision APIs and large vision-language models. Overall, SEA opens up the possibility of adaptively balancing transferability and efficiency according to specific resource requirements.",
    "published": "2025-05-19T02:56:41Z",
    "updated": "2025-11-17T11:44:21Z",
    "link": "http://arxiv.org/pdf/2505.12644v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bo Yang",
      "Hengwei Zhang",
      "Jindong Wang",
      "Yuchen Ren",
      "Chenhao Lin",
      "Chao Shen",
      "Zhengyu Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.06248v3",
    "title": "Deepfake Detection that Generalizes Across Benchmarks",
    "summary": "The generalization of deepfake detectors to unseen manipulation techniques remains a challenge for practical deployment. Although many approaches adapt foundation models by introducing significant architectural complexity, this work demonstrates that robust generalization is achievable through a parameter-efficient adaptation of one of the foundational pre-trained vision encoders. The proposed method, GenD, fine-tunes only the Layer Normalization parameters (0.03% of the total) and enhances generalization by enforcing a hyperspherical feature manifold using L2 normalization and metric learning on it.\n  We conducted an extensive evaluation on 14 benchmark datasets spanning from 2019 to 2025. The proposed method achieves state-of-the-art performance, outperforming more complex, recent approaches in average cross-dataset AUROC. Our analysis yields two primary findings for the field: 1) training on paired real-fake data from the same source video is essential for mitigating shortcut learning and improving generalization, and 2) detection difficulty on academic datasets has not strictly increased over time, with models trained on older, diverse datasets showing strong generalization capabilities.\n  This work delivers a computationally efficient and reproducible method, proving that state-of-the-art generalization is attainable by making targeted, minimal changes to a pre-trained foundational image encoder model. The code is at: https://github.com/yermandy/GenD",
    "published": "2025-08-08T12:03:56Z",
    "updated": "2025-11-17T11:41:58Z",
    "link": "http://arxiv.org/pdf/2508.06248v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Andrii Yermakov",
      "Jan Cech",
      "Jiri Matas",
      "Mario Fritz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13269v1",
    "title": "Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation",
    "summary": "Vision-Language Models (VLMs), leveraging their powerful visual perception and reasoning capabilities, have been widely applied in Unmanned Aerial Vehicle (UAV) tasks. However, the spatial intelligence capabilities of existing VLMs in UAV scenarios remain largely unexplored, raising concerns about their effectiveness in navigating and interpreting dynamic environments. To bridge this gap, we introduce SpatialSky-Bench, a comprehensive benchmark specifically designed to evaluate the spatial intelligence capabilities of VLMs in UAV navigation. Our benchmark comprises two categories-Environmental Perception and Scene Understanding-divided into 13 subcategories, including bounding boxes, color, distance, height, and landing safety analysis, among others. Extensive evaluations of various mainstream open-source and closed-source VLMs reveal unsatisfactory performance in complex UAV navigation scenarios, highlighting significant gaps in their spatial capabilities. To address this challenge, we developed the SpatialSky-Dataset, a comprehensive dataset containing 1M samples with diverse annotations across various scenarios. Leveraging this dataset, we introduce Sky-VLM, a specialized VLM designed for UAV spatial reasoning across multiple granularities and contexts. Extensive experimental results demonstrate that Sky-VLM achieves state-of-the-art performance across all benchmark tasks, paving the way for the development of VLMs suitable for UAV scenarios. The source code is available at https://github.com/linglingxiansen/SpatialSKy.",
    "published": "2025-11-17T11:39:20Z",
    "updated": "2025-11-17T11:39:20Z",
    "link": "http://arxiv.org/pdf/2511.13269v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Lingfeng Zhang",
      "Yuchen Zhang",
      "Hongsheng Li",
      "Haoxiang Fu",
      "Yingbo Tang",
      "Hangjun Ye",
      "Long Chen",
      "Xiaojun Liang",
      "Xiaoshuai Hao",
      "Wenbo Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.11136v2",
    "title": "JAFAR: Jack up Any Feature at Any Resolution",
    "summary": "Foundation Vision Encoders have become essential for a wide range of dense vision tasks. However, their low-resolution spatial feature outputs necessitate feature upsampling to produce the high-resolution modalities required for downstream tasks. In this work, we introduce JAFAR, a lightweight and flexible feature upsampler that enhances the spatial resolution of visual features from any Foundation Vision Encoder to an arbitrary target resolution. JAFAR employs an attention-based module designed to promote semantic alignment between high-resolution queries, derived from low-level image features, and semantically enriched low-resolution keys, using Spatial Feature Transform (SFT) modulation. Notably, despite the absence of high-resolution supervision, we demonstrate that learning at low upsampling ratios and resolutions generalizes remarkably well to significantly higher output scales. Extensive experiments show that JAFAR effectively recovers fine-grained spatial details and consistently outperforms existing feature upsampling methods across a diverse set of downstream tasks. Project page at https://jafar-upsampler.github.io",
    "published": "2025-06-10T20:53:12Z",
    "updated": "2025-11-17T11:39:19Z",
    "link": "http://arxiv.org/pdf/2506.11136v2.pdf",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Paul Couairon",
      "Loick Chambon",
      "Louis Serrano",
      "Jean-Emmanuel Haugeard",
      "Matthieu Cord",
      "Nicolas Thome"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13264v1",
    "title": "SymGS : Leveraging Local Symmetries for 3D Gaussian Splatting Compression",
    "summary": "3D Gaussian Splatting has emerged as a transformative technique in novel view synthesis, primarily due to its high rendering speed and photorealistic fidelity. However, its memory footprint scales rapidly with scene complexity, often reaching several gigabytes. Existing methods address this issue by introducing compression strategies that exploit primitive-level redundancy through similarity detection and quantization. We aim to surpass the compression limits of such methods by incorporating symmetry-aware techniques, specifically targeting mirror symmetries to eliminate redundant primitives. We propose a novel compression framework, \\textbf{\\textit{SymGS}}, introducing learnable mirrors into the scene, thereby eliminating local and global reflective redundancies for compression. Our framework functions as a plug-and-play enhancement to state-of-the-art compression methods, (e.g. HAC) to achieve further compression. Compared to HAC, we achieve $1.66 \\times$ compression across benchmark datasets (upto $3\\times$ on large-scale scenes). On an average, SymGS enables $\\bf{108\\times}$ compression of a 3DGS scene, while preserving rendering quality. The project page and supplementary can be found at \\textbf{\\color{cyan}{symgs.github.io}}",
    "published": "2025-11-17T11:26:09Z",
    "updated": "2025-11-17T11:26:09Z",
    "link": "http://arxiv.org/pdf/2511.13264v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Keshav Gupta",
      "Akshat Sanghvi",
      "Shreyas Reddy Palley",
      "Astitva Srivastava",
      "Charu Sharma",
      "Avinash Sharma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13261v1",
    "title": "Building Egocentric Procedural AI Assistant: Methods, Benchmarks, and Challenges",
    "summary": "Driven by recent advances in vision language models (VLMs) and egocentric perception research, we introduce the concept of an egocentric procedural AI assistant (EgoProceAssist) tailored to step-by-step support daily procedural tasks in a first-person view. In this work, we start by identifying three core tasks: egocentric procedural error detection, egocentric procedural learning, and egocentric procedural question answering. These tasks define the essential functions of EgoProceAssist within a new taxonomy. Specifically, our work encompasses a comprehensive review of current techniques, relevant datasets, and evaluation metrics across these three core areas. To clarify the gap between the proposed EgoProceAssist and existing VLM-based AI assistants, we introduce novel experiments and provide a comprehensive evaluation of representative VLM-based methods. Based on these findings and our technical analysis, we discuss the challenges ahead and suggest future research directions. Furthermore, an exhaustive list of this study is publicly available in an active repository that continuously collects the latest work: https://github.com/z1oong/Building-Egocentric-Procedural-AI-Assistant",
    "published": "2025-11-17T11:21:42Z",
    "updated": "2025-11-17T11:21:42Z",
    "link": "http://arxiv.org/pdf/2511.13261v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junlong Li",
      "Huaiyuan Xu",
      "Sijie Cheng",
      "Kejun Wu",
      "Kim-Hui Yap",
      "Lap-Pui Chau",
      "Yi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13249v1",
    "title": "Referring Camouflaged Object Detection With Multi-Context Overlapped Windows Cross-Attention",
    "summary": "Referring camouflaged object detection (Ref-COD) aims to identify hidden objects by incorporating reference information such as images and text descriptions. Previous research has transformed reference images with salient objects into one-dimensional prompts, yielding significant results. We explore ways to enhance performance through multi-context fusion of rich salient image features and camouflaged object features. Therefore, we propose RFMNet, which utilizes features from multiple encoding stages of the reference salient images and performs interactive fusion with the camouflage features at the corresponding encoding stages. Given that the features in salient object images contain abundant object-related detail information, performing feature fusion within local areas is more beneficial for detecting camouflaged objects. Therefore, we propose an Overlapped Windows Cross-attention mechanism to enable the model to focus more attention on the local information matching based on reference features. Besides, we propose the Referring Feature Aggregation (RFA) module to decode and segment the camouflaged objects progressively. Extensive experiments on the Ref-COD benchmark demonstrate that our method achieves state-of-the-art performance.",
    "published": "2025-11-17T11:08:50Z",
    "updated": "2025-11-17T11:08:50Z",
    "link": "http://arxiv.org/pdf/2511.13249v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yu Wen",
      "Shuyong Gao",
      "Shuping Zhang",
      "Miao Huang",
      "Lili Tao",
      "Han Yang",
      "Haozhe Xing",
      "Lihe Zhang",
      "Boxue Hou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.04842v2",
    "title": "Efficient SAR Vessel Detection for FPGA-Based On-Satellite Sensing",
    "summary": "Rapid analysis of satellite imagery within minutes-to-hours of acquisition is increasingly vital for many remote sensing applications, and is an essential component for developing next-generation autonomous and distributed satellite systems. On-satellite machine learning (ML) has the potential for such rapid analysis, by overcoming latency associated with intermittent satellite connectivity to ground stations or relay satellites, but state-of-the-art models are often too large or power-hungry for on-board deployment. Vessel detection using Synthetic Aperture Radar (SAR) is a critical time-sensitive application in maritime security that exemplifies this challenge. SAR vessel detection has previously been demonstrated only by ML models that either are too large for satellite deployment, have not been developed for sufficiently low-power hardware, or have only been tested on small SAR datasets that do not sufficiently represent the difficulty of the real-world task. Here we systematically explore a suite of architectural adaptations to develop a novel YOLOv8 architecture optimized for this task and FPGA-based processing. We deploy our model on a Kria KV260 MPSoC, and show it can analyze a ~700 megapixel SAR image in less than a minute, within common satellite power constraints (<10W). Our model has detection and classification performance only ~2% and 3% lower than values from state-of-the-art GPU-based models on the largest and most diverse open SAR vessel dataset, xView3-SAR, despite being ~50 and ~2500 times more computationally efficient. This work represents a key contribution towards on-satellite ML for time-critical SAR analysis, and more autonomous, scalable satellites.",
    "published": "2025-07-07T10:03:31Z",
    "updated": "2025-11-17T11:06:45Z",
    "link": "http://arxiv.org/pdf/2507.04842v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Colin Laganier",
      "Liam Fletcher",
      "Elim Kwan",
      "Richard Walters",
      "Victoria Nockles"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13242v1",
    "title": "MMD-Thinker: Adaptive Multi-Dimensional Thinking for Multimodal Misinformation Detection",
    "summary": "Multimodal misinformation floods on various social media, and continues to evolve in the era of AI-generated content (AIGC). The emerged misinformation with low creation cost and high deception poses significant threats to society. While recent studies leverage general-purpose multimodal large language models (MLLMs) to achieve remarkable results in detection, they encounter two critical limitations: (1) Insufficient reasoning, where general-purpose MLLMs often follow the uniform reasoning paradigm but generate inaccurate explanations and judgments, due to the lack of the task-specific knowledge of multimodal misinformation detection. (2) Reasoning biases, where a single thinking mode make detectors a suboptimal path for judgment, struggling to keep pace with the fast-growing and intricate multimodal misinformation. In this paper, we propose MMD-Thinker, a two-stage framework for multimodal misinformation detection through adaptive multi-dimensional thinking. First, we develop tailor-designed thinking mode for multimodal misinformation detection. Second, we adopt task-specific instruction tuning to inject the tailored thinking mode into general-purpose MLLMs. Third, we further leverage reinforcement learning strategy with a mixed advantage function, which incentivizes the reasoning capabilities in trajectories. Furthermore, we construct the multimodal misinformation reasoning (MMR) dataset, encompasses more than 8K image-text pairs with both reasoning processes and classification labels, to make progress in the relam of multimodal misinformation detection. Experimental results demonstrate that our proposed MMD-Thinker achieves state-of-the-art performance on both in-domain and out-of-domain benchmark datasets, while maintaining flexible inference and token usage. Code will be publicly available at Github.",
    "published": "2025-11-17T11:04:30Z",
    "updated": "2025-11-17T11:04:30Z",
    "link": "http://arxiv.org/pdf/2511.13242v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junjie Wu",
      "Guohong Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13232v1",
    "title": "MRIQT: Physics-Aware Diffusion Model for Image Quality Transfer in Neonatal Ultra-Low-Field MRI",
    "summary": "Portable ultra-low-field MRI (uLF-MRI, 0.064 T) offers accessible neuroimaging for neonatal care but suffers from low signal-to-noise ratio and poor diagnostic quality compared to high-field (HF) MRI. We propose MRIQT, a 3D conditional diffusion framework for image quality transfer (IQT) from uLF to HF MRI. MRIQT combines realistic K-space degradation for physics-consistent uLF simulation, v-prediction with classifier-free guidance for stable image-to-image generation, and an SNR-weighted 3D perceptual loss for anatomical fidelity. The model denoises from a noised uLF input conditioned on the same scan, leveraging volumetric attention-UNet architecture for structure-preserving translation. Trained on a neonatal cohort with diverse pathologies, MRIQT surpasses recent GAN and CNN baselines in PSNR 15.3% with 1.78% over the state of the art, while physicians rated 85% of its outputs as good quality with clear pathology present. MRIQT enables high-fidelity, diffusion-based enhancement of portable ultra-low-field (uLF) MRI for deliable neonatal brain assessment.",
    "published": "2025-11-17T10:51:11Z",
    "updated": "2025-11-17T10:51:11Z",
    "link": "http://arxiv.org/pdf/2511.13232v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Malek Al Abed",
      "Sebiha Demir",
      "Anne Groteklaes",
      "Elodie Germani",
      "Shahrooz Faghihroohi",
      "Hemmen Sabir",
      "Shadi Albarqouni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.24899v3",
    "title": "Attention Surgery: An Efficient Recipe to Linearize Your Video Diffusion Transformer",
    "summary": "Transformer-based video diffusion models (VDMs) deliver state-of-the-art video generation quality but are constrained by the quadratic cost of self-attention, making long sequences and high resolutions computationally expensive. While linear attention offers sub-quadratic complexity, previous approaches have failed to match the expressiveness of softmax attention unless retrained at significant computational cost. We introduce Attention Surgery, an efficient framework that enables linear or hybrid attention in pretrained VDMs, eliminating the need for training from scratch. Inspired by recent advances in language models, our method combines a novel hybrid attention mechanism-mixing softmax and linear tokens-with a lightweight distillation and fine-tuning pipeline requiring only a few GPU-days. Additionally, we incorporate a cost-aware block-rate strategy to balance expressiveness and efficiency across layers. Applied to Wan2.1 1.3B, a state-of-the-art efficient transformer VDM and evaluated on VBench, VBench2.0 and a human preference study, Attention Surgery achieves competitive results. Furthermore, measurements of on-mobile latency, memory usage, and FLOPs demonstrate notable improvements in scaling behavior for longer videos. Project page is available at: https://qualcomm-ai-research.github.io/attention-surgery.",
    "published": "2025-09-29T15:09:51Z",
    "updated": "2025-11-17T10:50:37Z",
    "link": "http://arxiv.org/pdf/2509.24899v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mohsen Ghafoorian",
      "Denis Korzhenkov",
      "Amirhossein Habibian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.10150v2",
    "title": "Decoupling Bias, Aligning Distributions: Synergistic Fairness Optimization for Deepfake Detection",
    "summary": "Fairness is a core element in the trustworthy deployment of deepfake detection models, especially in the field of digital identity security. Biases in detection models toward different demographic groups, such as gender and race, may lead to systemic misjudgments, exacerbating the digital divide and social inequities. However, current fairness-enhanced detectors often improve fairness at the cost of detection accuracy. To address this challenge, we propose a dual-mechanism collaborative optimization framework. Our proposed method innovatively integrates structural fairness decoupling and global distribution alignment: decoupling channels sensitive to demographic groups at the model architectural level, and subsequently reducing the distance between the overall sample distribution and the distributions corresponding to each demographic group at the feature level. Experimental results demonstrate that, compared with other methods, our framework improves both inter-group and intra-group fairness while maintaining overall detection accuracy across domains.",
    "published": "2025-11-13T10:04:45Z",
    "updated": "2025-11-17T10:45:19Z",
    "link": "http://arxiv.org/pdf/2511.10150v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Feng Ding",
      "Wenhui Yi",
      "Yunpeng Zhou",
      "Xinan He",
      "Hong Rao",
      "Shu Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17644v2",
    "title": "Towards Prospective Medical Image Reconstruction via Knowledge-Informed Dynamic Optimal Transport",
    "summary": "Medical image reconstruction from measurement data is a vital but challenging inverse problem. Deep learning approaches have achieved promising results, but often requires paired measurement and high-quality images, which is typically simulated through a forward model, i.e., retrospective reconstruction. However, training on simulated pairs commonly leads to performance degradation on real prospective data due to the retrospective-to-prospective gap caused by incomplete imaging knowledge in simulation. To address this challenge, this paper introduces imaging Knowledge-Informed Dynamic Optimal Transport (KIDOT), a novel dynamic optimal transport framework with optimality in the sense of preserving consistency with imaging physics in transport, that conceptualizes reconstruction as finding a dynamic transport path. KIDOT learns from unpaired data by modeling reconstruction as a continuous evolution path from measurements to images, guided by an imaging knowledge-informed cost function and transport equation. This dynamic and knowledge-aware approach enhances robustness and better leverages unpaired data while respecting acquisition physics. Theoretically, we demonstrate that KIDOT naturally generalizes dynamic optimal transport, ensuring its mathematical rationale and solution existence. Extensive experiments on MRI and CT reconstruction demonstrate KIDOT's superior performance.",
    "published": "2025-05-23T09:05:10Z",
    "updated": "2025-11-17T10:44:21Z",
    "link": "http://arxiv.org/pdf/2505.17644v2.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Taoran Zheng",
      "Yan Yang",
      "Xing Li",
      "Xiang Gu",
      "Jian Sun",
      "Zongben Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13222v1",
    "title": "Hybrid-Domain Adaptative Representation Learning for Gaze Estimation",
    "summary": "Appearance-based gaze estimation, aiming to predict accurate 3D gaze direction from a single facial image, has made promising progress in recent years. However, most methods suffer significant performance degradation in cross-domain evaluation due to interference from gaze-irrelevant factors, such as expressions, wearables, and image quality. To alleviate this problem, we present a novel Hybrid-domain Adaptative Representation Learning (shorted by HARL) framework that exploits multi-source hybrid datasets to learn robust gaze representation. More specifically, we propose to disentangle gaze-relevant representation from low-quality facial images by aligning features extracted from high-quality near-eye images in an unsupervised domain-adaptation manner, which hardly requires any computational or inference costs. Additionally, we analyze the effect of head-pose and design a simple yet efficient sparse graph fusion module to explore the geometric constraint between gaze direction and head-pose, leading to a dense and robust gaze representation. Extensive experiments on EyeDiap, MPIIFaceGaze, and Gaze360 datasets demonstrate that our approach achieves state-of-the-art accuracy of $\\textbf{5.02}^{\\circ}$ and $\\textbf{3.36}^{\\circ}$, and $\\textbf{9.26}^{\\circ}$ respectively, and present competitive performances through cross-dataset evaluation. The code is available at https://github.com/da60266/HARL.",
    "published": "2025-11-17T10:38:50Z",
    "updated": "2025-11-17T10:38:50Z",
    "link": "http://arxiv.org/pdf/2511.13222v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qida Tan",
      "Hongyu Yang",
      "Wenchao Du"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13211v1",
    "title": "3DAlign-DAER: Dynamic Attention Policy and Efficient Retrieval Strategy for Fine-grained 3D-Text Alignment at Scale",
    "summary": "Despite recent advancements in 3D-text cross-modal alignment, existing state-of-the-art methods still struggle to align fine-grained textual semantics with detailed geometric structures, and their alignment performance degrades significantly when scaling to large-scale 3D databases. To overcome this limitation, we introduce 3DAlign-DAER, a unified framework designed to align text and 3D geometry via the proposed dynamic attention policy and the efficient retrieval strategy, capturing subtle correspondences for diverse cross-modal retrieval and classification tasks. Specifically, during the training, our proposed dynamic attention policy (DAP) employs the Hierarchical Attention Fusion (HAF) module to represent the alignment as learnable fine-grained token-to-point attentions. To optimize these attentions across different tasks and geometric hierarchies, our DAP further exploits the Monte Carlo tree search to dynamically calibrate HAF attention weights via a hybrid reward signal and further enhances the alignment between textual descriptions and local 3D geometry. During the inference, our 3DAlign-DAER introduces an Efficient Retrieval Strategy (ERS) to leverage efficient hierarchical searching in the large-scale embedding spaces, outperforming traditional methods (e.g., KNN) in accuracy and efficiency. Furthermore, to facilitate text-3D alignment research and train our 3DAlign-DAER, we construct Align3D-2M, a large-scale dataset featuring 2M text-3D pairs, to provide sufficient fine-grained cross-modal annotations. Extensive and comprehensive experiments demonstrate the superior performance of our 3DAlign-DAER on diverse benchmarks. We will release our codes, models, and datasets.",
    "published": "2025-11-17T10:23:29Z",
    "updated": "2025-11-17T10:23:29Z",
    "link": "http://arxiv.org/pdf/2511.13211v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yijia Fan",
      "Jusheng Zhang",
      "Kaitong Cai",
      "Jing Yang",
      "Jian Wang",
      "Keze Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13208v1",
    "title": "End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer",
    "summary": "Existing multi-person video pose estimation methods typically adopt a two-stage pipeline: detecting individuals in each frame, followed by temporal modeling for single-person pose estimation. This design relies on heuristic operations such as detection, RoI cropping, and non-maximum suppression (NMS), limiting both accuracy and efficiency. In this paper, we present a fully end-to-end framework for multi-person 2D pose estimation in videos, effectively eliminating heuristic operations. A key challenge is to associate individuals across frames under complex and overlapping temporal trajectories. To address this, we introduce a novel Pose-Aware Video transformEr Network (PAVE-Net), which features a spatial encoder to model intra-frame relations and a spatiotemporal pose decoder to capture global dependencies across frames. To achieve accurate temporal association, we propose a pose-aware attention mechanism that enables each pose query to selectively aggregate features corresponding to the same individual across consecutive frames.Additionally, we explicitly model spatiotemporal dependencies among pose keypoints to improve accuracy. Notably, our approach is the first end-to-end method for multi-frame 2D human pose estimation.Extensive experiments show that PAVE-Net substantially outperforms prior image-based end-to-end methods, achieving a \\textbf{6.0} mAP improvement on PoseTrack2017, and delivers accuracy competitive with state-of-the-art two-stage video-based approaches, while offering significant gains in efficiency.Project page: https://github.com/zgspose/PAVENet",
    "published": "2025-11-17T10:19:35Z",
    "updated": "2025-11-17T10:19:35Z",
    "link": "http://arxiv.org/pdf/2511.13208v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yonghui Yu",
      "Jiahang Cai",
      "Xun Wang",
      "Wenwu Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13207v1",
    "title": "PIGEON: VLM-Driven Object Navigation via Points of Interest Selection",
    "summary": "Navigating to a specified object in an unknown environment is a fundamental yet challenging capability of embodied intelligence. However, current methods struggle to balance decision frequency with intelligence, resulting in decisions lacking foresight or discontinuous actions. In this work, we propose PIGEON: Point of Interest Guided Exploration for Object Navigation with VLM, maintaining a lightweight and semantically aligned snapshot memory during exploration as semantic input for the exploration strategy. We use a large Visual-Language Model (VLM), named PIGEON-VL, to select Points of Interest (PoI) formed during exploration and then employ a lower-level planner for action output, increasing the decision frequency. Additionally, this PoI-based decision-making enables the generation of Reinforcement Learning with Verifiable Reward (RLVR) data suitable for simulators. Experiments on classic object navigation benchmarks demonstrate that our zero-shot transfer method achieves state-of-the-art performance, while RLVR further enhances the model's semantic guidance capabilities, enabling deep reasoning during real-time navigation.",
    "published": "2025-11-17T10:19:13Z",
    "updated": "2025-11-17T10:19:13Z",
    "link": "http://arxiv.org/pdf/2511.13207v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Cheng Peng",
      "Zhenzhe Zhang",
      "Cheng Chi",
      "Xiaobao Wei",
      "Yanhao Zhang",
      "Heng Wang",
      "Pengwei Wang",
      "Zhongyuan Wang",
      "Jing Liu",
      "Shanghang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13204v1",
    "title": "RefineVAD: Semantic-Guided Feature Recalibration for Weakly Supervised Video Anomaly Detection",
    "summary": "Weakly-Supervised Video Anomaly Detection aims to identify anomalous events using only video-level labels, balancing annotation efficiency with practical applicability. However, existing methods often oversimplify the anomaly space by treating all abnormal events as a single category, overlooking the diverse semantic and temporal characteristics intrinsic to real-world anomalies. Inspired by how humans perceive anomalies, by jointly interpreting temporal motion patterns and semantic structures underlying different anomaly types, we propose RefineVAD, a novel framework that mimics this dual-process reasoning. Our framework integrates two core modules. The first, Motion-aware Temporal Attention and Recalibration (MoTAR), estimates motion salience and dynamically adjusts temporal focus via shift-based attention and global Transformer-based modeling. The second, Category-Oriented Refinement (CORE), injects soft anomaly category priors into the representation space by aligning segment-level features with learnable category prototypes through cross-attention. By jointly leveraging temporal dynamics and semantic structure, explicitly models both \"how\" motion evolves and \"what\" semantic category it resembles. Extensive experiments on WVAD benchmark validate the effectiveness of RefineVAD and highlight the importance of integrating semantic context to guide feature refinement toward anomaly-relevant patterns.",
    "published": "2025-11-17T10:15:34Z",
    "updated": "2025-11-17T10:15:34Z",
    "link": "http://arxiv.org/pdf/2511.13204v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junhee Lee",
      "ChaeBeen Bang",
      "MyoungChul Kim",
      "MyeongAh Cho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13197v1",
    "title": "Self-Supervised Ultrasound Screen Detection",
    "summary": "Ultrasound (US) machines display images on a built-in monitor, but routine transfer to hospital systems relies on DICOM. We propose a self-supervised pipeline to extract the US image from a photograph of the monitor. This removes the DICOM bottleneck and enables rapid testing and prototyping of new algorithms. In a proof-of-concept study, the rectified images retained enough visual fidelity to classify cardiac views with a balanced accuracy of 0.79 with respect to the native DICOMs.",
    "published": "2025-11-17T10:08:23Z",
    "updated": "2025-11-17T10:08:23Z",
    "link": "http://arxiv.org/pdf/2511.13197v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Alberto Gomez",
      "Jorge Oliveira",
      "Ramon Casero",
      "Agis Chartsias"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13195v1",
    "title": "Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection",
    "summary": "Monocular 3D object detection is a cost-effective solution for applications like autonomous driving and robotics, but remains fundamentally ill-posed due to inherently ambiguous depth cues. Recent DETR-based methods attempt to mitigate this through global attention and auxiliary depth prediction, yet they still struggle with inaccurate depth estimates. Moreover, these methods often overlook instance-level detection difficulty, such as occlusion, distance, and truncation, leading to suboptimal detection performance. We propose MonoDLGD, a novel Difficulty-Aware Label-Guided Denoising framework that adaptively perturbs and reconstructs ground-truth labels based on detection uncertainty. Specifically, MonoDLGD applies stronger perturbations to easier instances and weaker ones into harder cases, and then reconstructs them to effectively provide explicit geometric supervision. By jointly optimizing label reconstruction and 3D object detection, MonoDLGD encourages geometry-aware representation learning and improves robustness to varying levels of object complexity. Extensive experiments on the KITTI benchmark demonstrate that MonoDLGD achieves state-of-the-art performance across all difficulty levels.",
    "published": "2025-11-17T10:02:18Z",
    "updated": "2025-11-17T10:02:18Z",
    "link": "http://arxiv.org/pdf/2511.13195v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Soyul Lee",
      "Seungmin Baek",
      "Dongbo Min"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13191v1",
    "title": "Birth of a Painting: Differentiable Brushstroke Reconstruction",
    "summary": "Painting embodies a unique form of visual storytelling, where the creation process is as significant as the final artwork. Although recent advances in generative models have enabled visually compelling painting synthesis, most existing methods focus solely on final image generation or patch-based process simulation, lacking explicit stroke structure and failing to produce smooth, realistic shading. In this work, we present a differentiable stroke reconstruction framework that unifies painting, stylized texturing, and smudging to faithfully reproduce the human painting-smudging loop. Given an input image, our framework first optimizes single- and dual-color Bezier strokes through a parallel differentiable paint renderer, followed by a style generation module that synthesizes geometry-conditioned textures across diverse painting styles. We further introduce a differentiable smudge operator to enable natural color blending and shading. Coupled with a coarse-to-fine optimization strategy, our method jointly optimizes stroke geometry, color, and texture under geometric and semantic guidance. Extensive experiments on oil, watercolor, ink, and digital paintings demonstrate that our approach produces realistic and expressive stroke reconstructions, smooth tonal transitions, and richly stylized appearances, offering a unified model for expressive digital painting creation. See our project page for more demos: https://yingjiang96.github.io/DiffPaintWebsite/.",
    "published": "2025-11-17T09:55:53Z",
    "updated": "2025-11-17T09:55:53Z",
    "link": "http://arxiv.org/pdf/2511.13191v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ying Jiang",
      "Jiayin Lu",
      "Yunuo Chen",
      "Yumeng He",
      "Kui Wu",
      "Yin Yang",
      "Chenfanfu Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13190v1",
    "title": "Video Spatial Reasoning with Object-Centric 3D Rollout",
    "summary": "Recent advances in Multi-modal Large Language Models (MLLMs) have showcased remarkable capabilities in vision-language understanding. However, enabling robust video spatial reasoning-the ability to comprehend object locations, orientations, and inter-object relationships in dynamic 3D scenes-remains a key unsolved challenge. Existing approaches primarily rely on spatially grounded supervised fine-tuning or reinforcement learning, yet we observe that such models often exhibit query-locked reasoning, focusing narrowly on objects explicitly mentioned in the prompt while ignoring critical contextual cues. To address this limitation, we propose Object-Centric 3D Rollout (OCR), a novel strategy that introduces structured perturbations to the 3D geometry of selected objects during training. By degrading object-specific visual cues and projecting the altered geometry into 2D space, OCR compels the model to reason holistically across the entire scene. We further design a rollout-based training pipeline that jointly leverages vanilla and region-noisy videos to optimize spatial reasoning trajectories. Experiments demonstrate state-of-the-art performance: our 3B-parameter model achieves 47.5% accuracy on VSI-Bench, outperforming several 7B baselines. Ablations confirm OCR's superiority over prior rollout strategies (e.g., T-GRPO, NoisyRollout).",
    "published": "2025-11-17T09:53:41Z",
    "updated": "2025-11-17T09:53:41Z",
    "link": "http://arxiv.org/pdf/2511.13190v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Haoran Tang",
      "Meng Cao",
      "Ruyang Liu",
      "Xiaoxi Liang",
      "Linglong Li",
      "Ge Li",
      "Xiaodan Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13189v1",
    "title": "Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework",
    "summary": "Foundation models have revolutionized artificial intelligence across numerous domains, yet their transformative potential remains largely untapped in Extreme Multi-label Classification (XMC). Queries in XMC are associated with relevant labels from extremely large label spaces, where it is critical to strike a balance between efficiency and performance. Therefore, many recent approaches efficiently pose XMC as a maximum inner product search between embeddings learned from small encoder-only transformer architectures. In this paper, we address two important aspects in XMC: how to effectively harness larger decoder-only models, and how to exploit visual information while maintaining computational efficiency. We demonstrate that both play a critical role in XMC separately and can be combined for improved performance. We show that a few billion-size decoder can deliver substantial improvements while keeping computational overhead manageable. Furthermore, our Vision-enhanced eXtreme Multi-label Learning framework (ViXML) efficiently integrates foundation vision models by pooling a single embedding per image. This limits computational growth while unlocking multi-modal capabilities. Remarkably, ViXML with small encoders outperforms text-only decoder in most cases, showing that an image is worth billions of parameters. Finally, we present an extension of existing text-only datasets to exploit visual metadata and make them available for future benchmarking. Comprehensive experiments across four public text-only datasets and their corresponding image enhanced versions validate our proposals' effectiveness, surpassing previous state-of-the-art by up to +8.21\\% in P@1 on the largest dataset. ViXML's code is available at https://github.com/DiegoOrtego/vixml.",
    "published": "2025-11-17T09:52:53Z",
    "updated": "2025-11-17T09:52:53Z",
    "link": "http://arxiv.org/pdf/2511.13189v1.pdf",
    "category": [
      "cs.CV",
      "cs.IR"
    ],
    "authors": [
      "Diego Ortego",
      "Marlon Rodríguez",
      "Mario Almagro",
      "Kunal Dahiya",
      "David Jiménez",
      "Juan C. SanMiguel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11777v2",
    "title": "Self-NPO: Data-Free Diffusion Model Enhancement via Truncated Diffusion Fine-Tuning",
    "summary": "Diffusion models have demonstrated remarkable success in various visual generation tasks, including image, video, and 3D content generation. Preference optimization (PO) is a prominent and growing area of research that aims to align these models with human preferences. While existing PO methods primarily concentrate on producing favorable outputs, they often overlook the significance of classifier-free guidance (CFG) in mitigating undesirable results. Diffusion-NPO addresses this gap by introducing negative preference optimization (NPO), training models to generate outputs opposite to human preferences and thereby steering them away from unfavorable outcomes through CFG. However, prior NPO approaches rely on costly and fragile procedures for obtaining explicit preference annotations (e.g., manual pairwise labeling or reward model training), limiting their practicality in domains where such data are scarce or difficult to acquire. In this work, we propose Self-NPO, specifically truncated diffusion fine-tuning, a data-free approach of negative preference optimization by directly learning from the model itself, eliminating the need for manual data labeling or reward model training. This data-free approach is highly efficient (less than 1% training cost of Diffusion-NPO) and achieves comparable performance to Diffusion-NPO in a data-free manner. We demonstrate that Self-NPO integrates seamlessly into widely used diffusion models, including SD1.5, SDXL, and CogVideoX, as well as models already optimized for human preferences, consistently enhancing both their generation quality and alignment with human preferences. Code is available at https://github.com/G-U-N/Diffusion-NPO.",
    "published": "2025-05-17T01:03:46Z",
    "updated": "2025-11-17T09:50:27Z",
    "link": "http://arxiv.org/pdf/2505.11777v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Fu-Yun Wang",
      "Keqiang Sun",
      "Yao Teng",
      "Xihui Liu",
      "Jiale Yuan",
      "Jiaming Song",
      "Hongsheng Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13183v1",
    "title": "GenTract: Generative Global Tractography",
    "summary": "Tractography is the process of inferring the trajectories of white-matter pathways in the brain from diffusion magnetic resonance imaging (dMRI). Local tractography methods, which construct streamlines by following local fiber orientation estimates stepwise through an image, are prone to error accumulation and high false positive rates, particularly on noisy or low-resolution data. In contrast, global methods, which attempt to optimize a collection of streamlines to maximize compatibility with underlying fiber orientation estimates, are computationally expensive. To address these challenges, we introduce GenTract, the first generative model for global tractography. We frame tractography as a generative task, learning a direct mapping from dMRI to complete, anatomically plausible streamlines. We compare both diffusion-based and flow matching paradigms and evaluate GenTract's performance against state-of-the-art baselines. Notably, GenTract achieves precision 2.1x higher than the next-best method, TractOracle. This advantage becomes even more pronounced in challenging low-resolution and noisy settings, where it outperforms the closest competitor by an order of magnitude. By producing tractograms with high precision on research-grade data while also maintaining reliability on imperfect, lower-resolution data, GenTract represents a promising solution for global tractography.",
    "published": "2025-11-17T09:43:57Z",
    "updated": "2025-11-17T09:43:57Z",
    "link": "http://arxiv.org/pdf/2511.13183v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Alec Sargood",
      "Lemuel Puglisi",
      "Elinor Thompson",
      "Mirco Musolesi",
      "Daniel C. Alexander"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.02549v2",
    "title": "MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming",
    "summary": "Vision-Language Navigation (VLN) tasks often leverage panoramic RGB and depth inputs to provide rich spatial cues for action planning, but these sensors can be costly or less accessible in real-world deployments. Recent approaches based on Vision-Language Action (VLA) models achieve strong results with monocular input, yet they still lag behind methods using panoramic RGB-D information. We present MonoDream, a lightweight VLA framework that enables monocular agents to learn a Unified Navigation Representation (UNR). This shared feature representation jointly aligns navigation-relevant visual semantics (e.g., global layout, depth, and future cues) and language-grounded action intent, enabling more reliable action prediction. MonoDream further introduces Latent Panoramic Dreaming (LPD) tasks to supervise the UNR, which train the model to predict latent features of panoramic RGB and depth observations at both current and future steps based on only monocular input. Experiments on multiple VLN benchmarks show that MonoDream consistently improves monocular navigation performance and significantly narrows the gap with panoramic-based agents.",
    "published": "2025-08-04T16:01:30Z",
    "updated": "2025-11-17T09:32:41Z",
    "link": "http://arxiv.org/pdf/2508.02549v2.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Shuo Wang",
      "Yongcai Wang",
      "Zhaoxin Fan",
      "Yucheng Wang",
      "Maiyue Chen",
      "Kaihui Wang",
      "Zhizhong Su",
      "Wanting Li",
      "Xudong Cai",
      "Yeying Jin",
      "Deying Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.04743v2",
    "title": "SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs",
    "summary": "Visual language models (VLMs) have made significant progress in image captioning tasks, yet recent studies have found they are vulnerable to backdoor attacks. Attackers can inject undetectable perturbations into the data during inference, triggering abnormal behavior and generating malicious captions. These attacks are particularly challenging to detect and defend against due to the stealthiness and cross-modal propagation of the trigger signals. In this paper, we identify two key vulnerabilities by analyzing existing attack patterns: (1) the model exhibits abnormal attention concentration on certain regions of the input image, and (2) backdoor attacks often induce semantic drift and sentence incoherence. Based on these insights, we propose Semantic Reward Defense (SRD), a reinforcement learning framework that mitigates backdoor behavior without requiring any prior knowledge of trigger patterns. SRD learns to apply discrete perturbations to sensitive contextual regions of image inputs via a deep Q-network policy, aiming to confuse attention and disrupt the activation of malicious paths. To guide policy optimization, we design a reward signal named semantic fidelity score, which jointly assesses the semantic consistency and linguistic fluency of the generated captions, encouraging the agent to achieve a robust yet faithful output. SRD offers a trigger-agnostic, policy-interpretable defense paradigm that effectively mitigates local (TrojVLM) and global (Shadowcast) backdoor attacks, reducing ASR to 3.6% and 5.6% respectively, with less than 15% average CIDEr drop on the clean inputs. Our codes can be found at https://github.com/Ciconey/SRD.git.",
    "published": "2025-06-05T08:22:24Z",
    "updated": "2025-11-17T09:29:52Z",
    "link": "http://arxiv.org/pdf/2506.04743v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shuhan Xu",
      "Siyuan Liang",
      "Hongling Zheng",
      "Aishan Liu",
      "Xinbiao Wang",
      "Yong Luo",
      "Fu Lin",
      "Leszek Rutkowski",
      "Dacheng Tao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13175v1",
    "title": "HDW-SR: High-Frequency Guided Diffusion Model based on Wavelet Decomposition for Image Super-Resolution",
    "summary": "Diffusion-based methods have shown great promise in single image super-resolution (SISR); however, existing approaches often produce blurred fine details due to insufficient guidance in the high-frequency domain. To address this issue, we propose a High-Frequency Guided Diffusion Network based on Wavelet Decomposition (HDW-SR), which replaces the conventional U-Net backbone in diffusion frameworks. Specifically, we perform diffusion only on the residual map, allowing the network to focus more effectively on high-frequency information restoration. We then introduce wavelet-based downsampling in place of standard CNN downsampling to achieve multi-scale frequency decomposition, enabling sparse cross-attention between the high-frequency subbands of the pre-super-resolved image and the low-frequency subbands of the diffused image for explicit high-frequency guidance. Moreover, a Dynamic Thresholding Block (DTB) is designed to refine high-frequency selection during the sparse attention process. During upsampling, the invertibility of the wavelet transform ensures low-loss feature reconstruction. Experiments on both synthetic and real-world datasets demonstrate that HDW-SR achieves competitive super-resolution performance, excelling particularly in recovering fine-grained image details. The code will be available after acceptance.",
    "published": "2025-11-17T09:25:26Z",
    "updated": "2025-11-17T09:25:26Z",
    "link": "http://arxiv.org/pdf/2511.13175v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chao Yang",
      "Boqian Zhang",
      "Jinghao Xu",
      "Guang Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13170v1",
    "title": "THIR: Topological Histopathological Image Retrieval",
    "summary": "According to the World Health Organization, breast cancer claimed the lives of approximately 685,000 women in 2020. Early diagnosis and accurate clinical decision making are critical in reducing this global burden. In this study, we propose THIR, a novel Content-Based Medical Image Retrieval (CBMIR) framework that leverages topological data analysis specifically, Betti numbers derived from persistent homology to characterize and retrieve histopathological images based on their intrinsic structural patterns. Unlike conventional deep learning approaches that rely on extensive training, annotated datasets, and powerful GPU resources, THIR operates entirely without supervision. It extracts topological fingerprints directly from RGB histopathological images using cubical persistence, encoding the evolution of loops as compact, interpretable feature vectors. The similarity retrieval is then performed by computing the distances between these topological descriptors, efficiently returning the top-K most relevant matches.\n  Extensive experiments on the BreaKHis dataset demonstrate that THIR outperforms state of the art supervised and unsupervised methods. It processes the entire dataset in under 20 minutes on a standard CPU, offering a fast, scalable, and training free solution for clinical image retrieval.",
    "published": "2025-11-17T09:18:54Z",
    "updated": "2025-11-17T09:18:54Z",
    "link": "http://arxiv.org/pdf/2511.13170v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zahra Tabatabaei",
      "Jon Sporring"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13150v1",
    "title": "Skeletons Speak Louder than Text: A Motion-Aware Pretraining Paradigm for Video-Based Person Re-Identification",
    "summary": "Multimodal pretraining has revolutionized visual understanding, but its impact on video-based person re-identification (ReID) remains underexplored. Existing approaches often rely on video-text pairs, yet suffer from two fundamental limitations: (1) lack of genuine multimodal pretraining, and (2) text poorly captures fine-grained temporal motion-an essential cue for distinguishing identities in video. In this work, we take a bold departure from text-based paradigms by introducing the first skeleton-driven pretraining framework for ReID. To achieve this, we propose Contrastive Skeleton-Image Pretraining for ReID (CSIP-ReID), a novel two-stage method that leverages skeleton sequences as a spatiotemporally informative modality aligned with video frames. In the first stage, we employ contrastive learning to align skeleton and visual features at sequence level. In the second stage, we introduce a dynamic Prototype Fusion Updater (PFU) to refine multimodal identity prototypes, fusing motion and appearance cues. Moreover, we propose a Skeleton Guided Temporal Modeling (SGTM) module that distills temporal cues from skeleton data and integrates them into visual features. Extensive experiments demonstrate that CSIP-ReID achieves new state-of-the-art results on standard video ReID benchmarks (MARS, LS-VID, iLIDS-VID). Moreover, it exhibits strong generalization to skeleton-only ReID tasks (BIWI, IAS), significantly outperforming previous methods. CSIP-ReID pioneers an annotation-free and motion-aware pretraining paradigm for ReID, opening a new frontier in multimodal representation learning.",
    "published": "2025-11-17T08:59:41Z",
    "updated": "2025-11-17T08:59:41Z",
    "link": "http://arxiv.org/pdf/2511.13150v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Rifen Lin",
      "Alex Jinpeng Wang",
      "Jiawei Mo",
      "Min Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13138v1",
    "title": "WinMamba: Multi-Scale Shifted Windows in State Space Model for 3D Object Detection",
    "summary": "3D object detection is critical for autonomous driving, yet it remains fundamentally challenging to simultaneously maximize computational efficiency and capture long-range spatial dependencies. We observed that Mamba-based models, with their linear state-space design, capture long-range dependencies at lower cost, offering a promising balance between efficiency and accuracy. However, existing methods rely on axis-aligned scanning within a fixed window, inevitably discarding spatial information. To address this problem, we propose WinMamba, a novel Mamba-based 3D feature-encoding backbone composed of stacked WinMamba blocks. To enhance the backbone with robust multi-scale representation, the WinMamba block incorporates a window-scale-adaptive module that compensates voxel features across varying resolutions during sampling. Meanwhile, to obtain rich contextual cues within the linear state space, we equip the WinMamba layer with a learnable positional encoding and a window-shift strategy. Extensive experiments on the KITTI and Waymo datasets demonstrate that WinMamba significantly outperforms the baseline. Ablation studies further validate the individual contributions of the WSF and AWF modules in improving detection accuracy. The code will be made publicly available.",
    "published": "2025-11-17T08:46:54Z",
    "updated": "2025-11-17T08:46:54Z",
    "link": "http://arxiv.org/pdf/2511.13138v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Longhui Zheng",
      "Qiming Xia",
      "Xiaolu Chen",
      "Zhaoliang Liu",
      "Chenglu Wen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.04116v3",
    "title": "Segmentation and Smoothing Affect Explanation Quality More Than the Choice of Perturbation-based XAI Method for Image Explanations",
    "summary": "Perturbation-based post-hoc image explanation methods are commonly used to explain image prediction models. These methods perturb parts of the input to measure how those parts affect the output. Since the methods only require the input and output, they can be applied to any model, making them a popular choice to explain black-box models. While many different methods exist and have been compared with one another, it remains poorly understood which parameters of the different methods are responsible for their varying performance.\n  This work uses the Randomized Input Sampling for Explanations (RISE) method as a baseline to evaluate many combinations of mask sampling, segmentation techniques, smoothing, attribution calculation, and per-segment or per-pixel attribution, using a proxy metric. The results show that attribution calculation, which is frequently the focus of other works, has little impact on the results. Conversely, segmentation and per-pixel attribution, rarely examined parameters, have a significant impact.\n  The implementation of and data gathered in this work are available online: https://github.com/guspih/post-hoc-image-perturbation and https://bit.ly/smooth-mask-perturbation.",
    "published": "2024-09-06T08:33:26Z",
    "updated": "2025-11-17T08:46:03Z",
    "link": "http://arxiv.org/pdf/2409.04116v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Gustav Grund Pihlgren",
      "Kary Främling"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13135v1",
    "title": "MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation",
    "summary": "As Vision-Language Models (VLMs) increasingly gain traction in medical applications, clinicians are progressively expecting AI systems not only to generate textual diagnoses but also to produce corresponding medical images that integrate seamlessly into authentic clinical workflows. Despite the growing interest, existing medical visual benchmarks present notable limitations. They often rely on ambiguous queries that lack sufficient relevance to image content, oversimplify complex diagnostic reasoning into closed-ended shortcuts, and adopt a text-centric evaluation paradigm that overlooks the importance of image generation capabilities. To address these challenges, we introduce \\textsc{MedGEN-Bench}, a comprehensive multimodal benchmark designed to advance medical AI research. MedGEN-Bench comprises 6,422 expert-validated image-text pairs spanning six imaging modalities, 16 clinical tasks, and 28 subtasks. It is structured into three distinct formats: Visual Question Answering, Image Editing, and Contextual Multimodal Generation. What sets MedGEN-Bench apart is its focus on contextually intertwined instructions that necessitate sophisticated cross-modal reasoning and open-ended generative outputs, moving beyond the constraints of multiple-choice formats. To evaluate the performance of existing systems, we employ a novel three-tier assessment framework that integrates pixel-level metrics, semantic text analysis, and expert-guided clinical relevance scoring. Using this framework, we systematically assess 10 compositional frameworks, 3 unified models, and 5 VLMs.",
    "published": "2025-11-17T08:41:56Z",
    "updated": "2025-11-17T08:41:56Z",
    "link": "http://arxiv.org/pdf/2511.13135v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junjie Yang",
      "Yuhao Yan",
      "Gang Wu",
      "Yuxuan Wang",
      "Ruoyu Liang",
      "Xinjie Jiang",
      "Xiang Wan",
      "Fenglei Fan",
      "Yongquan Zhang",
      "Feiwei Qin",
      "Changmiao Wan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.14681v2",
    "title": "Virtual Multiplex Staining for Histological Images using a Marker-wise Conditioned Diffusion Model",
    "summary": "Multiplex imaging is revolutionizing pathology by enabling the simultaneous visualization of multiple biomarkers within tissue samples, providing molecular-level insights that traditional hematoxylin and eosin (H&E) staining cannot provide. However, the complexity and cost of multiplex data acquisition have hindered its widespread adoption. Additionally, most existing large repositories of H&E images lack corresponding multiplex images, limiting opportunities for multimodal analysis. To address these challenges, we leverage recent advances in latent diffusion models (LDMs), which excel at modeling complex data distributions by utilizing their powerful priors for fine-tuning to a target domain. In this paper, we introduce a novel framework for virtual multiplex staining that utilizes pretrained LDM parameters to generate multiplex images from H&E images using a conditional diffusion model. Our approach enables marker-by-marker generation by conditioning the diffusion model on each marker, while sharing the same architecture across all markers. To tackle the challenge of varying pixel value distributions across different marker stains and to improve inference speed, we fine-tune the model for single-step sampling, enhancing both color contrast fidelity and inference efficiency through pixel-level loss functions. We validate our framework on two publicly available datasets, notably demonstrating its effectiveness in generating up to 18 different marker types with improved accuracy, a substantial increase over the 2-3 marker types achieved in previous approaches. This validation highlights the potential of our framework, pioneering virtual multiplex staining. Finally, this paper bridges the gap between H&E and multiplex imaging, potentially enabling retrospective studies and large-scale analyses of existing H&E image repositories.",
    "published": "2025-08-20T12:54:58Z",
    "updated": "2025-11-17T08:38:58Z",
    "link": "http://arxiv.org/pdf/2508.14681v2.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Hyun-Jic Oh",
      "Junsik Kim",
      "Zhiyi Shi",
      "Yichen Wu",
      "Yu-An Chen",
      "Peter K. Sorger",
      "Hanspeter Pfister",
      "Won-Ki Jeong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13127v1",
    "title": "VEIL: Jailbreaking Text-to-Video Models via Visual Exploitation from Implicit Language",
    "summary": "Jailbreak attacks can circumvent model safety guardrails and reveal critical blind spots. Prior attacks on text-to-video (T2V) models typically add adversarial perturbations to obviously unsafe prompts, which are often easy to detect and defend. In contrast, we show that benign-looking prompts containing rich, implicit cues can induce T2V models to generate semantically unsafe videos that both violate policy and preserve the original (blocked) intent. To realize this, we propose VEIL, a jailbreak framework that leverages T2V models' cross-modal associative patterns via a modular prompt design. Specifically, our prompts combine three components: neutral scene anchors, which provide the surface-level scene description extracted from the blocked intent to maintain plausibility; latent auditory triggers, textual descriptions of innocuous-sounding audio events (e.g., creaking, muffled noises) that exploit learned audio-visual co-occurrence priors to bias the model toward particular unsafe visual concepts; and stylistic modulators, cinematic directives (e.g., camera framing, atmosphere) that amplify and stabilize the latent trigger's effect. We formalize attack generation as a constrained optimization over the above modular prompt space and solve it with a guided search procedure that balances stealth and effectiveness. Extensive experiments over 7 T2V models demonstrate the efficacy of our attack, achieving a 23 percent improvement in average attack success rate in commercial models.",
    "published": "2025-11-17T08:31:43Z",
    "updated": "2025-11-17T08:31:43Z",
    "link": "http://arxiv.org/pdf/2511.13127v1.pdf",
    "category": [
      "cs.CV",
      "cs.CR"
    ],
    "authors": [
      "Zonghao Ying",
      "Moyang Chen",
      "Nizhang Li",
      "Zhiqiang Wang",
      "Wenxin Zhang",
      "Quanchen Zou",
      "Zonglei Jing",
      "Aishan Liu",
      "Xianglong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13125v1",
    "title": "Region-Point Joint Representation for Effective Trajectory Similarity Learning",
    "summary": "Recent learning-based methods have reduced the computational complexity of traditional trajectory similarity computation, but state-of-the-art (SOTA) methods still fail to leverage the comprehensive spectrum of trajectory information for similarity modeling. To tackle this problem, we propose \\textbf{RePo}, a novel method that jointly encodes \\textbf{Re}gion-wise and \\textbf{Po}int-wise features to capture both spatial context and fine-grained moving patterns. For region-wise representation, the GPS trajectories are first mapped to grid sequences, and spatial context are captured by structural features and semantic context enriched by visual features. For point-wise representation, three lightweight expert networks extract local, correlation, and continuous movement patterns from dense GPS sequences. Then, a router network adaptively fuses the learned point-wise features, which are subsequently combined with region-wise features using cross-attention to produce the final trajectory embedding. To train RePo, we adopt a contrastive loss with hard negative samples to provide similarity ranking supervision. Experiment results show that RePo achieves an average accuracy improvement of 22.2\\% over SOTA baselines across all evaluation metrics.",
    "published": "2025-11-17T08:28:18Z",
    "updated": "2025-11-17T08:28:18Z",
    "link": "http://arxiv.org/pdf/2511.13125v1.pdf",
    "category": [
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "authors": [
      "Hao Long",
      "Silin Zhou",
      "Lisi Chen",
      "Shuo Shang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13121v1",
    "title": "CloseUpShot: Close-up Novel View Synthesis from Sparse-views via Point-conditioned Diffusion Model",
    "summary": "Reconstructing 3D scenes and synthesizing novel views from sparse input views is a highly challenging task. Recent advances in video diffusion models have demonstrated strong temporal reasoning capabilities, making them a promising tool for enhancing reconstruction quality under sparse-view settings. However, existing approaches are primarily designed for modest viewpoint variations, which struggle in capturing fine-grained details in close-up scenarios since input information is severely limited. In this paper, we present a diffusion-based framework, called CloseUpShot, for close-up novel view synthesis from sparse inputs via point-conditioned video diffusion. Specifically, we observe that pixel-warping conditioning suffers from severe sparsity and background leakage in close-up settings. To address this, we propose hierarchical warping and occlusion-aware noise suppression, enhancing the quality and completeness of the conditioning images for the video diffusion model. Furthermore, we introduce global structure guidance, which leverages a dense fused point cloud to provide consistent geometric context to the diffusion process, to compensate for the lack of globally consistent 3D constraints in sparse conditioning inputs. Extensive experiments on multiple datasets demonstrate that our method outperforms existing approaches, especially in close-up novel view synthesis, clearly validating the effectiveness of our design.",
    "published": "2025-11-17T08:20:06Z",
    "updated": "2025-11-17T08:20:06Z",
    "link": "http://arxiv.org/pdf/2511.13121v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuqi Zhang",
      "Guanying Chen",
      "Jiaxing Chen",
      "Chuanyu Fu",
      "Chuan Huang",
      "Shuguang Cui"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13115v1",
    "title": "A Lightweight 3D Anomaly Detection Method with Rotationally Invariant Features",
    "summary": "3D anomaly detection (AD) is a crucial task in computer vision, aiming to identify anomalous points or regions from point cloud data. However, existing methods may encounter challenges when handling point clouds with changes in orientation and position because the resulting features may vary significantly. To address this problem, we propose a novel Rotationally Invariant Features (RIF) framework for 3D AD. Firstly, to remove the adverse effect of variations on point cloud data, we develop a Point Coordinate Mapping (PCM) technique, which maps each point into a rotationally invariant space to maintain consistency of representation. Then, to learn robust and discriminative features, we design a lightweight Convolutional Transform Feature Network (CTF-Net) to extract rotationally invariant features for the memory bank. To improve the ability of the feature extractor, we introduce the idea of transfer learning to pre-train the feature extractor with 3D data augmentation. Experimental results show that the proposed method achieves the advanced performance on the Anomaly-ShapeNet dataset, with an average P-AUROC improvement of 17.7\\%, and also gains the best performance on the Real3D-AD dataset, with an average P-AUROC improvement of 1.6\\%. The strong generalization ability of RIF has been verified by combining it with traditional feature extraction methods on anomaly detection tasks, demonstrating great potential for industrial applications.",
    "published": "2025-11-17T08:16:05Z",
    "updated": "2025-11-17T08:16:05Z",
    "link": "http://arxiv.org/pdf/2511.13115v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hanzhe Liang",
      "Jie Zhou",
      "Can Gao",
      "Bingyang Guo",
      "Jinbao Wang",
      "Linlin Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13113v1",
    "title": "Semantics and Content Matter: Towards Multi-Prior Hierarchical Mamba for Image Deraining",
    "summary": "Rain significantly degrades the performance of computer vision systems, particularly in applications like autonomous driving and video surveillance. While existing deraining methods have made considerable progress, they often struggle with fidelity of semantic and spatial details. To address these limitations, we propose the Multi-Prior Hierarchical Mamba (MPHM) network for image deraining. This novel architecture synergistically integrates macro-semantic textual priors (CLIP) for task-level semantic guidance and micro-structural visual priors (DINOv2) for scene-aware structural information. To alleviate potential conflicts between heterogeneous priors, we devise a progressive Priors Fusion Injection (PFI) that strategically injects complementary cues at different decoder levels. Meanwhile, we equip the backbone network with an elaborate Hierarchical Mamba Module (HMM) to facilitate robust feature representation, featuring a Fourier-enhanced dual-path design that concurrently addresses global context modeling and local detail recovery. Comprehensive experiments demonstrate MPHM's state-of-the-art performance, achieving a 0.57 dB PSNR gain on the Rain200H dataset while delivering superior generalization on real-world rainy scenarios.",
    "published": "2025-11-17T08:08:59Z",
    "updated": "2025-11-17T08:08:59Z",
    "link": "http://arxiv.org/pdf/2511.13113v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhaocheng Yu",
      "Kui Jiang",
      "Junjun Jiang",
      "Xianming Liu",
      "Guanglu Sun",
      "Yi Xiao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13110v1",
    "title": "Learning Implicit Neural Degradation Representation for Unpaired Image Dehazing",
    "summary": "Image dehazing is an important task in the field of computer vision, aiming at restoring clear and detail-rich visual content from haze-affected images. However, when dealing with complex scenes, existing methods often struggle to strike a balance between fine-grained feature representation of inhomogeneous haze distribution and global consistency modeling. Furthermore, to better learn the common degenerate representation of haze in spatial variations, we propose an unsupervised dehaze method for implicit neural degradation representation. Firstly, inspired by the Kolmogorov-Arnold representation theorem, we propose a mechanism combining the channel-independent and channel-dependent mechanisms, which efficiently enhances the ability to learn from nonlinear dependencies. which in turn achieves good visual perception in complex scenes. Moreover, we design an implicit neural representation to model haze degradation as a continuous function to eliminate redundant information and the dependence on explicit feature extraction and physical models. To further learn the implicit representation of the haze features, we also designed a dense residual enhancement module from it to eliminate redundant information. This achieves high-quality image restoration. Experimental results show that our method achieves competitive dehaze performance on various public and real-world datasets. This project code will be available at https://github.com/Fan-pixel/NeDR-Dehaze.",
    "published": "2025-11-17T08:07:48Z",
    "updated": "2025-11-17T08:07:48Z",
    "link": "http://arxiv.org/pdf/2511.13110v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shuaibin Fan",
      "Senming Zhong",
      "Wenchao Yan",
      "Minglong Xue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13108v1",
    "title": "DGS-Net: Distillation-Guided Gradient Surgery for CLIP Fine-Tuning in AI-Generated Image Detection",
    "summary": "The rapid progress of generative models such as GANs and diffusion models has led to the widespread proliferation of AI-generated images, raising concerns about misinformation, privacy violations, and trust erosion in digital media. Although large-scale multimodal models like CLIP offer strong transferable representations for detecting synthetic content, fine-tuning them often induces catastrophic forgetting, which degrades pre-trained priors and limits cross-domain generalization. To address this issue, we propose the Distillation-guided Gradient Surgery Network (DGS-Net), a novel framework that preserves transferable pre-trained priors while suppressing task-irrelevant components. Specifically, we introduce a gradient-space decomposition that separates harmful and beneficial descent directions during optimization. By projecting task gradients onto the orthogonal complement of harmful directions and aligning with beneficial ones distilled from a frozen CLIP encoder, DGS-Net achieves unified optimization of prior preservation and irrelevant suppression. Extensive experiments on 50 generative models demonstrate that our method outperforms state-of-the-art approaches by an average margin of 6.6, achieving superior detection performance and generalization across diverse generation techniques.",
    "published": "2025-11-17T08:05:31Z",
    "updated": "2025-11-17T08:05:31Z",
    "link": "http://arxiv.org/pdf/2511.13108v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiazhen Yan",
      "Ziqiang Li",
      "Fan Wang",
      "Boyu Wang",
      "Zhangjie Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13106v1",
    "title": "Low-Level Dataset Distillation for Medical Image Enhancement",
    "summary": "Medical image enhancement is clinically valuable, but existing methods require large-scale datasets to learn complex pixel-level mappings. However, the substantial training and storage costs associated with these datasets hinder their practical deployment. While dataset distillation (DD) can alleviate these burdens, existing methods mainly target high-level tasks, where multiple samples share the same label. This many-to-one mapping allows distilled data to capture shared semantics and achieve information compression. In contrast, low-level tasks involve a many-to-many mapping that requires pixel-level fidelity, making low-level DD an underdetermined problem, as a small distilled dataset cannot fully constrain the dense pixel-level mappings. To address this, we propose the first low-level DD method for medical image enhancement. We first leverage anatomical similarities across patients to construct the shared anatomical prior based on a representative patient, which serves as the initialization for the distilled data of different patients. This prior is then personalized for each patient using a Structure-Preserving Personalized Generation (SPG) module, which integrates patient-specific anatomical information into the distilled dataset while preserving pixel-level fidelity. For different low-level tasks, the distilled data is used to construct task-specific high- and low-quality training pairs. Patient-specific knowledge is injected into the distilled data by aligning the gradients computed from networks trained on the distilled pairs with those from the corresponding patient's raw data. Notably, downstream users cannot access raw patient data. Instead, only a distilled dataset containing abstract training information is shared, which excludes patient-specific details and thus preserves privacy.",
    "published": "2025-11-17T08:05:07Z",
    "updated": "2025-11-17T08:05:07Z",
    "link": "http://arxiv.org/pdf/2511.13106v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Fengzhi Xu",
      "Ziyuan Yang",
      "Mengyu Sun",
      "Joey Tianyi Zhou",
      "Yi Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13105v1",
    "title": "PlugTrack: Multi-Perceptive Motion Analysis for Adaptive Fusion in Multi-Object Tracking",
    "summary": "Multi-object tracking (MOT) predominantly follows the tracking-by-detection paradigm, where Kalman filters serve as the standard motion predictor due to computational efficiency but inherently fail on non-linear motion patterns. Conversely, recent data-driven motion predictors capture complex non-linear dynamics but suffer from limited domain generalization and computational overhead. Through extensive analysis, we reveal that even in datasets dominated by non-linear motion, Kalman filter outperforms data-driven predictors in up to 34\\% of cases, demonstrating that real-world tracking scenarios inherently involve both linear and non-linear patterns. To leverage this complementarity, we propose PlugTrack, a novel framework that adaptively fuses Kalman filter and data-driven motion predictors through multi-perceptive motion understanding. Our approach employs multi-perceptive motion analysis to generate adaptive blending factors. PlugTrack achieves significant performance gains on MOT17/MOT20 and state-of-the-art on DanceTrack without modifying existing motion predictors. To the best of our knowledge, PlugTrack is the first framework to bridge classical and modern motion prediction paradigms through adaptive fusion in MOT.",
    "published": "2025-11-17T08:03:11Z",
    "updated": "2025-11-17T08:03:11Z",
    "link": "http://arxiv.org/pdf/2511.13105v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Seungjae Kim",
      "SeungJoon Lee",
      "MyeongAh Cho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.17347v2",
    "title": "Dereflection Any Image with Diffusion Priors and Diversified Data",
    "summary": "Reflection removal of a single image remains a highly challenging task due to the complex entanglement between target scenes and unwanted reflections. Despite significant progress, existing methods are hindered by the scarcity of high-quality, diverse data and insufficient restoration priors, resulting in limited generalization across various real-world scenarios. In this paper, we propose Dereflection Any Image, a comprehensive solution with an efficient data preparation pipeline and a generalizable model for robust reflection removal. First, we introduce a dataset named Diverse Reflection Removal (DRR) created by randomly rotating reflective mediums in target scenes, enabling variation of reflection angles and intensities, and setting a new benchmark in scale, quality, and diversity. Second, we propose a diffusion-based framework with one-step diffusion for deterministic outputs and fast inference. To ensure stable learning, we design a three-stage progressive training strategy, including reflection-invariant finetuning to encourage consistent outputs across varying reflection patterns that characterize our dataset. Extensive experiments show that our method achieves SOTA performance on both common benchmarks and challenging in-the-wild images, showing superior generalization across diverse real-world scenes.",
    "published": "2025-03-21T17:48:14Z",
    "updated": "2025-11-17T07:58:51Z",
    "link": "http://arxiv.org/pdf/2503.17347v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jichen Hu",
      "Chen Yang",
      "Zanwei Zhou",
      "Jiemin Fang",
      "Xiaokang Yang",
      "Qi Tian",
      "Wei Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13102v1",
    "title": "CapeNext: Rethinking and refining dynamic support information for category-agnostic pose estimation",
    "summary": "Recent research in Category-Agnostic Pose Estimation (CAPE) has adopted fixed textual keypoint description as semantic prior for two-stage pose matching frameworks. While this paradigm enhances robustness and flexibility by disentangling the dependency of support images, our critical analysis reveals two inherent limitations of static joint embedding: (1) polysemy-induced cross-category ambiguity during the matching process(e.g., the concept \"leg\" exhibiting divergent visual manifestations across humans and furniture), and (2) insufficient discriminability for fine-grained intra-category variations (e.g., posture and fur discrepancies between a sleeping white cat and a standing black cat). To overcome these challenges, we propose a new framework that innovatively integrates hierarchical cross-modal interaction with dual-stream feature refinement, enhancing the joint embedding with both class-level and instance-specific cues from textual description and specific images. Experiments on the MP-100 dataset demonstrate that, regardless of the network backbone, CapeNext consistently outperforms state-of-the-art CAPE methods by a large margin.",
    "published": "2025-11-17T07:56:01Z",
    "updated": "2025-11-17T07:56:01Z",
    "link": "http://arxiv.org/pdf/2511.13102v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yu Zhu",
      "Dan Zeng",
      "Shuiwang Li",
      "Qijun Zhao",
      "Qiaomu Shen",
      "Bo Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13099v1",
    "title": "MergeSlide: Continual Model Merging and Task-to-Class Prompt-Aligned Inference for Lifelong Learning on Whole Slide Images",
    "summary": "Lifelong learning on Whole Slide Images (WSIs) aims to train or fine-tune a unified model sequentially on cancer-related tasks, reducing the resources and effort required for data transfer and processing, especially given the gigabyte-scale size of WSIs. In this paper, we introduce MergeSlide, a simple yet effective framework that treats lifelong learning as a model merging problem by leveraging a vision-language pathology foundation model. When a new task arrives, it is: 1) defined with class-aware prompts, 2) fine-tuned for a few epochs using an MLP-free backbone, and 3) merged into a unified model using an orthogonal continual merging strategy that preserves performance and mitigates catastrophic forgetting. For inference under the class-incremental learning (CLASS-IL) setting, where task identity is unknown, we introduce Task-to-Class Prompt-aligned (TCP) inference. Specifically, TCP first identifies the most relevant task using task-level prompts and then applies the corresponding class-aware prompts to generate predictions. To evaluate MergeSlide, we conduct experiments on a stream of six TCGA datasets. The results show that MergeSlide outperforms both rehearsal-based continual learning and vision-language zero-shot baselines. Code and data are available at https://github.com/caodoanh2001/MergeSlide.",
    "published": "2025-11-17T07:51:18Z",
    "updated": "2025-11-17T07:51:18Z",
    "link": "http://arxiv.org/pdf/2511.13099v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Doanh C. Bui",
      "Ba Hung Ngo",
      "Hoai Luan Pham",
      "Khang Nguyen",
      "Maï K. Nguyen",
      "Yasuhiko Nakashima"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2403.10931v3",
    "title": "Towards Collective Intelligence: Uncertainty-aware SAM Adaptation for Ambiguous Medical Image Segmentation",
    "summary": "Collective intelligence from multiple medical experts consistently surpasses individual expertise in clinical diagnosis, particularly for ambiguous medical image segmentation tasks involving unclear tissue boundaries or pathological variations. The Segment Anything Model (SAM), a powerful vision foundation model originally designed for natural image segmentation, has shown remarkable potential when adapted to medical image segmentation tasks. However, existing SAM adaptation methods follow a single-expert paradigm, developing models based on individual expert annotations to predict deterministic masks. These methods systematically ignore the inherent uncertainty and variability in expert annotations, which fundamentally contradicts clinical practice, where multiple specialists provide different yet equally valid interpretations that collectively enhance diagnostic confidence. We propose an Uncertainty-aware Adapter, the first SAM adaptation framework designed to transition from single expert mindset to collective intelligence representation. Our approach integrates stochastic uncertainty sampling from a Conditional Variational Autoencoder into the adapters, enabling diverse prediction generation that captures expert knowledge distributions rather than individual expert annotations. We employ a novel position-conditioned control mechanism to integrate multi-expert knowledge, ensuring that the output distribution closely aligns with the multi-annotation distribution. Comprehensive evaluations across seven medical segmentation benchmarks have demonstrated that our collective intelligence-based adaptation achieves superior performance while maintaining computational efficiency, establishing a new adaptation framework for reliable clinical implementation.",
    "published": "2024-03-16T14:11:54Z",
    "updated": "2025-11-17T07:49:39Z",
    "link": "http://arxiv.org/pdf/2403.10931v3.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Mingzhou Jiang",
      "Jiaying Zhou",
      "Junde Wu",
      "Tianyang Wang",
      "Yueming Jin",
      "Min Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13082v1",
    "title": "Real-time prediction of breast cancer sites using deformation-aware graph neural network",
    "summary": "Early diagnosis of breast cancer is crucial, enabling the establishment of appropriate treatment plans and markedly enhancing patient prognosis. While direct magnetic resonance imaging-guided biopsy demonstrates promising performance in detecting cancer lesions, its practical application is limited by prolonged procedure times and high costs. To overcome these issues, an indirect MRI-guided biopsy that allows the procedure to be performed outside of the MRI room has been proposed, but it still faces challenges in creating an accurate real-time deformable breast model. In our study, we tackled this issue by developing a graph neural network (GNN)-based model capable of accurately predicting deformed breast cancer sites in real time during biopsy procedures. An individual-specific finite element (FE) model was developed by incorporating magnetic resonance (MR) image-derived structural information of the breast and tumor to simulate deformation behaviors. A GNN model was then employed, designed to process surface displacement and distance-based graph data, enabling accurate prediction of overall tissue displacement, including the deformation of the tumor region. The model was validated using phantom and real patient datasets, achieving an accuracy within 0.2 millimeters (mm) for cancer node displacement (RMSE) and a dice similarity coefficient (DSC) of 0.977 for spatial overlap with actual cancerous regions. Additionally, the model enabled real-time inference and achieved a speed-up of over 4,000 times in computational cost compared to conventional FE simulations. The proposed deformation-aware GNN model offers a promising solution for real-time tumor displacement prediction in breast biopsy, with high accuracy and real-time capability. Its integration with clinical procedures could significantly enhance the precision and efficiency of breast cancer diagnosis.",
    "published": "2025-11-17T07:32:28Z",
    "updated": "2025-11-17T07:32:28Z",
    "link": "http://arxiv.org/pdf/2511.13082v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Kyunghyun Lee",
      "Yong-Min Shin",
      "Minwoo Shin",
      "Jihun Kim",
      "Sunghwan Lim",
      "Won-Yong Shin",
      "Kyungho Yoon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13079v1",
    "title": "Decoupling Scene Perception and Ego Status: A Multi-Context Fusion Approach for Enhanced Generalization in End-to-End Autonomous Driving",
    "summary": "Modular design of planning-oriented autonomous driving has markedly advanced end-to-end systems. However, existing architectures remain constrained by an over-reliance on ego status, hindering generalization and robust scene understanding. We identify the root cause as an inherent design within these architectures that allows ego status to be easily leveraged as a shortcut. Specifically, the premature fusion of ego status in the upstream BEV encoder allows an information flow from this strong prior to dominate the downstream planning module. To address this challenge, we propose AdaptiveAD, an architectural-level solution based on a multi-context fusion strategy. Its core is a dual-branch structure that explicitly decouples scene perception and ego status. One branch performs scene-driven reasoning based on multi-task learning, but with ego status deliberately omitted from the BEV encoder, while the other conducts ego-driven reasoning based solely on the planning task. A scene-aware fusion module then adaptively integrates the complementary decisions from the two branches to form the final planning trajectory. To ensure this decoupling does not compromise multi-task learning, we introduce a path attention mechanism for ego-BEV interaction and add two targeted auxiliary tasks: BEV unidirectional distillation and autoregressive online mapping. Extensive evaluations on the nuScenes dataset demonstrate that AdaptiveAD achieves state-of-the-art open-loop planning performance. Crucially, it significantly mitigates the over-reliance on ego status and exhibits impressive generalization capabilities across diverse scenarios.",
    "published": "2025-11-17T07:27:55Z",
    "updated": "2025-11-17T07:27:55Z",
    "link": "http://arxiv.org/pdf/2511.13079v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiacheng Tang",
      "Mingyue Feng",
      "Jiachao Liu",
      "Yaonong Wang",
      "Jian Pu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.06266v3",
    "title": "Spatially-Aware Mixture of Experts with Log-Logistic Survival Modeling for Whole-Slide Images",
    "summary": "Accurate survival prediction from histopathology whole-slide images (WSIs) remains challenging due to their gigapixel resolution, strong spatial heterogeneity, and complex survival distributions. We introduce a comprehensive computational pathology framework that addresses these limitations through four complementary innovations: (1) Quantile-Gated Patch Selection for dynamically identifying prognostically relevant regions, (2) Graph-Guided Clustering to group patches by spatial and morphological similarity, (3) Hierarchical Context Attention to model both local tissue interactions and global slide-level context, and (4) an Expert-Driven Mixture of Log-Logistics module that flexibly models complex survival distributions. Across large TCGA cohorts, our method achieves state-of-the-art performance, yielding time-dependent concordance indices of 0.644 on LUAD, 0.751 on KIRC, and 0.752 on BRCA, consistently outperforming both histology-only and multimodal baselines. The framework further provides improved calibration and interpretability, advancing the use of WSIs for personalized cancer prognosis.",
    "published": "2025-11-09T08:02:15Z",
    "updated": "2025-11-17T07:13:24Z",
    "link": "http://arxiv.org/pdf/2511.06266v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ardhendu Sekhar",
      "Vasu Soni",
      "Keshav Aske",
      "Shivam Madnoorkar",
      "Pranav Jeevan",
      "Amit Sethi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13065v1",
    "title": "RobustGait: Robustness Analysis for Appearance Based Gait Recognition",
    "summary": "Appearance-based gait recognition have achieved strong performance on controlled datasets, yet systematic evaluation of its robustness to real-world corruptions and silhouette variability remains lacking. We present RobustGait, a framework for fine-grained robustness evaluation of appearance-based gait recognition systems. RobustGait evaluation spans four dimensions: the type of perturbation (digital, environmental, temporal, occlusion), the silhouette extraction method (segmentation and parsing networks), the architectural capacities of gait recognition models, and various deployment scenarios. The benchmark introduces 15 corruption types at 5 severity levels across CASIA-B, CCPG, and SUSTech1K, with in-the-wild validation on MEVID, and evaluates six state-of-the-art gait systems. We came across several exciting insights. First, applying noise at the RGB level better reflects real-world degradation, and reveal how distortions propagate through silhouette extraction to the downstream gait recognition systems. Second, gait accuracy is highly sensitive to silhouette extractor biases, revealing an overlooked source of benchmark bias. Third, robustness is dependent on both the type of perturbation and the architectural design. Finally, we explore robustness-enhancing strategies, showing that noise-aware training and knowledge distillation improve performance and move toward deployment-ready systems.",
    "published": "2025-11-17T07:12:06Z",
    "updated": "2025-11-17T07:12:06Z",
    "link": "http://arxiv.org/pdf/2511.13065v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Reeshoon Sayera",
      "Akash Kumar",
      "Sirshapan Mitra",
      "Prudvi Kamtam",
      "Yogesh S Rawat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13063v1",
    "title": "FGNet: Leveraging Feature-Guided Attention to Refine SAM2 for 3D EM Neuron Segmentation",
    "summary": "Accurate segmentation of neural structures in Electron Microscopy (EM) images is paramount for neuroscience. However, this task is challenged by intricate morphologies, low signal-to-noise ratios, and scarce annotations, limiting the accuracy and generalization of existing methods. To address these challenges, we seek to leverage the priors learned by visual foundation models on a vast amount of natural images to better tackle this task. Specifically, we propose a novel framework that can effectively transfer knowledge from Segment Anything 2 (SAM2), which is pre-trained on natural images, to the EM domain. We first use SAM2 to extract powerful, general-purpose features. To bridge the domain gap, we introduce a Feature-Guided Attention module that leverages semantic cues from SAM2 to guide a lightweight encoder, the Fine-Grained Encoder (FGE), in focusing on these challenging regions. Finally, a dual-affinity decoder generates both coarse and refined affinity maps. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art (SOTA) approaches with the SAM2 weights frozen. Upon further fine-tuning on EM data, our method significantly outperforms existing SOTA methods. This study validates that transferring representations pre-trained on natural images, when combined with targeted domain-adaptive guidance, can effectively address the specific challenges in neuron segmentation.",
    "published": "2025-11-17T07:11:07Z",
    "updated": "2025-11-17T07:11:07Z",
    "link": "http://arxiv.org/pdf/2511.13063v1.pdf",
    "category": [
      "cs.CV",
      "cs.IR"
    ],
    "authors": [
      "Zhenghua Li",
      "Hang Chen",
      "Zihao Sun",
      "Kai Li",
      "Xiaolin Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13055v1",
    "title": "Monocular 3D Lane Detection via Structure Uncertainty-Aware Network with Curve-Point Queries",
    "summary": "Monocular 3D lane detection is challenged by aleatoric uncertainty arising from inherent observation noise. Existing methods rely on simplified geometric assumptions, such as independent point predictions or global planar modeling, failing to capture structural variations and aleatoric uncertainty in real-world scenarios. In this paper, we propose MonoUnc, a bird's-eye view (BEV)-free 3D lane detector that explicitly models aleatoric uncertainty informed by local lane structures. Specifically, 3D lanes are projected onto the front-view (FV) space and approximated by parametric curves. Guided by curve predictions, curve-point query embeddings are dynamically generated for lane point predictions in 3D space. Each segment formed by two adjacent points is modeled as a 3D Gaussian, parameterized by the local structure and uncertainty estimations. Accordingly, a novel 3D Gaussian matching loss is designed to constrain these parameters jointly. Experiments on the ONCE-3DLanes and OpenLane datasets demonstrate that MonoUnc outperforms previous state-of-the-art (SoTA) methods across all benchmarks under stricter evaluation criteria. Additionally, we propose two comprehensive evaluation metrics for ONCE-3DLanes, calculating the average and maximum bidirectional Chamfer distances to quantify global and local errors. Codes are released at https://github.com/lrx02/MonoUnc.",
    "published": "2025-11-17T07:01:10Z",
    "updated": "2025-11-17T07:01:10Z",
    "link": "http://arxiv.org/pdf/2511.13055v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ruixin Liu",
      "Zejian Yuan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13054v1",
    "title": "ViSS-R1: Self-Supervised Reinforcement Video Reasoning",
    "summary": "Complex video reasoning remains a significant challenge for Multimodal Large Language Models (MLLMs), as current R1-based methodologies often prioritize text-centric reasoning derived from text-based and image-based developments. In video tasks, such strategies frequently underutilize rich visual information, leading to potential shortcut learning and increased susceptibility to hallucination. To foster a more robust, visual-centric video understanding, we start by introducing a novel self-supervised reinforcement learning GRPO algorithm (Pretext-GRPO) within the standard R1 pipeline, in which positive rewards are assigned for correctly solving pretext tasks on transformed visual inputs, which makes the model to non-trivially process the visual information. Building on the effectiveness of Pretext-GRPO, we further propose the ViSS-R1 framework, which streamlines and integrates pretext-task-based self-supervised learning directly into the MLLM's R1 post-training paradigm. Instead of relying solely on sparse visual cues, our framework compels models to reason about transformed visual input by simultaneously processing both pretext questions (concerning transformations) and true user queries. This necessitates identifying the applied transformation and reconstructing the original video to formulate accurate final answers. Comprehensive evaluations on six widely-used video reasoning and understanding benchmarks demonstrate the effectiveness and superiority of our Pretext-GRPO and ViSS-R1 for complex video reasoning. Our codes and models will be publicly available.",
    "published": "2025-11-17T07:00:42Z",
    "updated": "2025-11-17T07:00:42Z",
    "link": "http://arxiv.org/pdf/2511.13054v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bo Fang",
      "Yuxin Song",
      "Qiangqiang Wu",
      "Haoyuan Sun",
      "Wenhao Wu",
      "Antoni B. Chan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13047v1",
    "title": "DiffPixelFormer: Differential Pixel-Aware Transformer for RGB-D Indoor Scene Segmentation",
    "summary": "Indoor semantic segmentation is fundamental to computer vision and robotics, supporting applications such as autonomous navigation, augmented reality, and smart environments. Although RGB-D fusion leverages complementary appearance and geometric cues, existing methods often depend on computationally intensive cross-attention mechanisms and insufficiently model intra- and inter-modal feature relationships, resulting in imprecise feature alignment and limited discriminative representation. To address these challenges, we propose DiffPixelFormer, a differential pixel-aware Transformer for RGB-D indoor scene segmentation that simultaneously enhances intra-modal representations and models inter-modal interactions. At its core, the Intra-Inter Modal Interaction Block (IIMIB) captures intra-modal long-range dependencies via self-attention and models inter-modal interactions with the Differential-Shared Inter-Modal (DSIM) module to disentangle modality-specific and shared cues, enabling fine-grained, pixel-level cross-modal alignment. Furthermore, a dynamic fusion strategy balances modality contributions and fully exploits RGB-D information according to scene characteristics. Extensive experiments on the SUN RGB-D and NYUDv2 benchmarks demonstrate that DiffPixelFormer-L achieves mIoU scores of 54.28% and 59.95%, outperforming DFormer-L by 1.78% and 2.75%, respectively. Code is available at https://github.com/gongyan1/DiffPixelFormer.",
    "published": "2025-11-17T06:51:07Z",
    "updated": "2025-11-17T06:51:07Z",
    "link": "http://arxiv.org/pdf/2511.13047v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Yan Gong",
      "Jianli Lu",
      "Yongsheng Gao",
      "Jie Zhao",
      "Xiaojuan Zhang",
      "Susanto Rahardja"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.21761v3",
    "title": "IMC-Net: A Lightweight Content-Conditioned Encoder with Multi-Pass Processing for Image Classification",
    "summary": "We present a compact encoder for image categorization that emphasizes computation economy through content-conditioned multi-pass processing. The model employs a single lightweight core block that can be re-applied a small number of times, while a simple score-based selector decides whether further passes are beneficial for each region unit in the feature map. This design provides input-conditioned depth without introducing heavy auxiliary modules or specialized pretraining. On standard benchmarks, the approach attains competitive accuracy with reduced parameters, lower floating-point operations, and faster inference compared to similarly sized baselines. The method keeps the architecture minimal, implements module reuse to control footprint, and preserves stable training via mild regularization on selection scores. We discuss implementation choices for efficient masking, pass control, and representation caching, and show that the multi-pass strategy transfers well to several datasets without requiring task-specific customization.",
    "published": "2025-07-29T12:46:36Z",
    "updated": "2025-11-17T06:40:18Z",
    "link": "http://arxiv.org/pdf/2507.21761v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "YiZhou Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13039v1",
    "title": "MGCA-Net: Multi-Grained Category-Aware Network for Open-Vocabulary Temporal Action Localization",
    "summary": "Open-Vocabulary Temporal Action Localization (OV-TAL) aims to recognize and localize instances of any desired action categories in videos without explicitly curating training data for all categories. Existing methods mostly recognize action categories at a single granularity, which degrades the recognition accuracy of both base and novel action categories. To address these issues, we propose a Multi-Grained Category-Aware Network (MGCA-Net) comprising a localizer, an action presence predictor, a conventional classifier, and a coarse-to-fine classifier. Specifically, the localizer localizes category-agnostic action proposals. For these action proposals, the action presence predictor estimates the probability that they belong to an action instance. At the same time, the conventional classifier predicts the probability of each action proposal over base action categories at the snippet granularity. Novel action categories are recognized by the coarse-to-fine classifier, which first identifies action presence at the video granularity. Finally, it assigns each action proposal to one category from the coarse categories at the proposal granularity. Through coarse-to-fine category awareness for novel actions and the conventional classifier's awareness of base actions, multi-grained category awareness is achieved, effectively enhancing localization performance. Comprehensive evaluations on the THUMOS'14 and ActivityNet-1.3 benchmarks demonstrate that our method achieves state-of-the-art performance. Furthermore, our MGCA-Net achieves state-of-the-art results under the Zero-Shot Temporal Action Localization setting.",
    "published": "2025-11-17T06:40:02Z",
    "updated": "2025-11-17T06:40:02Z",
    "link": "http://arxiv.org/pdf/2511.13039v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhenying Fang",
      "Richang Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13036v1",
    "title": "uCLIP: Parameter-Efficient Multilingual Extension of Vision-Language Models with Unpaired Data",
    "summary": "Contrastive Language-Image Pre-training (CLIP) has demonstrated strong generalization across a wide range of visual tasks by leveraging large-scale English-image pairs. However, its extension to low-resource languages remains limited due to the scarcity of high-quality multilingual image-text data. Existing multilingual vision-language models exhibit consistently low retrieval performance in underrepresented languages including Czech, Finnish, Croatian, Hungarian, and Romanian on the Crossmodal-3600 (XM3600) benchmark. To address this, we propose a lightweight and data-efficient framework for multilingual vision-language alignment. Our approach requires no image-text pairs or text-text pairs and freezes both the pretrained image encoder and multilingual text encoder during training. Only a compact 1.7M-parameter projection module is trained, using a contrastive loss over English representations as semantic anchors. This minimal training setup enables robust multilingual alignment even for languages with limited supervision. Extensive evaluation across multiple multilingual retrieval benchmarks confirms the effectiveness of our method, showing significant gains in five underrepresented languages where existing models typically underperform. These findings highlight the effectiveness of our pivot-based, parameter-efficient alignment strategy for inclusive multimodal learning.",
    "published": "2025-11-17T06:34:49Z",
    "updated": "2025-11-17T06:34:49Z",
    "link": "http://arxiv.org/pdf/2511.13036v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dahyun Chung",
      "Donghyun Shin",
      "Yujin Sung",
      "Seunggi Moon",
      "Jinwoo Jeon",
      "Byung-Jun Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.21385v3",
    "title": "Physics-Guided Image Dehazing Diffusion",
    "summary": "Due to the domain gap between real-world and synthetic hazy images, current data-driven dehazing algorithms trained on synthetic datasets perform well on synthetic data but struggle to generalize to real-world scenarios. To address this challenge, we propose \\textbf{I}mage \\textbf{D}ehazing \\textbf{D}iffusion \\textbf{M}odels (IDDM), a novel diffusion process that incorporates the atmospheric scattering model into noise diffusion. IDDM aims to use the gradual haze formation process to help the denoising Unet robustly learn the distribution of clear images from the conditional input hazy images. We design a specialized training strategy centered around IDDM. Diffusion models are leveraged to bridge the domain gap from synthetic to real-world, while the atmospheric scattering model provides physical guidance for haze formation. During the forward process, IDDM simultaneously introduces haze and noise into clear images, and then robustly separates them during the sampling process. By training with physics-guided information, IDDM shows the ability of domain generalization, and effectively restores the real-world hazy images despite being trained on synthetic datasets. Extensive experiments demonstrate the effectiveness of our method through both quantitative and qualitative comparisons with state-of-the-art approaches.",
    "published": "2025-04-30T07:36:10Z",
    "updated": "2025-11-17T06:33:51Z",
    "link": "http://arxiv.org/pdf/2504.21385v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shijun Zhou",
      "Xing Xie",
      "Baojie Fan",
      "Jiandong Tian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13032v1",
    "title": "Uni-Inter: Unifying 3D Human Motion Synthesis Across Diverse Interaction Contexts",
    "summary": "We present Uni-Inter, a unified framework for human motion generation that supports a wide range of interaction scenarios: including human-human, human-object, and human-scene-within a single, task-agnostic architecture. In contrast to existing methods that rely on task-specific designs and exhibit limited generalization, Uni-Inter introduces the Unified Interactive Volume (UIV), a volumetric representation that encodes heterogeneous interactive entities into a shared spatial field. This enables consistent relational reasoning and compound interaction modeling. Motion generation is formulated as joint-wise probabilistic prediction over the UIV, allowing the model to capture fine-grained spatial dependencies and produce coherent, context-aware behaviors. Experiments across three representative interaction tasks demonstrate that Uni-Inter achieves competitive performance and generalizes well to novel combinations of entities. These results suggest that unified modeling of compound interactions offers a promising direction for scalable motion synthesis in complex environments.",
    "published": "2025-11-17T06:32:38Z",
    "updated": "2025-11-17T06:32:38Z",
    "link": "http://arxiv.org/pdf/2511.13032v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sheng Liu",
      "Yuanzhi Liang",
      "Jiepeng Wang",
      "Sidan Du",
      "Chi Zhang",
      "Xuelong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13031v1",
    "title": "Towards 3D Object-Centric Feature Learning for Semantic Scene Completion",
    "summary": "Vision-based 3D Semantic Scene Completion (SSC) has received growing attention due to its potential in autonomous driving. While most existing approaches follow an ego-centric paradigm by aggregating and diffusing features over the entire scene, they often overlook fine-grained object-level details, leading to semantic and geometric ambiguities, especially in complex environments. To address this limitation, we propose Ocean, an object-centric prediction framework that decomposes the scene into individual object instances to enable more accurate semantic occupancy prediction. Specifically, we first employ a lightweight segmentation model, MobileSAM, to extract instance masks from the input image. Then, we introduce a 3D Semantic Group Attention module that leverages linear attention to aggregate object-centric features in 3D space. To handle segmentation errors and missing instances, we further design a Global Similarity-Guided Attention module that leverages segmentation features for global interaction. Finally, we propose an Instance-aware Local Diffusion module that improves instance features through a generative process and subsequently refines the scene representation in the BEV space. Extensive experiments on the SemanticKITTI and SSCBench-KITTI360 benchmarks demonstrate that Ocean achieves state-of-the-art performance, with mIoU scores of 17.40 and 20.28, respectively.",
    "published": "2025-11-17T06:28:26Z",
    "updated": "2025-11-17T06:28:26Z",
    "link": "http://arxiv.org/pdf/2511.13031v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Weihua Wang",
      "Yubo Cui",
      "Xiangru Lin",
      "Zhiheng Li",
      "Zheng Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13026v1",
    "title": "REVISOR: Beyond Textual Reflection, Towards Multimodal Introspective Reasoning in Long-Form Video Understanding",
    "summary": "Self-reflection mechanisms that rely on purely text-based rethinking processes perform well in most multimodal tasks. However, when directly applied to long-form video understanding scenarios, they exhibit clear limitations. The fundamental reasons for this lie in two points: (1)long-form video understanding involves richer and more dynamic visual input, meaning rethinking only the text information is insufficient and necessitates a further rethinking process specifically targeting visual information; (2) purely text-based reflection mechanisms lack cross-modal interaction capabilities, preventing them from fully integrating visual information during reflection. Motivated by these insights, we propose REVISOR (REflective VIsual Segment Oriented Reasoning), a novel framework for tool-augmented multimodal reflection. REVISOR enables MLLMs to collaboratively construct introspective reflection processes across textual and visual modalities, significantly enhancing their reasoning capability for long-form video understanding. To ensure that REVISOR can learn to accurately review video segments highly relevant to the question during reinforcement learning, we designed the Dual Attribution Decoupled Reward (DADR) mechanism. Integrated into the GRPO training strategy, this mechanism enforces causal alignment between the model's reasoning and the selected video evidence. Notably, the REVISOR framework significantly enhances long-form video understanding capability of MLLMs without requiring supplementary supervised fine-tuning or external models, achieving impressive results on four benchmarks including VideoMME, LongVideoBench, MLVU, and LVBench.",
    "published": "2025-11-17T06:25:12Z",
    "updated": "2025-11-17T06:25:12Z",
    "link": "http://arxiv.org/pdf/2511.13026v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiaze Li",
      "Hao Yin",
      "Wenhui Tan",
      "Jingyang Chen",
      "Boshen Xu",
      "Yuxun Qu",
      "Yijing Chen",
      "Jianzhong Ju",
      "Zhenbo Luo",
      "Jian Luan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.11638v3",
    "title": "Safeguarding AI in Medical Imaging: Post-Hoc Out-of-Distribution Detection with Normalizing Flows",
    "summary": "In AI-driven medical imaging, the failure to detect out-of-distribution (OOD) data poses a severe risk to clinical reliability, potentially leading to critical diagnostic errors. Current OOD detection methods often demand impractical retraining or modifications to pre-trained models, hindering their adoption in regulated clinical environments. To address this challenge, we propose a post-hoc normalizing flow-based approach that seamlessly integrates with existing pre-trained models without altering their weights. We evaluate the approach on our in-house-curated MedOOD dataset, designed to capture clinically relevant distribution shifts, and on the MedMNIST benchmark. The proposed method achieves an AUROC of 84.61% on MedOOD, outperforming ViM (80.65%) and MDS (80.87%), and reaches 93.8% AUROC on MedMNIST, surpassing ViM (88.08%) and ReAct (87.05%). This combination of strong performance and post-hoc integration capability makes our approach a practical and effective safeguard for clinical imaging workflows. The model and code to build OOD datasets are publicly accessible at https://github.com/dlotfi/MedOODFlow.",
    "published": "2025-02-17T10:31:24Z",
    "updated": "2025-11-17T06:21:52Z",
    "link": "http://arxiv.org/pdf/2502.11638v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dariush Lotfi",
      "Mohammad-Ali Nikouei Mahani",
      "Mohamad Koohi-Moghadam",
      "Kyongtae Ty Bae"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11822v2",
    "title": "Robust Drone-View Geo-Localization via Content-Viewpoint Disentanglement",
    "summary": "Drone-view geo-localization (DVGL) aims to match images of the same geographic location captured from drone and satellite perspectives. Despite recent advances, DVGL remains challenging due to significant appearance changes and spatial distortions caused by viewpoint variations. Existing methods typically assume that drone and satellite images can be directly aligned in a shared feature space via contrastive learning. Nonetheless, this assumption overlooks the inherent conflicts induced by viewpoint discrepancies, resulting in extracted features containing inconsistent information that hinders precise localization. In this study, we take a manifold learning perspective and model $\\textit{the feature space of cross-view images as a composite manifold jointly governed by content and viewpoint}$. Building upon this insight, we propose $\\textbf{CVD}$, a new DVGL framework that explicitly disentangles $\\textit{content}$ and $\\textit{viewpoint}$ factors. To promote effective disentanglement, we introduce two constraints: $\\textit{(i)}$ an intra-view independence constraint that encourages statistical independence between the two factors by minimizing their mutual information; and $\\textit{(ii)}$ an inter-view reconstruction constraint that reconstructs each view by cross-combining $\\textit{content}$ and $\\textit{viewpoint}$ from paired images, ensuring factor-specific semantics are preserved. As a plug-and-play module, CVD integrates seamlessly into existing DVGL pipelines and reduces inference latency. Extensive experiments on University-1652 and SUES-200 show that CVD exhibits strong robustness and generalization across various scenarios, viewpoints and altitudes, with further evaluations on CVUSA and CVACT confirming consistent improvements.",
    "published": "2025-05-17T04:10:32Z",
    "updated": "2025-11-17T06:21:11Z",
    "link": "http://arxiv.org/pdf/2505.11822v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ke Li",
      "Di Wang",
      "Xiaowei Wang",
      "Zhihong Wu",
      "Yiming Zhang",
      "Yifeng Wang",
      "Quan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13015v1",
    "title": "Geometry Meets Light: Leveraging Geometric Priors for Universal Photometric Stereo under Limited Multi-Illumination Cues",
    "summary": "Universal Photometric Stereo is a promising approach for recovering surface normals without strict lighting assumptions. However, it struggles when multi-illumination cues are unreliable, such as under biased lighting or in shadows or self-occluded regions of complex in-the-wild scenes. We propose GeoUniPS, a universal photometric stereo network that integrates synthetic supervision with high-level geometric priors from large-scale 3D reconstruction models pretrained on massive in-the-wild data. Our key insight is that these 3D reconstruction models serve as visual-geometry foundation models, inherently encoding rich geometric knowledge of real scenes. To leverage this, we design a Light-Geometry Dual-Branch Encoder that extracts both multi-illumination cues and geometric priors from the frozen 3D reconstruction model. We also address the limitations of the conventional orthographic projection assumption by introducing the PS-Perp dataset with realistic perspective projection to enable learning of spatially varying view directions. Extensive experiments demonstrate that GeoUniPS delivers state-of-the-arts performance across multiple datasets, both quantitatively and qualitatively, especially in the complex in-the-wild scenes.",
    "published": "2025-11-17T06:14:38Z",
    "updated": "2025-11-17T06:14:38Z",
    "link": "http://arxiv.org/pdf/2511.13015v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "King-Man Tam",
      "Satoshi Ikehata",
      "Yuta Asano",
      "Zhaoyi An",
      "Rei Kawakami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13013v1",
    "title": "You Only Look Omni Gradient Backpropagation for Moving Infrared Small Target Detection",
    "summary": "Moving infrared small target detection is a key component of infrared search and tracking systems, yet it remains extremely challenging due to low signal-to-clutter ratios, severe target-background imbalance, and weak discriminative features. Existing deep learning methods primarily focus on spatio-temporal feature aggregation, but their gains are limited, revealing that the fundamental bottleneck lies in ambiguous per-frame feature representations rather than spatio-temporal modeling itself. Motivated by this insight, we propose BP-FPN, a backpropagation-driven feature pyramid architecture that fundamentally rethinks feature learning for small target. BP-FPN introduces Gradient-Isolated Low-Level Shortcut (GILS) to efficiently incorporate fine-grained target details without inducing shortcut learning, and Directional Gradient Regularization (DGR) to enforce hierarchical feature consistency during backpropagation. The design is theoretically grounded, introduces negligible computational overhead, and can be seamlessly integrated into existing frameworks. Extensive experiments on multiple public datasets show that BP-FPN consistently establishes new state-of-the-art performance. To the best of our knowledge, it is the first FPN designed for this task entirely from the backpropagation perspective.",
    "published": "2025-11-17T06:13:41Z",
    "updated": "2025-11-17T06:13:41Z",
    "link": "http://arxiv.org/pdf/2511.13013v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Guoyi Zhang",
      "Guangsheng Xu",
      "Siyang Chen",
      "Han Wang",
      "Xiaohu Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13011v1",
    "title": "Beyond Darkness: Thermal-Supervised 3D Gaussian Splatting for Low-Light Novel View Synthesis",
    "summary": "Under extremely low-light conditions, novel view synthesis (NVS) faces severe degradation in terms of geometry, color consistency, and radiometric stability. Standard 3D Gaussian Splatting (3DGS) pipelines fail when applied directly to underexposed inputs, as independent enhancement across views causes illumination inconsistencies and geometric distortion. To address this, we present DTGS, a unified framework that tightly couples Retinex-inspired illumination decomposition with thermal-guided 3D Gaussian Splatting for illumination-invariant reconstruction. Unlike prior approaches that treat enhancement as a pre-processing step, DTGS performs joint optimization across enhancement, geometry, and thermal supervision through a cyclic enhancement-reconstruction mechanism. A thermal supervisory branch stabilizes both color restoration and geometry learning by dynamically balancing enhancement, structural, and thermal losses. Moreover, a Retinex-based decomposition module embedded within the 3DGS loop provides physically interpretable reflectance-illumination separation, ensuring consistent color and texture across viewpoints. To evaluate our method, we construct RGBT-LOW, a new multi-view low-light thermal dataset capturing severe illumination degradation. Extensive experiments show that DTGS significantly outperforms existing low-light enhancement and 3D reconstruction baselines, achieving superior radiometric consistency, geometric fidelity, and color stability under extreme illumination.",
    "published": "2025-11-17T06:12:53Z",
    "updated": "2025-11-17T06:12:53Z",
    "link": "http://arxiv.org/pdf/2511.13011v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qingsen Ma",
      "Chen Zou",
      "Dianyun Wang",
      "Jia Wang",
      "Liuyu Xiang",
      "Zhaofeng He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13009v1",
    "title": "TR-Gaussians: High-fidelity Real-time Rendering of Planar Transmission and Reflection with 3D Gaussian Splatting",
    "summary": "We propose Transmission-Reflection Gaussians (TR-Gaussians), a novel 3D-Gaussian-based representation for high-fidelity rendering of planar transmission and reflection, which are ubiquitous in indoor scenes. Our method combines 3D Gaussians with learnable reflection planes that explicitly model the glass planes with view-dependent reflectance strengths. Real scenes and transmission components are modeled by 3D Gaussians and the reflection components are modeled by the mirrored Gaussians with respect to the reflection plane. The transmission and reflection components are blended according to a Fresnel-based, view-dependent weighting scheme, allowing for faithful synthesis of complex appearance effects under varying viewpoints. To effectively optimize TR-Gaussians, we develop a multi-stage optimization framework incorporating color and geometry constraints and an opacity perturbation mechanism. Experiments on different datasets demonstrate that TR-Gaussians achieve real-time, high-fidelity novel view synthesis in scenes with planar transmission and reflection, and outperform state-of-the-art approaches both quantitatively and qualitatively.",
    "published": "2025-11-17T06:09:21Z",
    "updated": "2025-11-17T06:09:21Z",
    "link": "http://arxiv.org/pdf/2511.13009v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Yong Liu",
      "Keyang Ye",
      "Tianjia Shao",
      "Kun Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.12015v2",
    "title": "QDM: Quadtree-Based Region-Adaptive Sparse Diffusion Models for Efficient Image Super-Resolution",
    "summary": "Deep learning-based super-resolution (SR) methods often perform pixel-wise computations uniformly across entire images, even in homogeneous regions where high-resolution refinement is redundant. We propose the Quadtree Diffusion Model (QDM), a region-adaptive diffusion framework that leverages a quadtree structure to selectively enhance detail-rich regions while reducing computations in homogeneous areas. By guiding the diffusion with a quadtree derived from the low-quality input, QDM identifies key regions-represented by leaf nodes-where fine detail is essential and applies minimal refinement elsewhere. This mask-guided, two-stream architecture adaptively balances quality and efficiency, producing high-fidelity outputs with low computational redundancy. Experiments demonstrate QDM's effectiveness in high-resolution SR tasks across diverse image types, particularly in medical imaging (e.g., CT scans), where large homogeneous regions are prevalent. Furthermore, QDM outperforms or is comparable to state-of-the-art SR methods on standard benchmarks while significantly reducing computational costs, highlighting its efficiency and suitability for resource-limited environments. Our code is available at https://github.com/linYDTHU/QDM.",
    "published": "2025-03-15T06:50:30Z",
    "updated": "2025-11-17T06:02:10Z",
    "link": "http://arxiv.org/pdf/2503.12015v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Donglin Yang",
      "Paul Vicol",
      "Xiaojuan Qi",
      "Renjie Liao",
      "Xiaofan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13002v1",
    "title": "Infinite-Story: A Training-Free Consistent Text-to-Image Generation",
    "summary": "We present Infinite-Story, a training-free framework for consistent text-to-image (T2I) generation tailored for multi-prompt storytelling scenarios. Built upon a scale-wise autoregressive model, our method addresses two key challenges in consistent T2I generation: identity inconsistency and style inconsistency. To overcome these issues, we introduce three complementary techniques: Identity Prompt Replacement, which mitigates context bias in text encoders to align identity attributes across prompts; and a unified attention guidance mechanism comprising Adaptive Style Injection and Synchronized Guidance Adaptation, which jointly enforce global style and identity appearance consistency while preserving prompt fidelity. Unlike prior diffusion-based approaches that require fine-tuning or suffer from slow inference, Infinite-Story operates entirely at test time, delivering high identity and style consistency across diverse prompts. Extensive experiments demonstrate that our method achieves state-of-the-art generation performance, while offering over 6X faster inference (1.72 seconds per image) than the existing fastest consistent T2I models, highlighting its effectiveness and practicality for real-world visual storytelling.",
    "published": "2025-11-17T05:46:16Z",
    "updated": "2025-11-17T05:46:16Z",
    "link": "http://arxiv.org/pdf/2511.13002v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jihun Park",
      "Kyoungmin Lee",
      "Jongmin Gim",
      "Hyeonseo Jo",
      "Minseok Oh",
      "Wonhyeok Choi",
      "Kyumin Hwang",
      "Jaeyeul Kim",
      "Minwoo Choi",
      "Sunghoon Im"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13001v1",
    "title": "Medal S: Spatio-Textual Prompt Model for Medical Segmentation",
    "summary": "We introduce Medal S, a medical segmentation foundation model that supports native-resolution spatial and textual prompts within an end-to-end trainable framework. Unlike text-only methods lacking spatial awareness, Medal S achieves channel-wise alignment between volumetric prompts and text embeddings, mitigating inaccuracies from resolution mismatches. By preserving full 3D context, it efficiently processes multiple native-resolution masks in parallel, enhancing multi-class segmentation performance. A lightweight 3D convolutional module enables precise voxel-space refinement guided by both prompt types, supporting up to 243 classes across CT, MRI, PET, ultrasound, and microscopy modalities in the BiomedSegFM dataset. Medal S offers two prompting modes: a text-only mode, where model predictions serve as spatial prompts for self-refinement without human input, and a hybrid mode, incorporating manual annotations for enhanced flexibility. For 24-class segmentation, parallel spatial prompting reduces inference time by more than 90% compared to sequential prompting. We propose dynamic resampling to address target-patch ratio imbalance, extending SAT and nnU-Net for data augmentation. Furthermore, we develop optimized text preprocessing, a two-stage inference strategy, and post-processing techniques to improve memory efficiency, precision, and inference speed. On the five-modality average on the validation set, Medal S outperforms SAT with a DSC of 75.44 (vs. 69.83), NSD of 77.34 (vs. 71.06), F1 of 38.24 (vs. 24.88), and DSC TP of 65.46 (vs. 46.97). Medal S achieves excellent performance by harmonizing spatial precision with semantic textual guidance, demonstrating superior efficiency and accuracy in multi-class medical segmentation tasks compared to sequential prompt-based approaches. Medal S will be publicly available at https://github.com/yinghemedical/Medal-S.",
    "published": "2025-11-17T05:44:19Z",
    "updated": "2025-11-17T05:44:19Z",
    "link": "http://arxiv.org/pdf/2511.13001v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Pengcheng Shi",
      "Jiawei Chen",
      "Jiaqi Liu",
      "Xinglin Zhang",
      "Tao Chen",
      "Lei Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12999v1",
    "title": "Scalable Vision-Guided Crop Yield Estimation",
    "summary": "Precise estimation and uncertainty quantification for average crop yields are critical for agricultural monitoring and decision making. Existing data collection methods, such as crop cuts in randomly sampled fields at harvest time, are relatively time-consuming. Thus, we propose an approach based on prediction-powered inference (PPI) to supplement these crop cuts with less time-consuming field photos. After training a computer vision model to predict the ground truth crop cut yields from the photos, we learn a ``control function\" that recalibrates these predictions with the spatial coordinates of each field. This enables fields with photos but not crop cuts to be leveraged to improve the precision of zone-wide average yield estimates. Our control function is learned by training on a dataset of nearly 20,000 real crop cuts and photos of rice and maize fields in sub-Saharan Africa. To improve precision, we pool training observations across different zones within the same first-level subdivision of each country. Our final PPI-based point estimates of the average yield are provably asymptotically unbiased and cannot increase the asymptotic variance beyond that of the natural baseline estimator -- the sample average of the crop cuts -- as the number of fields grows. We also propose a novel bias-corrected and accelerated (BCa) bootstrap to construct accompanying confidence intervals. Even in zones with as few as 20 fields, the point estimates show significant empirical improvement over the baseline, increasing the effective sample size by as much as 73% for rice and by 12-23% for maize. The confidence intervals are accordingly shorter at minimal cost to empirical finite-sample coverage. This demonstrates the potential for relatively low-cost images to make area-based crop insurance more affordable and thus spur investment into sustainable agricultural practices.",
    "published": "2025-11-17T05:39:21Z",
    "updated": "2025-11-17T05:39:21Z",
    "link": "http://arxiv.org/pdf/2511.12999v1.pdf",
    "category": [
      "stat.AP",
      "cs.CV"
    ],
    "authors": [
      "Harrison H. Li",
      "Medhanie Irgau",
      "Nabil Janmohamed",
      "Karen Solveig Rieckmann",
      "David B. Lobell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12998v1",
    "title": "PerTouch: VLM-Driven Agent for Personalized and Semantic Image Retouching",
    "summary": "Image retouching aims to enhance visual quality while aligning with users' personalized aesthetic preferences. To address the challenge of balancing controllability and subjectivity, we propose a unified diffusion-based image retouching framework called PerTouch. Our method supports semantic-level image retouching while maintaining global aesthetics. Using parameter maps containing attribute values in specific semantic regions as input, PerTouch constructs an explicit parameter-to-image mapping for fine-grained image retouching. To improve semantic boundary perception, we introduce semantic replacement and parameter perturbation mechanisms in the training process. To connect natural language instructions with visual control, we develop a VLM-driven agent that can handle both strong and weak user instructions. Equipped with mechanisms of feedback-driven rethinking and scene-aware memory, PerTouch better aligns with user intent and captures long-term preferences. Extensive experiments demonstrate each component's effectiveness and the superior performance of PerTouch in personalized image retouching. Code is available at: https://github.com/Auroral703/PerTouch.",
    "published": "2025-11-17T05:39:15Z",
    "updated": "2025-11-17T05:39:15Z",
    "link": "http://arxiv.org/pdf/2511.12998v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zewei Chang",
      "Zheng-Peng Duan",
      "Jianxing Zhang",
      "Chun-Le Guo",
      "Siyu Liu",
      "Hyungju Chun",
      "Hyunhee Park",
      "Zikun Liu",
      "Chongyi Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12992v1",
    "title": "Semantic Prioritization in Visual Counterfactual Explanations with Weighted Segmentation and Auto-Adaptive Region Selection",
    "summary": "In the domain of non-generative visual counterfactual explanations (CE), traditional techniques frequently involve the substitution of sections within a query image with corresponding sections from distractor images. Such methods have historically overlooked the semantic relevance of the replacement regions to the target object, thereby impairing the model's interpretability and hindering the editing workflow. Addressing these challenges, the present study introduces an innovative methodology named as Weighted Semantic Map with Auto-adaptive Candidate Editing Network (WSAE-Net). Characterized by two significant advancements: the determination of an weighted semantic map and the auto-adaptive candidate editing sequence. First, the generation of the weighted semantic map is designed to maximize the reduction of non-semantic feature units that need to be computed, thereby optimizing computational efficiency. Second, the auto-adaptive candidate editing sequences are designed to determine the optimal computational order among the feature units to be processed, thereby ensuring the efficient generation of counterfactuals while maintaining the semantic relevance of the replacement feature units to the target object. Through comprehensive experimentation, our methodology demonstrates superior performance, contributing to a more lucid and in-depth understanding of visual counterfactual explanations.",
    "published": "2025-11-17T05:34:10Z",
    "updated": "2025-11-17T05:34:10Z",
    "link": "http://arxiv.org/pdf/2511.12992v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Lintong Zhang",
      "Kang Yin",
      "Seong-Whan Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12985v1",
    "title": "Angular Gradient Sign Method: Uncovering Vulnerabilities in Hyperbolic Networks",
    "summary": "Adversarial examples in neural networks have been extensively studied in Euclidean geometry, but recent advances in \\textit{hyperbolic networks} call for a reevaluation of attack strategies in non-Euclidean geometries. Existing methods such as FGSM and PGD apply perturbations without regard to the underlying hyperbolic structure, potentially leading to inefficient or geometrically inconsistent attacks. In this work, we propose a novel adversarial attack that explicitly leverages the geometric properties of hyperbolic space. Specifically, we compute the gradient of the loss function in the tangent space of hyperbolic space, decompose it into a radial (depth) component and an angular (semantic) component, and apply perturbation derived solely from the angular direction. Our method generates adversarial examples by focusing perturbations in semantically sensitive directions encoded in angular movement within the hyperbolic geometry. Empirical results on image classification, cross-modal retrieval tasks and network architectures demonstrate that our attack achieves higher fooling rates than conventional adversarial attacks, while producing high-impact perturbations with deeper insights into vulnerabilities of hyperbolic embeddings. This work highlights the importance of geometry-aware adversarial strategies in curved representation spaces and provides a principled framework for attacking hierarchical embeddings.",
    "published": "2025-11-17T05:16:07Z",
    "updated": "2025-11-17T05:16:07Z",
    "link": "http://arxiv.org/pdf/2511.12985v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Minsoo Jo",
      "Dongyoon Yang",
      "Taesup Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11436v2",
    "title": "Unsupervised Motion-Compensated Decomposition for Cardiac MRI Reconstruction via Neural Representation",
    "summary": "Cardiac magnetic resonance (CMR) imaging is widely used to characterize cardiac morphology and function. To accelerate CMR imaging, various methods have been proposed to recover high-quality spatiotemporal CMR images from highly undersampled k-t space data. However, current CMR reconstruction techniques either fail to achieve satisfactory image quality or are restricted by the scarcity of ground truth data, leading to limited applicability in clinical scenarios. In this work, we proposed MoCo-INR, a new unsupervised method that integrates implicit neural representations (INR) with the conventional motion-compensated (MoCo) framework. Using explicit motion modeling and the continuous prior of INRs, MoCo-INR can produce accurate cardiac motion decomposition and high-quality CMR reconstruction. Furthermore, we introduce a new INR network architecture tailored to the CMR problem, which significantly stabilizes model optimization. Experiments on retrospective (simulated) datasets demonstrate the superiority of MoCo-INR over state-of-the-art methods, achieving fast convergence and fine-detailed reconstructions at ultra-high acceleration factors (e.g., 20x in VISTA sampling). Additionally, evaluations on prospective (real-acquired) free-breathing CMR scans highlight the clinical practicality of MoCo-INR for real-time imaging. Several ablation studies further confirm the effectiveness of the critical components of MoCo-INR.",
    "published": "2025-11-14T16:05:37Z",
    "updated": "2025-11-17T05:14:44Z",
    "link": "http://arxiv.org/pdf/2511.11436v2.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Xuanyu Tian",
      "Lixuan Chen",
      "Qing Wu",
      "Xiao Wang",
      "Jie Feng",
      "Yuyao Zhang",
      "Hongjiang Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12982v1",
    "title": "SafeGRPO: Self-Rewarded Multimodal Safety Alignment via Rule-Governed Policy Optimization",
    "summary": "Multimodal large language models (MLLMs) have demonstrated impressive reasoning and instruction-following capabilities, yet their expanded modality space introduces new compositional safety risks that emerge from complex text-image interactions. Such cross-modal couplings can produce unsafe semantics even when individual inputs are benign, exposing the fragile safety awareness of current MLLMs. While recent works enhance safety by guiding models to reason about potential risks, unregulated reasoning traces may compromise alignment; although Group Relative Policy Optimization (GRPO) offers self-rewarded refinement without human supervision, it lacks verifiable signals for reasoning safety. To address this, we propose SafeGRPO a self-rewarded multimodal safety alignment framework that integrates rule-governed reward construction into GRPO, enabling interpretable and verifiable optimization of reasoning safety. Built upon the constructed SafeTag-VL-3K dataset with explicit visual, textual, and combined safety tags, SafeGRPO performs step-guided safety thinking to enforce structured reasoning and behavior alignment, substantially improving multimodal safety awareness, compositional robustness, and reasoning stability across diverse benchmarks without sacrificing general capabilities.",
    "published": "2025-11-17T05:09:49Z",
    "updated": "2025-11-17T05:09:49Z",
    "link": "http://arxiv.org/pdf/2511.12982v1.pdf",
    "category": [
      "cs.CR",
      "cs.CV"
    ],
    "authors": [
      "Xuankun Rong",
      "Wenke Huang",
      "Tingfeng Wang",
      "Daiguo Zhou",
      "Bo Du",
      "Mang Ye"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12978v1",
    "title": "Concept Regions Matter: Benchmarking CLIP with a New Cluster-Importance Approach",
    "summary": "Contrastive vision-language models (VLMs) such as CLIP achieve strong zero-shot recognition yet remain vulnerable to spurious correlations, particularly background over-reliance. We introduce Cluster-based Concept Importance (CCI), a novel interpretability method that uses CLIP's own patch embeddings to group spatial patches into semantically coherent clusters, mask them, and evaluate relative changes in model predictions. CCI sets a new state of the art on faithfulness benchmarks, surpassing prior methods by large margins; for example, it yields more than a twofold improvement on the deletion-AUC metric for MS COCO retrieval. We further propose that CCI, when combined with GroundedSAM, automatically categorizes predictions as foreground- or background-driven, providing a crucial diagnostic ability. Existing benchmarks such as CounterAnimals, however, rely solely on accuracy and implicitly attribute all performance degradation to background correlations. Our analysis shows this assumption to be incomplete, since many errors arise from viewpoint variation, scale shifts, and fine-grained object confusions. To disentangle these effects, we introduce COVAR, a benchmark that systematically varies object foregrounds and backgrounds. Leveraging CCI with COVAR, we present a comprehensive evaluation of eighteen CLIP variants, offering methodological advances and empirical evidence that chart a path toward more robust VLMs.",
    "published": "2025-11-17T05:01:24Z",
    "updated": "2025-11-17T05:01:24Z",
    "link": "http://arxiv.org/pdf/2511.12978v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Aishwarya Agarwal",
      "Srikrishna Karanam",
      "Vineet Gandhi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12977v1",
    "title": "ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes",
    "summary": "Building interactive simulators and scalable robot-learning environments requires a large number of articulated assets. However, most existing 3D assets in simulation are rigid, and manually converting them into articulated objects is extremely labor- and cost-intensive. This raises a natural question: can we automatically identify articulable objects in a scene and convert them into articulated assets directly? In this paper, we present ArtiWorld, a scene-aware pipeline that localizes candidate articulable objects from textual scene descriptions and reconstructs executable URDF models that preserve the original geometry. At the core of this pipeline is Arti4URDF, which leverages 3D point cloud, prior knowledge of a large language model (LLM), and a URDF-oriented prompt design to rapidly convert rigid objects into interactive URDF-based articulated objects while maintaining their 3D shape. We evaluate ArtiWorld at three levels: 3D simulated objects, full 3D simulated scenes, and real-world scan scenes. Across all three settings, our method consistently outperforms existing approaches and achieves state-of-the-art performance, while preserving object geometry and correctly capturing object interactivity to produce usable URDF-based articulated models. This provides a practical path toward building interactive, robot-ready simulation environments directly from existing 3D assets. Code and data will be released.",
    "published": "2025-11-17T04:59:21Z",
    "updated": "2025-11-17T04:59:21Z",
    "link": "http://arxiv.org/pdf/2511.12977v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yixuan Yang",
      "Luyang Xie",
      "Zhen Luo",
      "Zixiang Zhao",
      "Mingqi Gao",
      "Feng Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12976v1",
    "title": "MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning",
    "summary": "Most neural network quantization methods apply uniform bit precision across spatial regions, ignoring the heterogeneous structural and textural complexity of visual data. This paper introduces MCAQ-YOLO, a morphological complexity-aware quantization framework for object detection. The framework employs five morphological metrics - fractal dimension, texture entropy, gradient variance, edge density, and contour complexity - to characterize local visual morphology and guide spatially adaptive bit allocation. By correlating these metrics with quantization sensitivity, MCAQ-YOLO dynamically adjusts bit precision according to spatial complexity. In addition, a curriculum-based quantization-aware training scheme progressively increases quantization difficulty to stabilize optimization and accelerate convergence. Experimental results demonstrate a strong correlation between morphological complexity and quantization sensitivity and show that MCAQ-YOLO achieves superior detection accuracy and convergence efficiency compared with uniform quantization. On a safety equipment dataset, MCAQ-YOLO attains 85.6 percent mAP@0.5 with an average of 4.2 bits and a 7.6x compression ratio, yielding 3.5 percentage points higher mAP than uniform 4-bit quantization while introducing only 1.8 ms of additional runtime overhead per image. Cross-dataset validation on COCO and Pascal VOC further confirms consistent performance gains, indicating that morphology-driven spatial quantization can enhance efficiency and robustness for computationally constrained, safety-critical visual recognition tasks.",
    "published": "2025-11-17T04:53:34Z",
    "updated": "2025-11-17T04:53:34Z",
    "link": "http://arxiv.org/pdf/2511.12976v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Yoonjae Seo",
      "Ermal Elbasani",
      "Jaehong Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12969v1",
    "title": "HiFusion: Hierarchical Intra-Spot Alignment and Regional Context Fusion for Spatial Gene Expression Prediction from Histopathology",
    "summary": "Spatial transcriptomics (ST) bridges gene expression and tissue morphology but faces clinical adoption barriers due to technical complexity and prohibitive costs. While computational methods predict gene expression from H&E-stained whole-slide images (WSIs), existing approaches often fail to capture the intricate biological heterogeneity within spots and are susceptible to morphological noise when integrating contextual information from surrounding tissue. To overcome these limitations, we propose HiFusion, a novel deep learning framework that integrates two complementary components. First, we introduce the Hierarchical Intra-Spot Modeling module that extracts fine-grained morphological representations through multi-resolution sub-patch decomposition, guided by a feature alignment loss to ensure semantic consistency across scales. Concurrently, we present the Context-aware Cross-scale Fusion module, which employs cross-attention to selectively incorporate biologically relevant regional context, thereby enhancing representational capacity. This architecture enables comprehensive modeling of both cellular-level features and tissue microenvironmental cues, which are essential for accurate gene expression prediction. Extensive experiments on two benchmark ST datasets demonstrate that HiFusion achieves state-of-the-art performance across both 2D slide-wise cross-validation and more challenging 3D sample-specific scenarios. These results underscore HiFusion's potential as a robust, accurate, and scalable solution for ST inference from routine histopathology.",
    "published": "2025-11-17T04:47:39Z",
    "updated": "2025-11-17T04:47:39Z",
    "link": "http://arxiv.org/pdf/2511.12969v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ziqiao Weng",
      "Yaoyu Fang",
      "Jiahe Qian",
      "Xinkun Wang",
      "Lee AD Cooper",
      "Weidong Cai",
      "Bo Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12968v1",
    "title": "GrOCE:Graph-Guided Online Concept Erasure for Text-to-Image Diffusion Models",
    "summary": "Concept erasure aims to remove harmful, inappropriate, or copyrighted content from text-to-image diffusion models while preserving non-target semantics. However, existing methods either rely on costly fine-tuning or apply coarse semantic separation, often degrading unrelated concepts and lacking adaptability to evolving concept sets. To alleviate this issue, we propose Graph-Guided Online Concept Erasure (GrOCE), a training-free framework that performs precise and adaptive concept removal through graph-based semantic reasoning. GrOCE models concepts and their interrelations as a dynamic semantic graph, enabling principled reasoning over dependencies and fine-grained isolation of undesired content. It comprises three components: (1) Dynamic Topological Graph Construction for incremental graph building, (2) Adaptive Cluster Identification for multi-hop traversal with similarity-decay scoring, and (3) Selective Edge Severing for targeted edge removal while preserving global semantics. Extensive experiments demonstrate that GrOCE achieves state-of-the-art performance on Concept Similarity (CS) and Fréchet Inception Distance (FID) metrics, offering efficient, accurate, and stable concept erasure without retraining.",
    "published": "2025-11-17T04:47:16Z",
    "updated": "2025-11-17T04:47:16Z",
    "link": "http://arxiv.org/pdf/2511.12968v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ning Han",
      "Zhenyu Ge",
      "Feng Han",
      "Yuhua Sun",
      "Chengqing Li",
      "Jingjing Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12961v1",
    "title": "Inertia-Informed Orientation Priors for Event-Based Optical Flow Estimation",
    "summary": "Event cameras, by virtue of their working principle, directly encode motion within a scene. Many learning-based and model-based methods exist that estimate event-based optical flow, however the temporally dense yet spatially sparse nature of events poses significant challenges. To address these issues, contrast maximization (CM) is a prominent model-based optimization methodology that estimates the motion trajectories of events within an event volume by optimally warping them. Since its introduction, the CM framework has undergone a series of refinements by the computer vision community. Nonetheless, it remains a highly non-convex optimization problem. In this paper, we introduce a novel biologically-inspired hybrid CM method for event-based optical flow estimation that couples visual and inertial motion cues. Concretely, we propose the use of orientation maps, derived from camera 3D velocities, as priors to guide the CM process. The orientation maps provide directional guidance and constrain the space of estimated motion trajectories. We show that this orientation-guided formulation leads to improved robustness and convergence in event-based optical flow estimation. The evaluation of our approach on the MVSEC, DSEC, and ECD datasets yields superior accuracy scores over the state of the art.",
    "published": "2025-11-17T04:39:18Z",
    "updated": "2025-11-17T04:39:18Z",
    "link": "http://arxiv.org/pdf/2511.12961v1.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Pritam P. Karmokar",
      "William J. Beksi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12956v1",
    "title": "T2I-Based Physical-World Appearance Attack against Traffic Sign Recognition Systems in Autonomous Driving",
    "summary": "Traffic Sign Recognition (TSR) systems play a critical role in Autonomous Driving (AD) systems, enabling real-time detection of road signs, such as STOP and speed limit signs. While these systems are increasingly integrated into commercial vehicles, recent research has exposed their vulnerability to physical-world adversarial appearance attacks. In such attacks, carefully crafted visual patterns are misinterpreted by TSR models as legitimate traffic signs, while remaining inconspicuous or benign to human observers. However, existing adversarial appearance attacks suffer from notable limitations. Pixel-level perturbation-based methods often lack stealthiness and tend to overfit to specific surrogate models, resulting in poor transferability to real-world TSR systems. On the other hand, text-to-image (T2I) diffusion model-based approaches demonstrate limited effectiveness and poor generalization to out-of-distribution sign types.\n  In this paper, we present DiffSign, a novel T2I-based appearance attack framework designed to generate physically robust, highly effective, transferable, practical, and stealthy appearance attacks against TSR systems. To overcome the limitations of prior approaches, we propose a carefully designed attack pipeline that integrates CLIP-based loss and masked prompts to improve attack focus and controllability. We also propose two novel style customization methods to guide visual appearance and improve out-of-domain traffic sign attack generalization and attack stealthiness. We conduct extensive evaluations of DiffSign under varied real-world conditions, including different distances, angles, light conditions, and sign categories. Our method achieves an average physical-world attack success rate of 83.3%, leveraging DiffSign's high effectiveness in attack transferability.",
    "published": "2025-11-17T04:29:55Z",
    "updated": "2025-11-17T04:29:55Z",
    "link": "http://arxiv.org/pdf/2511.12956v1.pdf",
    "category": [
      "cs.CV",
      "cs.CR"
    ],
    "authors": [
      "Chen Ma",
      "Ningfei Wang",
      "Junhao Zheng",
      "Qing Guo",
      "Qian Wang",
      "Qi Alfred Chen",
      "Chao Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.07767v2",
    "title": "Regression-based Pelvic Pose Initialization for Fast and Robust 2D/3D Pelvis Registration",
    "summary": "This paper presents an approach for improving 2D/3D pelvis registration in optimization-based pose estimators using a learned initialization function. Current methods often fail to converge to the optimal solution when initialized naively. We find that even a coarse initializer greatly improves pose estimator accuracy, and improves overall computational efficiency. This approach proves to be effective also in challenging cases under more extreme pose variation. Experimental validation demonstrates that our method consistently achieves robust and accurate registration, enhancing the reliability of 2D/3D registration for clinical applications.",
    "published": "2025-03-10T18:42:13Z",
    "updated": "2025-11-17T04:25:33Z",
    "link": "http://arxiv.org/pdf/2503.07767v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yehyun Suh",
      "J. Ryan Martin",
      "Daniel Moyer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.08374v2",
    "title": "InsFusion: Rethink Instance-level LiDAR-Camera Fusion for 3D Object Detection",
    "summary": "Three-dimensional Object Detection from multi-view cameras and LiDAR is a crucial component for autonomous driving and smart transportation. However, in the process of basic feature extraction, perspective transformation, and feature fusion, noise and error will gradually accumulate. To address this issue, we propose InsFusion, which can extract proposals from both raw and fused features and utilizes these proposals to query the raw features, thereby mitigating the impact of accumulated errors. Additionally, by incorporating attention mechanisms applied to the raw features, it thereby mitigates the impact of accumulated errors. Experiments on the nuScenes dataset demonstrate that InsFusion is compatible with various advanced baseline methods and delivers new state-of-the-art performance for 3D object detection.",
    "published": "2025-09-10T08:12:15Z",
    "updated": "2025-11-17T04:04:06Z",
    "link": "http://arxiv.org/pdf/2509.08374v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhongyu Xia",
      "Hansong Yang",
      "Yongtao Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.05982v6",
    "title": "MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness Against VLM-based Attacks",
    "summary": "As automated attack techniques rapidly advance, CAPTCHAs remain a critical defense mechanism against malicious bots. However, existing CAPTCHA schemes encompass a diverse range of modalities -- from static distorted text and obfuscated images to interactive clicks, sliding puzzles, and logic-based questions -- yet the community still lacks a unified, large-scale, multimodal benchmark to rigorously evaluate their security robustness. To address this gap, we introduce MCA-Bench, a comprehensive and reproducible benchmarking suite that integrates heterogeneous CAPTCHA types into a single evaluation protocol. Leveraging a shared vision-language model backbone, we fine-tune specialized cracking agents for each CAPTCHA category, enabling consistent, cross-modal assessments. Extensive experiments reveal that MCA-Bench effectively maps the vulnerability spectrum of modern CAPTCHA designs under varied attack settings, and crucially offers the first quantitative analysis of how challenge complexity, interaction depth, and model solvability interrelate. Based on these findings, we propose three actionable design principles and identify key open challenges, laying the groundwork for systematic CAPTCHA hardening, fair benchmarking, and broader community collaboration. Datasets and code are available online.",
    "published": "2025-06-06T11:02:01Z",
    "updated": "2025-11-17T03:59:38Z",
    "link": "http://arxiv.org/pdf/2506.05982v6.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zonglin Wu",
      "Yule Xue",
      "Yaoyao Feng",
      "Xiaolong Wang",
      "Yiren Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18991v2",
    "title": "Fast Kernel-Space Diffusion for Remote Sensing Pansharpening",
    "summary": "Pansharpening seeks to fuse high-resolution panchromatic (PAN) and low-resolution multispectral (LRMS) images into a single image with both fine spatial and rich spectral detail. Despite progress in deep learning-based approaches, existing methods often fail to capture global priors inherent in remote sensing data distributions. Diffusion-based models have recently emerged as promising solutions due to their powerful distribution mapping capabilities, however, they suffer from heavy inference latency. We introduce KSDiff, a fast kernel-space diffusion framework that generates convolutional kernels enriched with global context to enhance pansharpening quality and accelerate inference. Specifically, KSDiff constructs these kernels through the integration of a low-rank core tensor generator and a unified factor generator, orchestrated by a structure-aware multi-head attention mechanism. We further introduce a two-stage training strategy tailored for pansharpening, facilitating integration into existing pansharpening architectures. Experiments show that KSDiff achieves superior performance compared to recent promising methods, and with over $500 \\times$ faster inference than diffusion-based pansharpening baselines. Ablation studies, visualizations and further evaluations substantiate the effectiveness of our approach. Code will be released upon possible acceptance.",
    "published": "2025-05-25T06:25:31Z",
    "updated": "2025-11-17T03:57:55Z",
    "link": "http://arxiv.org/pdf/2505.18991v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hancong Jin",
      "Zihan Cao",
      "Liang-jian Deng",
      "Jingjing Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12940v1",
    "title": "Recurrent Autoregressive Diffusion: Global Memory Meets Local Attention",
    "summary": "Recent advancements in video generation have demonstrated the potential of using video diffusion models as world models, with autoregressive generation of infinitely long videos through masked conditioning. However, such models, usually with local full attention, lack effective memory compression and retrieval for long-term generation beyond the window size, leading to issues of forgetting and spatiotemporal inconsistencies. To enhance the retention of historical information within a fixed memory budget, we introduce a recurrent neural network (RNN) into the diffusion transformer framework. Specifically, a diffusion model incorporating LSTM with attention achieves comparable performance to state-of-the-art RNN blocks, such as TTT and Mamba2. Moreover, existing diffusion-RNN approaches often suffer from performance degradation due to training-inference gap or the lack of overlap across windows. To address these limitations, we propose a novel Recurrent Autoregressive Diffusion (RAD) framework, which executes frame-wise autoregression for memory update and retrieval, consistently across training and inference time. Experiments on Memory Maze and Minecraft datasets demonstrate the superiority of RAD for long video generation, highlighting the efficiency of LSTM in sequence modeling.",
    "published": "2025-11-17T03:47:12Z",
    "updated": "2025-11-17T03:47:12Z",
    "link": "http://arxiv.org/pdf/2511.12940v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Taiye Chen",
      "Zihan Ding",
      "Anjian Li",
      "Christina Zhang",
      "Zeqi Xiao",
      "Yisen Wang",
      "Chi Jin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12939v1",
    "title": "Semi-Supervised High Dynamic Range Image Reconstructing via Bi-Level Uncertain Area Masking",
    "summary": "Reconstructing high dynamic range (HDR) images from low dynamic range (LDR) bursts plays an essential role in the computational photography. Impressive progress has been achieved by learning-based algorithms which require LDR-HDR image pairs. However, these pairs are hard to obtain, which motivates researchers to delve into the problem of annotation-efficient HDR image reconstructing: how to achieve comparable performance with limited HDR ground truths (GTs). This work attempts to address this problem from the view of semi-supervised learning where a teacher model generates pseudo HDR GTs for the LDR samples without GTs and a student model learns from pseudo GTs. Nevertheless, the confirmation bias, i.e., the student may learn from the artifacts in pseudo HDR GTs, presents an impediment. To remove this impediment, an uncertainty-based masking process is proposed to discard unreliable parts of pseudo GTs at both pixel and patch levels, then the trusted areas can be learned from by the student. With this novel masking process, our semi-supervised HDR reconstructing method not only outperforms previous annotation-efficient algorithms, but also achieves comparable performance with up-to-date fully-supervised methods by using only 6.7% HDR GTs.",
    "published": "2025-11-17T03:46:58Z",
    "updated": "2025-11-17T03:46:58Z",
    "link": "http://arxiv.org/pdf/2511.12939v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wei Jiang",
      "Jiahao Cui",
      "Yizheng Wu",
      "Zhan Peng",
      "Zhiyu Pan",
      "Zhiguo Cao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12938v1",
    "title": "ProtoAnomalyNCD: Prototype Learning for Multi-class Novel Anomaly Discovery in Industrial Scenarios",
    "summary": "Existing industrial anomaly detection methods mainly determine whether an anomaly is present. However, real-world applications also require discovering and classifying multiple anomaly types. Since industrial anomalies are semantically subtle and current methods do not sufficiently exploit image priors, direct clustering approaches often perform poorly. To address these challenges, we propose ProtoAnomalyNCD, a prototype-learning-based framework for discovering unseen anomaly classes of multiple types that can be integrated with various anomaly detection methods. First, to suppress background clutter, we leverage Grounded SAM with text prompts to localize object regions as priors for the anomaly classification network. Next, because anomalies usually appear as subtle and fine-grained patterns on the product, we introduce an Anomaly-Map-Guided Attention block. Within this block, we design a Region Guidance Factor that helps the attention module distinguish among background, object regions, and anomalous regions. By using both localized product regions and anomaly maps as priors, the module enhances anomalous features while suppressing background noise and preserving normal features for contrastive learning. Finally, under a unified prototype-learning framework, ProtoAnomalyNCD discovers and clusters unseen anomaly classes while simultaneously enabling multi-type anomaly classification. We further extend our method to detect unseen outliers, achieving task-level unification. Our method outperforms state-of-the-art approaches on the MVTec AD, MTD, and Real-IAD datasets.",
    "published": "2025-11-17T03:45:34Z",
    "updated": "2025-11-17T03:45:34Z",
    "link": "http://arxiv.org/pdf/2511.12938v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Botong Zhao",
      "Qijun Shi",
      "Shujing Lyu",
      "Yue Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12932v1",
    "title": "Text2Traffic: A Text-to-Image Generation and Editing Method for Traffic Scenes",
    "summary": "With the rapid advancement of intelligent transportation systems, text-driven image generation and editing techniques have demonstrated significant potential in providing rich, controllable visual scene data for applications such as traffic monitoring and autonomous driving. However, several challenges remain, including insufficient semantic richness of generated traffic elements, limited camera viewpoints, low visual fidelity of synthesized images, and poor alignment between textual descriptions and generated content. To address these issues, we propose a unified text-driven framework for both image generation and editing, leveraging a controllable mask mechanism to seamlessly integrate the two tasks. Furthermore, we incorporate both vehicle-side and roadside multi-view data to enhance the geometric diversity of traffic scenes. Our training strategy follows a two-stage paradigm: first, we perform conceptual learning using large-scale coarse-grained text-image data; then, we fine-tune with fine-grained descriptive data to enhance text-image alignment and detail quality. Additionally, we introduce a mask-region-weighted loss that dynamically emphasizes small yet critical regions during training, thereby substantially enhancing the generation fidelity of small-scale traffic elements. Extensive experiments demonstrate that our method achieves leading performance in text-based image generation and editing within traffic scenes.",
    "published": "2025-11-17T03:39:13Z",
    "updated": "2025-11-17T03:39:13Z",
    "link": "http://arxiv.org/pdf/2511.12932v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Feng Lv",
      "Haoxuan Feng",
      "Zilu Zhang",
      "Chunlong Xia",
      "Yanfeng Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12930v1",
    "title": "Neo: Real-Time On-Device 3D Gaussian Splatting with Reuse-and-Update Sorting Acceleration",
    "summary": "3D Gaussian Splatting (3DGS) rendering in real-time on resource-constrained devices is essential for delivering immersive augmented and virtual reality (AR/VR) experiences. However, existing solutions struggle to achieve high frame rates, especially for high-resolution rendering. Our analysis identifies the sorting stage in the 3DGS rendering pipeline as the major bottleneck due to its high memory bandwidth demand. This paper presents Neo, which introduces a reuse-and-update sorting algorithm that exploits temporal redundancy in Gaussian ordering across consecutive frames, and devises a hardware accelerator optimized for this algorithm. By efficiently tracking and updating Gaussian depth ordering instead of re-sorting from scratch, Neo significantly reduces redundant computations and memory bandwidth pressure. Experimental results show that Neo achieves up to 10.0x and 5.6x higher throughput than state-of-the-art edge GPU and ASIC solution, respectively, while reducing DRAM traffic by 94.5% and 81.3%. These improvements make high-quality and low-latency on-device 3D rendering more practical.",
    "published": "2025-11-17T03:37:13Z",
    "updated": "2025-11-17T03:37:13Z",
    "link": "http://arxiv.org/pdf/2511.12930v1.pdf",
    "category": [
      "cs.AR",
      "cs.CV"
    ],
    "authors": [
      "Changhun Oh",
      "Seongryong Oh",
      "Jinwoo Hwang",
      "Yoonsung Kim",
      "Hardik Sharma",
      "Jongse Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12921v1",
    "title": "Generative Photographic Control for Scene-Consistent Video Cinematic Editing",
    "summary": "Cinematic storytelling is profoundly shaped by the artful manipulation of photographic elements such as depth of field and exposure. These effects are crucial in conveying mood and creating aesthetic appeal. However, controlling these effects in generative video models remains highly challenging, as most existing methods are restricted to camera motion control. In this paper, we propose CineCtrl, the first video cinematic editing framework that provides fine control over professional camera parameters (e.g., bokeh, shutter speed). We introduce a decoupled cross-attention mechanism to disentangle camera motion from photographic inputs, allowing fine-grained, independent control without compromising scene consistency. To overcome the shortage of training data, we develop a comprehensive data generation strategy that leverages simulated photographic effects with a dedicated real-world collection pipeline, enabling the construction of a large-scale dataset for robust model training. Extensive experiments demonstrate that our model generates high-fidelity videos with precisely controlled, user-specified photographic camera effects.",
    "published": "2025-11-17T03:17:23Z",
    "updated": "2025-11-17T03:17:23Z",
    "link": "http://arxiv.org/pdf/2511.12921v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Huiqiang Sun",
      "Liao Shen",
      "Zhan Peng",
      "Kun Wang",
      "Size Wu",
      "Yuhang Zang",
      "Tianqi Liu",
      "Zihao Huang",
      "Xingyu Zeng",
      "Zhiguo Cao",
      "Wei Li",
      "Chen Change Loy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12919v1",
    "title": "CoordAR: One-Reference 6D Pose Estimation of Novel Objects via Autoregressive Coordinate Map Generation",
    "summary": "Object 6D pose estimation, a crucial task for robotics and augmented reality applications, becomes particularly challenging when dealing with novel objects whose 3D models are not readily available. To reduce dependency on 3D models, recent studies have explored one-reference-based pose estimation, which requires only a single reference view instead of a complete 3D model. However, existing methods that rely on real-valued coordinate regression suffer from limited global consistency due to the local nature of convolutional architectures and face challenges in symmetric or occluded scenarios owing to a lack of uncertainty modeling. We present CoordAR, a novel autoregressive framework for one-reference 6D pose estimation of unseen objects. CoordAR formulates 3D-3D correspondences between the reference and query views as a map of discrete tokens, which is obtained in an autoregressive and probabilistic manner. To enable accurate correspondence regression, CoordAR introduces 1) a novel coordinate map tokenization that enables probabilistic prediction over discretized 3D space; 2) a modality-decoupled encoding strategy that separately encodes RGB appearance and coordinate cues; and 3) an autoregressive transformer decoder conditioned on both position-aligned query features and the partially generated token sequence. With these novel mechanisms, CoordAR significantly outperforms existing methods on multiple benchmarks and demonstrates strong robustness to symmetry, occlusion, and other challenges in real-world tests.",
    "published": "2025-11-17T03:15:46Z",
    "updated": "2025-11-17T03:15:46Z",
    "link": "http://arxiv.org/pdf/2511.12919v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dexin Zuo",
      "Ang Li",
      "Wei Wang",
      "Wenxian Yu",
      "Danping Zou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12917v1",
    "title": "Explore How to Inject Beneficial Noise in MLLMs",
    "summary": "Multimodal Large Language Models (MLLMs) have played an increasingly important role in multimodal intelligence. However, the existing fine-tuning methods often ignore cross-modal heterogeneity, limiting their full potential. In this work, we propose a novel fine-tuning strategy by injecting beneficial random noise, which outperforms previous methods and even surpasses full fine-tuning, with minimal additional parameters. The proposed Multimodal Noise Generator (MuNG) enables efficient modality fine-tuning by injecting customized noise into the frozen MLLMs. Specifically, we reformulate the reasoning process of MLLMs from a variational inference perspective, upon which we design a multimodal noise generator that dynamically analyzes cross-modal relationships in image-text pairs to generate task-adaptive beneficial noise. Injecting this type of noise into the MLLMs effectively suppresses irrelevant semantic components, leading to significantly improved cross-modal representation alignment and enhanced performance on downstream tasks. Experiments on two mainstream MLLMs, QwenVL and LLaVA, demonstrate that our method surpasses full-parameter fine-tuning and other existing fine-tuning approaches, while requiring adjustments to only about $1\\sim2\\%$ additional parameters. The relevant code is uploaded in the supplementary.",
    "published": "2025-11-17T03:11:41Z",
    "updated": "2025-11-17T03:11:41Z",
    "link": "http://arxiv.org/pdf/2511.12917v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ruishu Zhu",
      "Sida Huang",
      "Ziheng Jiao",
      "Hongyuan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.06499v2",
    "title": "SportR: A Benchmark for Multimodal Large Language Model Reasoning in Sports",
    "summary": "Deeply understanding sports requires an intricate blend of fine-grained visual perception and rule-based reasoning - a challenge that pushes the limits of current multimodal models. To succeed, models must master three critical capabilities: perceiving nuanced visual details, applying abstract sport rule knowledge, and grounding that knowledge in specific visual evidence. Current sports benchmarks either cover single sports or lack the detailed reasoning chains and precise visual grounding needed to robustly evaluate these core capabilities in a multi-sport context. To address this gap, we introduce SportR, the first multi-sports large-scale benchmark designed to train and evaluate MLLMs on the fundamental reasoning required for sports intelligence. Our benchmark provides a dataset of 5,017 images and 2,101 videos. To enable granular evaluation, we structure our benchmark around a progressive hierarchy of question-answer (QA) pairs designed to probe reasoning at increasing depths - from simple infraction identification to complex penalty prediction. For the most advanced tasks requiring multi-step reasoning, such as determining penalties or explaining tactics, we provide 7,118 high-quality, human-authored Chain of Thought (CoT) annotations. In addition, our benchmark incorporates both image and video modalities and provides manual bounding box annotations to test visual grounding in the image part directly. Extensive experiments demonstrate the profound difficulty of our benchmark. State-of-the-art baseline models perform poorly on our most challenging tasks. While training on our data via Supervised Fine-Tuning and Reinforcement Learning improves these scores, they remain relatively low, highlighting a significant gap in current model capabilities. SportR presents a new challenge for the community, providing a critical resource to drive future research in multimodal sports reasoning.",
    "published": "2025-11-09T18:55:20Z",
    "updated": "2025-11-17T03:11:19Z",
    "link": "http://arxiv.org/pdf/2511.06499v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Haotian Xia",
      "Haonan Ge",
      "Junbo Zou",
      "Hyun Woo Choi",
      "Xuebin Zhang",
      "Danny Suradja",
      "Botao Rui",
      "Ethan Tran",
      "Wendy Jin",
      "Zhen Ye",
      "Xiyang Lin",
      "Christopher Lai",
      "Shengjie Zhang",
      "Junwen Miao",
      "Shichao Chen",
      "Rhys Tracy",
      "Vicente Ordonez",
      "Weining Shen",
      "Hanjie Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11522v2",
    "title": "CVChess: A Deep Learning Framework for Converting Chessboard Images to Forsyth-Edwards Notation",
    "summary": "Chess has experienced a large increase in viewership since the pandemic, driven largely by the accessibility of online learning platforms. However, no equivalent assistance exists for physical chess games, creating a divide between analog and digital chess experiences. This paper presents CVChess, a deep learning framework for converting chessboard images to Forsyth-Edwards Notation (FEN), which is later input into online chess engines to provide you with the best next move. Our approach employs a convolutional neural network (CNN) with residual layers to perform piece recognition from smartphone camera images. The system processes RGB images of a physical chess board through a multistep process: image preprocessing using the Hough Line Transform for edge detection, projective transform to achieve a top-down board alignment, segmentation into 64 individual squares, and piece classification into 13 classes (6 unique white pieces, 6 unique black pieces and an empty square) using the residual CNN. Residual connections help retain low-level visual features while enabling deeper feature extraction, improving accuracy and stability during training. We train and evaluate our model using the Chess Recognition Dataset (ChessReD), containing 10,800 annotated smartphone images captured under diverse lighting conditions and angles. The resulting classifications are encoded as an FEN string, which can be fed into a chess engine to generate the most optimal move",
    "published": "2025-11-14T17:50:35Z",
    "updated": "2025-11-17T03:00:45Z",
    "link": "http://arxiv.org/pdf/2511.11522v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Luthira Abeykoon",
      "Ved Patel",
      "Gawthaman Senthilvelan",
      "Darshan Kasundra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12909v1",
    "title": "CASL: Curvature-Augmented Self-supervised Learning for 3D Anomaly Detection",
    "summary": "Deep learning-based 3D anomaly detection methods have demonstrated significant potential in industrial manufacturing. However, many approaches are specifically designed for anomaly detection tasks, which limits their generalizability to other 3D understanding tasks. In contrast, self-supervised point cloud models aim for general-purpose representation learning, yet our investigation reveals that these classical models are suboptimal at anomaly detection under the unified fine-tuning paradigm. This motivates us to develop a more generalizable 3D model that can effectively detect anomalies without relying on task-specific designs. Interestingly, we find that using only the curvature of each point as its anomaly score already outperforms several classical self-supervised and dedicated anomaly detection models, highlighting the critical role of curvature in 3D anomaly detection. In this paper, we propose a Curvature-Augmented Self-supervised Learning (CASL) framework based on a reconstruction paradigm. Built upon the classical U-Net architecture, our approach introduces multi-scale curvature prompts to guide the decoder in predicting the spatial coordinates of each point. Without relying on any dedicated anomaly detection mechanisms, it achieves leading detection performance through straightforward anomaly classification fine-tuning. Moreover, the learned representations generalize well to standard 3D understanding tasks such as point cloud classification. The code is available at https://github.com/zyh16143998882/CASL.",
    "published": "2025-11-17T02:58:09Z",
    "updated": "2025-11-17T02:58:09Z",
    "link": "http://arxiv.org/pdf/2511.12909v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yaohua Zha",
      "Xue Yuerong",
      "Chunlin Fan",
      "Yuansong Wang",
      "Tao Dai",
      "Ke Chen",
      "Shu-Tao Xia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.19210v3",
    "title": "FlexPara: Flexible Neural Surface Parameterization",
    "summary": "Surface parameterization is a fundamental geometry processing task, laying the foundations for the visual presentation of 3D assets and numerous downstream shape analysis scenarios. Conventional parameterization approaches demand high-quality mesh triangulation and are restricted to certain simple topologies unless additional surface cutting and decomposition are provided. In practice, the optimal configurations (e.g., type of parameterization domains, distribution of cutting seams, number of mapping charts) may vary drastically with different surface structures and task characteristics, thus requiring more flexible and controllable processing pipelines. To this end, this paper introduces FlexPara, an unsupervised neural optimization framework to achieve both global and multi-chart surface parameterizations by establishing point-wise mappings between 3D surface points and adaptively-deformed 2D UV coordinates. We ingeniously design and combine a series of geometrically-interpretable sub-networks, with specific functionalities of cutting, deforming, unwrapping, and wrapping, to construct a bi-directional cycle mapping framework for global parameterization without the need for manually specified cutting seams. Furthermore, we construct a multi-chart parameterization framework with adaptively-learned chart assignment. Extensive experiments demonstrate the universality, superiority, and inspiring potential of our neural surface parameterization paradigm. The code will be publicly available at https://github.com/AidenZhao/FlexPara",
    "published": "2025-04-27T12:30:08Z",
    "updated": "2025-11-17T02:50:18Z",
    "link": "http://arxiv.org/pdf/2504.19210v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuming Zhao",
      "Qijian Zhang",
      "Junhui Hou",
      "Jiazhi Xia",
      "Wenping Wang",
      "Ying He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12899v1",
    "title": "FDP: A Frequency-Decomposition Preprocessing Pipeline for Unsupervised Anomaly Detection in Brain MRI",
    "summary": "Due to the diversity of brain anatomy and the scarcity of annotated data, supervised anomaly detection for brain MRI remains challenging, driving the development of unsupervised anomaly detection (UAD) approaches. Current UAD methods typically utilize artificially generated noise perturbations on healthy MRIs to train generative models for normal anatomy reconstruction, enabling anomaly detection via residual mapping. However, such simulated anomalies lack the biophysical fidelity and morphological complexity characteristic of true clinical lesions. To advance UAD in brain MRI, we conduct the first systematic frequency-domain analysis of pathological signatures, revealing two key properties: (1) anomalies exhibit unique frequency patterns distinguishable from normal anatomy, and (2) low-frequency signals maintain consistent representations across healthy scans. These insights motivate our Frequency-Decomposition Preprocessing (FDP) framework, the first UAD method to leverage frequency-domain reconstruction for simultaneous pathology suppression and anatomical preservation. FDP can integrate seamlessly with existing anomaly simulation techniques, consistently enhancing detection performance across diverse architectures while maintaining diagnostic fidelity. Experimental results demonstrate that FDP consistently improves anomaly detection performance when integrated with existing methods. Notably, FDP achieves a 17.63% increase in DICE score with LDM while maintaining robust improvements across multiple baselines. The code is available at https://github.com/ls1rius/MRI_FDP.",
    "published": "2025-11-17T02:40:14Z",
    "updated": "2025-11-17T02:40:14Z",
    "link": "http://arxiv.org/pdf/2511.12899v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hao Li",
      "Zhenfeng Zhuang",
      "Jingyu Lin",
      "Yu Liu",
      "Yifei Chen",
      "Qiong Peng",
      "Lequan Yu",
      "Liansheng Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12898v1",
    "title": "Functional Mean Flow in Hilbert Space",
    "summary": "We present Functional Mean Flow (FMF) as a one-step generative model defined in infinite-dimensional Hilbert space. FMF extends the one-step Mean Flow framework to functional domains by providing a theoretical formulation for Functional Flow Matching and a practical implementation for efficient training and sampling. We also introduce an $x_1$-prediction variant that improves stability over the original $u$-prediction form. The resulting framework is a practical one-step Flow Matching method applicable to a wide range of functional data generation tasks such as time series, images, PDEs, and 3D geometry.",
    "published": "2025-11-17T02:38:28Z",
    "updated": "2025-11-17T02:38:28Z",
    "link": "http://arxiv.org/pdf/2511.12898v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Zhiqi Li",
      "Yuchen Sun",
      "Greg Turk",
      "Bo Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12895v1",
    "title": "Reconstructing 3D Scenes in Native High Dynamic Range",
    "summary": "High Dynamic Range (HDR) imaging is essential for professional digital media creation, e.g., filmmaking, virtual production, and photorealistic rendering. However, 3D scene reconstruction has primarily focused on Low Dynamic Range (LDR) data, limiting its applicability to professional workflows. Existing approaches that reconstruct HDR scenes from LDR observations rely on multi-exposure fusion or inverse tone-mapping, which increase capture complexity and depend on synthetic supervision. With the recent emergence of cameras that directly capture native HDR data in a single exposure, we present the first method for 3D scene reconstruction that directly models native HDR observations. We propose {\\bf Native High dynamic range 3D Gaussian Splatting (NH-3DGS)}, which preserves the full dynamic range throughout the reconstruction pipeline. Our key technical contribution is a novel luminance-chromaticity decomposition of the color representation that enables direct optimization from native HDR camera data. We demonstrate on both synthetic and real multi-view HDR datasets that NH-3DGS significantly outperforms existing methods in reconstruction quality and dynamic range preservation, enabling professional-grade 3D reconstruction directly from native HDR captures. Code and datasets will be made available.",
    "published": "2025-11-17T02:33:31Z",
    "updated": "2025-11-17T02:33:31Z",
    "link": "http://arxiv.org/pdf/2511.12895v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kaixuan Zhang",
      "Minxian Li",
      "Mingwu Ren",
      "Jiankang Deng",
      "Xiatian Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12893v1",
    "title": "ActVAR: Activating Mixtures of Weights and Tokens for Efficient Visual Autoregressive Generation",
    "summary": "Visual Autoregressive (VAR) models enable efficient image generation via next-scale prediction but face escalating computational costs as sequence length grows. Existing static pruning methods degrade performance by permanently removing weights or tokens, disrupting pretrained dependencies. To address this, we propose ActVAR, a dynamic activation framework that introduces dual sparsity across model weights and token sequences to enhance efficiency without sacrificing capacity. ActVAR decomposes feedforward networks (FFNs) into lightweight expert sub-networks and employs a learnable router to dynamically select token-specific expert subsets based on content. Simultaneously, a gated token selector identifies high-update-potential tokens for computation while reconstructing unselected tokens to preserve global context and sequence alignment. Training employs a two-stage knowledge distillation strategy, where the original VAR model supervises the learning of routing and gating policies to align with pretrained knowledge. Experiments on the ImageNet $256\\times 256$ benchmark demonstrate that ActVAR achieves up to $21.2\\%$ FLOPs reduction with minimal performance degradation.",
    "published": "2025-11-17T02:28:06Z",
    "updated": "2025-11-17T02:28:06Z",
    "link": "http://arxiv.org/pdf/2511.12893v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kaixin Zhang",
      "Ruiqing Yang",
      "Yuan Zhang",
      "Shan You",
      "Tao Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.07251v3",
    "title": "Understanding Dynamic Scenes in Ego Centric 4D Point Clouds",
    "summary": "Understanding dynamic 4D scenes from an egocentric perspective-modeling changes in 3D spatial structure over time-is crucial for human-machine interaction, autonomous navigation, and embodied intelligence. While existing egocentric datasets contain dynamic scenes, they lack unified 4D annotations and task-driven evaluation protocols for fine-grained spatio-temporal reasoning, especially on motion of objects and human, together with their interactions. To address this gap, we introduce EgoDynamic4D, a novel QA benchmark on highly dynamic scenes, comprising RGB-D video, camera poses, globally unique instance masks, and 4D bounding boxes. We construct 927K QA pairs accompanied by explicit Chain-of-Thought (CoT), enabling verifiable, step-by-step spatio-temporal reasoning. We design 12 dynamic QA tasks covering agent motion, human-object interaction, trajectory prediction, relation understanding, and temporal-causal reasoning, with fine-grained, multidimensional metrics. To tackle these tasks, we propose an end-to-end spatio-temporal reasoning framework that unifies dynamic and static scene information, using instance-aware feature encoding, time and camera encoding, and spatially adaptive down-sampling to compress large 4D scenes into token sequences manageable by LLMs. Experiments on EgoDynamic4D show that our method consistently outperforms baselines, validating the effectiveness of multimodal temporal modeling for egocentric dynamic scene understanding.",
    "published": "2025-08-10T09:08:04Z",
    "updated": "2025-11-17T02:19:41Z",
    "link": "http://arxiv.org/pdf/2508.07251v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junsheng Huang",
      "Shengyu Hao",
      "Bocheng Hu",
      "Hongwei Wang",
      "Gaoang Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12880v1",
    "title": "Simple Lines, Big Ideas: Towards Interpretable Assessment of Human Creativity from Drawings",
    "summary": "Assessing human creativity through visual outputs, such as drawings, plays a critical role in fields including psychology, education, and cognitive science. However, current assessment practices still rely heavily on expert-based subjective scoring, which is both labor-intensive and inherently subjective. In this paper, we propose a data-driven framework for automatic and interpretable creativity assessment from drawings. Motivated by the cognitive understanding that creativity can emerge from both what is drawn (content) and how it is drawn (style), we reinterpret the creativity score as a function of these two complementary dimensions.Specifically, we first augment an existing creativity labeled dataset with additional annotations targeting content categories. Based on the enriched dataset, we further propose a multi-modal, multi-task learning framework that simultaneously predicts creativity scores, categorizes content types, and extracts stylistic features. In particular, we introduce a conditional learning mechanism that enables the model to adapt its visual feature extraction by dynamically tuning it to creativity-relevant signals conditioned on the drawing's stylistic and semantic cues.Experimental results demonstrate that our model achieves state-of-the-art performance compared to existing regression-based approaches and offers interpretable visualizations that align well with human judgments. The code and annotations will be made publicly available at https://github.com/WonderOfU9/CSCA_PRCV_2025",
    "published": "2025-11-17T02:16:01Z",
    "updated": "2025-11-17T02:16:01Z",
    "link": "http://arxiv.org/pdf/2511.12880v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zihao Lin",
      "Zhenshan Shi",
      "Sasa Zhao",
      "Hanwei Zhu",
      "Lingyu Zhu",
      "Baoliang Chen",
      "Lei Mo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22344v2",
    "title": "Task-Driven Implicit Representations for Automated Design of LiDAR Systems",
    "summary": "Imaging system design is a complex, time-consuming, and largely manual process; LiDAR design, ubiquitous in mobile devices, autonomous vehicles, and aerial imaging platforms, adds further complexity through unique spatial and temporal sampling requirements. In this work, we propose a framework for automated, task-driven LiDAR system design under arbitrary constraints. To achieve this, we represent LiDAR configurations in a continuous six-dimensional design space and learn task-specific implicit densities in this space via flow-based generative modeling. We then synthesize new LiDAR systems by modeling sensors as parametric distributions in 6D space and fitting these distributions to our learned implicit density using expectation-maximization, enabling efficient, constraint-aware LiDAR system design. We validate our method on diverse tasks in 3D vision, enabling automated LiDAR system design across real-world-inspired applications in face scanning, robotic tracking, and object detection.",
    "published": "2025-05-28T13:27:42Z",
    "updated": "2025-11-17T02:14:26Z",
    "link": "http://arxiv.org/pdf/2505.22344v2.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Nikhil Behari",
      "Aaron Young",
      "Tzofi Klinghoffer",
      "Akshat Dave",
      "Ramesh Raskar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12878v1",
    "title": "Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views",
    "summary": "Analyzing hand-object interaction in egocentric vision facilitates VR/AR applications and human-robot policy transfer. Existing research has mostly focused on modeling the behavior paradigm of interactive actions (i.e., \"how to interact\"). However, the more challenging and fine-grained problem of capturing the critical moments of contact and separation between the hand and the target object (i.e., \"when to interact\") is still underexplored, which is crucial for immersive interactive experiences in mixed reality and robotic motion planning. Therefore, we formulate this problem as temporal interaction localization (TIL). Some recent works extract semantic masks as TIL references, but suffer from inaccurate object grounding and cluttered scenarios. Although current temporal action localization (TAL) methods perform well in detecting verb-noun action segments, they rely on category annotations during training and exhibit limited precision in localizing hand-object contact/separation moments. To address these issues, we propose a novel zero-shot approach dubbed EgoLoc to localize hand-object contact and separation timestamps in egocentric videos. EgoLoc introduces hand-dynamics-guided sampling to generate high-quality visual prompts. It exploits the vision-language model to identify contact/separation attributes, localize specific timestamps, and provide closed-loop feedback for further refinement. EgoLoc eliminates the need for object masks and verb-noun taxonomies, leading to generalizable zero-shot implementation. Comprehensive experiments on the public dataset and our novel benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric videos. It is also validated to effectively facilitate multiple downstream applications in egocentric vision and robotic manipulation tasks. Code and relevant data will be released at https://github.com/IRMVLab/EgoLoc.",
    "published": "2025-11-17T02:14:13Z",
    "updated": "2025-11-17T02:14:13Z",
    "link": "http://arxiv.org/pdf/2511.12878v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Junyi Ma",
      "Wentao Bao",
      "Jingyi Xu",
      "Guanzhong Sun",
      "Yu Zheng",
      "Erhang Zhang",
      "Xieyuanli Chen",
      "Hesheng Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.11069v9",
    "title": "Refinement Module based on Parse Graph for Human Pose Estimation",
    "summary": "Parse graphs have been widely used in Human Pose Estimation (HPE) to model the hierarchical structure and context relations of the human body. However, such methods often suffer from parameter redundancy. More importantly, they rely on predefined network structures, which limits their use in other methods. To address these issues, we propose a new context relation and hierarchical structure modeling module, RMPG (Refinement Module based on Parse Graph). RMPG adaptively refines feature maps through recursive top-down decomposition of feature maps and bottom-up composition of sub-node feature maps with context information. Through recursive hierarchical composition, RMPG fuses local details and global semantics into more structured feature representations, accompanied by context information, thereby improving the accuracy of joint inference. RMPG can be flexibly embedded as a plug-in into various mainstream HPE networks. Moreover, by supervising sub-node features map, RMPG learns the context relations and hierarchical structure between different body parts with fewer parameters. Extensive experiments show that RMPG improves performance across different architectures while effectively modeling hierarchical and context relations of the human body with fewer parameters. The RMPG code can be found at https://github.com/lushbng/RMPG.",
    "published": "2025-01-19T15:05:15Z",
    "updated": "2025-11-17T02:09:52Z",
    "link": "http://arxiv.org/pdf/2501.11069v9.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shibang Liu",
      "Xuemei Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.14475v3",
    "title": "Fine-grained Image Quality Assessment for Perceptual Image Restoration",
    "summary": "Recent years have witnessed remarkable achievements in perceptual image restoration (IR), creating an urgent demand for accurate image quality assessment (IQA), which is essential for both performance comparison and algorithm optimization. Unfortunately, the existing IQA metrics exhibit inherent weakness for IR task, particularly when distinguishing fine-grained quality differences among restored images. To address this dilemma, we contribute the first-of-its-kind fine-grained image quality assessment dataset for image restoration, termed FGRestore, comprising 18,408 restored images across six common IR tasks. Beyond conventional scalar quality scores, FGRestore was also annotated with 30,886 fine-grained pairwise preferences. Based on FGRestore, a comprehensive benchmark was conducted on the existing IQA metrics, which reveal significant inconsistencies between score-based IQA evaluations and the fine-grained restoration quality. Motivated by these findings, we further propose FGResQ, a new IQA model specifically designed for image restoration, which features both coarse-grained score regression and fine-grained quality ranking. Extensive experiments and comparisons demonstrate that FGResQ significantly outperforms state-of-the-art IQA metrics. Codes and model weights have been released in https://sxfly99.github.io/FGResQ-Homepage.",
    "published": "2025-08-20T06:58:32Z",
    "updated": "2025-11-17T02:08:08Z",
    "link": "http://arxiv.org/pdf/2508.14475v3.pdf",
    "category": [
      "eess.IV",
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Xiangfei Sheng",
      "Xiaofeng Pan",
      "Zhichao Yang",
      "Pengfei Chen",
      "Leida Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09611v2",
    "title": "MMaDA-Parallel: Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation",
    "summary": "While thinking-aware generation aims to improve performance on complex tasks, we identify a critical failure mode where existing sequential, autoregressive approaches can paradoxically degrade performance due to error propagation. To systematically analyze this issue, we propose ParaBench, a new benchmark designed to evaluate both text and image output modalities. Our analysis using ParaBench reveals that this performance degradation is strongly correlated with poor alignment between the generated reasoning and the final image. To resolve this, we propose a parallel multimodal diffusion framework, MMaDA-Parallel, that enables continuous, bidirectional interaction between text and images throughout the entire denoising trajectory. MMaDA-Parallel is trained with supervised finetuning and then further optimized by Parallel Reinforcement Learning (ParaRL), a novel strategy that applies semantic rewards along the trajectory to enforce cross-modal consistency. Experiments validate that our model significantly improves cross-modal alignment and semantic consistency, achieving a 6.9\\% improvement in Output Alignment on ParaBench compared to the state-of-the-art model, Bagel, establishing a more robust paradigm for thinking-aware image synthesis. Our code is open-sourced at https://github.com/tyfeld/MMaDA-Parallel",
    "published": "2025-11-12T18:58:21Z",
    "updated": "2025-11-17T02:05:46Z",
    "link": "http://arxiv.org/pdf/2511.09611v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ye Tian",
      "Ling Yang",
      "Jiongfan Yang",
      "Anran Wang",
      "Yu Tian",
      "Jiani Zheng",
      "Haochen Wang",
      "Zhiyang Teng",
      "Zhuochen Wang",
      "Yinjie Wang",
      "Yunhai Tong",
      "Mengdi Wang",
      "Xiangtai Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.02473v2",
    "title": "Generative Perception of Shape and Material from Differential Motion",
    "summary": "Perceiving the shape and material of an object from a single image is inherently ambiguous, especially when lighting is unknown and unconstrained. Despite this, humans can often disentangle shape and material, and when they are uncertain, they often move their head slightly or rotate the object to help resolve the ambiguities. Inspired by this behavior, we introduce a novel conditional denoising-diffusion model that generates samples of shape-and-material maps from a short video of an object undergoing differential motions. Our parameter-efficient architecture allows training directly in pixel-space, and it generates many disentangled attributes of an object simultaneously. Trained on a modest number of synthetic object-motion videos with supervision on shape and material, the model exhibits compelling emergent behavior: For static observations, it produces diverse, multimodal predictions of plausible shape-and-material maps that capture the inherent ambiguities; and when objects move, the distributions converge to more accurate explanations. The model also produces high-quality shape-and-material estimates for less ambiguous, real-world objects. By moving beyond single-view to continuous motion observations, and by using generative perception to capture visual ambiguities, our work suggests ways to improve visual reasoning in physically-embodied systems.",
    "published": "2025-06-03T05:43:20Z",
    "updated": "2025-11-17T02:00:36Z",
    "link": "http://arxiv.org/pdf/2506.02473v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xinran Nicole Han",
      "Ko Nishino",
      "Todd Zickler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12870v1",
    "title": "View-aware Cross-modal Distillation for Multi-view Action Recognition",
    "summary": "The widespread use of multi-sensor systems has increased research in multi-view action recognition. While existing approaches in multi-view setups with fully overlapping sensors benefit from consistent view coverage, partially overlapping settings where actions are visible in only a subset of views remain underexplored. This challenge becomes more severe in real-world scenarios, as many systems provide only limited input modalities and rely on sequence-level annotations instead of dense frame-level labels. In this study, we propose View-aware Cross-modal Knowledge Distillation (ViCoKD), a framework that distills knowledge from a fully supervised multi-modal teacher to a modality- and annotation-limited student. ViCoKD employs a cross-modal adapter with cross-modal attention, allowing the student to exploit multi-modal correlations while operating with incomplete modalities. Moreover, we propose a View-aware Consistency module to address view misalignment, where the same action may appear differently or only partially across viewpoints. It enforces prediction alignment when the action is co-visible across views, guided by human-detection masks and confidence-weighted Jensen-Shannon divergence between their predicted class distributions. Experiments on the real-world MultiSensor-Home dataset show that ViCoKD consistently outperforms competitive distillation methods across multiple backbones and environments, delivering significant gains and surpassing the teacher model under limited conditions.",
    "published": "2025-11-17T02:00:22Z",
    "updated": "2025-11-17T02:00:22Z",
    "link": "http://arxiv.org/pdf/2511.12870v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Trung Thanh Nguyen",
      "Yasutomo Kawanishi",
      "Vijay John",
      "Takahiro Komamizu",
      "Ichiro Ide"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2307.11470v6",
    "title": "Physics-Aware Semi-Supervised Underwater Image Enhancement",
    "summary": "Underwater images normally suffer from degradation due to the transmission medium of water bodies. Both traditional prior-based approaches and deep learning-based methods have been used to address this problem. However, the inflexible assumption of the former often impairs their effectiveness in handling diverse underwater scenes, while the generalization of the latter to unseen images is usually weakened by insufficient data. In this study, we leverage both the physics-based underwater Image Formation Model (IFM) and deep learning techniques for Underwater Image Enhancement (UIE). To this end, we propose a novel Physics-Aware Dual-Stream Underwater Image Enhancement Network, i.e., PA-UIENet, which comprises a Transmission Estimation Steam (T-Stream) and an Ambient Light Estimation Stream (A-Stream). This network fulfills the UIE task by explicitly estimating the degradation parameters of the IFM. We also adopt an IFM-inspired semi-supervised learning framework, which exploits both the labeled and unlabeled images, to address the issue of insufficient data. Our method performs better than, or at least comparably to, eight baselines across five testing sets in the degradation estimation and UIE tasks. This should be due to the fact that it not only can model the degradation but also can learn the characteristics of diverse underwater scenes.",
    "published": "2023-07-21T10:10:18Z",
    "updated": "2025-11-17T01:50:51Z",
    "link": "http://arxiv.org/pdf/2307.11470v6.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hao Qi",
      "Xinghui Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.07978v2",
    "title": "DANCE: Density-agnostic and Class-aware Network for Point Cloud Completion",
    "summary": "Point cloud completion aims to recover missing geometric structures from incomplete 3D scans, which often suffer from occlusions or limited sensor viewpoints. Existing methods typically assume fixed input/output densities or rely on image-based representations, making them less suitable for real-world scenarios with variable sparsity and limited supervision. In this paper, we introduce Density-agnostic and Class-aware Network (DANCE), a novel framework that completes only the missing regions while preserving the observed geometry. DANCE generates candidate points via ray-based sampling from multiple viewpoints. A transformer decoder then refines their positions and predicts opacity scores, which determine the validity of each point for inclusion in the final surface. To incorporate semantic guidance, a lightweight classification head is trained directly on geometric features, enabling category-consistent completion without external image supervision. Extensive experiments on the PCN and MVP benchmarks show that DANCE outperforms state-of-the-art methods in accuracy and structural consistency, while remaining robust to varying input densities and noise levels.",
    "published": "2025-11-11T08:45:06Z",
    "updated": "2025-11-17T01:28:46Z",
    "link": "http://arxiv.org/pdf/2511.07978v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Da-Yeong Kim",
      "Yeong-Jun Cho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.06298v3",
    "title": "SFFR: Spatial-Frequency Feature Reconstruction for Multispectral Aerial Object Detection",
    "summary": "Recent multispectral object detection methods have primarily focused on spatial-domain feature fusion based on CNNs or Transformers, while the potential of frequency-domain feature remains underexplored. In this work, we propose a novel Spatial and Frequency Feature Reconstruction method (SFFR) method, which leverages the spatial-frequency feature representation mechanisms of the Kolmogorov-Arnold Network (KAN) to reconstruct complementary representations in both spatial and frequency domains prior to feature fusion. The core components of SFFR are the proposed Frequency Component Exchange KAN (FCEKAN) module and Multi-Scale Gaussian KAN (MSGKAN) module. The FCEKAN introduces an innovative selective frequency component exchange strategy that effectively enhances the complementarity and consistency of cross-modal features based on the frequency feature of RGB and IR images. The MSGKAN module demonstrates excellent nonlinear feature modeling capability in the spatial domain. By leveraging multi-scale Gaussian basis functions, it effectively captures the feature variations caused by scale changes at different UAV flight altitudes, significantly enhancing the model's adaptability and robustness to scale variations. It is experimentally validated that our proposed FCEKAN and MSGKAN modules are complementary and can effectively capture the frequency and spatial semantic features respectively for better feature fusion. Extensive experiments on the SeaDroneSee, DroneVehicle and DVTOD datasets demonstrate the superior performance and significant advantages of the proposed method in UAV multispectral object perception task. Code will be available at https://github.com/qchenyu1027/SFFR.",
    "published": "2025-11-09T09:34:10Z",
    "updated": "2025-11-17T01:08:49Z",
    "link": "http://arxiv.org/pdf/2511.06298v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xin Zuo",
      "Chenyu Qu",
      "Haibo Zhan",
      "Jifeng Shen",
      "Wankou Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12853v1",
    "title": "BrainNormalizer: Anatomy-Informed Pseudo-Healthy Brain Reconstruction from Tumor MRI via Edge-Guided ControlNet",
    "summary": "Brain tumors are among the most clinically significant neurological diseases and remain a major cause of morbidity and mortality due to their aggressive growth and structural heterogeneity. As tumors expand, they induce substantial anatomical deformation that disrupts both local tissue organization and global brain architecture, complicating diagnosis, treatment planning, and surgical navigation. Yet a subject-specific reference of how the brain would appear without tumor-induced changes is fundamentally unobtainable in clinical practice. We present BrainNormalizer, an anatomy-informed diffusion framework that reconstructs pseudo-healthy MRIs directly from tumorous scans by conditioning the generative process on boundary cues extracted from the subject's own anatomy. This boundary-guided conditioning enables anatomically plausible pseudo-healthy reconstruction without requiring paired non-tumorous and tumorous scans. BrainNormalizer employs a two-stage training strategy. The pretrained diffusion model is first adapted through inpainting-based fine-tuning on tumorous and non-tumorous scans. Next, an edge-map-guided ControlNet branch is trained to inject fine-grained anatomical contours into the frozen decoder while preserving learned priors. During inference, a deliberate misalignment strategy pairs tumorous inputs with non-tumorous prompts and mirrored contralateral edge maps, leveraging hemispheric correspondence to guide reconstruction. On the BraTS2020 dataset, BrainNormalizer achieves strong quantitative performance and qualitatively produces anatomically plausible reconstructions in tumor-affected regions while retaining overall structural coherence. BrainNormalizer provides clinically reliable anatomical references for treatment planning and supports new research directions in counterfactual modeling and tumor-induced deformation analysis.",
    "published": "2025-11-17T00:48:30Z",
    "updated": "2025-11-17T00:48:30Z",
    "link": "http://arxiv.org/pdf/2511.12853v1.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Min Gu Kwak",
      "Yeonju Lee",
      "Hairong Wang",
      "Jing Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.17451v2",
    "title": "Subjective and Objective Quality Evaluation of Super-Resolution Enhanced Broadcast Images on a Novel SR-IQA Dataset",
    "summary": "Super-Resolution (SR) is essential for displaying low-quality broadcast content on high-resolution screens. Recently, SR methods have been developed that not only increase resolution while preserving the original image information but also enhance the perceived quality. However, evaluating the quality of SR images generated from low-quality sources, such as SR-enhanced broadcast content, is challenging due to the need to consider both distortions and improvements. Additionally, assessing SR image quality without original high-quality sources presents another significant challenge. Unfortunately, there has been a dearth of research specifically addressing the Image Quality Assessment (IQA) of SR images under these conditions. In this work, we introduce a new IQA dataset for SR broadcast images in both 2K and 4K resolutions. We conducted a subjective quality evaluation to obtain Mean Opinion Score (MOS) for these SR images and performed a comprehensive human study to identify key factors influencing perceived quality. Finally, we evaluated the performance of existing IQA metrics on our dataset. This study reveals the limitations of current metrics, highlighting the need for a more robust IQA metric that better correlates with the perceived quality of SR images. The proposed dataset and the subjective evaluation platform are publicly available at https://sites.google.com/hanyang.ac.kr/ivml/datasets/sreb.",
    "published": "2024-09-26T01:07:15Z",
    "updated": "2025-11-17T00:11:56Z",
    "link": "http://arxiv.org/pdf/2409.17451v2.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Yongrok Kim",
      "Junha Shin",
      "Juhyun Lee",
      "Hyunsuk Ko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.18875v2",
    "title": "Self-Supervised Learning Using Nonlinear Dependence",
    "summary": "Self-supervised learning has gained significant attention in contemporary applications, particularly due to the scarcity of labeled data. While existing SSL methodologies primarily address feature variance and linear correlations, they often neglect the intricate relations between samples and the nonlinear dependencies inherent in complex data--especially prevalent in high-dimensional visual data. In this paper, we introduce Correlation-Dependence Self-Supervised Learning (CDSSL), a novel framework that unifies and extends existing SSL paradigms by integrating both linear correlations and nonlinear dependencies, encapsulating sample-wise and feature-wise interactions. Our approach incorporates the Hilbert-Schmidt Independence Criterion (HSIC) to robustly capture nonlinear dependencies within a Reproducing Kernel Hilbert Space, enriching representation learning. Experimental evaluations on diverse benchmarks demonstrate the efficacy of CDSSL in improving representation quality.",
    "published": "2025-01-31T04:11:34Z",
    "updated": "2025-11-16T22:59:47Z",
    "link": "http://arxiv.org/pdf/2501.18875v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "authors": [
      "M. Hadi Sepanj",
      "Benyamin Ghojogh",
      "Paul Fieguth"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12801v1",
    "title": "Enhancing Neuro-Oncology Through Self-Assessing Deep Learning Models for Brain Tumor Unified Model for MRI Segmentation",
    "summary": "Accurate segmentation of brain tumors is vital for diagnosis, surgical planning, and treatment monitoring. Deep learning has advanced on benchmarks, but two issues limit clinical use: no uncertainty estimates for errors and no segmentation of healthy brain structures around tumors for surgery. Current methods fail to unify tumor localization with anatomical context and lack confidence scores. This study presents an uncertainty-aware framework augmenting nnUNet with a channel for voxel-wise uncertainty. Trained on BraTS2023, it yields a correlation of 0.750 and RMSD of 0.047 for uncertainty without hurting tumor accuracy. It predicts uncertainty in one pass, with no extra networks or inferences, aiding clinical decisions. For whole-brain context, a unified model combines normal and cancer datasets, achieving a DSC of 0.81 for brain structures and 0.86 for tumor, with robust key-region performance. Combining both innovations gives the first model outputting tumor in natural surroundings plus an overlaid uncertainty map. Visual checks of outputs show uncertainty offers key insights to evaluate predictions and fix errors, helping informed surgical decisions from AI.",
    "published": "2025-11-16T22:13:45Z",
    "updated": "2025-11-16T22:13:45Z",
    "link": "http://arxiv.org/pdf/2511.12801v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Andrew Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.08484v2",
    "title": "MeshCone: Second-Order Cone Programming for Geometrically-Constrained Mesh Enhancement",
    "summary": "Modern geometric generation methods rely heavily on deep learning methods that, while powerful, often lack interpretability and require extensive training data. This work introduces MeshCone, a convex optimization framework for mesh enhancement from partially deformed meshes that requires no training data. We formulate the problem as a second-order cone program where vertex positions are optimized to align with target geometry while enforcing smoothness through convex edge-length regularization. Our convex relaxation enables deterministic, interpretable solutions with proven convergence properties via the Splitting Conic Solver (SCS). We demonstrate robust performance across 56 diverse object categories from ShapeNet and ThreeDScans, achieving superior refinement quality compared to classical baselines while maintaining sub-second inference times. This work establishes a principled baseline demonstrating what convex optimization alone can achieve, providing mathematical guarantees and interpretability that complement data-driven approaches.",
    "published": "2024-12-11T15:48:25Z",
    "updated": "2025-11-16T22:03:02Z",
    "link": "http://arxiv.org/pdf/2412.08484v2.pdf",
    "category": [
      "cs.GR",
      "cs.CV",
      "math.OC"
    ],
    "authors": [
      "Alexander Valverde"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12767v1",
    "title": "RoCoISLR: A Romanian Corpus for Isolated Sign Language Recognition",
    "summary": "Automatic sign language recognition plays a crucial role in bridging the communication gap between deaf communities and hearing individuals; however, most available datasets focus on American Sign Language. For Romanian Isolated Sign Language Recognition (RoISLR), no large-scale, standardized dataset exists, which limits research progress. In this work, we introduce a new corpus for RoISLR, named RoCoISLR, comprising over 9,000 video samples that span nearly 6,000 standardized glosses from multiple sources. We establish benchmark results by evaluating seven state-of-the-art video recognition models-I3D, SlowFast, Swin Transformer, TimeSformer, Uniformer, VideoMAE, and PoseConv3D-under consistent experimental setups, and compare their performance with that of the widely used WLASL2000 corpus. According to the results, transformer-based architectures outperform convolutional baselines; Swin Transformer achieved a Top-1 accuracy of 34.1%. Our benchmarks highlight the challenges associated with long-tail class distributions in low-resource sign languages, and RoCoISLR provides the initial foundation for systematic RoISLR research.",
    "published": "2025-11-16T20:35:36Z",
    "updated": "2025-11-16T20:35:36Z",
    "link": "http://arxiv.org/pdf/2511.12767v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Cătălin-Alexandru Rîpanu",
      "Andrei-Theodor Hotnog",
      "Giulia-Stefania Imbrea",
      "Dumitru-Clementin Cercel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.16362v2",
    "title": "Almost Right: Making First-Layer Kernels Nearly Orthogonal Improves Model Generalization",
    "summary": "Despite several algorithmic advances in the training of convolutional neural networks (CNNs) over the years, their generalization capabilities are still subpar across several pertinent domains, particularly within open-set tasks often found in biometric and medical contexts. On the contrary, humans have an uncanny ability to generalize to unknown visual stimuli. The efficient coding hypothesis posits that early visual structures (retina, Lateral Geniculate Nucleus, and primary visual cortex) transform inputs to reduce redundancy and maximize information efficiency. This mechanism of redundancy minimization in early vision was the inspiration for CNN regularization techniques that force convolutional kernels to be orthogonal. However, the existing works rely upon matrix projections, architectural modifications, or specific weight initializations, which frequently overtly constrain the network's learning process and excessively increase the computational load during loss function calculation. In this paper, we introduce a flexible and lightweight approach that regularizes a subset of first-layer convolutional filters by making them pairwise-orthogonal, which reduces the redundancy of the extracted features but at the same time prevents putting excessive constraints on the network. We evaluate the proposed method on three open-set visual tasks (anomaly detection in chest X-ray images, synthetic face detection, and iris presentation attack detection) and observe an increase in the generalization capabilities of models trained with the proposed regularizer compared to state-of-the-art kernel orthogonalization approaches. We offer source codes along with the paper.",
    "published": "2025-04-23T02:27:20Z",
    "updated": "2025-11-16T19:55:56Z",
    "link": "http://arxiv.org/pdf/2504.16362v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Colton R. Crum",
      "Adam Czajka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.01317v2",
    "title": "A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model",
    "summary": "The rapid growth of deep learning has brought about powerful models that can handle various tasks, like identifying images and understanding language. However, adversarial attacks, an unnoticed alteration, can deceive models, leading to inaccurate predictions. In this paper, a generative adversarial attack method is proposed that uses the CLIP model to create highly effective and visually imperceptible adversarial perturbations. The CLIP model's ability to align text and image representation helps incorporate natural language semantics with a guided loss to generate effective adversarial examples that look identical to the original inputs. This integration allows extensive scene manipulation, creating perturbations in multi-object environments specifically designed to deceive multilabel classifiers. Our approach integrates the concentrated perturbation strategy from Saliency-based Auto-Encoder (SSAE) with the dissimilar text embeddings similar to Generative Adversarial Multi-Object Scene Attacks (GAMA), resulting in perturbations that both deceive classification models and maintain high structural similarity to the original images. The model was tested on various tasks across diverse black-box victim models. The experimental results show that our method performs competitively, achieving comparable or superior results to existing techniques, while preserving greater visual fidelity.",
    "published": "2025-11-03T08:02:48Z",
    "updated": "2025-11-16T19:27:44Z",
    "link": "http://arxiv.org/pdf/2511.01317v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Sampriti Soor",
      "Alik Pramanick",
      "Jothiprakash K",
      "Arijit Sur"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12744v1",
    "title": "SAGE: Saliency-Guided Contrastive Embeddings",
    "summary": "Integrating human perceptual priors into the training of neural networks has been shown to raise model generalization, serve as an effective regularizer, and align models with human expertise for applications in high-risk domains. Existing approaches to integrate saliency into model training often rely on internal model mechanisms, which recent research suggests may be unreliable. Our insight is that many challenges associated with saliency-guided training stem from the placement of the guidance approaches solely within the image space. Instead, we move away from the image space, use the model's latent space embeddings to steer human guidance during training, and we propose SAGE (Saliency-Guided Contrastive Embeddings): a loss function that integrates human saliency into network training using contrastive embeddings. We apply salient-preserving and saliency-degrading signal augmentations to the input and capture the changes in embeddings and model logits. We guide the model towards salient features and away from non-salient features using a contrastive triplet loss. Additionally, we perform a sanity check on the logit distributions to ensure that the model outputs match the saliency-based augmentations. We demonstrate a boost in classification performance across both open- and closed-set scenarios against SOTA saliency-based methods, showing SAGE's effectiveness across various backbones, and include experiments to suggest its wide generalization across tasks.",
    "published": "2025-11-16T19:19:59Z",
    "updated": "2025-11-16T19:19:59Z",
    "link": "http://arxiv.org/pdf/2511.12744v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Colton R. Crum",
      "Adam Czajka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12740v1",
    "title": "Deep Imbalanced Multi-Target Regression: 3D Point Cloud Voxel Content Estimation in Simulated Forests",
    "summary": "Voxelization is an effective approach to reduce the computational cost of processing Light Detection and Ranging (LiDAR) data, yet it results in a loss of fine-scale structural information. This study explores whether low-level voxel content information, specifically target occupancy percentage within a voxel, can be inferred from high-level voxelized LiDAR point cloud data collected from Digital Imaging and remote Sensing Image Generation (DIRSIG) software. In our study, the targets include bark, leaf, soil, and miscellaneous materials. We propose a multi-target regression approach in the context of imbalanced learning using Kernel Point Convolutions (KPConv). Our research leverages cost-sensitive learning to address class imbalance called density-based relevance (DBR). We employ weighted Mean Saquared Erorr (MSE), Focal Regression (FocalR), and regularization to improve the optimization of KPConv. This study performs a sensitivity analysis on the voxel size (0.25 - 2 meters) to evaluate the effect of various grid representations in capturing the nuances of the forest. This sensitivity analysis reveals that larger voxel sizes (e.g., 2 meters) result in lower errors due to reduced variability, while smaller voxel sizes (e.g., 0.25 or 0.5 meter) exhibit higher errors, particularly within the canopy, where variability is greatest. For bark and leaf targets, error values at smaller voxel size datasets (0.25 and 0.5 meter) were significantly higher than those in larger voxel size datasets (2 meters), highlighting the difficulty in accurately estimating within-canopy voxel content at fine resolutions. This suggests that the choice of voxel size is application-dependent. Our work fills the gap in deep imbalance learning models for multi-target regression and simulated datasets for 3D LiDAR point clouds of forests.",
    "published": "2025-11-16T19:14:13Z",
    "updated": "2025-11-16T19:14:13Z",
    "link": "http://arxiv.org/pdf/2511.12740v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Amirhossein Hassanzadeh",
      "Bartosz Krawczyk",
      "Michael Saunders",
      "Rob Wible",
      "Keith Krause",
      "Dimah Dera",
      "Jan van Aardt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12738v1",
    "title": "Direct Visual Grounding by Directing Attention of Visual Tokens",
    "summary": "Vision Language Models (VLMs) mix visual tokens and text tokens. A puzzling issue is the fact that visual tokens most related to the query receive little to no attention in the final layers of the LLM module of VLMs from the answer tokens, where all tokens are treated equally, in particular, visual and language tokens in the LLM attention layers. This fact may result in wrong answers to visual questions, as our experimental results confirm. It appears that the standard next-token prediction (NTP) loss provides an insufficient signal for directing attention to visual tokens. We hypothesize that a more direct supervision of the attention of visual tokens to corresponding language tokens in the LLM module of VLMs will lead to improved performance on visual tasks. To demonstrate that this is indeed the case, we propose a novel loss function that directly supervises the attention of visual tokens. It directly grounds the answer language tokens in images by directing their attention to the relevant visual tokens. This is achieved by aligning the attention distribution of visual tokens to ground truth attention maps with KL divergence. The ground truth attention maps are obtained from task geometry in synthetic cases or from standard grounding annotations (e.g., bounding boxes or point annotations) in real images, and are used inside the LLM for attention supervision without requiring new labels. The obtained KL attention loss (KLAL) when combined with NTP encourages VLMs to attend to relevant visual tokens while generating answer tokens. This results in notable improvements across geometric tasks, pointing, and referring expression comprehension on both synthetic and real-world data, as demonstrated by our experiments. We also introduce a new dataset to evaluate the line tracing abilities of VLMs. Surprisingly, even commercial VLMs do not perform well on this task.",
    "published": "2025-11-16T19:09:21Z",
    "updated": "2025-11-16T19:09:21Z",
    "link": "http://arxiv.org/pdf/2511.12738v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Parsa Esmaeilkhani",
      "Longin Jan Latecki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12735v1",
    "title": "Backdoor Attacks on Open Vocabulary Object Detectors via Multi-Modal Prompt Tuning",
    "summary": "Open-vocabulary object detectors (OVODs) unify vision and language to detect arbitrary object categories based on text prompts, enabling strong zero-shot generalization to novel concepts. As these models gain traction in high-stakes applications such as robotics, autonomous driving, and surveillance, understanding their security risks becomes crucial. In this work, we conduct the first study of backdoor attacks on OVODs and reveal a new attack surface introduced by prompt tuning. We propose TrAP (Trigger-Aware Prompt tuning), a multi-modal backdoor injection strategy that jointly optimizes prompt parameters in both image and text modalities along with visual triggers. TrAP enables the attacker to implant malicious behavior using lightweight, learnable prompt tokens without retraining the base model weights, thus preserving generalization while embedding a hidden backdoor. We adopt a curriculum-based training strategy that progressively shrinks the trigger size, enabling effective backdoor activation using small trigger patches at inference. Experiments across multiple datasets show that TrAP achieves high attack success rates for both object misclassification and object disappearance attacks, while also improving clean image performance on downstream datasets compared to the zero-shot setting.",
    "published": "2025-11-16T19:05:31Z",
    "updated": "2025-11-16T19:05:31Z",
    "link": "http://arxiv.org/pdf/2511.12735v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ankita Raj",
      "Chetan Arora"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13541v1",
    "title": "Graph Out-of-Distribution Detection via Test-Time Calibration with Dual Dynamic Dictionaries",
    "summary": "A key challenge in graph out-of-distribution (OOD) detection lies in the absence of ground-truth OOD samples during training. Existing methods are typically optimized to capture features within the in-distribution (ID) data and calculate OOD scores, which often limits pre-trained models from representing distributional boundaries, leading to unreliable OOD detection. Moreover, the latent structure of graph data is often governed by multiple underlying factors, which remains less explored. To address these challenges, we propose a novel test-time graph OOD detection method, termed BaCa, that calibrates OOD scores using dual dynamically updated dictionaries without requiring fine-tuning the pre-trained model. Specifically, BaCa estimates graphons and applies a mix-up strategy solely with test samples to generate diverse boundary-aware discriminative topologies, eliminating the need for exposing auxiliary datasets as outliers. We construct dual dynamic dictionaries via priority queues and attention mechanisms to adaptively capture latent ID and OOD representations, which are then utilized for boundary-aware OOD score calibration. To the best of our knowledge, extensive experiments on real-world datasets show that BaCa significantly outperforms existing state-of-the-art methods in OOD detection.",
    "published": "2025-11-17T16:14:48Z",
    "updated": "2025-11-17T16:14:48Z",
    "link": "http://arxiv.org/pdf/2511.13541v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yue Hou",
      "Ruomei Liu",
      "Yingke Su",
      "Junran Wu",
      "Ke Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13540v1",
    "title": "Fairness-Aware Graph Representation Learning with Limited Demographic Information",
    "summary": "Ensuring fairness in Graph Neural Networks is fundamental to promoting trustworthy and socially responsible machine learning systems. In response, numerous fair graph learning methods have been proposed in recent years. However, most of them assume full access to demographic information, a requirement rarely met in practice due to privacy, legal, or regulatory restrictions. To this end, this paper introduces a novel fair graph learning framework that mitigates bias in graph learning under limited demographic information. Specifically, we propose a mechanism guided by partial demographic data to generate proxies for demographic information and design a strategy that enforces consistent node embeddings across demographic groups. In addition, we develop an adaptive confidence strategy that dynamically adjusts each node's contribution to fairness and utility based on prediction confidence. We further provide theoretical analysis demonstrating that our framework, FairGLite, achieves provable upper bounds on group fairness metrics, offering formal guarantees for bias mitigation. Through extensive experiments on multiple datasets and fair graph learning frameworks, we demonstrate the framework's effectiveness in both mitigating bias and maintaining model utility.",
    "published": "2025-11-17T16:14:28Z",
    "updated": "2025-11-17T16:14:28Z",
    "link": "http://arxiv.org/pdf/2511.13540v1.pdf",
    "category": [
      "cs.LG",
      "cs.CY"
    ],
    "authors": [
      "Zichong Wang",
      "Zhipeng Yin",
      "Liping Yang",
      "Jun Zhuang",
      "Rui Yu",
      "Qingzhao Kong",
      "Wenbin Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13527v1",
    "title": "Mitigating Spurious Correlations in Patch-wise Tumor Classification on High-Resolution Multimodal Images",
    "summary": "Patch-wise multi-label classification provides an efficient alternative to full pixel-wise segmentation on high-resolution images, particularly when the objective is to determine the presence or absence of target objects within a patch rather than their precise spatial extent. This formulation substantially reduces annotation cost, simplifies training, and allows flexible patch sizing aligned with the desired level of decision granularity. In this work, we focus on a special case, patch-wise binary classification, applied to the detection of a single class of interest (tumor) on high-resolution multimodal nonlinear microscopy images. We show that, although this simplified formulation enables efficient model development, it can introduce spurious correlations between patch composition and labels: tumor patches tend to contain larger tissue regions, whereas non-tumor patches often consist mostly of background with small tissue areas. We further quantify the bias in model predictions caused by this spurious correlation, and propose to use a debiasing strategy to mitigate its effect. Specifically, we apply GERNE, a debiasing method that can be adapted to maximize worst-group accuracy (WGA). Our results show an improvement in WGA by approximately 7% compared to ERM for two different thresholds used to binarize the spurious feature. This enhancement boosts model performance on critical minority cases, such as tumor patches with small tissues and non-tumor patches with large tissues, and underscores the importance of spurious correlation-aware learning in patch-wise classification problems.",
    "published": "2025-11-17T16:01:30Z",
    "updated": "2025-11-17T16:01:30Z",
    "link": "http://arxiv.org/pdf/2511.13527v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ihab Asaad",
      "Maha Shadaydeh",
      "Joachim Denzler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.00846v2",
    "title": "On the emergence of numerical instabilities in Next Generation Reservoir Computing",
    "summary": "Next Generation Reservoir Computing (NGRC) is a low-cost machine learning method for forecasting chaotic time series from data. Computational efficiency is crucial for scalable reservoir computing, requiring better strategies to reduce training cost. In this work, we uncover a connection between the numerical conditioning of the NGRC feature matrix -- formed by polynomial evaluations on time-delay coordinates -- and the long-term NGRC dynamics. We show that NGRC can be trained without regularization, reducing computational time. Our contributions are twofold. First, merging tools from numerical linear algebra and ergodic theory of dynamical systems, we systematically study how the feature matrix conditioning varies across hyperparameters. We demonstrate that the NGRC feature matrix tends to be ill-conditioned for short time lags, high-degree polynomials, and short length of training data. Second, we evaluate the impact of different numerical algorithms (Cholesky, singular value decomposition (SVD), and lower-upper (LU) decomposition) for solving the regularized least-squares problem. Our results reveal that SVD-based training achieves accurate forecasts without regularization, being preferable when compared against the other algorithms.",
    "published": "2025-05-01T20:16:44Z",
    "updated": "2025-11-17T15:49:48Z",
    "link": "http://arxiv.org/pdf/2505.00846v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.DS",
      "physics.data-an"
    ],
    "authors": [
      "Edmilson Roque dos Santos",
      "Erik Bollt"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13514v1",
    "title": "A Quantum Tensor Network-Based Viewpoint for Modeling and Analysis of Time Series Data",
    "summary": "Accurate uncertainty quantification is a critical challenge in machine learning. While neural networks are highly versatile and capable of learning complex patterns, they often lack interpretability due to their ``black box'' nature. On the other hand, probabilistic ``white box'' models, though interpretable, often suffer from a significant performance gap when compared to neural networks. To address this, we propose a novel quantum physics-based ``white box'' method that offers both accurate uncertainty quantification and enhanced interpretability. By mapping the kernel mean embedding (KME) of a time series data vector to a reproducing kernel Hilbert space (RKHS), we construct a tensor network-inspired 1D spin chain Hamiltonian, with the KME as one of its eigen-functions or eigen-modes. We then solve the associated Schr{ö}dinger equation and apply perturbation theory to quantify uncertainty, thereby improving the interpretability of tasks performed with the quantum tensor network-based model. We demonstrate the effectiveness of this methodology, compared to state-of-the-art ``white box\" models, in change point detection and time series clustering, providing insights into the uncertainties associated with decision-making throughout the process.",
    "published": "2025-11-17T15:49:17Z",
    "updated": "2025-11-17T15:49:17Z",
    "link": "http://arxiv.org/pdf/2511.13514v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT"
    ],
    "authors": [
      "Pragatheeswaran Vipulananthan",
      "Kamal Premaratne",
      "Dilip Sarkar",
      "Manohar N. Murthi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13503v1",
    "title": "The Shape of Data: Topology Meets Analytics. A Practical Introduction to Topological Analytics and the Stability Index (TSI) in Business",
    "summary": "Modern business and economic datasets often exhibit nonlinear, multi-scale structures that traditional linear tools under-represent. Topological Data Analysis (TDA) offers a geometric lens for uncovering robust patterns, such as connected components, loops and voids, across scales. This paper provides an intuitive, figure-driven introduction to persistent homology and a practical, reproducible TDA pipeline for applied analysts. Through comparative case studies in consumer behavior, equity markets (SAX/eSAX vs.\\ TDA) and foreign exchange dynamics, we demonstrate how topological features can reveal segmentation patterns and structural relationships beyond classical statistical methods. We discuss methodological choices regarding distance metrics, complex construction and interpretation, and we introduce the \\textit{Topological Stability Index} (TSI), a simple yet interpretable indicator of structural variability derived from persistence lifetimes. We conclude with practical guidelines for TDA implementation, visualization and communication in business and economic analytics.",
    "published": "2025-11-17T15:41:11Z",
    "updated": "2025-11-17T15:41:11Z",
    "link": "http://arxiv.org/pdf/2511.13503v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "econ.EM",
      "stat.AP"
    ],
    "authors": [
      "Ioannis Diamantis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13497v1",
    "title": "Quantum Machine Learning via Contrastive Training",
    "summary": "Quantum machine learning (QML) has attracted growing interest with the rapid parallel advances in large-scale classical machine learning and quantum technologies. Similar to classical machine learning, QML models also face challenges arising from the scarcity of labeled data, particularly as their scale and complexity increase. Here, we introduce self-supervised pretraining of quantum representations that reduces reliance on labeled data by learning invariances from unlabeled examples. We implement this paradigm on a programmable trapped-ion quantum computer, encoding images as quantum states. In situ contrastive pretraining on hardware yields a representation that, when fine-tuned, classifies image families with higher mean test accuracy and lower run-to-run variability than models trained from random initialization. Performance improvement is especially significant in regimes with limited labeled training data. We show that the learned invariances generalize beyond the pretraining image samples. Unlike prior work, our pipeline derives similarity from measured quantum overlaps and executes all training and classification stages on hardware. These results establish a label-efficient route to quantum representation learning, with direct relevance to quantum-native datasets and a clear path to larger classical inputs.",
    "published": "2025-11-17T15:36:23Z",
    "updated": "2025-11-17T15:36:23Z",
    "link": "http://arxiv.org/pdf/2511.13497v1.pdf",
    "category": [
      "cs.LG",
      "quant-ph"
    ],
    "authors": [
      "Liudmila A. Zhukas",
      "Vivian Ni Zhang",
      "Qiang Miao",
      "Qingfeng Wang",
      "Marko Cetina",
      "Jungsang Kim",
      "Lawrence Carin",
      "Christopher Monroe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.17772v3",
    "title": "An Improved Privacy and Utility Analysis of Differentially Private SGD with Bounded Domain and Smooth Losses",
    "summary": "Differentially Private Stochastic Gradient Descent (DPSGD) is widely used to protect sensitive data during the training of machine learning models, but its privacy guarantee often comes at a large cost of model performance due to the lack of tight theoretical bounds quantifying privacy loss. While recent efforts have achieved more accurate privacy guarantees, they still impose some assumptions prohibited from practical applications, such as convexity and complex parameter requirements, and rarely investigate in-depth the impact of privacy mechanisms on the model's utility. In this paper, we provide a rigorous privacy characterization for DPSGD with general L-smooth and non-convex loss functions, revealing converged privacy loss with iteration in bounded-domain cases. Specifically, we track the privacy loss over multiple iterations, leveraging the noisy smooth-reduction property, and further establish comprehensive convergence analysis in different scenarios. In particular, we show that for DPSGD with a bounded domain, (i) the privacy loss can still converge without the convexity assumption, (ii) a smaller bounded diameter can improve both privacy and utility simultaneously under certain conditions, and (iii) the attainable big-O order of the privacy utility trade-off for DPSGD with gradient clipping (DPSGD-GC) and for DPSGD-GC with bounded domain (DPSGD-DC) and mu-strongly convex population risk function, respectively. Experiments via membership inference attack (MIA) in a practical setting validate insights gained from the theoretical results.",
    "published": "2025-02-25T02:05:41Z",
    "updated": "2025-11-17T15:28:55Z",
    "link": "http://arxiv.org/pdf/2502.17772v3.pdf",
    "category": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "authors": [
      "Hao Liang",
      "Wanrong Zhang",
      "Xinlei He",
      "Kaishun Wu",
      "Hong Xing"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13487v1",
    "title": "Systematic evaluation of time-frequency features for binaural sound source localization",
    "summary": "This study presents a systematic evaluation of time-frequency feature design for binaural sound source localization (SSL), focusing on how feature selection influences model performance across diverse conditions. We investigate the performance of a convolutional neural network (CNN) model using various combinations of amplitude-based features (magnitude spectrogram, interaural level difference - ILD) and phase-based features (phase spectrogram, interaural phase difference - IPD). Evaluations on in-domain and out-of-domain data with mismatched head-related transfer functions (HRTFs) reveal that carefully chosen feature combinations often outperform increases in model complexity. While two-feature sets such as ILD + IPD are sufficient for in-domain SSL, generalization to diverse content requires richer inputs combining channel spectrograms with both ILD and IPD. Using the optimal feature sets, our low-complexity CNN model achieves competitive performance. Our findings underscore the importance of feature design in binaural SSL and provide practical guidance for both domain-specific and general-purpose localization.",
    "published": "2025-11-17T15:25:49Z",
    "updated": "2025-11-17T15:25:49Z",
    "link": "http://arxiv.org/pdf/2511.13487v1.pdf",
    "category": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ],
    "authors": [
      "Davoud Shariat Panah",
      "Alessandro Ragano",
      "Dan Barry",
      "Jan Skoglund",
      "Andrew Hines"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.18332v6",
    "title": "Early Classification of Time Series: A Survey and Benchmark",
    "summary": "In many situations, the measurements of a studied phenomenon are provided sequentially, and the prediction of its class needs to be made as early as possible so as not to incur too high a time penalty, but not too early and risk paying the cost of misclassification. This problem has been particularly studied in the case of time series, and is known as Early Classification of Time Series (ECTS). Although it has been the subject of a growing body of literature, there is still a lack of a systematic, shared evaluation protocol to compare the relative merits of the various existing methods. In this paper, we highlight the two components of an ECTS system: decision and prediction, and focus on the approaches that separate them. This document begins by situating these methods within a principle-based taxonomy. It defines dimensions for organizing their evaluation and then reports the results of a very extensive set of experiments along these dimensions involving nine state-of-the-art ECTS algorithms. In addition, these and other experiments can be carried out using an open-source library in which most of the existing ECTS algorithms have been implemented (see https://github.com/ML-EDM/ml_edm).",
    "published": "2024-06-26T13:21:00Z",
    "updated": "2025-11-17T15:13:34Z",
    "link": "http://arxiv.org/pdf/2406.18332v6.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Aurélien Renault",
      "Alexis Bondu",
      "Antoine Cornuéjols",
      "Vincent Lemaire"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13469v1",
    "title": "GREAT: Generalizable Representation Enhancement via Auxiliary Transformations for Zero-Shot Environmental Prediction",
    "summary": "Environmental modeling faces critical challenges in predicting ecosystem dynamics across unmonitored regions due to limited and geographically imbalanced observation data. This challenge is compounded by spatial heterogeneity, causing models to learn spurious patterns that fit only local data. Unlike conventional domain generalization, environmental modeling must preserve invariant physical relationships and temporal coherence during augmentation. In this paper, we introduce Generalizable Representation Enhancement via Auxiliary Transformations (GREAT), a framework that effectively augments available datasets to improve predictions in completely unseen regions. GREAT guides the augmentation process to ensure that the original governing processes can be recovered from the augmented data, and the inclusion of the augmented data leads to improved model generalization. Specifically, GREAT learns transformation functions at multiple layers of neural networks to augment both raw environmental features and temporal influence. They are refined through a novel bi-level training process that constrains augmented data to preserve key patterns of the original source data. We demonstrate GREAT's effectiveness on stream temperature prediction across six ecologically diverse watersheds in the eastern U.S., each containing multiple stream segments. Experimental results show that GREAT significantly outperforms existing methods in zero-shot scenarios. This work provides a practical solution for environmental applications where comprehensive monitoring is infeasible.",
    "published": "2025-11-17T15:11:03Z",
    "updated": "2025-11-17T15:11:03Z",
    "link": "http://arxiv.org/pdf/2511.13469v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Shiyuan Luo",
      "Chonghao Qiu",
      "Runlong Yu",
      "Yiqun Xie",
      "Xiaowei Jia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13465v1",
    "title": "AdamX: An Adam improvement algorithm based on a novel exponential decay mechanism for the second-order moment estimate",
    "summary": "Since the 21st century, artificial intelligence has been leading a new round of industrial revolution. Under the training framework, the optimization algorithm aims to stably converge high-dimensional optimization to local and even global minima. Entering the era of large language models, although the scale of model parameters and data has increased, Adam remains the mainstream optimization algorithm. However, compared with stochastic gradient descent (SGD) based optimization algorithms, Adam is more likely to converge to non-flat minima. To address this issue, the AdamX algorithm is proposed. Its core innovation lies in the proposition of a novel type of second-order moment estimation exponential decay rate, which gradually weakens the learning step correction strength as training progresses, and degrades to SGD in the stable training period, thereby improving the stability of training in the stable period and possibly enhancing generalization ability. Experimental results show that our second-order moment estimation exponential decay rate is better than the current second-order moment estimation exponential decay rate, and AdamX can stably outperform Adam and its variants in terms of performance. Our code is open-sourced at https://github.com/mengzhu0308/AdamX.",
    "published": "2025-11-17T15:07:55Z",
    "updated": "2025-11-17T15:07:55Z",
    "link": "http://arxiv.org/pdf/2511.13465v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Meng Zhu",
      "Quan Xiao",
      "Weidong Min"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.15813v2",
    "title": "Meta-Learning an In-Context Transformer Model of Human Higher Visual Cortex",
    "summary": "Understanding functional representations within higher visual cortex is a fundamental question in computational neuroscience. While artificial neural networks pretrained on large-scale datasets exhibit striking representational alignment with human neural responses, learning image-computable models of visual cortex relies on individual-level, large-scale fMRI datasets. The necessity for expensive, time-intensive, and often impractical data acquisition limits the generalizability of encoders to new subjects and stimuli. BraInCoRL uses in-context learning to predict voxelwise neural responses from few-shot examples without any additional finetuning for novel subjects and stimuli. We leverage a transformer architecture that can flexibly condition on a variable number of in-context image stimuli, learning an inductive bias over multiple subjects. During training, we explicitly optimize the model for in-context learning. By jointly conditioning on image features and voxel activations, our model learns to directly generate better performing voxelwise models of higher visual cortex. We demonstrate that BraInCoRL consistently outperforms existing voxelwise encoder designs in a low-data regime when evaluated on entirely novel images, while also exhibiting strong test-time scaling behavior. The model also generalizes to an entirely new visual fMRI dataset, which uses different subjects and fMRI data acquisition parameters. Further, BraInCoRL facilitates better interpretability of neural signals in higher visual cortex by attending to semantically relevant stimuli. Finally, we show that our framework enables interpretable mappings from natural language queries to voxel selectivity.",
    "published": "2025-05-21T17:59:41Z",
    "updated": "2025-11-17T15:03:27Z",
    "link": "http://arxiv.org/pdf/2505.15813v2.pdf",
    "category": [
      "cs.LG",
      "q-bio.NC"
    ],
    "authors": [
      "Muquan Yu",
      "Mu Nan",
      "Hossein Adeli",
      "Jacob S. Prince",
      "John A. Pyles",
      "Leila Wehbe",
      "Margaret M. Henderson",
      "Michael J. Tarr",
      "Andrew F. Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13453v1",
    "title": "Hardware optimization on Android for inference of AI models",
    "summary": "The pervasive integration of Artificial Intelligence models into contemporary mobile computing is notable across numerous use cases, from virtual assistants to advanced image processing. Optimizing the mobile user experience involves minimal latency and high responsiveness from deployed AI models with challenges from execution strategies that fully leverage real time constraints to the exploitation of heterogeneous hardware architecture. In this paper, we research and propose the optimal execution configurations for AI models on an Android system, focusing on two critical tasks: object detection (YOLO family) and image classification (ResNet). These configurations evaluate various model quantization schemes and the utilization of on device accelerators, specifically the GPU and NPU. Our core objective is to empirically determine the combination that achieves the best trade-off between minimal accuracy degradation and maximal inference speed-up.",
    "published": "2025-11-17T14:58:15Z",
    "updated": "2025-11-17T14:58:15Z",
    "link": "http://arxiv.org/pdf/2511.13453v1.pdf",
    "category": [
      "cs.LG",
      "cs.PF"
    ],
    "authors": [
      "Iulius Gherasim",
      "Carlos García Sánchez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.18184v2",
    "title": "Learning Operators by Regularized Stochastic Gradient Descent with Operator-valued Kernels",
    "summary": "We consider a class of statistical inverse problems involving the estimation of a regression operator from a Polish space to a separable Hilbert space, where the target lies in a vector-valued reproducing kernel Hilbert space induced by an operator-valued kernel. To address the associated ill-posedness, we analyze regularized stochastic gradient descent (SGD) algorithms in both online and finite-horizon settings. The former uses polynomially decaying step sizes and regularization parameters, while the latter adopts fixed values. Under suitable structural and distributional assumptions, we establish dimension-independent bounds for prediction and estimation errors. The resulting convergence rates are near-optimal in expectation, and we also derive high-probability estimates that imply almost sure convergence. Our analysis introduces a general technique for obtaining high-probability guarantees in infinite-dimensional settings. Possible extensions to broader kernel classes and encoder-decoder structures are briefly discussed.",
    "published": "2025-04-25T08:57:38Z",
    "updated": "2025-11-17T14:56:43Z",
    "link": "http://arxiv.org/pdf/2504.18184v2.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.FA",
      "math.ST"
    ],
    "authors": [
      "Jia-Qi Yang",
      "Lei Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.17067v2",
    "title": "Convergence of Regret Matching in Potential Games and Constrained Optimization",
    "summary": "Regret matching (RM) -- and its modern variants -- is a foundational online algorithm that has been at the heart of many AI breakthrough results in solving benchmark zero-sum games, such as poker. Yet, surprisingly little is known so far in theory about its convergence beyond two-player zero-sum games. For example, whether regret matching converges to Nash equilibria in potential games has been an open problem for two decades. Even beyond games, one could try to use RM variants for general constrained optimization problems. Recent empirical evidence suggests that they -- particularly regret matching$^+$ (RM$^+$) -- attain strong performance on benchmark constrained optimization problems, outperforming traditional gradient descent-type algorithms.\n  We show that RM$^+$ converges to an $ε$-KKT point after $O_ε(1/ε^4)$ iterations, establishing for the first time that it is a sound and fast first-order optimizer. Our argument relates the KKT gap to the accumulated regret, two quantities that are entirely disparate in general but interact in an intriguing way in our setting, so much so that when regrets are bounded, our complexity bound improves all the way to $O_ε(1/ε^2)$. From a technical standpoint, while RM$^+$ does not have the usual one-step improvement property in general, we show that it does in a certain region that the algorithm will quickly reach and remain in thereafter. In sharp contrast, our second main result establishes a lower bound: RM, with or without alternation, can take an exponential number of iterations to reach a crude approximate solution even in two-player potential games. This represents the first worst-case separation between RM and RM$^+$. Our lower bound shows that convergence to coarse correlated equilibria in potential games is exponentially faster than convergence to Nash equilibria.",
    "published": "2025-10-20T00:45:47Z",
    "updated": "2025-11-17T14:55:00Z",
    "link": "http://arxiv.org/pdf/2510.17067v2.pdf",
    "category": [
      "cs.GT",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Ioannis Anagnostides",
      "Emanuel Tewolde",
      "Brian Hu Zhang",
      "Ioannis Panageas",
      "Vincent Conitzer",
      "Tuomas Sandholm"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.10644v2",
    "title": "Conditional Information Bottleneck for Multimodal Fusion: Overcoming Shortcut Learning in Sarcasm Detection",
    "summary": "Multimodal sarcasm detection is a complex task that requires distinguishing subtle complementary signals across modalities while filtering out irrelevant information. Many advanced methods rely on learning shortcuts from datasets rather than extracting intended sarcasm-related features. However, our experiments show that shortcut learning impairs the model's generalization in real-world scenarios. Furthermore, we reveal the weaknesses of current modality fusion strategies for multimodal sarcasm detection through systematic experiments, highlighting the necessity of focusing on effective modality fusion for complex emotion recognition. To address these challenges, we construct MUStARD++$^{R}$ by removing shortcut signals from MUStARD++. Then, a Multimodal Conditional Information Bottleneck (MCIB) model is introduced to enable efficient multimodal fusion for sarcasm detection. Experimental results show that the MCIB achieves the best performance without relying on shortcut learning.",
    "published": "2025-08-14T13:39:03Z",
    "updated": "2025-11-17T14:45:06Z",
    "link": "http://arxiv.org/pdf/2508.10644v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yihua Wang",
      "Qi Jia",
      "Cong Xu",
      "Feiyu Chen",
      "Yuhan Liu",
      "Haotian Zhang",
      "Liang Jin",
      "Lu Liu",
      "Zhichun Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21020v4",
    "title": "NeuralOM: Neural Ocean Model for Subseasonal-to-Seasonal Simulation",
    "summary": "Long-term, high-fidelity simulation of slow-changing physical systems, such as the ocean and climate, presents a fundamental challenge in scientific computing. Traditional autoregressive machine learning models often fail in these tasks as minor errors accumulate and lead to rapid forecast degradation. To address this problem, we propose NeuralOM, a general neural operator framework designed for simulating complex, slow-changing dynamics. NeuralOM's core consists of two key innovations: (1) a Progressive Residual Correction Framework that decomposes the forecasting task into a series of fine-grained refinement steps, effectively suppressing long-term error accumulation; and (2) a Physics-Guided Graph Network whose built-in adaptive messaging mechanism explicitly models multi-scale physical interactions, such as gradient-driven flows and multiplicative couplings, thereby enhancing physical consistency while maintaining computational efficiency. We validate NeuralOM on the challenging task of global Subseasonal-to-Seasonal (S2S) ocean simulation. Extensive experiments demonstrate that NeuralOM not only surpasses state-of-the-art models in forecast accuracy and long-term stability, but also excels in simulating extreme events. For instance, at a 60-day lead time, NeuralOM achieves a 13.3% lower RMSE compared to the best-performing baseline, offering a stable, efficient, and physically-aware paradigm for data-driven scientific computing. Code link: https://github.com/YuanGao-YG/NeuralOM.",
    "published": "2025-05-27T10:54:40Z",
    "updated": "2025-11-17T14:40:20Z",
    "link": "http://arxiv.org/pdf/2505.21020v4.pdf",
    "category": [
      "cs.LG",
      "physics.ao-ph"
    ],
    "authors": [
      "Yuan Gao",
      "Hao Wu",
      "Fan Xu",
      "Yanfei Xiang",
      "Ruijian Gou",
      "Ruiqi Shu",
      "Qingsong Wen",
      "Xian Wu",
      "Kun Wang",
      "Xiaomeng Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13421v1",
    "title": "Larger Datasets Can Be Repeated More: A Theoretical Analysis of Multi-Epoch Scaling in Linear Regression",
    "summary": "While data scaling laws of large language models (LLMs) have been widely examined in the one-pass regime with massive corpora, their form under limited data and repeated epochs remains largely unexplored. This paper presents a theoretical analysis of how a common workaround, training for multiple epochs on the same dataset, reshapes the data scaling laws in linear regression. Concretely, we ask: to match the performance of training on a dataset of size $N$ for $K$ epochs, how much larger must a dataset be if the model is trained for only one pass? We quantify this using the \\textit{effective reuse rate} of the data, $E(K, N)$, which we define as the multiplicative factor by which the dataset must grow under one-pass training to achieve the same test loss as $K$-epoch training. Our analysis precisely characterizes the scaling behavior of $E(K, N)$ for SGD in linear regression under either strong convexity or Zipf-distributed data: (1) When $K$ is small, we prove that $E(K, N) \\approx K$, indicating that every new epoch yields a linear gain; (2) As $K$ increases, $E(K, N)$ plateaus at a problem-dependent value that grows with $N$ ($Θ(\\log N)$ for the strongly-convex case), implying that larger datasets can be repeated more times before the marginal benefit vanishes. These theoretical findings point out a neglected factor in a recent empirical study (Muennighoff et al. (2023)), which claimed that training LLMs for up to $4$ epochs results in negligible loss differences compared to using fresh data at each step, \\textit{i.e.}, $E(K, N) \\approx K$ for $K \\le 4$ in our notation. Supported by further empirical validation with LLMs, our results reveal that the maximum $K$ value for which $E(K, N) \\approx K$ in fact depends on the data size and distribution, and underscore the need to explicitly model both factors in future studies of scaling laws with data reuse.",
    "published": "2025-11-17T14:34:03Z",
    "updated": "2025-11-17T14:34:03Z",
    "link": "http://arxiv.org/pdf/2511.13421v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Tingkai Yan",
      "Haodong Wen",
      "Binghui Li",
      "Kairong Luo",
      "Wenguang Chen",
      "Kaifeng Lyu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13419v1",
    "title": "MMWSTM-ADRAN+: A Novel Hybrid Deep Learning Architecture for Enhanced Climate Time Series Forecasting and Extreme Event Prediction",
    "summary": "Accurate short-range prediction of extreme air temperature events remains a fundamental challenge in operational climate-risk management. We present Multi-Modal Weather State Transition Model with Anomaly-Driven Recurrent Attention Network Plus (MMWSTM-ADRAN+), a dual-stream deep learning architecture that couples a regime-aware dynamics model with an anomaly-focused attention mechanism to forecast daily maximum temperature and its extremes. The first stream, MMWSTM, combines bidirectional Long Short-Term Memory (BiLSTM) units with a learnable Markov state transition matrix to capture synoptic-scale weather regime changes. The second stream, ADRAN, integrates bidirectional Gated Recurrent Units (BiGRUs), multi-head self-attention, and a novel anomaly amplification layer to enhance sensitivity to low-probability signals. A lightweight attentive fusion gate adaptively determines the contribution of each stream to the final prediction. Model optimization employs a custom ExtremeWeatherLoss function that up-weights errors on the upper 5% and lower 5% of the temperature distribution, and a time-series data augmentation suite (jittering, scaling, time/magnitude warping) that effectively quadruples the training data",
    "published": "2025-11-17T14:31:54Z",
    "updated": "2025-11-17T14:31:54Z",
    "link": "http://arxiv.org/pdf/2511.13419v1.pdf",
    "category": [
      "cs.LG",
      "physics.ao-ph"
    ],
    "authors": [
      "Shaheen Mohammed Saleh Ahmed",
      "Hakan Hakan Guneyli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13408v1",
    "title": "Taming Barren Plateaus in Arbitrary Parameterized Quantum Circuits Without Sacrificing Expressibility",
    "summary": "Quantum algorithms based on parameterized quantum circuits (PQCs) have enabled a wide range of applications on near-term quantum devices. However, existing PQC architectures face several challenges, among which the ``barren plateaus\" phenomenon is particularly prominent. In such cases, the loss function concentrates exponentially with increasing system size, thereby hindering effective parameter optimization. To address this challenge, we propose a general and hardware-efficient method for eliminating barren plateaus in an arbitrary PQC. Specifically, our approach achieves this by inserting a layer of easily implementable quantum channels into the original PQC, each channel requiring only one ancilla qubit and four additional gates, yielding a modified PQC (MPQC) that is provably at least as expressive as the original PQC and, under mild assumptions, is guaranteed to be free from barren plateaus. Furthermore, by appropriately adjusting the structure of MPQCs, we rigorously prove that any parameter in the original PQC can be made trainable. Importantly, the absence of barren plateaus in MPQCs is robust against realistic noise, making our approach directly applicable to current noisy intermediate-scale quantum (NISQ) hardware. Numerically, we demonstrate the practicality of our method by modifying a commonly used PQC for thermal-state preparation. The results show that {barren plateaus are effectively eliminated} in this class of circuits with up to 100 qubits and 2400 layers, whereas the original ansatz suffers from severe gradient vanishing.",
    "published": "2025-11-17T14:21:43Z",
    "updated": "2025-11-17T14:21:43Z",
    "link": "http://arxiv.org/pdf/2511.13408v1.pdf",
    "category": [
      "quant-ph",
      "cs.CC",
      "cs.IT",
      "cs.LG"
    ],
    "authors": [
      "Zhenyu Chen",
      "Yuguo Shao",
      "Zhengwei Liu",
      "Zhaohui Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13394v1",
    "title": "Fast and Robust Simulation-Based Inference With Optimization Monte Carlo",
    "summary": "Bayesian parameter inference for complex stochastic simulators is challenging due to intractable likelihood functions. Existing simulation-based inference methods often require large number of simulations and become costly to use in high-dimensional parameter spaces or in problems with partially uninformative outputs. We propose a new method for differentiable simulators that delivers accurate posterior inference with substantially reduced runtimes. Building on the Optimization Monte Carlo framework, our approach reformulates stochastic simulation as deterministic optimization problems. Gradient-based methods are then applied to efficiently navigate toward high-density posterior regions and avoid wasteful simulations in low-probability areas. A JAX-based implementation further enhances the performance through vectorization of key method components. Extensive experiments, including high-dimensional parameter spaces, uninformative outputs, multiple observations and multimodal posteriors show that our method consistently matches, and often exceeds, the accuracy of state-of-the-art approaches, while reducing the runtime by a substantial margin.",
    "published": "2025-11-17T14:07:36Z",
    "updated": "2025-11-17T14:07:36Z",
    "link": "http://arxiv.org/pdf/2511.13394v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Vasilis Gkolemis",
      "Christos Diou",
      "Michael Gutmann"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13389v1",
    "title": "Uncovering Causal Drivers of Energy Efficiency for Industrial Process in Foundry via Time-Series Causal Inference",
    "summary": "Improving energy efficiency in industrial foundry processes is a critical challenge, as these operations are highly energy-intensive and marked by complex interdependencies among process variables. Correlation-based analyses often fail to distinguish true causal drivers from spurious associations, limiting their usefulness for decision-making. This paper applies a time-series causal inference framework to identify the operational factors that directly affect energy efficiency in induction furnace melting. Using production data from a Danish foundry, the study integrates time-series clustering to segment melting cycles into distinct operational modes with the PCMCI+ algorithm, a state-of-the-art causal discovery method, to uncover cause-effect relationships within each mode. Across clusters, robust causal relations among energy consumption, furnace temperature, and material weight define the core drivers of efficiency, while voltage consistently influences cooling water temperature with a delayed response. Cluster-specific differences further distinguish operational regimes: efficient clusters are characterized by stable causal structures, whereas inefficient ones exhibit reinforcing feedback loops and atypical dependencies. The contributions of this study are twofold. First, it introduces an integrated clustering-causal inference pipeline as a methodological innovation for analyzing energy-intensive processes. Second, it provides actionable insights that enable foundry operators to optimize performance, reduce energy consumption, and lower emissions.",
    "published": "2025-11-17T14:00:00Z",
    "updated": "2025-11-17T14:00:00Z",
    "link": "http://arxiv.org/pdf/2511.13389v1.pdf",
    "category": [
      "cs.IR",
      "cs.LG"
    ],
    "authors": [
      "Zhipeng Ma",
      "Bo Nørregaard Jørgensen",
      "Zheng Grace Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.19276v3",
    "title": "Quantum Neural Networks in Practice: A Comparative Study with Classical Models from Standard Data Sets to Industrial Images",
    "summary": "We compare the performance of randomized classical and quantum neural networks (NNs) as well as classical and quantum-classical hybrid convolutional neural networks (CNNs) for the task of supervised binary image classification. We keep the employed quantum circuits compatible with near-term quantum devices and use two distinct methodologies: applying randomized NNs on dimensionality-reduced data and applying CNNs to full image data. We evaluate these approaches on three fully-classical data sets of increasing complexity: an artificial hypercube data set, MNIST handwritten digits and industrial images. Our central goal is to shed more light on how quantum and classical models perform for various binary classification tasks and on what defines a good quantum model. Our study involves a correlation analysis between classification accuracy and quantum model hyperparameters, and an analysis on the role of entanglement in quantum models, as well as on the impact of initial training parameters. We find classical and quantum-classical hybrid models achieve statistically-equivalent classification accuracies across most data sets with no approach consistently outperforming the other. Interestingly, we observe that quantum NNs show lower variance with respect to initial training parameters and that the role of entanglement is nuanced. While incorporating entangling gates seems advantageous, we also observe the (optimizable) entangling power not to be correlated with model performance. We also observe an inverse proportionality between the number of entangling gates and the average gate entangling power. Our study provides an industry perspective on quantum machine learning for binary image classification tasks, highlighting both limitations and potential avenues for further research in quantum circuit design, entanglement utilization, and model transferability across varied applications.",
    "published": "2024-11-28T17:13:45Z",
    "updated": "2025-11-17T13:56:53Z",
    "link": "http://arxiv.org/pdf/2411.19276v3.pdf",
    "category": [
      "quant-ph",
      "cs.LG"
    ],
    "authors": [
      "Daniel Basilewitsch",
      "João F. Bravo",
      "Christian Tutschku",
      "Frederick Struckmeier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04102v2",
    "title": "Why Cannot Neural Networks Master Extrapolation? Insights from Physical Laws",
    "summary": "Motivated by the remarkable success of Foundation Models (FMs) in language modeling, there has been growing interest in developing FMs for time series prediction, given the transformative power such models hold for science and engineering. This culminated in significant success of FMs in short-range forecasting settings. However, extrapolation or long-range forecasting remains elusive for FMs, which struggle to outperform even simple baselines. This contrasts with physical laws which have strong extrapolation properties, and raises the question of the fundamental difference between the structure of neural networks and physical laws. In this work, we identify and formalize a fundamental property characterizing the ability of statistical learning models to predict more accurately outside of their training domain, hence explaining performance deterioration for deep learning models in extrapolation settings. In addition to a theoretical analysis, we present empirical results showcasing the implications of this property on current deep learning architectures. Our results not only clarify the root causes of the extrapolation gap but also suggest directions for designing next-generation forecasting models capable of mastering extrapolation.",
    "published": "2025-10-05T09:07:25Z",
    "updated": "2025-11-17T13:49:32Z",
    "link": "http://arxiv.org/pdf/2510.04102v2.pdf",
    "category": [
      "cs.LG",
      "math.NA",
      "math.PR"
    ],
    "authors": [
      "Ramzi Dakhmouche",
      "Hossein Gorji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04108v2",
    "title": "Can Linear Probes Measure LLM Uncertainty?",
    "summary": "Effective Uncertainty Quantification (UQ) represents a key aspect for reliable deployment of Large Language Models (LLMs) in automated decision-making and beyond. Yet, for LLM generation with multiple choice structure, the state-of-the-art in UQ is still dominated by the naive baseline given by the maximum softmax score. To address this shortcoming, we demonstrate that taking a principled approach via Bayesian statistics leads to improved performance despite leveraging the simplest possible model, namely linear regression. More precisely, we propose to train multiple Bayesian linear models, each predicting the output of a layer given the output of the previous one. Based on the obtained layer-level posterior distributions, we infer the global uncertainty level of the LLM by identifying a sparse combination of distributional features, leading to an efficient UQ scheme. Numerical experiments on various LLMs show consistent improvement over state-of-the-art baselines.",
    "published": "2025-10-05T09:14:57Z",
    "updated": "2025-11-17T13:43:43Z",
    "link": "http://arxiv.org/pdf/2510.04108v2.pdf",
    "category": [
      "cs.LG",
      "math.NA",
      "math.ST"
    ],
    "authors": [
      "Ramzi Dakhmouche",
      "Adrien Letellier",
      "Hossein Gorji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09144v2",
    "title": "Practical Global and Local Bounds in Gaussian Process Regression via Chaining",
    "summary": "Gaussian process regression (GPR) is a popular nonparametric Bayesian method that provides predictive uncertainty estimates and is widely used in safety-critical applications. While prior research has introduced various uncertainty bounds, most existing approaches require access to specific input features, and rely on posterior mean and variance estimates or the tuning of hyperparameters. These limitations hinder robustness and fail to capture the model's global behavior in expectation. To address these limitations, we propose a chaining-based framework for estimating upper and lower bounds on the expected extreme values over unseen data, without requiring access to specific input features. We provide kernel-specific refinements for commonly used kernels such as RBF and Matérn, in which our bounds are tighter than generic constructions. We further improve numerical tightness by avoiding analytical relaxations. In addition to global estimation, we also develop a novel method for local uncertainty quantification at specified inputs. This approach leverages chaining geometry through partition diameters, adapting to local structures without relying on posterior variance scaling. Our experimental results validate the theoretical findings and demonstrate that our method outperforms existing approaches on both synthetic and real-world datasets.",
    "published": "2025-11-12T09:30:01Z",
    "updated": "2025-11-17T13:26:40Z",
    "link": "http://arxiv.org/pdf/2511.09144v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Junyi Liu",
      "Stanley Kok"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.18720v2",
    "title": "Appa: Bending Weather Dynamics with Latent Diffusion Models for Global Data Assimilation",
    "summary": "Deep learning has advanced weather forecasting, but accurate predictions first require identifying the current state of the atmosphere from observational data. In this work, we introduce Appa, a score-based data assimilation model generating global atmospheric trajectories at 0.25\\si{\\degree} resolution and 1-hour intervals. Powered by a 565M-parameter latent diffusion model trained on ERA5, Appa can be conditioned on arbitrary observations to infer plausible trajectories, without retraining. Our probabilistic framework handles reanalysis, filtering, and forecasting, within a single model, producing physically consistent reconstructions from various inputs. Results establish latent score-based data assimilation as a promising foundation for future global atmospheric modeling systems.",
    "published": "2025-04-25T22:14:29Z",
    "updated": "2025-11-17T13:14:33Z",
    "link": "http://arxiv.org/pdf/2504.18720v2.pdf",
    "category": [
      "cs.LG",
      "physics.ao-ph"
    ],
    "authors": [
      "Gérôme Andry",
      "Sacha Lewin",
      "François Rozet",
      "Omer Rochman",
      "Victor Mangeleer",
      "Matthias Pirlet",
      "Elise Faulx",
      "Marilaure Grégoire",
      "Gilles Louppe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13339v1",
    "title": "Statistically Accurate and Robust Generative Prediction of Rock Discontinuities with A Tabular Foundation Model",
    "summary": "Rock discontinuities critically govern the mechanical behavior and stability of rock masses. Their internal distributions remain largely unobservable and are typically inferred from surface-exposed discontinuities using generative prediction approaches. However, surface-exposed observations are inherently sparse, and existing generative prediction approaches either fail to capture the underlying complex distribution patterns or lack robustness under data-sparse conditions. Here, we proposed a simple yet robust approach for statistically accurate generative prediction of rock discontinuities by utilizing a tabular foundation model. By leveraging the powerful sample learning capability of the foundation model specifically designed for small data, our approach can effectively capture the underlying complex distribution patterns within limited measured discontinuities. Comparative experiments on ten datasets with diverse scales and distribution patterns of discontinuities demonstrate superior accuracy and robustness over conventional statistical models and deep generative approaches. This work advances quantitative characterization of rock mass structures, supporting safer and more reliable data-driven geotechnical design.",
    "published": "2025-11-17T13:09:53Z",
    "updated": "2025-11-17T13:09:53Z",
    "link": "http://arxiv.org/pdf/2511.13339v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Han Meng",
      "Gang Mei",
      "Hong Tian",
      "Nengxiong Xu",
      "Jianbing Peng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13338v1",
    "title": "Tab-PET: Graph-Based Positional Encodings for Tabular Transformers",
    "summary": "Supervised learning with tabular data presents unique challenges, including low data sizes, the absence of structural cues, and heterogeneous features spanning both categorical and continuous domains. Unlike vision and language tasks, where models can exploit inductive biases in the data, tabular data lacks inherent positional structure, hindering the effectiveness of self-attention mechanisms. While recent transformer-based models like TabTransformer, SAINT, and FT-Transformer (which we refer to as 3T) have shown promise on tabular data, they typically operate without leveraging structural cues such as positional encodings (PEs), as no prior structural information is usually available. In this work, we find both theoretically and empirically that structural cues, specifically PEs can be a useful tool to improve generalization performance for tabular transformers. We find that PEs impart the ability to reduce the effective rank (a form of intrinsic dimensionality) of the features, effectively simplifying the task by reducing the dimensionality of the problem, yielding improved generalization. To that end, we propose Tab-PET (PEs for Tabular Transformers), a graph-based framework for estimating and inculcating PEs into embeddings. Inspired by approaches that derive PEs from graph topology, we explore two paradigms for graph estimation: association-based and causality-based. We empirically demonstrate that graph-derived PEs significantly improve performance across 50 classification and regression datasets for 3T. Notably, association-based graphs consistently yield more stable and pronounced gains compared to causality-driven ones. Our work highlights an unexpected role of PEs in tabular transformers, revealing how they can be harnessed to improve generalization.",
    "published": "2025-11-17T13:08:34Z",
    "updated": "2025-11-17T13:08:34Z",
    "link": "http://arxiv.org/pdf/2511.13338v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yunze Leng",
      "Rohan Ghosh",
      "Mehul Motani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16817v2",
    "title": "Trace Regularity PINNs: Enforcing $\\mathrm{H}^{\\frac{1}{2}}(\\partial Ω)$ for Boundary Data",
    "summary": "We propose an enhanced physics-informed neural network (PINN), the Trace Regularity Physics-Informed Neural Network (TRPINN), which enforces the boundary loss in the Sobolev-Slobodeckij norm $H^{1/2}(\\partial Ω)$, the correct trace space associated with $H^1(Ω)$. We reduce computational cost by computing only the theoretically essential portion of the semi-norm and enhance convergence stability by avoiding denominator evaluations in the discretization. By incorporating the exact $H^{1/2}(\\partial Ω)$ norm, we show that the approximation converges to the true solution in the $H^{1}(Ω)$ sense, and, through Neural Tangent Kernel (NTK) analysis, we demonstrate that TRPINN can converge faster than standard PINNs. Numerical experiments on the Laplace equation with highly oscillatory Dirichlet boundary conditions exhibit cases where TRPINN succeeds even when standard PINNs fail, and show performance improvements of one to three decimal digits.",
    "published": "2025-10-19T13:08:16Z",
    "updated": "2025-11-17T13:05:51Z",
    "link": "http://arxiv.org/pdf/2510.16817v2.pdf",
    "category": [
      "cs.LG",
      "math.AP"
    ],
    "authors": [
      "Doyoon Kim",
      "Junbin Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.04715v5",
    "title": "Causality Pursuit from Heterogeneous Environments via Neural Adversarial Invariance Learning",
    "summary": "Pursuing causality from data is a fundamental problem in scientific discovery, treatment intervention, and transfer learning. This paper introduces a novel algorithmic method for addressing nonparametric invariance and causality learning in regression models across multiple environments, where the joint distribution of response variables and covariates varies, but the conditional expectations of outcome given an unknown set of quasi-causal variables are invariant. The challenge of finding such an unknown set of quasi-causal or invariant variables is compounded by the presence of endogenous variables that have heterogeneous effects across different environments. The proposed Focused Adversarial Invariant Regularization (FAIR) framework utilizes an innovative minimax optimization approach that drives regression models toward prediction-invariant solutions through adversarial testing. Leveraging the representation power of neural networks, FAIR neural networks (FAIR-NN) are introduced for causality pursuit. It is shown that FAIR-NN can find the invariant variables and quasi-causal variables under a minimal identification condition and that the resulting procedure is adaptive to low-dimensional composition structures in a non-asymptotic analysis. Under a structural causal model, variables identified by FAIR-NN represent pragmatic causality and provably align with exact causal mechanisms under conditions of sufficient heterogeneity. Computationally, FAIR-NN employs a novel Gumbel approximation with decreased temperature and a stochastic gradient descent ascent algorithm. The procedures are demonstrated using simulated and real-data examples.",
    "published": "2024-05-07T23:37:40Z",
    "updated": "2025-11-17T13:05:01Z",
    "link": "http://arxiv.org/pdf/2405.04715v5.pdf",
    "category": [
      "math.ST",
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "authors": [
      "Yihong Gu",
      "Cong Fang",
      "Peter Bühlmann",
      "Jianqing Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.11411v3",
    "title": "Robust-Multi-Task Gradient Boosting",
    "summary": "Multi-task learning (MTL) has shown effectiveness in exploiting shared information across tasks to improve generalization. MTL assumes tasks share similarities that can improve performance. In addition, boosting algorithms have demonstrated exceptional performance across diverse learning problems, primarily due to their ability to focus on hard-to-learn instances and iteratively reduce residual errors. This makes them a promising approach for learning multi-task problems. However, real-world MTL scenarios often involve tasks that are not well-aligned (known as outlier or adversarial tasks), which do not share beneficial similarities with others and can, in fact, deteriorate the performance of the overall model. To overcome this challenge, we propose Robust-Multi-Task Gradient Boosting (R-MTGB), a novel boosting framework that explicitly models and adapts to task heterogeneity during training. R-MTGB structures the learning process into three sequential blocks: (1) learning shared patterns, (2) partitioning tasks into outliers and non-outliers with regularized parameters, and (3) fine-tuning task-specific predictors. This architecture enables R-MTGB to automatically detect and penalize outlier tasks while promoting effective knowledge transfer among related tasks. Our method integrates these mechanisms seamlessly within gradient boosting, allowing robust handling of noisy or adversarial tasks without sacrificing accuracy. Extensive experiments on both synthetic benchmarks and real-world datasets demonstrate that our approach successfully isolates outliers, transfers knowledge, and consistently reduces prediction errors for each task individually, and achieves overall performance gains across all tasks. These results highlight robustness, adaptability, and reliable convergence of R-MTGB in challenging MTL environments.",
    "published": "2025-07-15T15:31:12Z",
    "updated": "2025-11-17T12:50:24Z",
    "link": "http://arxiv.org/pdf/2507.11411v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Seyedsaman Emami",
      "Gonzalo Martínez-Muñoz",
      "Daniel Hernández-Lobato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.03806v2",
    "title": "Certified Coil Geometry Learning for Short-Range Magnetic Actuation and Spacecraft Docking Application",
    "summary": "This paper presents a learning-based framework for approximating an exact magnetic-field interaction model, supported by both numerical and experimental validation. High-fidelity magnetic-field interaction modeling is essential for achieving exceptional accuracy and responsiveness across a wide range of fields, including transportation, energy systems, medicine, biomedical robotics, and aerospace robotics. In aerospace engineering, magnetic actuation has been investigated as a fuel-free solution for multi-satellite attitude and formation control. Although the exact magnetic field can be computed from the Biot-Savart law, the associated computational cost is prohibitive, and prior studies have therefore relied on dipole approximations to improve efficiency. However, these approximations lose accuracy during proximity operations, leading to unstable behavior and even collisions. To address this limitation, we develop a learning-based approximation framework that faithfully reproduces the exact field while dramatically reducing computational cost. The proposed method additionally provides a certified error bound, derived from the number of training samples, ensuring reliable prediction accuracy. The learned model can also accommodate interactions between coils of different sizes through appropriate geometric transformations, without retraining. To verify the effectiveness of the proposed framework under challenging conditions, a spacecraft docking scenario is examined through both numerical simulations and experimental validation.",
    "published": "2025-07-04T20:54:30Z",
    "updated": "2025-11-17T12:36:41Z",
    "link": "http://arxiv.org/pdf/2507.03806v2.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Yuta Takahashi",
      "Hayate Tajima",
      "Shin-ichiro Sakai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13295v1",
    "title": "Causal Inference, Biomarker Discovery, Graph Neural Network, Feature Selection",
    "summary": "Biomarker discovery from high-throughput transcriptomic data is crucial for advancing precision medicine. However, existing methods often neglect gene-gene regulatory relationships and lack stability across datasets, leading to conflation of spurious correlations with genuine causal effects. To address these issues, we develop a causal graph neural network (Causal-GNN) method that integrates causal inference with multi-layer graph neural networks (GNNs). The key innovation is the incorporation of causal effect estimation for identifying stable biomarkers, coupled with a GNN-based propensity scoring mechanism that leverages cross-gene regulatory networks. Experimental results demonstrate that our method achieves consistently high predictive accuracy across four distinct datasets and four independent classifiers. Moreover, it enables the identification of more stable biomarkers compared to traditional methods. Our work provides a robust, efficient, and biologically interpretable tool for biomarker discovery, demonstrating strong potential for broad application across medical disciplines.",
    "published": "2025-11-17T12:16:20Z",
    "updated": "2025-11-17T12:16:20Z",
    "link": "http://arxiv.org/pdf/2511.13295v1.pdf",
    "category": [
      "q-bio.QM",
      "cs.LG"
    ],
    "authors": [
      "Chaowang Lan",
      "Jingxin Wu",
      "Yulong Yuan",
      "Chuxun Liu",
      "Huangyi Kang",
      "Caihua Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.02423v2",
    "title": "Time-Series-Informed Closed-loop Learning for Sequential Decision Making and Control",
    "summary": "Closed-loop performance of sequential decision making algorithms, such as model predictive control, depends strongly on the choice of controller parameters. Bayesian optimization allows learning of parameters from closed-loop experiments, but standard Bayesian optimization treats this as a black-box problem and ignores the temporal structure of closed-loop trajectories, leading to slow convergence and inefficient use of experimental resources. We propose a time-series-informed multi-fidelity Bayesian optimization framework that aligns the fidelity dimension with closed-loop time, enabling intermediate performance evaluations within a closed-loop experiment to be incorporated as lower-fidelity observations. Additionally, we derive probabilistic early stopping criteria to terminate unpromising closed-loop experiments based on the surrogate model's posterior belief, avoiding full episodes for poor parameterizations and thereby reducing resource usage. Simulation results on a nonlinear control benchmark demonstrate that, compared to standard black-box Bayesian optimization approaches, the proposed method achieves comparable closed-loop performance with roughly half the experimental resources, and yields better final performance when using the same resource budget, highlighting the value of exploiting temporal structure for sample-efficient closed-loop controller tuning.",
    "published": "2024-12-03T12:38:53Z",
    "updated": "2025-11-17T11:41:27Z",
    "link": "http://arxiv.org/pdf/2412.02423v2.pdf",
    "category": [
      "eess.SY",
      "cs.LG"
    ],
    "authors": [
      "Sebastian Hirt",
      "Lukas Theiner",
      "Rolf Findeisen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13262v1",
    "title": "Case study of a differentiable heterogeneous multiphysics solver for a nuclear fusion application",
    "summary": "This work presents a case study of a heterogeneous multiphysics solver from the nuclear fusion domain. At the macroscopic scale, an auto-differentiable ODE solver in JAX computes the evolution of the pulsed power circuit and bulk plasma parameters for a compressing Z Pinch. The ODE solver requires a closure for the impedance of the plasma load obtained via root-finding at every timestep, which we solve efficiently using gradient-based Newton iteration. However, incorporating non-differentiable production-grade plasma solvers like Gkeyll (a C/CUDA plasma simulation suite) into a gradient-based workflow is non-trivial. The ''Tesseract'' software addresses this challenge by providing a multi-physics differentiable abstraction layer made fully compatible with JAX (through the `tesseract_jax` adapter). This architecture ensures end-to-end differentiability while allowing seamless interchange between high-fidelity solvers (Gkeyll), neural surrogates, and analytical approximations for rapid, progressive prototyping.",
    "published": "2025-11-17T11:23:16Z",
    "updated": "2025-11-17T11:23:16Z",
    "link": "http://arxiv.org/pdf/2511.13262v1.pdf",
    "category": [
      "physics.comp-ph",
      "cs.CE",
      "cs.LG",
      "cs.MS",
      "physics.plasm-ph"
    ],
    "authors": [
      "Jack B. Coughlin",
      "Archis Joglekar",
      "Jonathan Brodrick",
      "Alexander Lavin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.01956v2",
    "title": "EXAGREE: Mitigating Explanation Disagreement with Stakeholder-Aligned Models",
    "summary": "Conflicting explanations, arising from different attribution methods or model internals, limit the adoption of machine learning models in safety-critical domains. We turn this disagreement into an advantage and introduce EXplanation AGREEment (EXAGREE), a two-stage framework that selects a Stakeholder-Aligned Explanation Model (SAEM) from a set of similar-performing models. The selection maximizes Stakeholder-Machine Agreement (SMA), a single metric that unifies faithfulness and plausibility. EXAGREE couples a differentiable mask-based attribution network (DMAN) with monotone differentiable sorting, enabling gradient-based search inside the constrained model space. Experiments on six real-world datasets demonstrate simultaneous gains of faithfulness, plausibility, and fairness over baselines, while preserving task accuracy. Extensive ablation studies, significance tests, and case studies confirm the robustness and feasibility of the method in practice.",
    "published": "2024-11-04T10:28:38Z",
    "updated": "2025-11-17T11:11:28Z",
    "link": "http://arxiv.org/pdf/2411.01956v2.pdf",
    "category": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "authors": [
      "Sichao Li",
      "Tommy Liu",
      "Quanling Deng",
      "Amanda S. Barnard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13250v1",
    "title": "Edge-aware baselines for ogbn-proteins in PyTorch Geometric: species-wise normalization, post-hoc calibration, and cost-accuracy trade-offs",
    "summary": "We present reproducible, edge-aware baselines for ogbn-proteins in PyTorch Geometric (PyG). We study two system choices that dominate practice: (i) how 8-dimensional edge evidence is aggregated into node inputs, and (ii) how edges are used inside message passing. Our strongest baseline is GraphSAGE with sum-based edge-to-node features. We compare LayerNorm (LN), BatchNorm (BN), and a species-aware Conditional LayerNorm (CLN), and report compute cost (time, VRAM, parameters) together with accuracy (ROC-AUC) and decision quality. In our primary experimental setup (hidden size 512, 3 layers, 3 seeds), sum consistently beats mean and max; BN attains the best AUC, while CLN matches the AUC frontier with better thresholded F1. Finally, post-hoc per-label temperature scaling plus per-label thresholds substantially improves micro-F1 and expected calibration error (ECE) with negligible AUC change, and light label-correlation smoothing yields small additional gains. We release standardized artifacts and scripts used for all of the runs presented in the paper.",
    "published": "2025-11-17T11:09:46Z",
    "updated": "2025-11-17T11:09:46Z",
    "link": "http://arxiv.org/pdf/2511.13250v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Aleksandar Stanković",
      "Dejan Lisica"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13240v1",
    "title": "Incoherent Beliefs & Inconsistent Actions in Large Language Models",
    "summary": "Real-world tasks and environments exhibit differences from the static datasets that large language models (LLMs) are typically evaluated on. Such tasks can involve sequential interaction, requiring coherent updating of beliefs in light of new evidence, and making appropriate decisions based on those beliefs. Predicting how LLMs will perform in such dynamic environments is important, but can be tricky to determine from measurements in static settings. In this work, we examine two critical components of LLM performance: the ability of LLMs to coherently update their beliefs, and the extent to which the actions they take are consistent with those beliefs. First, we find that LLMs are largely inconsistent in how they update their beliefs; models can exhibit up to a 30% average difference between the directly elicited posterior, and the correct update of their prior. Second, we find that LLMs also often take actions which are inconsistent with the beliefs they hold. On a betting market, for example, LLMs often do not even bet in the same direction as their internally held beliefs over the underlying outcomes. We also find they have moderate self-inconsistency in how they respond to challenges by users to given answers. Finally, we show that the above properties hold even for strong models that obtain high accuracy or that are well-calibrated on the tasks at hand. Our results highlight the difficulties of predicting LLM behavior in complex real-world settings.",
    "published": "2025-11-17T11:04:00Z",
    "updated": "2025-11-17T11:04:00Z",
    "link": "http://arxiv.org/pdf/2511.13240v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Arka Pal",
      "Teo Kitanovski",
      "Arthur Liang",
      "Akilesh Potti",
      "Micah Goldblum"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13237v1",
    "title": "Counterfactual Explainable AI (XAI) Method for Deep Learning-Based Multivariate Time Series Classification",
    "summary": "Recent advances in deep learning have improved multivariate time series (MTS) classification and regression by capturing complex patterns, but their lack of transparency hinders decision-making. Explainable AI (XAI) methods offer partial insights, yet often fall short of conveying the full decision space. Counterfactual Explanations (CE) provide a promising alternative, but current approaches typically prioritize either accuracy, proximity or sparsity -- rarely all -- limiting their practical value. To address this, we propose CONFETTI, a novel multi-objective CE method for MTS. CONFETTI identifies key MTS subsequences, locates a counterfactual target, and optimally modifies the time series to balance prediction confidence, proximity and sparsity. This method provides actionable insights with minimal changes, improving interpretability, and decision support. CONFETTI is evaluated on seven MTS datasets from the UEA archive, demonstrating its effectiveness in various domains. CONFETTI consistently outperforms state-of-the-art CE methods in its optimization objectives, and in six other metrics from the literature, achieving $\\geq10\\%$ higher confidence while improving sparsity in $\\geq40\\%$.",
    "published": "2025-11-17T11:00:43Z",
    "updated": "2025-11-17T11:00:43Z",
    "link": "http://arxiv.org/pdf/2511.13237v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Alan G. Paredes Cetina",
      "Kaouther Benguessoum",
      "Raoni Lourenço",
      "Sylvain Kubler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13234v1",
    "title": "MorphBoost: Self-Organizing Universal Gradient Boosting with Adaptive Tree Morphing",
    "summary": "Traditional gradient boosting algorithms employ static tree structures with fixed splitting criteria that remain unchanged throughout training, limiting their ability to adapt to evolving gradient distributions and problem-specific characteristics across different learning stages. This work introduces MorphBoost, a new gradient boosting framework featuring self-organizing tree structures that dynamically morph their splitting behavior during training. The algorithm implements adaptive split functions that evolve based on accumulated gradient statistics and iteration-dependent learning pressures, enabling automatic adjustment to problem complexity. Key innovations include: (1) morphing split criterion combining gradient-based scores with information-theoretic metrics weighted by training progress; (2) automatic problem fingerprinting for intelligent parameter configuration across binary/multiclass/regression tasks; (3) vectorized tree prediction achieving significant computational speedups; (4) interaction-aware feature importance detecting multiplicative relationships; and (5) fast-mode optimization balancing speed and accuracy. Comprehensive benchmarking across 10 diverse datasets against competitive models (XGBoost, LightGBM, GradientBoosting, HistGradientBoosting, ensemble methods) demonstrates that MorphBoost achieves state-of-the-art performance, outperforming XGBoost by 0.84% on average. MorphBoost secured the overall winner position with 4/10 dataset wins (40% win rate) and 6/30 top-3 finishes (20%), while maintaining the lowest variance (σ=0.0948) and highest minimum accuracy across all models, revealing superior consistency and robustness. Performance analysis across difficulty levels shows competitive results on easy datasets while achieving notable improvements on advanced problems due to higher adaptation levels.",
    "published": "2025-11-17T10:54:01Z",
    "updated": "2025-11-17T10:54:01Z",
    "link": "http://arxiv.org/pdf/2511.13234v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Boris Kriuk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13229v1",
    "title": "Laplace Learning in Wasserstein Space",
    "summary": "The manifold hypothesis posits that high-dimensional data typically resides on low-dimensional sub spaces. In this paper, we assume manifold hypothesis to investigate graph-based semi-supervised learning\n  methods. In particular, we examine Laplace Learning in the Wasserstein space, extending the classical\n  notion of graph-based semi-supervised learning algorithms from finite-dimensional Euclidean spaces to\n  an infinite-dimensional setting. To achieve this, we prove variational convergence of a discrete graph p- Dirichlet energy to its continuum counterpart. In addition, we characterize the Laplace-Beltrami operator\n  on asubmanifold of the Wasserstein space. Finally, we validate the proposed theoretical framework through\n  numerical experiments conducted on benchmark datasets, demonstrating the consistency of our classification performance in high-dimensional settings.",
    "published": "2025-11-17T10:49:36Z",
    "updated": "2025-11-17T10:49:36Z",
    "link": "http://arxiv.org/pdf/2511.13229v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Mary Chriselda Antony Oliver",
      "Michael Roberts",
      "Carola-Bibiane Schönlieb",
      "Matthew Thorpe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13221v1",
    "title": "Likelihood-guided Regularization in Attention Based Models",
    "summary": "The transformer architecture has demonstrated strong performance in classification tasks involving structured and high-dimensional data. However, its success often hinges on large- scale training data and careful regularization to prevent overfitting. In this paper, we intro- duce a novel likelihood-guided variational Ising-based regularization framework for Vision Transformers (ViTs), which simultaneously enhances model generalization and dynamically prunes redundant parameters. The proposed variational Ising-based regularization approach leverages Bayesian sparsification techniques to impose structured sparsity on model weights, allowing for adaptive architecture search during training. Unlike traditional dropout-based methods, which enforce fixed sparsity patterns, the variational Ising-based regularization method learns task-adaptive regularization, improving both efficiency and interpretability. We evaluate our approach on benchmark vision datasets, including MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100, demonstrating improved generalization under sparse, complex data and allowing for principled uncertainty quantification on both weights and selection parameters. Additionally, we show that the Ising regularizer leads to better-calibrated probability estimates and structured feature selection through uncertainty-aware attention mechanisms. Our results highlight the effectiveness of structured Bayesian sparsification in enhancing transformer-based architectures, offering a principled alternative to standard regularization techniques.",
    "published": "2025-11-17T10:38:09Z",
    "updated": "2025-11-17T10:38:09Z",
    "link": "http://arxiv.org/pdf/2511.13221v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Mohamed Salem",
      "Inyoung Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.08361v3",
    "title": "Upper Bounds for Learning in Reproducing Kernel Hilbert Spaces for Non IID Samples",
    "summary": "In this paper, we study a Markov chain-based stochastic gradient algorithm in general Hilbert spaces, aiming to approximate the optimal solution of a quadratic loss function. We establish probabilistic upper bounds on its convergence. We further extend these results to an online regularized learning algorithm in reproducing kernel Hilbert spaces, where the samples are drawn along a Markov chain trajectory hence the samples are of the non i.i.d. type.",
    "published": "2024-10-10T20:34:22Z",
    "updated": "2025-11-17T10:07:47Z",
    "link": "http://arxiv.org/pdf/2410.08361v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.FA"
    ],
    "authors": [
      "Priyanka Roy",
      "Susanne Saminger-Platz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13186v1",
    "title": "DiffFP: Learning Behaviors from Scratch via Diffusion-based Fictitious Play",
    "summary": "Self-play reinforcement learning has demonstrated significant success in learning complex strategic and interactive behaviors in competitive multi-agent games. However, achieving such behaviors in continuous decision spaces remains challenging. Ensuring adaptability and generalization in self-play settings is critical for achieving competitive performance in dynamic multi-agent environments. These challenges often cause methods to converge slowly or fail to converge at all to a Nash equilibrium, making agents vulnerable to strategic exploitation by unseen opponents. To address these challenges, we propose DiffFP, a fictitious play (FP) framework that estimates the best response to unseen opponents while learning a robust and multimodal behavioral policy. Specifically, we approximate the best response using a diffusion policy that leverages generative modeling to learn adaptive and diverse strategies. Through empirical evaluation, we demonstrate that the proposed FP framework converges towards $ε$-Nash equilibria in continuous- space zero-sum games. We validate our method on complex multi-agent environments, including racing and multi-particle zero-sum games. Simulation results show that the learned policies are robust against diverse opponents and outperform baseline reinforcement learning policies. Our approach achieves up to 3$\\times$ faster convergence and 30$\\times$ higher success rates on average against RL-based baselines, demonstrating its robustness to opponent strategies and stability across training iterations",
    "published": "2025-11-17T09:48:29Z",
    "updated": "2025-11-17T09:48:29Z",
    "link": "http://arxiv.org/pdf/2511.13186v1.pdf",
    "category": [
      "cs.LG",
      "eess.SY"
    ],
    "authors": [
      "Akash Karthikeyan",
      "Yash Vardhan Pant"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13185v1",
    "title": "Uncertainty-aware Physics-informed Neural Networks for Robust CARS-to-Raman Signal Reconstruction",
    "summary": "Coherent anti-Stokes Raman scattering (CARS) spectroscopy is a powerful and rapid technique widely used in medicine, material science, and chemical analyses. However, its effectiveness is hindered by the presence of a non-resonant background that interferes with and distorts the true Raman signal. Deep learning methods have been employed to reconstruct the true Raman spectrum from measured CARS data using labeled datasets. A more recent development integrates the domain knowledge of Kramers-Kronig relationships and smoothness constraints in the form of physics-informed loss functions. However, these deterministic models lack the ability to quantify uncertainty, an essential feature for reliable deployment in high-stakes scientific and biomedical applications. In this work, we evaluate and compare various uncertainty quantification (UQ) techniques within the context of CARS-to-Raman signal reconstruction. Furthermore, we demonstrate that incorporating physics-informed constraints into these models improves their calibration, offering a promising path toward more trustworthy CARS data analysis.",
    "published": "2025-11-17T09:46:15Z",
    "updated": "2025-11-17T09:46:15Z",
    "link": "http://arxiv.org/pdf/2511.13185v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Aishwarya Venkataramanan",
      "Sai Karthikeya Vemuri",
      "Adithya Ashok Chalain Valapil",
      "Joachim Denzler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.18921v3",
    "title": "GLANCE: Global Actions in a Nutshell for Counterfactual Explainability",
    "summary": "The widespread deployment of machine learning systems in critical real-world decision-making applications has highlighted the urgent need for counterfactual explainability methods that operate effectively. Global counterfactual explanations, expressed as actions to offer recourse, aim to provide succinct explanations and insights applicable to large population subgroups. High effectiveness, measured by the fraction of the population that is provided recourse, ensures that the actions benefit as many individuals as possible. Keeping the cost of actions low ensures the proposed recourse actions remain practical and actionable. Limiting the number of actions that provide global counterfactuals is essential to maximizing interpretability. The primary challenge, therefore, is to balance these trade-offs--maximizing effectiveness, minimizing cost, while maintaining a small number of actions. We introduce $\\texttt{GLANCE}$, a versatile and adaptive algorithm that employs a novel agglomerative approach, jointly considering both the feature space and the space of counterfactual actions, thereby accounting for the distribution of points in a way that aligns with the model's structure. This design enables the careful balancing of the trade-offs among the three key objectives, with the size objective functioning as a tunable parameter to keep the actions few and easy to interpret. Our extensive experimental evaluation demonstrates that $\\texttt{GLANCE}$ consistently shows greater robustness and performance compared to existing methods across various datasets and models.",
    "published": "2024-05-29T09:24:25Z",
    "updated": "2025-11-17T09:44:58Z",
    "link": "http://arxiv.org/pdf/2405.18921v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Loukas Kavouras",
      "Eleni Psaroudaki",
      "Konstantinos Tsopelas",
      "Dimitrios Rontogiannis",
      "Nikolaos Theologitis",
      "Dimitris Sacharidis",
      "Giorgos Giannopoulos",
      "Dimitrios Tomaras",
      "Kleopatra Markou",
      "Dimitrios Gunopulos",
      "Dimitris Fotakis",
      "Ioannis Emiris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13178v1",
    "title": "Real-time distortion prediction in metallic additive manufacturing via a physics-informed neural operator approach",
    "summary": "With the development of digital twins and smart manufacturing systems, there is an urgent need for real-time distortion field prediction to control defects in metal Additive Manufacturing (AM). However, numerical simulation methods suffer from high computational cost, long run-times that prevent real-time use, while conventional Machine learning (ML) models struggle to extract spatiotemporal features for long-horizon prediction and fail to decouple thermo-mechanical fields. This paper proposes a Physics-informed Neural Operator (PINO) to predict z and y-direction distortion for the future 15 s. Our method, Physics-informed Deep Operator Network-Recurrent Neural Network (PIDeepONet-RNN) employs trunk and branch network to process temperature history and encode distortion fields, respectively, enabling decoupling of thermo-mechanical responses. By incorporating the heat conduction equation as a soft constraint, the model ensures physical consistency and suppresses unphysical artifacts, thereby establishing a more physically consistent mapping between the thermal history and distortion. This is important because such a basis function, grounded in physical laws, provides a robust and interpretable foundation for predictions. The proposed models are trained and tested using datasets generated from experimentally validated Finite Element Method (FEM). Evaluation shows that the model achieves high accuracy, low error accumulation, time efficiency. The max absolute errors in the z and y-directions are as low as 0.9733 mm and 0.2049 mm, respectively. The error distribution shows high errors in the molten pool but low gradient norms in the deposited and key areas. The performance of PINO surrogate model highlights its potential for real-time long-horizon physics field prediction in controlling defects.",
    "published": "2025-11-17T09:37:04Z",
    "updated": "2025-11-17T09:37:04Z",
    "link": "http://arxiv.org/pdf/2511.13178v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Mingxuan Tian",
      "Haochen Mu",
      "Donghong Ding",
      "Mengjiao Li",
      "Yuhan Ding",
      "Jianping Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.11217v3",
    "title": "Deep Joint Distribution Optimal Transport for Universal Domain Adaptation on Time Series",
    "summary": "Universal Domain Adaptation (UniDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain, even when their classes are not fully shared. Few dedicated UniDA methods exist for Time Series (TS), which remains a challenging case. In general, UniDA approaches align common class samples and detect unknown target samples from emerging classes. Such detection often results from thresholding a discriminability metric. The threshold value is typically either a fine-tuned hyperparameter or a fixed value, which limits the ability of the model to adapt to new data. Furthermore, discriminability metrics exhibit overconfidence for unknown samples, leading to misclassifications. This paper introduces UniJDOT, an optimal-transport-based method that accounts for the unknown target samples in the transport cost. Our method also proposes a joint decision space to improve the discriminability of the detection module. In addition, we use an auto-thresholding algorithm to reduce the dependence on fixed or fine-tuned thresholds. Finally, we rely on a Fourier transform-based layer inspired by the Fourier Neural Operator for better TS representation. Experiments on TS benchmarks demonstrate the discriminability, robustness, and state-of-the-art performance of UniJDOT.",
    "published": "2025-03-14T09:09:21Z",
    "updated": "2025-11-17T09:32:44Z",
    "link": "http://arxiv.org/pdf/2503.11217v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Romain Mussard",
      "Fannia Pacheco",
      "Maxime Berar",
      "Gilles Gasso",
      "Paul Honeine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13174v1",
    "title": "Warm-starting active-set solvers using graph neural networks",
    "summary": "Quadratic programming (QP) solvers are widely used in real-time control and optimization, but their computational cost often limits applicability in time-critical settings. We propose a learning-to-optimize approach using graph neural networks (GNNs) to predict active sets in the dual active-set solver DAQP. The method exploits the structural properties of QPs by representing them as bipartite graphs and learning to identify the optimal active set for efficiently warm-starting the solver. Across varying problem sizes, the GNN consistently reduces the number of solver iterations compared to cold-starting, while performance is comparable to a multilayer perceptron (MLP) baseline. Furthermore, a GNN trained on varying problem sizes generalizes effectively to unseen dimensions, demonstrating flexibility and scalability. These results highlight the potential of structure-aware learning to accelerate optimization in real-time applications such as model predictive control.",
    "published": "2025-11-17T09:22:45Z",
    "updated": "2025-11-17T09:22:45Z",
    "link": "http://arxiv.org/pdf/2511.13174v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ella J. Schmidtobreick",
      "Daniel Arnström",
      "Paul Häusner",
      "Jens Sjölund"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25323v3",
    "title": "CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices",
    "summary": "Normalizing flows are deep generative models that enable efficient likelihood estimation and sampling through invertible transformations. A key challenge is to design linear layers that enhance expressiveness while maintaining efficient computation of the Jacobian determinant and inverse. We introduce a novel invertible linear layer based on the product of circulant and diagonal matrices. This decomposition reduces parameter complexity from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(mn)$ using $m$ diagonal matrices and $m-1$ circulant matrices while still approximating general linear transformations. By leveraging the Fast Fourier Transform, our approach reduces the time complexity of matrix inversion from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(mn\\log n)$ and that of computing the log-determinant from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(mn)$, where $n$ is the input dimension. We build upon this layer to develop Circulant-Diagonal Flow (CDFlow), which achieves strong density estimation on natural image datasets and effectively models data with inherent periodic structure. Furthermore, CDFlow significantly accelerates key operations in normalizing flows, providing practical benefits for scalable generative modeling.",
    "published": "2025-10-29T09:38:50Z",
    "updated": "2025-11-17T09:04:17Z",
    "link": "http://arxiv.org/pdf/2510.25323v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xuchen Feng",
      "Siyu Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13147v1",
    "title": "OTARo: Once Tuning for All Precisions toward Robust On-Device LLMs",
    "summary": "Large Language Models (LLMs) fine-tuning techniques not only improve the adaptability to diverse downstream tasks, but also mitigate adverse effects of model quantization. Despite this, conventional quantization suffers from its structural limitation that hinders flexibility during the fine-tuning and deployment stages. Practical on-device tasks demand different quantization precisions (i.e. different bit-widths), e.g., understanding tasks tend to exhibit higher tolerance to reduced precision compared to generation tasks. Conventional quantization, typically relying on scaling factors that are incompatible across bit-widths, fails to support the on-device switching of precisions when confronted with complex real-world scenarios. To overcome the dilemma, we propose OTARo, a novel method that enables on-device LLMs to flexibly switch quantization precisions while maintaining performance robustness through once fine-tuning. OTARo introduces Shared Exponent Floating Point (SEFP), a distinct quantization mechanism, to produce different bit-widths through simple mantissa truncations of a single model. Moreover, to achieve bit-width robustness in downstream applications, OTARo performs a learning process toward losses induced by different bit-widths. The method involves two critical strategies: (1) Exploitation-Exploration Bit-Width Path Search (BPS), which iteratively updates the search path via a designed scoring mechanism; (2) Low-Precision Asynchronous Accumulation (LAA), which performs asynchronous gradient accumulations and delayed updates under low bit-widths. Experiments on popular LLMs, e.g., LLaMA3.2-1B, LLaMA3-8B, demonstrate that OTARo achieves consistently strong and robust performance for all precisions.",
    "published": "2025-11-17T08:56:27Z",
    "updated": "2025-11-17T08:56:27Z",
    "link": "http://arxiv.org/pdf/2511.13147v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Shaoyuan Chen",
      "Zhixuan Chen",
      "Dawei Yang",
      "Zhihang Yuan",
      "Qiang Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13144v1",
    "title": "Personalized Federated Learning with Bidirectional Communication Compression via One-Bit Random Sketching",
    "summary": "Federated Learning (FL) enables collaborative training across decentralized data, but faces key challenges of bidirectional communication overhead and client-side data heterogeneity. To address communication costs while embracing data heterogeneity, we propose pFed1BS, a novel personalized federated learning framework that achieves extreme communication compression through one-bit random sketching. In personalized FL, the goal shifts from training a single global model to creating tailored models for each client. In our framework, clients transmit highly compressed one-bit sketches, and the server aggregates and broadcasts a global one-bit consensus. To enable effective personalization, we introduce a sign-based regularizer that guides local models to align with the global consensus while preserving local data characteristics. To mitigate the computational burden of random sketching, we employ the Fast Hadamard Transform for efficient projection. Theoretical analysis guarantees that our algorithm converges to a stationary neighborhood of the global potential function. Numerical simulations demonstrate that pFed1BS substantially reduces communication costs while achieving competitive performance compared to advanced communication-efficient FL algorithms.",
    "published": "2025-11-17T08:55:22Z",
    "updated": "2025-11-17T08:55:22Z",
    "link": "http://arxiv.org/pdf/2511.13144v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jiacheng Cheng",
      "Xu Zhang",
      "Guanghui Qiu",
      "Yifang Zhang",
      "Yinchuan Li",
      "Kaiyuan Feng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.16625v3",
    "title": "Self-Supervised Learning of Graph Representations for Network Intrusion Detection",
    "summary": "Detecting intrusions in network traffic is a challenging task, particularly under limited supervision and constantly evolving attack patterns. While recent works have leveraged graph neural networks for network intrusion detection, they often decouple representation learning from anomaly detection, limiting the utility of the embeddings for identifying attacks. We propose GraphIDS, a self-supervised intrusion detection model that unifies these two stages by learning local graph representations of normal communication patterns through a masked autoencoder. An inductive graph neural network embeds each flow with its local topological context to capture typical network behavior, while a Transformer-based encoder-decoder reconstructs these embeddings, implicitly learning global co-occurrence patterns via self-attention without requiring explicit positional information. During inference, flows with unusually high reconstruction errors are flagged as potential intrusions. This end-to-end framework ensures that embeddings are directly optimized for the downstream task, facilitating the recognition of malicious traffic. On diverse NetFlow benchmarks, GraphIDS achieves up to 99.98% PR-AUC and 99.61% macro F1-score, outperforming baselines by 5-25 percentage points.",
    "published": "2025-09-20T11:02:50Z",
    "updated": "2025-11-17T08:36:59Z",
    "link": "http://arxiv.org/pdf/2509.16625v3.pdf",
    "category": [
      "cs.LG",
      "cs.CR"
    ],
    "authors": [
      "Lorenzo Guerra",
      "Thomas Chapuis",
      "Guillaume Duc",
      "Pavlo Mozharovskyi",
      "Van-Tam Nguyen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13124v1",
    "title": "Departures: Distributional Transport for Single-Cell Perturbation Prediction with Neural Schrödinger Bridges",
    "summary": "Predicting single-cell perturbation outcomes directly advances gene function analysis and facilitates drug candidate selection, making it a key driver of both basic and translational biomedical research. However, a major bottleneck in this task is the unpaired nature of single-cell data, as the same cell cannot be observed both before and after perturbation due to the destructive nature of sequencing. Although some neural generative transport models attempt to tackle unpaired single-cell perturbation data, they either lack explicit conditioning or depend on prior spaces for indirect distribution alignment, limiting precise perturbation modeling. In this work, we approximate Schrödinger Bridge (SB), which defines stochastic dynamic mappings recovering the entropy-regularized optimal transport (OT), to directly align the distributions of control and perturbed single-cell populations across different perturbation conditions. Unlike prior SB approximations that rely on bidirectional modeling to infer optimal source-target sample coupling, we leverage Minibatch-OT based pairing to avoid such bidirectional inference and the associated ill-posedness of defining the reverse process. This pairing directly guides bridge learning, yielding a scalable approximation to the SB. We approximate two SB models, one modeling discrete gene activation states and the other continuous expression distributions. Joint training enables accurate perturbation modeling and captures single-cell heterogeneity. Experiments on public genetic and drug perturbation datasets show that our model effectively captures heterogeneous single-cell responses and achieves state-of-the-art performance.",
    "published": "2025-11-17T08:27:13Z",
    "updated": "2025-11-17T08:27:13Z",
    "link": "http://arxiv.org/pdf/2511.13124v1.pdf",
    "category": [
      "cs.LG",
      "q-bio.QM"
    ],
    "authors": [
      "Changxi Chi",
      "Yufei Huang",
      "Jun Xia",
      "Jiangbin Zheng",
      "Yunfan Liu",
      "Zelin Zang",
      "Stan Z. Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13103v1",
    "title": "Transformer-Based Scalable Multi-Agent Reinforcement Learning for Networked Systems with Long-Range Interactions",
    "summary": "Multi-agent reinforcement learning (MARL) has shown promise for large-scale network control, yet existing methods face two major limitations. First, they typically rely on assumptions leading to decay properties of local agent interactions, limiting their ability to capture long-range dependencies such as cascading power failures or epidemic outbreaks. Second, most approaches lack generalizability across network topologies, requiring retraining when applied to new graphs. We introduce STACCA (Shared Transformer Actor-Critic with Counterfactual Advantage), a unified transformer-based MARL framework that addresses both challenges. STACCA employs a centralized Graph Transformer Critic to model long-range dependencies and provide system-level feedback, while its shared Graph Transformer Actor learns a generalizable policy capable of adapting across diverse network structures. Further, to improve credit assignment during training, STACCA integrates a novel counterfactual advantage estimator that is compatible with state-value critic estimates. We evaluate STACCA on epidemic containment and rumor-spreading network control tasks, demonstrating improved performance, network generalization, and scalability. These results highlight the potential of transformer-based MARL architectures to achieve scalable and generalizable control in large-scale networked systems.",
    "published": "2025-11-17T07:58:13Z",
    "updated": "2025-11-17T07:58:13Z",
    "link": "http://arxiv.org/pdf/2511.13103v1.pdf",
    "category": [
      "cs.LG",
      "cs.MA",
      "eess.SY"
    ],
    "authors": [
      "Vidur Sinha",
      "Muhammed Ustaomeroglu",
      "Guannan Qu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.07892v2",
    "title": "A Generalized Spectral Framework to Expain Neural Scaling and Compression Dynamics",
    "summary": "Empirical scaling laws describe how test loss and other performance metrics depend on model size, dataset size, and compute. While such laws are consistent within specific regimes, apparently distinct scaling behaviors have been reported for related settings such as model compression. Motivated by recent progress in spectral analyses of neural representations, this paper develops a \\emph{generalized spectral framework} that unifies learning dynamics and compression phenomena under a common functional ansatz. We generalize the spectral evolution function from the linear kernel form $g(λt)=λt$ to an asymptotically polynomial function $g(λ,t;β)$, characterized by an effective spectral--temporal elasticity $ρ(β)$. This framework recovers existing lazy and feature-learning theories as special cases and yields an invariant relation between learning and compression",
    "published": "2025-11-11T06:47:23Z",
    "updated": "2025-11-17T07:55:03Z",
    "link": "http://arxiv.org/pdf/2511.07892v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yizhou Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.17208v2",
    "title": "Active Learning for Machine Learning Driven Molecular Dynamics",
    "summary": "Machine-learned coarse-grained (CG) potentials are fast, but degrade over time when simulations reach under-sampled bio-molecular conformations, and generating widespread all-atom (AA) data to combat this is computationally infeasible. We propose a novel active learning (AL) framework for CG neural network potentials in molecular dynamics (MD). Building on the CGSchNet model, our method employs root mean squared deviation (RMSD)-based frame selection from MD simulations in order to generate data on-the-fly by querying an oracle during the training of a neural network potential. This framework preserves CG-level efficiency while correcting the model at precise, RMSD-identified coverage gaps. By training CGSchNet, a coarse-grained neural network potential, we empirically show that our framework explores previously unseen configurations and trains the model on unexplored regions of conformational space. Our active learning framework enables a CGSchNet model trained on the Chignolin protein to achieve a 33.05\\% improvement in the Wasserstein-1 (W1) metric in Time-lagged Independent Component Analysis (TICA) space on an in-house benchmark suite.",
    "published": "2025-09-21T19:26:32Z",
    "updated": "2025-11-17T07:47:36Z",
    "link": "http://arxiv.org/pdf/2509.17208v2.pdf",
    "category": [
      "cs.LG",
      "physics.atm-clus"
    ],
    "authors": [
      "Kevin Bachelor",
      "Sanya Murdeshwar",
      "Daniel Sabo",
      "Razvan Marinescu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13078v1",
    "title": "A Smart-Glasses for Emergency Medical Services via Multimodal Multitask Learning",
    "summary": "Emergency Medical Technicians (EMTs) operate in high-pressure environments, making rapid, life-critical decisions under heavy cognitive and operational loads. We present EMSGlass, a smart-glasses system powered by EMSNet, the first multimodal multitask model for Emergency Medical Services (EMS), and EMSServe, a low-latency multimodal serving framework tailored to EMS scenarios. EMSNet integrates text, vital signs, and scene images to construct a unified real-time understanding of EMS incidents. Trained on real-world multimodal EMS datasets, EMSNet simultaneously supports up to five critical EMS tasks with superior accuracy compared to state-of-the-art unimodal baselines. Built on top of PyTorch, EMSServe introduces a modality-aware model splitter and a feature caching mechanism, achieving adaptive and efficient inference across heterogeneous hardware while addressing the challenge of asynchronous modality arrival in the field. By optimizing multimodal inference execution in EMS scenarios, EMSServe achieves 1.9x -- 11.7x speedup over direct PyTorch multimodal inference. A user study evaluation with six professional EMTs demonstrates that EMSGlass enhances real-time situational awareness, decision-making speed, and operational efficiency through intuitive on-glass interaction. In addition, qualitative insights from the user study provide actionable directions for extending EMSGlass toward next-generation AI-enabled EMS systems, bridging multimodal intelligence with real-world emergency response workflows.",
    "published": "2025-11-17T07:27:52Z",
    "updated": "2025-11-17T07:27:52Z",
    "link": "http://arxiv.org/pdf/2511.13078v1.pdf",
    "category": [
      "cs.LG",
      "eess.AS",
      "eess.IV"
    ],
    "authors": [
      "Liuyi Jin",
      "Pasan Gunawardena",
      "Amran Haroon",
      "Runzhi Wang",
      "Sangwoo Lee",
      "Radu Stoleru",
      "Michael Middleton",
      "Zepeng Huo",
      "Jeeeun Kim",
      "Jason Moats"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13071v1",
    "title": "Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers",
    "summary": "Low-cost micro-electromechanical accelerometers are widely used in navigation, robotics, and consumer devices for motion sensing and position estimation. However, their performance is often degraded by bias errors. To eliminate deterministic bias terms a calibration procedure is applied under stationary conditions. It requires accelerom- eter leveling or complex orientation-dependent calibration procedures. To overcome those requirements, in this paper we present a model-free learning-based calibration method that estimates accelerometer bias under stationary conditions, without requiring knowledge of the sensor orientation and without the need to rotate the sensors. The proposed approach provides a fast, practical, and scalable solution suitable for rapid field deployment. Experimental validation on a 13.39-hour dataset collected from six accelerometers shows that the proposed method consistently achieves error levels more than 52% lower than traditional techniques. On a broader scale, this work contributes to the advancement of accurate calibration methods in orientation-free scenarios. As a consequence, it improves the reliability of low-cost inertial sensors in diverse scientific and industrial applications and eliminates the need for leveled calibration.",
    "published": "2025-11-17T07:15:24Z",
    "updated": "2025-11-17T07:15:24Z",
    "link": "http://arxiv.org/pdf/2511.13071v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Michal Levin",
      "Itzik Klein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.11250v4",
    "title": "Rethinking Irregular Time Series Forecasting: A Simple yet Effective Baseline",
    "summary": "The forecasting of irregular multivariate time series (IMTS) is crucial in key areas such as healthcare, biomechanics, climate science, and astronomy. However, achieving accurate and practical predictions is challenging due to two main factors. First, the inherent irregularity and data missingness in irregular time series make modeling difficult. Second, most existing methods are typically complex and resource-intensive. In this study, we propose a general framework called APN to address these challenges. Specifically, we design a novel Time-Aware Patch Aggregation (TAPA) module that achieves adaptive patching. By learning dynamically adjustable patch boundaries and a time-aware weighted averaging strategy, TAPA transforms the original irregular sequences into high-quality, regularized representations in a channel-independent manner. Additionally, we use a simple query module to effectively integrate historical information while maintaining the model's efficiency. Finally, predictions are made by a shallow MLP. Experimental results on multiple real-world datasets show that APN outperforms existing state-of-the-art methods in both efficiency and accuracy.",
    "published": "2025-05-16T13:42:00Z",
    "updated": "2025-11-17T07:00:11Z",
    "link": "http://arxiv.org/pdf/2505.11250v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Xvyuan Liu",
      "Xiangfei Qiu",
      "Xingjian Wu",
      "Zhengyu Li",
      "Chenjuan Guo",
      "Jilin Hu",
      "Bin Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.03746v3",
    "title": "A Dynamic Recurrent Adjacency Memory Network for Mixed-Generation Power System Stability Forecasting",
    "summary": "Modern power systems with high penetration of inverter-based resources exhibit complex dynamic behaviors that challenge the scalability and generalizability of traditional stability assessment methods. This paper presents a dynamic recurrent adjacency memory network (DRAMN) that combines physics-informed analysis with deep learning for real-time power system stability forecasting. The framework employs sliding-window dynamic mode decomposition to construct time-varying, multi-layer adjacency matrices from phasor measurement unit and sensor data to capture system dynamics such as modal participation factors, coupling strengths, phase relationships, and spectral energy distributions. As opposed to processing spatial and temporal dependencies separately, DRAMN integrates graph convolution operations directly within recurrent gating mechanisms, enabling simultaneous modeling of evolving dynamics and temporal dependencies. Extensive validations on modified IEEE 9-bus, 39-bus, and a multi-terminal HVDC network demonstrate high performance, achieving 99.85%, 99.90%, and 99.69% average accuracies, respectively, surpassing all tested benchmarks, including classical machine learning algorithms and recent graph-based models. The framework identifies optimal combinations of measurements that reduce feature dimensionality by 82% without performance degradation. Correlation analysis between dominant measurements for small-signal and transient stability events validates generalizability across different stability phenomena. DRAMN achieves state-of-the-art accuracy while providing enhanced interpretability for power system operators, making it suitable for real-time deployment in modern control centers.",
    "published": "2025-11-02T05:40:16Z",
    "updated": "2025-11-17T06:59:50Z",
    "link": "http://arxiv.org/pdf/2511.03746v3.pdf",
    "category": [
      "eess.SY",
      "cs.LG"
    ],
    "authors": [
      "Guang An Ooi",
      "Otavio Bertozzi",
      "Mohd Asim Aftab",
      "Charalambos Konstantinou",
      "Shehab Ahmed"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13053v1",
    "title": "Self-Organization of Attractor Landscapes in High-Capacity Kernel Logistic Regression Hopfield Networks",
    "summary": "Kernel-based learning methods can dramatically increase the storage capacity of Hopfield networks, yet the dynamical mechanism behind this enhancement remains poorly understood. We address this gap by conducting a geometric analysis of the network's energy landscape. We introduce a novel metric, ``Pinnacle Sharpness,'' to quantify the local stability of attractors. By systematically varying the kernel width and storage load, we uncover a rich phase diagram of attractor shapes. Our central finding is the emergence of a ``ridge of optimization,'' where the network maximizes attractor stability under challenging high-load and global-kernel conditions. Through a theoretical decomposition of the landscape gradient into a direct ``driving'' force and an indirect ``feedback'' force, we reveal the origin of this phenomenon. The optimization ridge corresponds to a regime of strong anti-correlation between the two forces, where the direct force, amplified by the high storage load, dominates the opposing collective feedback force. This demonstrates a sophisticated self-organization mechanism: the network adaptively harnesses inter-pattern interactions as a cooperative feedback control system to sculpt a robust energy landscape. Our findings provide a new physical picture for the stability of high-capacity associative memories and offer principles for their design.",
    "published": "2025-11-17T06:58:34Z",
    "updated": "2025-11-17T06:58:34Z",
    "link": "http://arxiv.org/pdf/2511.13053v1.pdf",
    "category": [
      "cs.LG",
      "cs.NE"
    ],
    "authors": [
      "Akira Tamamori"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13049v1",
    "title": "Generalization Bounds for Semi-supervised Matrix Completion with Distributional Side Information",
    "summary": "We study a matrix completion problem where both the ground truth $R$ matrix and the unknown sampling distribution $P$ over observed entries are low-rank matrices, and \\textit{share a common subspace}. We assume that a large amount $M$ of \\textit{unlabeled} data drawn from the sampling distribution $P$ is available, together with a small amount $N$ of labeled data drawn from the same distribution and noisy estimates of the corresponding ground truth entries. This setting is inspired by recommender systems scenarios where the unlabeled data corresponds to `implicit feedback' (consisting in interactions such as purchase, click, etc. ) and the labeled data corresponds to the `explicit feedback', consisting of interactions where the user has given an explicit rating to the item. Leveraging powerful results from the theory of low-rank subspace recovery, together with classic generalization bounds for matrix completion models, we show error bounds consisting of a sum of two error terms scaling as $\\widetilde{O}\\left(\\sqrt{\\frac{nd}{M}}\\right)$ and $\\widetilde{O}\\left(\\sqrt{\\frac{dr}{N}}\\right)$ respectively, where $d$ is the rank of $P$ and $r$ is the rank of $M$. In synthetic experiments, we confirm that the true generalization error naturally splits into independent error terms corresponding to the estimations of $P$ and and the ground truth matrix $\\ground$ respectively. In real-life experiments on Douban and MovieLens with most explicit ratings removed, we demonstrate that the method can outperform baselines relying only on the explicit ratings, demonstrating that our assumptions provide a valid toy theoretical setting to study the interaction between explicit and implicit feedbacks in recommender systems.",
    "published": "2025-11-17T06:53:50Z",
    "updated": "2025-11-17T06:53:50Z",
    "link": "http://arxiv.org/pdf/2511.13049v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Antoine Ledent",
      "Mun Chong Soo",
      "Nong Minh Hieu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.18320v2",
    "title": "State of Health Estimation of Batteries Using a Time-Informed Dynamic Sequence-Inverted Transformer",
    "summary": "The rapid adoption of battery-powered vehicles and energy storage systems over the past decade has made battery health monitoring increasingly critical. Batteries play a central role in the efficiency and safety of these systems, yet they inevitably degrade over time due to repeated charge-discharge cycles. This degradation leads to reduced energy efficiency and potential overheating, posing significant safety concerns. Accurate estimation of a State of Health (SoH) of battery is therefore essential for ensuring operational reliability and safety. Several machine learning architectures, such as LSTMs, transformers, and encoder-based models, have been proposed to estimate SoH from discharge cycle data. However, these models struggle with the irregularities inherent in real-world measurements: discharge readings are often recorded at non-uniform intervals, and the lengths of discharge cycles vary significantly. To address this, most existing approaches extract features from the sequences rather than processing them in full, which introduces information loss and compromises accuracy. To overcome these challenges, we propose a novel architecture: Time-Informed Dynamic Sequence Inverted Transformer (TIDSIT). TIDSIT incorporates continuous time embeddings to effectively represent irregularly sampled data and utilizes padded sequences with temporal attention mechanisms to manage variable-length inputs without discarding sequence information. Experimental results on the NASA battery degradation dataset show that TIDSIT significantly outperforms existing models, achieving over 50% reduction in prediction error and maintaining an SoH prediction error below 0.58%. Furthermore, the architecture is generalizable and holds promise for broader applications in health monitoring tasks involving irregular time-series data.",
    "published": "2025-07-24T11:43:46Z",
    "updated": "2025-11-17T06:49:27Z",
    "link": "http://arxiv.org/pdf/2507.18320v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Janak M. Patel",
      "Milad Ramezankhani",
      "Anirudh Deodhar",
      "Dagnachew Birru"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13044v1",
    "title": "Bi-View Embedding Fusion: A Hybrid Learning Approach for Knowledge Graph's Nodes Classification Addressing Problems with Limited Data",
    "summary": "Traditional Machine Learning (ML) methods require large amounts of data to perform well, limiting their applicability in sparse or incomplete scenarios and forcing the usage of additional synthetic data to improve the model training. To overcome this challenge, the research community is looking more and more at Graph Machine Learning (GML) as it offers a powerful alternative by using relationships within data. However, this method also faces limitations, particularly when dealing with Knowledge Graphs (KGs), which can hide huge information due to their semantic nature. This study introduces Bi-View, a novel hybrid approach that increases the informative content of node features in KGs to generate enhanced Graph Embeddings (GEs) that are used to improve GML models without relying on additional synthetic data. The proposed work combines two complementary GE techniques: Node2Vec, which captures structural patterns through unsupervised random walks, and GraphSAGE, which aggregates neighbourhood information in a supervised way. Node2Vec embeddings are first computed to represent the graph topology, and node features are then enriched with centrality-based metrics, which are used as input for the GraphSAGE model. Moreover, a fusion layer combines the original Node2Vec embeddings with the GraphSAGE-influenced representations, resulting in a dual-perspective embedding space. Such a fusion captures both topological and semantic properties of the graph, enabling the model to exploit informative features that may exist in the dataset but that are not explicitly represented. Our approach improves downstream task performance, especially in scenarios with poor initial features, giving the basis for more accurate and precise KG-enanched GML models.",
    "published": "2025-11-17T06:45:14Z",
    "updated": "2025-11-17T06:45:14Z",
    "link": "http://arxiv.org/pdf/2511.13044v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Rosario Napoli",
      "Giovanni Lonia",
      "Antonio Celesti",
      "Massimo Villari",
      "Maria Fazio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13025v1",
    "title": "Reconstruction of Manifold Distances from Noisy Observations",
    "summary": "We consider the problem of reconstructing the intrinsic geometry of a manifold from noisy pairwise distance observations. Specifically, let $M$ denote a diameter 1 d-dimensional manifold and $μ$ a probability measure on $M$ that is mutually absolutely continuous with the volume measure. Suppose $X_1,\\dots,X_N$ are i.i.d. samples of $μ$ and we observe noisy-distance random variables $d'(X_j, X_k)$ that are related to the true geodesic distances $d(X_j,X_k)$. With mild assumptions on the distributions and independence of the noisy distances, we develop a new framework for recovering all distances between points in a sufficiently dense subsample of $M$. Our framework improves on previous work which assumed i.i.d. additive noise with known moments. Our method is based on a new way to estimate $L_2$-norms of certain expectation-functions $f_x(y)=\\mathbb{E}d'(x,y)$ and use them to build robust clusters centered at points of our sample. Using a new geometric argument, we establish that, under mild geometric assumptions--bounded curvature and positive injectivity radius--these clusters allow one to recover the true distances between points in the sample up to an additive error of $O(\\varepsilon \\log \\varepsilon^{-1})$. We develop two distinct algorithms for producing these clusters. The first achieves a sample complexity $N \\asymp \\varepsilon^{-2d-2}\\log(1/\\varepsilon)$ and runtime $o(N^3)$. The second introduces novel geometric ideas that warrant further investigation. In the presence of missing observations, we show that a quantitative lower bound on sampling probabilities suffices to modify the cluster construction in the first algorithm and extend all recovery guarantees. Our main technical result also elucidates which properties of a manifold are necessary for the distance recovery, which suggests further extension of our techniques to a broader class of metric probability spaces.",
    "published": "2025-11-17T06:24:31Z",
    "updated": "2025-11-17T06:24:31Z",
    "link": "http://arxiv.org/pdf/2511.13025v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.DG",
      "math.PR"
    ],
    "authors": [
      "Charles Fefferman",
      "Jonathan Marty",
      "Kevin Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13022v1",
    "title": "Learning Time-Scale Invariant Population-Level Neural Representations",
    "summary": "General-purpose foundation models for neural time series can help accelerate neuroscientific discoveries and enable applications such as brain computer interfaces (BCIs). A key component in scaling these models is population-level representation learning, which leverages information across channels to capture spatial as well as temporal structure. Population-level approaches have recently shown that such representations can be both efficient to learn on top of pretrained temporal encoders and produce useful representations for decoding a variety of downstream tasks. However, these models remain sensitive to mismatches in preprocessing, particularly on time-scales, between pretraining and downstream settings. We systematically examine how time-scale mismatches affects generalization and find that existing representations lack invariance. To address this, we introduce Time-scale Augmented Pretraining (TSAP), which consistently improves robustness to different time-scales across decoding tasks and builds invariance in the representation space. These results highlight handling preprocessing diversity as a key step toward building generalizable neural foundation models.",
    "published": "2025-11-17T06:20:31Z",
    "updated": "2025-11-17T06:20:31Z",
    "link": "http://arxiv.org/pdf/2511.13022v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Eshani Patel",
      "Yisong Yue",
      "Geeling Chau"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13018v1",
    "title": "The Final-Stage Bottleneck: A Systematic Dissection of the R-Learner for Network Causal Inference",
    "summary": "The R-Learner is a powerful, theoretically-grounded framework for estimating heterogeneous treatment effects, prized for its robustness to nuisance model errors. However, its application to network data, where causal heterogeneity is often graph-dependent, presents a critical challenge to its core assumption of a well-specified final-stage model. In this paper, we conduct a large-scale empirical study to systematically dissect the R-Learner framework on graphs. We provide the first rigorous evidence that the primary driver of performance is the inductive bias of the final-stage CATE estimator, an effect that dominates the choice of nuisance models. Our central finding is the quantification of a catastrophic \"representation bottleneck\": we prove with overwhelming statistical significance (p < 0.001) that R-Learners with a graph-blind final stage fail completely (MSE > 4.0), even when paired with powerful GNN nuisance models. Conversely, our proposed end-to-end Graph R-Learner succeeds and significantly outperforms a strong, non-DML GNN T-Learner baseline. Furthermore, we identify and provide a mechanistic explanation for a subtle, topology-dependent \"nuisance bottleneck,\" linking it to GNN over-squashing via a targeted \"Hub-Periphery Trade-off\" analysis. Our findings are validated across diverse synthetic and semi-synthetic benchmarks. We release our code as a reproducible benchmark to facilitate future research on this critical \"final-stage bottleneck.\"",
    "published": "2025-11-17T06:16:04Z",
    "updated": "2025-11-17T06:16:04Z",
    "link": "http://arxiv.org/pdf/2511.13018v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sairam S",
      "Sara Girdhar",
      "Shivam Soni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13016v1",
    "title": "The Good, The Bad, and The Hybrid: A Reward Structure Showdown in Reasoning Models Training",
    "summary": "Reward design is central to reinforcement learning from human feedback (RLHF) and alignment research. In this work, we propose a unified framework to study hard, continuous, and hybrid reward structures for fine-tuning large language models (LLMs) on mathematical reasoning tasks. Using Qwen3-4B with LoRA fine-tuning on the GSM8K dataset, we formalize and empirically evaluate reward formulations that incorporate correctness, perplexity, reasoning quality, and consistency. We introduce an adaptive hybrid reward scheduler that transitions between discrete and continuous signals, balancing exploration and stability. Our results show that hybrid reward structures improve convergence speed and training stability over purely hard or continuous approaches, offering insights for alignment via adaptive reward modeling.",
    "published": "2025-11-17T06:15:26Z",
    "updated": "2025-11-17T06:15:26Z",
    "link": "http://arxiv.org/pdf/2511.13016v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Subramanyam Sahoo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12995v1",
    "title": "Revealing the dynamic responses of Pb under shock loading based on DFT-accuracy machine learning potential",
    "summary": "Lead (Pb) is a typical low-melting-point ductile metal and serves as an important model material in the study of dynamic responses. Under shock-wave loading, its dynamic mechanical behavior comprises two key phenomena: plastic deformation and shock induced phase transitions. The underlying mechanisms of these processes are still poorly understood. Revealing these mechanisms remains challenging for experimental approaches. Non-equilibrium molecular dynamics (NEMD) simulations are an alternative theoretical tool for studying dynamic responses, as they capture atomic-scale mechanisms such as defect evolution and deformation pathways. However, due to the limited accuracy of empirical interatomic potentials, the reliability of previous NEMD studies is questioned. Using our newly developed machine learning potential for Pb-Sn alloys, we revisited the microstructure evolution in response to shock loading under various shock orientations. The results reveal that shock loading along the [001] orientation of Pb exhibits a fast, reversible, and massive phase transition and stacking fault evolution. The behavior of Pb differs from previous studies by the absence of twinning during plastic deformation. Loading along the [011] orientation leads to slow, irreversible plastic deformation, and a localized FCC-BCC phase transition in the Pitsch orientation relationship. This study provides crucial theoretical insights into the dynamic mechanical response of Pb, offering a theoretical input for understanding the microstructure-performance relationship under extreme conditions.",
    "published": "2025-11-17T05:38:19Z",
    "updated": "2025-11-17T05:38:19Z",
    "link": "http://arxiv.org/pdf/2511.12995v1.pdf",
    "category": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "authors": [
      "Enze Hou",
      "Xiaoyang Wang",
      "Han Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09901v2",
    "title": "Explore and Establish Synergistic Effects Between Weight Pruning and Coreset Selection in Neural Network Training",
    "summary": "Modern deep neural networks rely heavily on massive model weights and training samples, incurring substantial computational costs. Weight pruning and coreset selection are two emerging paradigms proposed to improve computational efficiency. In this paper, we first explore the interplay between redundant weights and training samples through a transparent analysis: redundant samples, particularly noisy ones, cause model weights to become unnecessarily overtuned to fit them, complicating the identification of irrelevant weights during pruning; conversely, irrelevant weights tend to overfit noisy data, undermining coreset selection effectiveness. To further investigate and harness this interplay in deep learning, we develop a Simultaneous Weight and Sample Tailoring mechanism (SWaST) that alternately performs weight pruning and coreset selection to establish a synergistic effect in training. During this investigation, we observe that when simultaneously removing a large number of weights and samples, a phenomenon we term critical double-loss can occur, where important weights and their supportive samples are mistakenly eliminated at the same time, leading to model instability and nearly irreversible degradation that cannot be recovered in subsequent training. Unlike classic machine learning models, this issue can arise in deep learning due to the lack of theoretical guarantees on the correctness of weight pruning and coreset selection, which explains why these paradigms are often developed independently. We mitigate this by integrating a state preservation mechanism into SWaST, enabling stable joint optimization. Extensive experiments reveal a strong synergy between pruning and coreset selection across varying prune rates and coreset sizes, delivering accuracy boosts of up to 17.83% alongside 10% to 90% FLOPs reductions.",
    "published": "2025-11-13T03:01:16Z",
    "updated": "2025-11-17T05:30:42Z",
    "link": "http://arxiv.org/pdf/2511.09901v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Weilin Wan",
      "Fan Yi",
      "Weizhong Zhang",
      "Quan Zhou",
      "Cheng Jin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.07843v3",
    "title": "Emotional EEG Classification using Upscaled Connectivity Matrices",
    "summary": "In recent studies of emotional EEG classification, connectivity matrices have been successfully employed as input to convolutional neural networks (CNNs), which can effectively consider inter-regional interaction patterns in EEG. However, we find that such an approach has a limitation that important patterns in connectivity matrices may be lost during the convolutional operations in CNNs. To resolve this issue, we propose and validate an idea to upscale the connectivity matrices to strengthen the local patterns. Experimental results demonstrate that this simple idea can significantly enhance the classification performance.",
    "published": "2025-02-11T07:56:19Z",
    "updated": "2025-11-17T05:10:04Z",
    "link": "http://arxiv.org/pdf/2502.07843v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Chae-Won Lee",
      "Jong-Seok Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12979v1",
    "title": "RAGPulse: An Open-Source RAG Workload Trace to Optimize RAG Serving Systems",
    "summary": "Retrieval-Augmented Generation (RAG) is a critical paradigm for building reliable, knowledge-intensive Large Language Model (LLM) applications. However, the multi-stage pipeline (retrieve, generate) and unique workload characteristics (e.g., knowledge dependency) of RAG systems pose significant challenges for serving performance optimization. Existing generic LLM inference traces fail to capture these RAG-specific dynamics, creating a significant performance gap between academic research and real-world deployment. To bridge this gap, this paper introduces RAGPulse, an open-source RAG workload trace dataset. This dataset was collected from an university-wide Q&A system serving that has served more than 40,000 students and faculties since April 2024. We detail RAGPulse's system architecture, its privacy-preserving hash-based data format, and provide an in-depth statistical analysis. Our analysis reveals that real-world RAG workloads exhibit significant temporal locality and a highly skewed hot document access pattern. RAGPulse provides a high-fidelity foundation for researchers to develop and validate novel optimization strategies for RAG systems, such as content-aware batching and retrieval caching, ultimately enhancing the efficiency and reliability of RAG services. The code is available at https://github.com/flashserve/RAGPulse.",
    "published": "2025-11-17T05:06:47Z",
    "updated": "2025-11-17T05:06:47Z",
    "link": "http://arxiv.org/pdf/2511.12979v1.pdf",
    "category": [
      "cs.LG",
      "cs.DB"
    ],
    "authors": [
      "Zhengchao Wang",
      "Yitao Hu",
      "Jianing Ye",
      "Zhuxuan Chang",
      "Jiazheng Yu",
      "Youpeng Deng",
      "Keqiu Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08229v5",
    "title": "Towards Non-Stationary Time Series Forecasting with Temporal Stabilization and Frequency Differencing",
    "summary": "Time series forecasting is critical for decision-making across dynamic domains such as energy, finance, transportation, and cloud computing. However, real-world time series often exhibit non-stationarity, including temporal distribution shifts and spectral variability, which pose significant challenges for long-term time series forecasting. In this paper, we propose DTAF, a dual-branch framework that addresses non-stationarity in both the temporal and frequency domains. For the temporal domain, the Temporal Stabilizing Fusion (TFS) module employs a non-stationary mix of experts (MOE) filter to disentangle and suppress temporal non-stationary patterns while preserving long-term dependencies. For the frequency domain, the Frequency Wave Modeling (FWM) module applies frequency differencing to dynamically highlight components with significant spectral shifts. By fusing the complementary outputs of TFS and FWM, DTAF generates robust forecasts that adapt to both temporal and frequency domain non-stationarity. Extensive experiments on real-world benchmarks demonstrate that DTAF outperforms state-of-the-art baselines, yielding significant improvements in forecasting accuracy under non-stationary conditions. All codes are available at https://github.com/PandaJunk/DTAF.",
    "published": "2025-11-11T13:30:38Z",
    "updated": "2025-11-17T05:04:56Z",
    "link": "http://arxiv.org/pdf/2511.08229v5.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Junkai Lu",
      "Peng Chen",
      "Chenjuan Guo",
      "Yang Shu",
      "Meng Wang",
      "Bin Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.12487v2",
    "title": "Diff-XYZ: A Benchmark for Evaluating Diff Understanding",
    "summary": "Reliable handling of code diffs is central to agents that edit and refactor repositories at scale. We introduce Diff-XYZ, a compact benchmark for code-diff understanding with three supervised tasks: apply (old code $+$ diff $\\rightarrow$ new code), anti-apply (new code $-$ diff $\\rightarrow$ old code), and diff generation (new code $-$ old code $\\rightarrow$ diff). Instances in the benchmark are triples $\\langle \\textit{old code}, \\textit{new code}, \\textit{diff} \\rangle$ drawn from real commits in CommitPackFT, paired with automatic metrics and a clear evaluation protocol. We use the benchmark to do a focused empirical study of the unified diff format and run a cross-format comparison of different diff representations. Our findings reveal that different formats should be used depending on the use case and model size. For example, representing diffs in search-replace format performs best for larger models across most tasks, while structured udiff variants offer similar but slightly weaker performance. In contrast, smaller open models benefit little from any formatting choice. The Diff-XYZ benchmark is a reusable foundation for assessing and improving diff handling in LLMs that can aid future development of diff formats and models editing code. The dataset is published on HuggingFace Hub: https://huggingface.co/datasets/JetBrains-Research/diff-xyz.",
    "published": "2025-10-14T13:23:01Z",
    "updated": "2025-11-17T05:00:01Z",
    "link": "http://arxiv.org/pdf/2510.12487v2.pdf",
    "category": [
      "cs.SE",
      "cs.LG"
    ],
    "authors": [
      "Evgeniy Glukhov",
      "Michele Conti",
      "Egor Bogomolov",
      "Yaroslav Golubev",
      "Alexander Bezzubov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.09862v2",
    "title": "RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-Wave Point Cloud Sequence",
    "summary": "Millimeter-wave radar offers a privacy-preserving and environment-robust alternative to vision-based sensing, enabling human motion analysis in challenging conditions such as low light, occlusions, rain, or smoke. However, its sparse point clouds pose significant challenges for semantic understanding. We present RadarLLM, the first framework that leverages large language models (LLMs) for human motion understanding from radar signals. RadarLLM introduces two key innovations: (1) a motion-guided radar tokenizer based on our Aggregate VQ-VAE architecture, integrating deformable body templates and masked trajectory modeling to convert spatial-temporal radar sequences into compact semantic tokens; and (2) a radar-aware language model that establishes cross-modal alignment between radar and text in a shared embedding space. To overcome the scarcity of paired radar-text data, we generate a realistic radar-text dataset from motion-text datasets with a physics-aware synthesis pipeline. Extensive experiments on both synthetic and real-world benchmarks show that RadarLLM achieves state-of-the-art performance, enabling robust and interpretable motion understanding under privacy and visibility constraints, even in adverse environments. This paper has been accepted for presentation at AAAI 2026. This is an extended version with supplementary materials.",
    "published": "2025-04-14T04:18:25Z",
    "updated": "2025-11-17T04:20:12Z",
    "link": "http://arxiv.org/pdf/2504.09862v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zengyuan Lai",
      "Jiarui Yang",
      "Songpengcheng Xia",
      "Lizhou Lin",
      "Lan Sun",
      "Renwen Wang",
      "Jianran Liu",
      "Qi Wu",
      "Ling Pei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12951v1",
    "title": "A FEDformer-Based Hybrid Framework for Anomaly Detection and Risk Forecasting in Financial Time Series",
    "summary": "Financial markets are inherently volatile and prone to sudden disruptions such as market crashes, flash collapses, and liquidity crises. Accurate anomaly detection and early risk forecasting in financial time series are therefore crucial for preventing systemic instability and supporting informed investment decisions. Traditional deep learning models, such as LSTM and GRU, often fail to capture long-term dependencies and complex periodic patterns in highly nonstationary financial data. To address this limitation, this study proposes a FEDformer-Based Hybrid Framework for Anomaly Detection and Risk Forecasting in Financial Time Series, which integrates the Frequency Enhanced Decomposed Transformer (FEDformer) with a residual-based anomaly detector and a risk forecasting head. The FEDformer module models temporal dynamics in both time and frequency domains, decomposing signals into trend and seasonal components for improved interpretability. The residual-based detector identifies abnormal fluctuations by analyzing prediction errors, while the risk head predicts potential financial distress using learned latent embeddings. Experiments conducted on the S&P 500, NASDAQ Composite, and Brent Crude Oil datasets (2000-2024) demonstrate the superiority of the proposed model over benchmark methods, achieving a 15.7 percent reduction in RMSE and an 11.5 percent improvement in F1-score for anomaly detection. These results confirm the effectiveness of the model in capturing financial volatility, enabling reliable early-warning systems for market crash prediction and risk management.",
    "published": "2025-11-17T04:09:04Z",
    "updated": "2025-11-17T04:09:04Z",
    "link": "http://arxiv.org/pdf/2511.12951v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ziling Fan",
      "Ruijia Liang",
      "Yiwen Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.06190v2",
    "title": "On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond",
    "summary": "Diffusion language models have recently emerged as a competitive alternative to autoregressive language models. Beyond next-token generation, they are more efficient and flexible by enabling parallel and any-order token generation. However, despite empirical successes, their computational power and fundamental limitations remain poorly understood. In this paper, we formally study whether non-autoregressive generation in Masked Diffusion Models (MDM) enables solving problems beyond the reach of Auto-Regressive Models (ARM). Our results show that MDM with sufficiently large context length is computationally universal with decoding steps matching the optimal parallel time complexity in PRAM. However, when controlling for other factors, MDM's flexibility to generate in any-order does not expand what ARM can already solve. To address this, we propose a new form of generation called any-process generation, which extends MDM with capabilities to remask, insert and delete tokens, allowing self-correction, length-variable editing, and adaptive parallelism. Theoretically and empirically, we demonstrate these capabilities enable scalability to significantly harder reasoning problems that are otherwise intractable for ARM and vanilla MDM. Additionally, they prove essential for generation tasks where objects naturally evolve through non-sequential processes, crucial for extending current LLMs beyond natural language to domains such as coding and science.",
    "published": "2025-10-07T17:49:30Z",
    "updated": "2025-11-17T03:58:26Z",
    "link": "http://arxiv.org/pdf/2510.06190v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Chenxiao Yang",
      "Cai Zhou",
      "David Wipf",
      "Zhiyuan Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12945v1",
    "title": "APT: Affine Prototype-Timestamp For Time Series Forecasting Under Distribution Shift",
    "summary": "Time series forecasting under distribution shift remains challenging, as existing deep learning models often rely on local statistical normalization (e.g., mean and variance) that fails to capture global distribution shift. Methods like RevIN and its variants attempt to decouple distribution and pattern but still struggle with missing values, noisy observations, and invalid channel-wise affine transformation. To address these limitations, we propose Affine Prototype Timestamp (APT), a lightweight and flexible plug-in module that injects global distribution features into the normalization-forecasting pipeline. By leveraging timestamp conditioned prototype learning, APT dynamically generates affine parameters that modulate both input and output series, enabling the backbone to learn from self-supervised, distribution-aware clustered instances. APT is compatible with arbitrary forecasting backbones and normalization strategies while introducing minimal computational overhead. Extensive experiments across six benchmark datasets and multiple backbone-normalization combinations demonstrate that APT significantly improves forecasting performance under distribution shift.",
    "published": "2025-11-17T03:56:53Z",
    "updated": "2025-11-17T03:56:53Z",
    "link": "http://arxiv.org/pdf/2511.12945v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yujie Li",
      "Zezhi Shao",
      "Chengqing Yu",
      "Yisong Fu",
      "Tao Sun",
      "Yongjun Xu",
      "Fei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12934v1",
    "title": "AIF: Asynchronous Inference Framework for Cost-Effective Pre-Ranking",
    "summary": "In industrial recommendation systems, pre-ranking models based on deep neural networks (DNNs) commonly adopt a sequential execution framework: feature fetching and model forward computation are triggered only after receiving candidates from the upstream retrieval stage. This design introduces inherent bottlenecks, including redundant computations of identical users/items and increased latency due to strictly sequential operations, which jointly constrain the model's capacity and system efficiency. To address these limitations, we propose the Asynchronous Inference Framework (AIF), a cost-effective computational architecture that decouples interaction-independent components, those operating within a single user or item, from real-time prediction. AIF reorganizes the model inference process by performing user-side computations in parallel with the retrieval stage and conducting item-side computations in a nearline manner. This means that interaction-independent components are calculated just once and completed before the real-time prediction phase of the pre-ranking stage. As a result, AIF enhances computational efficiency and reduces latency, freeing up resources to significantly improve the feature set and model architecture of interaction-independent components. Moreover, we delve into model design within the AIF framework, employing approximated methods for interaction-dependent components in online real-time predictions. By co-designing both the framework and the model, our solution achieves notable performance gains without significantly increasing computational and latency costs. This has enabled the successful deployment of AIF in the Taobao display advertising system.",
    "published": "2025-11-17T03:39:32Z",
    "updated": "2025-11-17T03:39:32Z",
    "link": "http://arxiv.org/pdf/2511.12934v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR"
    ],
    "authors": [
      "Zhi Kou",
      "Xiang-Rong Sheng",
      "Shuguang Han",
      "Zhishan Zhao",
      "Yueyao Cheng",
      "Han Zhu",
      "Jian Xu",
      "Bo Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09598v2",
    "title": "Parametric Expensive Multi-Objective Optimization via Generative Solution Modeling",
    "summary": "Many real-world applications require solving families of expensive multi-objective optimization problems~(EMOPs) under varying operational conditions. This gives rise to parametric expensive multi-objective optimization problems (P-EMOPs) where each task parameter defines a distinct optimization instance. Current multi-objective Bayesian optimization methods have been widely used for finding finite sets of Pareto optimal solutions for individual tasks. However, P-EMOPs present a fundamental challenge: the continuous task parameter space can contain infinite distinct problems, each requiring separate expensive evaluations. This demands learning an inverse model that can directly predict optimized solutions for any task-preference query without expensive re-evaluation. This paper introduces the first parametric multi-objective Bayesian optimizer that learns this inverse model by alternating between (1) acquisition-driven search leveraging inter-task synergies and (2) generative solution sampling via conditional generative models. This approach enables efficient optimization across related tasks and finally achieves direct solution prediction for unseen parameterized EMOPs without additional expensive evaluations. We theoretically justify the faster convergence by leveraging inter-task synergies through task-aware Gaussian processes. Meanwhile, empirical studies in synthetic and real-world benchmarks further verify the effectiveness of our alternating framework.",
    "published": "2025-11-12T15:13:27Z",
    "updated": "2025-11-17T03:24:12Z",
    "link": "http://arxiv.org/pdf/2511.09598v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Tingyang Wei",
      "Jiao Liu",
      "Abhishek Gupta",
      "Chin Chun Ooi",
      "Puay Siew Tan",
      "Yew-Soon Ong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.04407v2",
    "title": "Exploiting Missing Data Remediation Strategies using Adversarial Missingness Attacks",
    "summary": "Adversarial Missingness (AM) attacks aim to manipulate model fitting by carefully engineering a missing data problem to achieve a specific malicious objective. AM attacks are significantly different from prior data poisoning attacks in that no malicious data inserted and no data is maliciously perturbed. Current AM attacks are feasible only under the assumption that the modeler (victim) uses full-information maximum likelihood methods to handle missingness. This work aims to remedy this limitation of AM attacks; in the approach taken here, the adversary achieves their goal by solving a bi-level optimization problem to engineer the adversarial missingness mechanism, where the lower level problem incorporates a differentiable approximation of the targeted missingness remediation technique. As instantiations of this framework, AM attacks are provided for three popular techniques: (i) complete case analysis, (ii) mean imputation, and (iii) regression-based imputation for general empirical risk minimization (ERM) problems. Experiments on real-world data show that AM attacks are successful with modest levels of missingness (less than 20%). Furthermore, we show on the real-world Twins dataset that AM attacks can manipulate the estimated average treatment effect (ATE) as an instance of the general ERM problems: the adversary succeeds in not only reversing the sign, but also in substantially inflating the ATE values from a true value of -1.61% to a manipulated one as high as 10%. These experimental results hold when the ATE is calculated using multiple regression-based estimators with different architectures, even when the adversary is restricted to modifying only a subset of the training data.",
    "published": "2024-09-06T17:10:28Z",
    "updated": "2025-11-17T03:22:55Z",
    "link": "http://arxiv.org/pdf/2409.04407v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Deniz Koyuncu",
      "Alex Gittens",
      "Bülent Yener",
      "Moti Yung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11472v2",
    "title": "Quantifying and Improving Adaptivity in Conformal Prediction through Input Transformations",
    "summary": "Conformal prediction constructs a set of labels instead of a single point prediction, while providing a probabilistic coverage guarantee. Beyond the coverage guarantee, adaptiveness to example difficulty is an important property. It means that the method should produce larger prediction sets for more difficult examples, and smaller ones for easier examples. Existing evaluation methods for adaptiveness typically analyze coverage rate violation or average set size across bins of examples grouped by difficulty. However, these approaches often suffer from imbalanced binning, which can lead to inaccurate estimates of coverage or set size. To address this issue, we propose a binning method that leverages input transformations to sort examples by difficulty, followed by uniform-mass binning. Building on this binning, we introduce two metrics to better evaluate adaptiveness. These metrics provide more reliable estimates of coverage rate violation and average set size due to balanced binning, leading to more accurate adaptivity assessment. Through experiments, we demonstrate that our proposed metric correlates more strongly with the desired adaptiveness property compared to existing ones. Furthermore, motivated by our findings, we propose a new adaptive prediction set algorithm that groups examples by estimated difficulty and applies group-conditional conformal prediction. This allows us to determine appropriate thresholds for each group. Experimental results on both (a) an Image Classification (ImageNet) (b) a medical task (visual acuity prediction) show that our method outperforms existing approaches according to the new metrics.",
    "published": "2025-11-14T16:42:42Z",
    "updated": "2025-11-17T03:21:34Z",
    "link": "http://arxiv.org/pdf/2511.11472v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Sooyong Jang",
      "Insup Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.04524v3",
    "title": "Provably data-driven projection method for quadratic programming",
    "summary": "Projection methods aim to reduce the dimensionality of the optimization instance, thereby improving the scalability of high-dimensional problems. Recently, Sakaue and Oki proposed a data-driven approach for linear programs (LPs), where the projection matrix is learned from observed problem instances drawn from an application-specific distribution of problems. We analyze the generalization guarantee for the data-driven projection matrix learning for convex quadratic programs (QPs). Unlike in LPs, the optimal solutions of convex QPs are not confined to the vertices of the feasible polyhedron, and this complicates the analysis of the optimal value function. To overcome this challenge, we demonstrate that the solutions of convex QPs can be localized within a feasible region corresponding to a special active set, utilizing Caratheodory's theorem. Building on such observation, we propose the unrolled active set method, which models the computation of the optimal value as a Goldberg-Jerrum (GJ) algorithm with bounded complexities, thereby establishing learning guarantees. We then further extend our analysis to other settings, including learning to match the optimal solution and input-aware setting, where we learn a mapping from QP problem instances to projection matrices.",
    "published": "2025-09-03T14:44:25Z",
    "updated": "2025-11-17T02:57:46Z",
    "link": "http://arxiv.org/pdf/2509.04524v3.pdf",
    "category": [
      "math.OC",
      "cs.LG"
    ],
    "authors": [
      "Anh Tuan Nguyen",
      "Viet Anh Nguyen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12890v1",
    "title": "Method of Manufactured Learning for Solver-free Training of Neural Operators",
    "summary": "Training neural operators to approximate mappings between infinite-dimensional function spaces often requires extensive datasets generated by either demanding experimental setups or computationally expensive numerical solvers. This dependence on solver-based data limits scalability and constrains exploration across physical systems. Here we introduce the Method of Manufactured Learning (MML), a solver-independent framework for training neural operators using analytically constructed, physics-consistent datasets. Inspired by the classical method of manufactured solutions, MML replaces numerical data generation with functional synthesis, i.e., smooth candidate solutions are sampled from controlled analytical spaces, and the corresponding forcing fields are derived by direct application of the governing differential operators. During inference, setting these forcing terms to zero restores the original governing equations, allowing the trained neural operator to emulate the true solution operator of the system. The framework is agnostic to network architecture and can be integrated with any operator learning paradigm. In this paper, we employ Fourier neural operator as a representative example. Across canonical benchmarks including heat, advection, Burgers, and diffusion-reaction equations. MML achieves high spectral accuracy, low residual errors, and strong generalization to unseen conditions. By reframing data generation as a process of analytical synthesis, MML offers a scalable, solver-agnostic pathway toward constructing physically grounded neural operators that retain fidelity to governing laws without reliance on expensive numerical simulations or costly experimental data for training.",
    "published": "2025-11-17T02:24:19Z",
    "updated": "2025-11-17T02:24:19Z",
    "link": "http://arxiv.org/pdf/2511.12890v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Arth Sojitra",
      "Omer San"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12881v1",
    "title": "On the Information Processing of One-Dimensional Wasserstein Distances with Finite Samples",
    "summary": "Leveraging the Wasserstein distance -- a summation of sample-wise transport distances in data space -- is advantageous in many applications for measuring support differences between two underlying density functions. However, when supports significantly overlap while densities exhibit substantial pointwise differences, it remains unclear whether and how this transport information can accurately identify these differences, particularly their analytic characterization in finite-sample settings. We address this issue by conducting an analysis of the information processing capabilities of the one-dimensional Wasserstein distance with finite samples. By utilizing the Poisson process and isolating the rate factor, we demonstrate the capability of capturing the pointwise density difference with Wasserstein distances and how this information harmonizes with support differences. The analyzed properties are confirmed using neural spike train decoding and amino acid contact frequency data. The results reveal that the one-dimensional Wasserstein distance highlights meaningful density differences related to both rate and support.",
    "published": "2025-11-17T02:16:20Z",
    "updated": "2025-11-17T02:16:20Z",
    "link": "http://arxiv.org/pdf/2511.12881v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Cheongjae Jang",
      "Jonghyun Won",
      "Soyeon Jun",
      "Chun Kee Chung",
      "Keehyoung Joo",
      "Yung-Kyun Noh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.10809v2",
    "title": "Near-optimal Linear Predictive Clustering in Non-separable Spaces via Mixed Integer Programming and Quadratic Pseudo-Boolean Reductions",
    "summary": "Linear Predictive Clustering (LPC) partitions samples based on shared linear relationships between feature and target variables, with numerous applications including marketing, medicine, and education. Greedy optimization methods, commonly used for LPC, alternate between clustering and linear regression but lack global optimality. While effective for separable clusters, they struggle in non-separable settings where clusters overlap in feature space. In an alternative constrained optimization paradigm, Bertsimas and Shioda (2007) formulated LPC as a Mixed-Integer Program (MIP), ensuring global optimality regardless of separability but suffering from poor scalability. This work builds on the constrained optimization paradigm to introduce two novel approaches that improve the efficiency of global optimization for LPC. By leveraging key theoretical properties of separability, we derive near-optimal approximations with provable error bounds, significantly reducing the MIP formulation's complexity and improving scalability. Additionally, we can further approximate LPC as a Quadratic Pseudo-Boolean Optimization (QPBO) problem, achieving substantial computational improvements in some settings. Comparative analyses on synthetic and real-world datasets demonstrate that our methods consistently achieve near-optimal solutions with substantially lower regression errors than greedy optimization while exhibiting superior scalability over existing MIP formulations.",
    "published": "2025-11-13T21:22:47Z",
    "updated": "2025-11-17T02:13:44Z",
    "link": "http://arxiv.org/pdf/2511.10809v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jiazhou Liang",
      "Hassan Khurram",
      "Scott Sanner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2407.19858v7",
    "title": "AI-Powered Energy Algorithmic Trading: Integrating Hidden Markov Models with Neural Networks",
    "summary": "In quantitative finance, machine learning methods are essential for alpha generation. This study introduces a new approach that combines Hidden Markov Models (HMM) and neural networks, integrated with Black-Litterman portfolio optimization. During the COVID period (2019-2022), this dual-model approach achieved a 83% return with a Sharpe ratio of 0.77. It incorporates two risk models to enhance risk management, showing efficiency during volatile periods. The methodology was implemented on the QuantConnect platform, which was chosen for its robust framework and experimental reproducibility. The system, which predicts future price movements, includes a three-year warm-up to ensure proper algorithm function. It targets highly liquid, large-cap energy stocks to ensure stable and predictable performance while also considering broker payments. The dual-model alpha system utilizes log returns to select the optimal state based on the historical performance. It combines state predictions with neural network outputs, which are based on historical data, to generate trading signals. This study examined the architecture of the trading system, data pre-processing, training, and performance. The full code and backtesting data are available under the QuantConnect terms: https://github.com/tiagomonteiro0715/AI-Powered-Energy-Algorithmic-Trading-Integrating-Hidden-Markov-Models-with-Neural-Networks",
    "published": "2024-07-29T10:26:52Z",
    "updated": "2025-11-17T01:54:48Z",
    "link": "http://arxiv.org/pdf/2407.19858v7.pdf",
    "category": [
      "q-fin.PM",
      "cs.LG",
      "q-fin.GN",
      "stat.AP"
    ],
    "authors": [
      "Tiago Monteiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.03472v4",
    "title": "A Symplectic Analysis of Alternating Mirror Descent",
    "summary": "Motivated by understanding the behavior of the Alternating Mirror Descent (AMD) algorithm for bilinear zero-sum games, we study the discretization of continuous-time Hamiltonian flow via the symplectic Euler method. We provide a framework for analysis using results from Hamiltonian dynamics, Lie algebra, and symplectic numerical integrators, with an emphasis on the existence and properties of a conserved quantity, the modified Hamiltonian (MH), for the symplectic Euler method. We compute the MH in closed-form when the original Hamiltonian is a quadratic function, and show that it generally differs from the other conserved quantity known previously in that case. We derive new error bounds on the MH when truncated at orders in the stepsize in terms of the number of iterations, $K$, and use these bounds to show an improved $\\mathcal{O}(K^{1/5})$ total regret bound and an $\\mathcal{O}(K^{-4/5})$ duality gap of the average iterates for AMD. Finally, we propose a conjecture which, if true, would imply that the total regret for AMD scales as $\\mathcal{O}\\left(K^{\\varepsilon}\\right)$ and the duality gap of the average iterates as $\\mathcal{O}\\left(K^{-1+\\varepsilon}\\right)$ for any $\\varepsilon>0$, and we can take $\\varepsilon=0$ upon certain convergence conditions for the MH.",
    "published": "2024-05-06T13:47:09Z",
    "updated": "2025-11-17T00:52:37Z",
    "link": "http://arxiv.org/pdf/2405.03472v4.pdf",
    "category": [
      "math.OC",
      "cs.GT",
      "cs.LG",
      "math.DS",
      "math.NA"
    ],
    "authors": [
      "Jonas Katona",
      "Xiuyuan Wang",
      "Andre Wibisono"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12848v1",
    "title": "Structured Imitation Learning of Interactive Policies through Inverse Games",
    "summary": "Generative model-based imitation learning methods have recently achieved strong results in learning high-complexity motor skills from human demonstrations. However, imitation learning of interactive policies that coordinate with humans in shared spaces without explicit communication remains challenging, due to the significantly higher behavioral complexity in multi-agent interactions compared to non-interactive tasks. In this work, we introduce a structured imitation learning framework for interactive policies by combining generative single-agent policy learning with a flexible yet expressive game-theoretic structure. Our method explicitly separates learning into two steps: first, we learn individual behavioral patterns from multi-agent demonstrations using standard imitation learning; then, we structurally learn inter-agent dependencies by solving an inverse game problem. Preliminary results in a synthetic 5-agent social navigation task show that our method significantly improves non-interactive policies and performs comparably to the ground truth interactive policy using only 50 demonstrations. These results highlight the potential of structured imitation learning in interactive settings.",
    "published": "2025-11-17T00:42:45Z",
    "updated": "2025-11-17T00:42:45Z",
    "link": "http://arxiv.org/pdf/2511.12848v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Max M. Sun",
      "Todd Murphey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12842v1",
    "title": "Scalable learning of macroscopic stochastic dynamics",
    "summary": "Macroscopic dynamical descriptions of complex physical systems are crucial for understanding and controlling material behavior. With the growing availability of data and compute, machine learning has become a promising alternative to first-principles methods to build accurate macroscopic models from microscopic trajectory simulations. However, for spatially extended systems, direct simulations of sufficiently large microscopic systems that inform macroscopic behavior is prohibitive. In this work, we propose a framework that learns the macroscopic dynamics of large stochastic microscopic systems using only small-system simulations. Our framework employs a partial evolution scheme to generate training data pairs by evolving large-system snapshots within local patches. We subsequently identify the closure variables associated with the macroscopic observables and learn the macroscopic dynamics using a custom loss. Furthermore, we introduce a hierarchical upsampling scheme that enables efficient generation of large-system snapshots from small-system trajectory distributions. We empirically demonstrate the accuracy and robustness of our framework through a variety of stochastic spatially extended systems, including those described by stochastic partial differential equations, idealised lattice spin systems, and a more realistic NbMoTa alloy system.",
    "published": "2025-11-17T00:11:06Z",
    "updated": "2025-11-17T00:11:06Z",
    "link": "http://arxiv.org/pdf/2511.12842v1.pdf",
    "category": [
      "physics.comp-ph",
      "cs.LG"
    ],
    "authors": [
      "Mengyi Chen",
      "Pengru Huang",
      "Kostya S. Novoselov",
      "Qianxiao Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.14234v2",
    "title": "Optimal Subspace Embeddings: Resolving Nelson-Nguyen Conjecture Up to Sub-Polylogarithmic Factors",
    "summary": "We give a proof of the conjecture of Nelson and Nguyen [FOCS 2013] on the optimal dimension and sparsity of oblivious subspace embeddings, up to sub-polylogarithmic factors: For any $n\\geq d$ and $ε\\geq d^{-O(1)}$, there is a random $\\tilde O(d/ε^2)\\times n$ matrix $Π$ with $\\tilde O(\\log(d)/ε)$ non-zeros per column such that for any $A\\in\\mathbb{R}^{n\\times d}$, with high probability, $(1-ε)\\|Ax\\|\\leq\\|ΠAx\\|\\leq(1+ε)\\|Ax\\|$ for all $x\\in\\mathbb{R}^d$, where $\\tilde O(\\cdot)$ hides only sub-polylogarithmic factors in $d$. Our result in particular implies a new fastest sub-current matrix multiplication time reduction of size $\\tilde O(d/ε^2)$ for a broad class of $n\\times d$ linear regression tasks.\n  A key novelty in our analysis is a matrix concentration technique we call iterative decoupling, which we use to fine-tune the higher-order trace moment bounds attainable via existing random matrix universality tools [Brailovskaya and van Handel, GAFA 2024].",
    "published": "2025-08-19T19:45:52Z",
    "updated": "2025-11-17T00:00:57Z",
    "link": "http://arxiv.org/pdf/2508.14234v2.pdf",
    "category": [
      "cs.DS",
      "cs.LG",
      "math.NA",
      "math.PR",
      "stat.ML"
    ],
    "authors": [
      "Shabarish Chenakkod",
      "Michał Dereziński",
      "Xiaoyu Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12840v1",
    "title": "Benign Overfitting in Linear Classifiers with a Bias Term",
    "summary": "Modern machine learning models with a large number of parameters often generalize well despite perfectly interpolating noisy training data - a phenomenon known as benign overfitting. A foundational explanation for this in linear classification was recently provided by Hashimoto et al. (2025). However, this analysis was limited to the setting of \"homogeneous\" models, which lack a bias (intercept) term - a standard component in practice. This work directly extends Hashimoto et al.'s results to the more realistic inhomogeneous case, which incorporates a bias term. Our analysis proves that benign overfitting persists in these more complex models. We find that the presence of the bias term introduces new constraints on the data's covariance structure required for generalization, an effect that is particularly pronounced when label noise is present. However, we show that in the isotropic case, these new constraints are dominated by the requirements inherited from the homogeneous model. This work provides a more complete picture of benign overfitting, revealing the non-trivial impact of the bias term on the conditions required for good generalization.",
    "published": "2025-11-16T23:59:36Z",
    "updated": "2025-11-16T23:59:36Z",
    "link": "http://arxiv.org/pdf/2511.12840v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Yuta Kondo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12836v1",
    "title": "DIGing--SGLD: Decentralized and Scalable Langevin Sampling over Time--Varying Networks",
    "summary": "Sampling from a target distribution induced by training data is central to Bayesian learning, with Stochastic Gradient Langevin Dynamics (SGLD) serving as a key tool for scalable posterior sampling and decentralized variants enabling learning when data are distributed across a network of agents. This paper introduces DIGing-SGLD, a decentralized SGLD algorithm designed for scalable Bayesian learning in multi-agent systems operating over time-varying networks. Existing decentralized SGLD methods are restricted to static network topologies, and many exhibit steady-state sampling bias caused by network effects, even when full batches are used. DIGing-SGLD overcomes these limitations by integrating Langevin-based sampling with the gradient-tracking mechanism of the DIGing algorithm, originally developed for decentralized optimization over time-varying networks, thereby enabling efficient and bias-free sampling without a central coordinator. To our knowledge, we provide the first finite-time non-asymptotic Wasserstein convergence guarantees for decentralized SGLD-based sampling over time-varying networks, with explicit constants. Under standard strong convexity and smoothness assumptions, DIGing-SGLD achieves geometric convergence to an $O(\\sqrtη)$ neighborhood of the target distribution, where $η$ is the stepsize, with dependence on the target accuracy matching the best-known rates for centralized and static-network SGLD algorithms using constant stepsize. Numerical experiments on Bayesian linear and logistic regression validate the theoretical results and demonstrate the strong empirical performance of DIGing-SGLD under dynamically evolving network conditions.",
    "published": "2025-11-16T23:42:44Z",
    "updated": "2025-11-16T23:42:44Z",
    "link": "http://arxiv.org/pdf/2511.12836v1.pdf",
    "category": [
      "math.OC",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Waheed U. Bajwa",
      "Mert Gurbuzbalaban",
      "Mustafa Ali Kutbay",
      "Lingjiong Zhu",
      "Muhammad Zulqarnain"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12829v1",
    "title": "An Evaluation of Representation Learning Methods in Particle Physics Foundation Models",
    "summary": "We present a systematic evaluation of representation learning objectives for particle physics within a unified framework. Our study employs a shared transformer-based particle-cloud encoder with standardized preprocessing, matched sampling, and a consistent evaluation protocol on a jet classification dataset. We compare contrastive (supervised and self-supervised), masked particle modeling, and generative reconstruction objectives under a common training regimen. In addition, we introduce targeted supervised architectural modifications that achieve state-of-the-art performance on benchmark evaluations. This controlled comparison isolates the contributions of the learning objective, highlights their respective strengths and limitations, and provides reproducible baselines. We position this work as a reference point for the future development of foundation models in particle physics, enabling more transparent and robust progress across the community.",
    "published": "2025-11-16T23:23:47Z",
    "updated": "2025-11-16T23:23:47Z",
    "link": "http://arxiv.org/pdf/2511.12829v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Michael Chen",
      "Raghav Kansal",
      "Abhijith Gandrakota",
      "Zichun Hao",
      "Jennifer Ngadiuba",
      "Maria Spiropulu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12827v1",
    "title": "Efficient Adversarial Malware Defense via Trust-Based Raw Override and Confidence-Adaptive Bit-Depth Reduction",
    "summary": "The deployment of robust malware detection systems in big data environments requires careful consideration of both security effectiveness and computational efficiency. While recent advances in adversarial defenses have demonstrated strong robustness improvements, they often introduce computational overhead ranging from 4x to 22x, which presents significant challenges for production systems processing millions of samples daily. In this work, we propose a novel framework that combines Trust-Raw Override (TRO) with Confidence-Adaptive Bit-Depth Reduction (CABDR) to explicitly optimize the trade-off between adversarial robustness and computational efficiency. Our approach leverages adaptive confidence-based mechanisms to selectively apply defensive measures, achieving 1.76x computational overhead - a 2.3x improvement over state-of-the-art smoothing defenses. Through comprehensive evaluation on the EMBER v2 dataset comprising 800K samples, we demonstrate that our framework maintains 91 percent clean accuracy while reducing attack success rates to 31-37 percent across multiple attack types, with particularly strong performance against optimization-based attacks such as C and W (48.8 percent reduction). The framework achieves throughput of up to 1.26 million samples per second (measured on pre-extracted EMBER features with no runtime feature extraction), validated across 72 production configurations with statistical significance (5 independent runs, 95 percent confidence intervals, p less than 0.01). Our results suggest that practical adversarial robustness in production environments requires explicit optimization of the efficiency-robustness trade-off, providing a viable path for organizations to deploy robust defenses without prohibitive infrastructure costs.",
    "published": "2025-11-16T23:21:44Z",
    "updated": "2025-11-16T23:21:44Z",
    "link": "http://arxiv.org/pdf/2511.12827v1.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Ayush Chaudhary",
      "Sisir Doppalpudi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12823v1",
    "title": "Enhancing LLM Code Generation Capabilities through Test-Driven Development and Code Interpreter",
    "summary": "Over the past few years, improving LLM code generation capabilities has been a key focus in NLP research. Despite Bengali having 242 million native speakers worldwide, it receives little attention when it comes to training LLMs. More recently, various fine-tuning and augmented generation techniques have been employed to significantly enhance code generation performance. However, they require considerable expertise and resources to utilize effectively as an end user. The goal of our work is to democratize access to powerful code generation tools in resource-constrained emerging markets, enabling users to leverage them in their native language.\n  We introduce a novel approach that combines Test-Driven Development (TDD) and Code Interpreter (CI), utilizing open-weight models, which improves the baseline accuracy for code generation with Bengali prompts and achieves an overall accuracy of 85%. Our approach requires no finetuning and proves that even the smallest models in the same family can attain up to 98% accuracy compared to the largest models. All of our results are publicly shared in GitHub for validation and reproducibility.",
    "published": "2025-11-16T23:05:11Z",
    "updated": "2025-11-16T23:05:11Z",
    "link": "http://arxiv.org/pdf/2511.12823v1.pdf",
    "category": [
      "cs.SE",
      "cs.LG",
      "cs.PL"
    ],
    "authors": [
      "Sajed Jalil",
      "Shuvo Saha",
      "Hossain Mohammad Seym"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12817v1",
    "title": "Assessing Automated Fact-Checking for Medical LLM Responses with Knowledge Graphs",
    "summary": "The recent proliferation of large language models (LLMs) holds the potential to revolutionize healthcare, with strong capabilities in diverse medical tasks. Yet, deploying LLMs in high-stakes healthcare settings requires rigorous verification and validation to understand any potential harm. This paper investigates the reliability and viability of using medical knowledge graphs (KGs) for the automated factuality evaluation of LLM-generated responses. To ground this investigation, we introduce FAITH, a framework designed to systematically probe the strengths and limitations of this KG-based approach. FAITH operates without reference answers by decomposing responses into atomic claims, linking them to a medical KG, and scoring them based on evidence paths. Experiments on diverse medical tasks with human subjective evaluations demonstrate that KG-grounded evaluation achieves considerably higher correlations with clinician judgments and can effectively distinguish LLMs with varying capabilities. It is also robust to textual variances. The inherent explainability of its scoring can further help users understand and mitigate the limitations of current LLMs. We conclude that while limitations exist, leveraging KGs is a prominent direction for automated factuality assessment in healthcare.",
    "published": "2025-11-16T22:58:22Z",
    "updated": "2025-11-16T22:58:22Z",
    "link": "http://arxiv.org/pdf/2511.12817v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Shasha Zhou",
      "Mingyu Huang",
      "Jack Cole",
      "Charles Britton",
      "Ming Yin",
      "Jan Wolber",
      "Ke Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.06838v3",
    "title": "P3-LLM: An Integrated NPU-PIM Accelerator for LLM Inference Using Hybrid Numerical Formats",
    "summary": "The substantial memory bandwidth and computational demands of large language models (LLMs) present critical challenges for efficient inference. To tackle this, the literature has explored heterogeneous systems that combine neural processing units (NPUs) with DRAM-based processing-in-memory (PIM) for LLM acceleration. However, existing high-precision (e.g., FP16) PIM compute units incur significant area and power overhead in DRAM technology, limiting the effective computation throughput. In this paper, we introduce P3-LLM, a novel NPU-PIM integrated accelerator for LLM inference using hybrid numerical formats. Our approach is threefold: First, we propose a flexible mixed-precision quantization scheme, which leverages hybrid numerical formats to quantize different LLM operands with high compression efficiency and minimal accuracy loss. Second, we architect an efficient PIM accelerator for P3-LLM, featuring enhanced compute units to support hybrid numerical formats. Our careful choice of numerical formats allows to co-design low-precision PIM compute units that significantly boost the computation throughput under iso-area constraints. Third, we optimize the low-precision dataflow of different LLM modules by applying operator fusion to minimize the overhead of runtime dequantization. Evaluation on a diverse set of representative LLMs and tasks demonstrates that P3-LLM achieves state-of-the-art accuracy in terms of both KV-cache quantization and weight-activation quantization. Combining the proposed quantization scheme with PIM architecture co-design, P3-LLM yields an average of $4.9\\times$, $2.0\\times$, and $3.4\\times$ speedups over the state-of-the-art LLM accelerators HBM-PIM, Ecco, and Pimba, respectively. Our quantization code is available at https://github.com/yc2367/P3-LLM.git",
    "published": "2025-11-10T08:29:34Z",
    "updated": "2025-11-16T22:19:39Z",
    "link": "http://arxiv.org/pdf/2511.06838v3.pdf",
    "category": [
      "cs.AR",
      "cs.LG"
    ],
    "authors": [
      "Yuzong Chen",
      "Chao Fang",
      "Xilai Dai",
      "Yuheng Wu",
      "Thierry Tambe",
      "Marian Verhelst",
      "Mohamed S. Abdelfattah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12805v1",
    "title": "Practical Causal Evaluation Metrics for Biological Networks",
    "summary": "Estimating causal networks from biological data is a critical step in systems biology. When evaluating the inferred network, assessing the networks based on their intervention effects is particularly important for downstream probabilistic reasoning and the identification of potential drug targets. In the context of gene regulatory network inference, biological databases are often used as reference sources. These databases typically describe relationships in a qualitative rather than quantitative manner. However, few evaluation metrics have been developed that take this qualitative nature into account. To address this, we developed a metric, the sign-augmented Structural Intervention Distance (sSID), and a weighted sSID that incorporates the net effects of the intervention. Through simulations and analyses of real transcriptomic datasets, we found that our proposed metrics could identify a different algorithm as optimal compared to conventional metrics, and the network selected by sSID had a superior performance in the classification task of clinical covariates using transcriptomic data. This suggests that sSID can distinguish networks that are structurally correct but functionally incorrect, highlighting its potential as a more biologically meaningful and practical evaluation metric.",
    "published": "2025-11-16T22:18:15Z",
    "updated": "2025-11-16T22:18:15Z",
    "link": "http://arxiv.org/pdf/2511.12805v1.pdf",
    "category": [
      "q-bio.MN",
      "cs.LG"
    ],
    "authors": [
      "Noriaki Sato",
      "Marco Scutari",
      "Shuichi Kawano",
      "Rui Yamaguchi",
      "Seiya Imoto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12788v1",
    "title": "Physics-Constrained Adaptive Neural Networks Enable Real-Time Semiconductor Manufacturing Optimization with Minimal Training Data",
    "summary": "The semiconductor industry faces a computational crisis in extreme ultraviolet (EUV) lithography optimization, where traditional methods consume billions of CPU hours while failing to achieve sub-nanometer precision. We present a physics-constrained adaptive learning framework that automatically calibrates electromagnetic approximations through learnable parameters $\\boldsymbolθ = \\{θ_d, θ_a, θ_b, θ_p, θ_c\\}$ while simultaneously minimizing Edge Placement Error (EPE) between simulated aerial images and target photomasks. The framework integrates differentiable modules for Fresnel diffraction, material absorption, optical point spread function blur, phase-shift effects, and contrast modulation with direct geometric pattern matching objectives, enabling cross-geometry generalization with minimal training data. Through physics-constrained learning on 15 representative patterns spanning current production to future research nodes, we demonstrate consistent sub-nanometer EPE performance (0.664-2.536 nm range) using only 50 training samples per pattern. Adaptive physics learning achieves an average improvement of 69.9\\% over CNN baselines without physics constraints, with a significant inference speedup over rigorous electromagnetic solvers after training completion. This approach requires 90\\% fewer training samples through cross-geometry generalization compared to pattern-specific CNN training approaches. This work establishes physics-constrained adaptive learning as a foundational methodology for real-time semiconductor manufacturing optimization, addressing the critical gap between academic physics-informed neural networks and industrial deployment requirements through joint physics calibration and manufacturing precision objectives.",
    "published": "2025-11-16T21:40:57Z",
    "updated": "2025-11-16T21:40:57Z",
    "link": "http://arxiv.org/pdf/2511.12788v1.pdf",
    "category": [
      "cs.LG",
      "cs.AR",
      "math.OC"
    ],
    "authors": [
      "Rubén Darío Guerrero"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09828v2",
    "title": "SMoFi: Step-wise Momentum Fusion for Split Federated Learning on Heterogeneous Data",
    "summary": "Split Federated Learning is a system-efficient federated learning paradigm that leverages the rich computing resources at a central server to train model partitions. Data heterogeneity across silos, however, presents a major challenge undermining the convergence speed and accuracy of the global model. This paper introduces Step-wise Momentum Fusion (SMoFi), an effective and lightweight framework that counteracts gradient divergence arising from data heterogeneity by synchronizing the momentum buffers across server-side optimizers. To control gradient divergence over the training process, we design a staleness-aware alignment mechanism that imposes constraints on gradient updates of the server-side submodel at each optimization step. Extensive validations on multiple real-world datasets show that SMoFi consistently improves global model accuracy (up to 7.1%) and convergence speed (up to 10.25$\\times$). Furthermore, SMoFi has a greater impact with more clients involved and deeper learning models, making it particularly suitable for model training in resource-constrained contexts.",
    "published": "2025-11-13T00:21:05Z",
    "updated": "2025-11-16T21:33:02Z",
    "link": "http://arxiv.org/pdf/2511.09828v2.pdf",
    "category": [
      "cs.LG",
      "cs.DC"
    ],
    "authors": [
      "Mingkun Yang",
      "Ran Zhu",
      "Qing Wang",
      "Jie Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.20102v3",
    "title": "Extendable Planning via Multiscale Diffusion",
    "summary": "Long-horizon planning is crucial in complex environments, but diffusion-based planners like Diffuser are limited by the trajectory lengths observed during training. This creates a dilemma: long trajectories are needed for effective planning, yet they degrade model performance. In this paper, we introduce this extendable long-horizon planning challenge and propose a two-phase solution. First, Progressive Trajectory Extension incrementally constructs longer trajectories through multi-round compositional stitching. Second, the Hierarchical Multiscale Diffuser enables efficient training and inference over long horizons by reasoning across temporal scales. To avoid the need for multiple separate models, we propose Adaptive Plan Pondering and the Recursive HM-Diffuser, which unify hierarchical planning within a single model. Experiments show our approach yields strong performance gains, advancing scalable and efficient decision-making over long-horizons.",
    "published": "2025-03-25T22:52:46Z",
    "updated": "2025-11-16T21:28:31Z",
    "link": "http://arxiv.org/pdf/2503.20102v3.pdf",
    "category": [
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Chang Chen",
      "Hany Hamed",
      "Doojin Baek",
      "Taegu Kang",
      "Samyeul Noh",
      "Yoshua Bengio",
      "Sungjin Ahn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12783v1",
    "title": "Function-on-Function Bayesian Optimization",
    "summary": "Bayesian optimization (BO) has been widely used to optimize expensive and gradient-free objective functions across various domains. However, existing BO methods have not addressed the objective where both inputs and outputs are functions, which increasingly arise in complex systems as advanced sensing technologies. To fill this gap, we propose a novel function-on-function Bayesian optimization (FFBO) framework. Specifically, we first introduce a function-on-function Gaussian process (FFGP) model with a separable operator-valued kernel to capture the correlations between function-valued inputs and outputs. Compared to existing Gaussian process models, FFGP is modeled directly in the function space. Based on FFGP, we define a scalar upper confidence bound (UCB) acquisition function using a weighted operator-based scalarization strategy. Then, a scalable functional gradient ascent algorithm (FGA) is developed to efficiently identify the optimal function-valued input. We further analyze the theoretical properties of the proposed method. Extensive experiments on synthetic and real-world data demonstrate the superior performance of FFBO over existing approaches.",
    "published": "2025-11-16T21:24:57Z",
    "updated": "2025-11-16T21:24:57Z",
    "link": "http://arxiv.org/pdf/2511.12783v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Jingru Huang",
      "Haijie Xu",
      "Manrui Jiang",
      "Chen Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/1910.03867v3",
    "title": "Loss Patterns of Neural Networks",
    "summary": "We present multi-point optimization: an optimization technique that allows to train several models simultaneously without the need to keep the parameters of each one individually. The proposed method is used for a thorough empirical analysis of the loss landscape of neural networks. By extensive experiments on FashionMNIST and CIFAR10 datasets we demonstrate two things: 1) loss surface is surprisingly diverse and intricate in terms of landscape patterns it contains, and 2) adding batch normalization makes it more smooth. Source code to reproduce all the reported results is available on GitHub: https://github.com/universome/loss-patterns.",
    "published": "2019-10-09T09:44:27Z",
    "updated": "2025-11-16T21:06:59Z",
    "link": "http://arxiv.org/pdf/1910.03867v3.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Ivan Skorokhodov",
      "Mikhail Burtsev"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12770v1",
    "title": "MolEdit: Knowledge Editing for Multimodal Molecule Language Models",
    "summary": "Understanding and continuously refining multimodal molecular knowledge is crucial for advancing biomedicine, chemistry, and materials science. Molecule language models (MoLMs) have become powerful tools in these domains, integrating structural representations (e.g., SMILES strings, molecular graphs) with rich contextual descriptions (e.g., physicochemical properties). However, MoLMs can encode and propagate inaccuracies due to outdated web-mined training corpora or malicious manipulation, jeopardizing downstream discovery pipelines. While knowledge editing has been explored for general-domain AI, its application to MoLMs remains uncharted, presenting unique challenges due to the multifaceted and interdependent nature of molecular knowledge. In this paper, we take the first step toward MoLM editing for two critical tasks: molecule-to-caption generation and caption-to-molecule generation. To address molecule-specific challenges, we propose MolEdit, a powerful framework that enables targeted modifications while preserving unrelated molecular knowledge. MolEdit combines a Multi-Expert Knowledge Adapter that routes edits to specialized experts for different molecular facets with an Expertise-Aware Editing Switcher that activates the adapters only when input closely matches the stored edits across all expertise, minimizing interference with unrelated knowledge. To systematically evaluate editing performance, we introduce MEBench, a comprehensive benchmark assessing multiple dimensions, including Reliability (accuracy of the editing), Locality (preservation of irrelevant knowledge), and Generality (robustness to reformed queries). Across extensive experiments on two popular MoLM backbones, MolEdit delivers up to 18.8% higher Reliability and 12.0% better Locality than baselines while maintaining efficiency. The code is available at: https://github.com/LzyFischer/MolEdit.",
    "published": "2025-11-16T20:48:37Z",
    "updated": "2025-11-16T20:48:37Z",
    "link": "http://arxiv.org/pdf/2511.12770v1.pdf",
    "category": [
      "cs.LG",
      "cs.CE"
    ],
    "authors": [
      "Zhenyu Lei",
      "Patrick Soga",
      "Yaochen Zhu",
      "Yinhan He",
      "Yushun Dong",
      "Jundong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.01857v4",
    "title": "Using Linearized Optimal Transport to Predict the Evolution of Stochastic Particle Systems",
    "summary": "We develop an Euler-type method to predict the evolution of a time-dependent probability measure without explicitly learning an operator that governs its evolution. We use linearized optimal transport theory to prove that the measure-valued analog of Euler's method is first-order accurate when the measure evolves ``smoothly.'' In applications of interest, however, the measure is an empirical distribution of a system of stochastic particles whose behavior is only accessible through an agent-based micro-scale simulation. In such cases, this empirical measure does not evolve smoothly because the individual particles move chaotically on short time scales. However, we can still perform our Euler-type method, and when the particles' collective distribution approximates a measure that \\emph{does} evolve smoothly, we observe that the algorithm still accurately predicts this collective behavior over relatively large Euler steps, thus reducing the number of micro-scale steps required to step forward in time. In this way, our algorithm provides a ``macro-scale timestepper'' that requires less micro-scale data to still maintain accuracy, which we demonstrate with three illustrative examples: a biological agent-based model, a model of a PDE, and a model of Langevin dynamics.",
    "published": "2024-08-03T20:00:36Z",
    "updated": "2025-11-16T20:46:52Z",
    "link": "http://arxiv.org/pdf/2408.01857v4.pdf",
    "category": [
      "math.NA",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Nicholas Karris",
      "Evangelos A. Nikitopoulos",
      "Ioannis G. Kevrekidis",
      "Seungjoon Lee",
      "Alexander Cloninger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12764v1",
    "title": "INC: An Indirect Neural Corrector for Auto-Regressive Hybrid PDE Solvers",
    "summary": "When simulating partial differential equations, hybrid solvers combine coarse numerical solvers with learned correctors. They promise accelerated simulations while adhering to physical constraints. However, as shown in our theoretical framework, directly applying learned corrections to solver outputs leads to significant autoregressive errors, which originate from amplified perturbations that accumulate during long-term rollouts, especially in chaotic regimes. To overcome this, we propose the Indirect Neural Corrector (\\(\\mathrm{INC}\\)), which integrates learned corrections into the governing equations rather than applying direct state updates. Our key insight is that \\(\\mathrm{INC}\\) reduces the error amplification on the order of \\(Δt^{-1} + L\\), where \\(Δt\\) is the timestep and $L$ the Lipschitz constant. At the same time, our framework poses no architectural requirements and integrates seamlessly with arbitrary neural networks and solvers. We test \\(\\mathrm{INC}\\) in extensive benchmarks, covering numerous differentiable solvers, neural backbones, and test cases ranging from a 1D chaotic system to 3D turbulence. INC improves the long-term trajectory performance (\\(R^2\\)) by up to 158.7\\%, stabilizes blowups under aggressive coarsening, and for complex 3D turbulence cases yields speed-ups of several orders of magnitude. INC thus enables stable, efficient PDE emulation with formal error reduction, paving the way for faster scientific and engineering simulations with reliable physics guarantees. Our source code is available at https://github.com/tum-pbs/INC",
    "published": "2025-11-16T20:14:28Z",
    "updated": "2025-11-16T20:14:28Z",
    "link": "http://arxiv.org/pdf/2511.12764v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hao Wei",
      "Aleksandra Franz",
      "Bjoern List",
      "Nils Thuerey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12760v1",
    "title": "Conformal Online Learning of Deep Koopman Linear Embeddings",
    "summary": "We introduce Conformal Online Learning of Koopman embeddings (COLoKe), a novel framework for adaptively updating Koopman-invariant representations of nonlinear dynamical systems from streaming data. Our modeling approach combines deep feature learning with multistep prediction consistency in the lifted space, where the dynamics evolve linearly. To prevent overfitting, COLoKe employs a conformal-style mechanism that shifts the focus from evaluating the conformity of new states to assessing the consistency of the current Koopman model. Updates are triggered only when the current model's prediction error exceeds a dynamically calibrated threshold, allowing selective refinement of the Koopman operator and embedding. Empirical results on benchmark dynamical systems demonstrate the effectiveness of COLoKe in maintaining long-term predictive accuracy while significantly reducing unnecessary updates and avoiding overfitting.",
    "published": "2025-11-16T20:08:48Z",
    "updated": "2025-11-16T20:08:48Z",
    "link": "http://arxiv.org/pdf/2511.12760v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Ben Gao",
      "Jordan Patracone",
      "Stéphane Chrétien",
      "Olivier Alata"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12755v1",
    "title": "Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL",
    "summary": "Despite significant progress and advances in autonomous driving, many end-to-end systems still struggle with domain adaptation (DA), such as transferring a policy trained under clear weather to adverse weather conditions. Typical DA strategies in the literature include collecting additional data in the target domain or re-training the model, or both. Both these strategies quickly become impractical as we increase scale and complexity of driving. These limitations have encouraged investigation into few-shot and zero-shot prompt-driven DA at inference time involving LLMs and VLMs. These methods work by adding a few state-action trajectories during inference to the prompt (similar to in-context learning). However, there are two limitations of such an approach: $(i)$ prompt-driven DA methods are currently restricted to perception tasks such as detection and segmentation and $(ii)$ they require expert few-shot data. In this work, we present a new approach to inference-time few-shot prompt-driven DA for closed-loop autonomous driving in adverse weather condition using in-context reinforcement learning (ICRL). Similar to other prompt-driven DA methods, our approach does not require any updates to the model parameters nor does it require additional data collection in adversarial weather regime. Furthermore, our approach advances the state-of-the-art in prompt-driven DA by extending to closed driving using general trajectories observed during inference. Our experiments using the CARLA simulator show that ICRL results in safer, more efficient, and more comfortable driving policies in the target domain compared to state-of-the-art prompt-driven DA baselines.",
    "published": "2025-11-16T19:46:03Z",
    "updated": "2025-11-16T19:46:03Z",
    "link": "http://arxiv.org/pdf/2511.12755v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Aleesha Khurram",
      "Amir Moeini",
      "Shangtong Zhang",
      "Rohan Chandra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12749v1",
    "title": "TSB-HB: A Hierarchical Bayesian Extension of the TSB Model for Intermittent Demand Forecasting",
    "summary": "Intermittent demand forecasting poses unique challenges due to sparse observations, cold-start items, and obsolescence. Classical models such as Croston, SBA, and the Teunter-Syntetos-Babai (TSB) method provide simple heuristics but lack a principled generative foundation. Deep learning models address these limitations but often require large datasets and sacrifice interpretability.\n  We introduce TSB-HB, a hierarchical Bayesian extension of TSB. Demand occurrence is modeled with a Beta-Binomial distribution, while nonzero demand sizes follow a Log-Normal distribution. Crucially, hierarchical priors enable partial pooling across items, stabilizing estimates for sparse or cold-start series while preserving heterogeneity. This framework yields a fully generative and interpretable model that generalizes classical exponential smoothing.\n  On the UCI Online Retail dataset, TSB-HB achieves lower RMSE and RMSSE than Croston, SBA, TSB, ADIDA, IMAPA, ARIMA and Theta, and on a subset of the M5 dataset it outperforms all classical baselines we evaluate. The model provides calibrated probabilistic forecasts and improved accuracy on intermittent and lumpy items by combining a generative formulation with hierarchical shrinkage, while remaining interpretable and scalable.",
    "published": "2025-11-16T19:24:33Z",
    "updated": "2025-11-16T19:24:33Z",
    "link": "http://arxiv.org/pdf/2511.12749v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Zong-Han Bai",
      "Po-Yen Chu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12745v1",
    "title": "DIVIDE: A Framework for Learning from Independent Multi-Mechanism Data Using Deep Encoders and Gaussian Processes",
    "summary": "Scientific datasets often arise from multiple independent mechanisms such as spatial, categorical or structural effects, whose combined influence obscures their individual contributions. We introduce DIVIDE, a framework that disentangles these influences by integrating mechanism-specific deep encoders with a structured Gaussian Process in a joint latent space. Disentanglement here refers to separating independently acting generative factors. The encoders isolate distinct mechanisms while the Gaussian Process captures their combined effect with calibrated uncertainty. The architecture supports structured priors, enabling interpretable and mechanism-aware prediction as well as efficient active learning. DIVIDE is demonstrated on synthetic datasets combining categorical image patches with nonlinear spatial fields, on FerroSIM spin lattice simulations of ferroelectric patterns, and on experimental PFM hysteresis loops from PbTiO3 films. Across benchmarks, DIVIDE separates mechanisms, reproduces additive and scaled interactions, and remains robust under noise. The framework extends naturally to multifunctional datasets where mechanical, electromagnetic or optical responses coexist.",
    "published": "2025-11-16T19:22:59Z",
    "updated": "2025-11-16T19:22:59Z",
    "link": "http://arxiv.org/pdf/2511.12745v1.pdf",
    "category": [
      "cs.LG",
      "cond-mat.mtrl-sci"
    ],
    "authors": [
      "Vivek Chawla",
      "Boris Slautin",
      "Utkarsh Pratiush",
      "Dayakar Penumadu",
      "Sergei Kalinin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.09832v2",
    "title": "Learning Intersections of Two Margin Halfspaces under Factorizable Distributions",
    "summary": "Learning intersections of halfspaces is a central problem in Computational Learning Theory. Even for just two halfspaces, it remains a major open question whether learning is possible in polynomial time with respect to the margin $γ$ of the data points and their dimensionality $d$. The best-known algorithms run in quasi-polynomial time $d^{O(\\log(1/γ))}$, and it has been shown that this complexity is unavoidable for any algorithm relying solely on correlational statistical queries (CSQ).\n  In this work, we introduce a novel algorithm that provably circumvents the CSQ hardness barrier. Our approach applies to a broad class of distributions satisfying a natural, previously studied, factorizability assumption. Factorizable distributions lie between distribution-specific and distribution-free settings, and significantly extend previously known tractable cases. Under these distributions, we show that CSQ-based methods still require quasipolynomial time even for weakly learning, whereas our algorithm achieves $poly(d,1/γ)$ time by leveraging more general statistical queries (SQ), establishing a strong separation between CSQ and SQ for this simple realizable PAC learning problem.\n  Our result is grounded in a rigorous analysis utilizing a novel duality framework that characterizes the moment tensor structure induced by the marginal distributions. Building on these structural insights, we propose new, efficient learning algorithms. These algorithms combine a refined variant of Jennrich's Algorithm with PCA over random projections of the moment tensor, along with a gradient-descent-based non-convex optimization framework.",
    "published": "2025-11-13T00:28:24Z",
    "updated": "2025-11-16T19:17:22Z",
    "link": "http://arxiv.org/pdf/2511.09832v2.pdf",
    "category": [
      "cs.LG",
      "cs.DS"
    ],
    "authors": [
      "Ilias Diakonikolas",
      "Mingchen Ma",
      "Lisheng Ren",
      "Christos Tzamos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12742v1",
    "title": "Stabilizing Self-Consuming Diffusion Models with Latent Space Filtering",
    "summary": "As synthetic data proliferates across the Internet, it is often reused to train successive generations of generative models. This creates a ``self-consuming loop\" that can lead to training instability or \\textit{model collapse}. Common strategies to address the issue -- such as accumulating historical training data or injecting fresh real data -- either increase computational cost or require expensive human annotation. In this paper, we empirically analyze the latent space dynamics of self-consuming diffusion models and observe that the low-dimensional structure of latent representations extracted from synthetic data degrade over generations. Based on this insight, we propose \\textit{Latent Space Filtering} (LSF), a novel approach that mitigates model collapse by filtering out less realistic synthetic data from mixed datasets. Theoretically, we present a framework that connects latent space degradation to empirical observations. Experimentally, we show that LSF consistently outperforms existing baselines across multiple real-world datasets, effectively mitigating model collapse without increasing training cost or relying on human annotation.",
    "published": "2025-11-16T19:17:00Z",
    "updated": "2025-11-16T19:17:00Z",
    "link": "http://arxiv.org/pdf/2511.12742v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Zhongteng Cai",
      "Yaxuan Wang",
      "Yang Liu",
      "Xueru Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12743v1",
    "title": "An Evaluation Framework for Network IDS/IPS Datasets: Leveraging MITRE ATT&CK and Industry Relevance Metrics",
    "summary": "The performance of Machine Learning (ML) and Deep Learning (DL)-based Intrusion Detection and Prevention Systems (IDS/IPS) is critically dependent on the relevance and quality of the datasets used for training and evaluation. However, current AI model evaluation practices for developing IDS/IPS focus predominantly on accuracy metrics, often overlooking whether datasets represent industry-specific threats. To address this gap, we introduce a novel multi-dimensional framework that integrates the MITRE ATT&CK knowledge base for threat intelligence and employs five complementary metrics that together provide a comprehensive assessment of dataset suitability. Methodologically, this framework combines threat intelligence, natural language processing, and quantitative analysis to assess the suitability of datasets for specific industry contexts. Applying this framework to nine publicly available IDS/IPS datasets reveals significant gaps in threat coverage, particularly in the healthcare, energy, and financial sectors. In particular, recent datasets (e.g., CIC-IoMT, CIC-UNSW-NB15) align better with sector-specific threats, whereas others, like CICIoV-24, underperform despite their recency. Our findings provide a standardized, interpretable approach for selecting datasets aligned with sector-specific operational requirements, ultimately enhancing the real-world effectiveness of AI-driven IDS/IPS deployments. The efficiency and practicality of the framework are validated through deployment in a real-world case study, underscoring its capacity to inform dataset selection and enhance the effectiveness of AI-driven IDS/IPS in operational environments.",
    "published": "2025-11-16T19:17:00Z",
    "updated": "2025-11-16T19:17:00Z",
    "link": "http://arxiv.org/pdf/2511.12743v1.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Adrita Rahman Tori",
      "Khondokar Fida Hasan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13146v1",
    "title": "Towards Practical Real-Time Low-Latency Music Source Separation",
    "summary": "In recent years, significant progress has been made in the field of deep learning for music demixing. However, there has been limited attention on real-time, low-latency music demixing, which holds potential for various applications, such as hearing aids, audio stream remixing, and live performances. Additionally, a notable tendency has emerged towards the development of larger models, limiting their applicability in certain scenarios. In this paper, we introduce a lightweight real-time low-latency model called Real-Time Single-Path TFC-TDF UNET (RT-STT), which is based on the Dual-Path TFC-TDF UNET (DTTNet). In RT-STT, we propose a feature fusion technique based on channel expansion. We also demonstrate the superiority of single-path modeling over dual-path modeling in real-time models. Moreover, we investigate the method of quantization to further reduce inference time. RT-STT exhibits superior performance with significantly fewer parameters and shorter inference times compared to state-of-the-art models.",
    "published": "2025-11-17T08:56:14Z",
    "updated": "2025-11-17T08:56:14Z",
    "link": "http://arxiv.org/pdf/2511.13146v1.pdf",
    "category": [
      "cs.SD",
      "cs.MM"
    ],
    "authors": [
      "Junyu Wu",
      "Jie Liu",
      "Tianrui Pan",
      "Jie Tang",
      "Gangshan Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13247v1",
    "title": "Force-Aware 3D Contact Modeling for Stable Grasp Generation",
    "summary": "Contact-based grasp generation plays a crucial role in various applications. Recent methods typically focus on the geometric structure of objects, producing grasps with diverse hand poses and plausible contact points. However, these approaches often overlook the physical attributes of the grasp, specifically the contact force, leading to reduced stability of the grasp. In this paper, we focus on stable grasp generation using explicit contact force predictions. First, we define a force-aware contact representation by transforming the normal force value into discrete levels and encoding it using a one-hot vector. Next, we introduce force-aware stability constraints. We define the stability problem as an acceleration minimization task and explicitly relate stability with contact geometry by formulating the underlying physical constraints. Finally, we present a pose optimizer that systematically integrates our contact representation and stability constraints to enable stable grasp generation. We show that these constraints can help identify key contact points for stability which provide effective initialization and guidance for optimization towards a stable grasp. Experiments are carried out on two public benchmarks, showing that our method brings about 20% improvement in stability metrics and adapts well to novel objects.",
    "published": "2025-11-17T11:08:32Z",
    "updated": "2025-11-17T11:08:32Z",
    "link": "http://arxiv.org/pdf/2511.13247v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Zhuo Chen",
      "Zhongqun Zhang",
      "Yihua Cheng",
      "Ales Leonardis",
      "Hyung Jin Chang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.05685v4",
    "title": "DogFit: Domain-guided Fine-tuning for Efficient Transfer Learning of Diffusion Models",
    "summary": "Transfer learning of diffusion models to smaller target domains is challenging, as naively fine-tuning the model often results in poor generalization. Test-time guidance methods help mitigate this by offering controllable improvements in image fidelity through a trade-off with sample diversity. However, this benefit comes at a high computational cost, typically requiring dual forward passes during sampling. We propose the Domain-guided Fine-tuning (DogFit) method, an effective guidance mechanism for diffusion transfer learning that maintains controllability without incurring additional computational overhead. DogFit injects a domain-aware guidance offset into the training loss, effectively internalizing the guided behavior during the fine-tuning process. The domain-aware design is motivated by our observation that during fine-tuning, the unconditional source model offers a stronger marginal estimate than the target model. To support efficient controllable fidelity-diversity trade-offs at inference, we encode the guidance strength value as an additional model input through a lightweight conditioning mechanism. We further investigate the optimal placement and timing of the guidance offset during training and propose two simple scheduling strategies, i.e., late-start and cut-off, which improve generation quality and training stability. Experiments on DiT and SiT backbones across six diverse target domains show that DogFit can outperform prior guidance methods in transfer learning in terms of FID and FDDINOV2 while requiring up to 2x fewer sampling TFLOPS. Code is available at https://github.com/yaramohamadi/DogFit.",
    "published": "2025-08-05T21:33:05Z",
    "updated": "2025-11-17T05:17:34Z",
    "link": "http://arxiv.org/pdf/2508.05685v4.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Yara Bahram",
      "Mohammadhadi Shateri",
      "Eric Granger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13459v1",
    "title": "Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness",
    "summary": "Reinforcement learning (RL) approaches based on Markov Decision Processes (MDPs) are predominantly applied in the robot joint space, often relying on limited task-specific information and partial awareness of the 3D environment. In contrast, episodic RL has demonstrated advantages over traditional MDP-based methods in terms of trajectory consistency, task awareness, and overall performance in complex robotic tasks. Moreover, traditional step-wise and episodic RL methods often neglect the contact-rich information inherent in task-space manipulation, especially considering the contact-safety and robustness. In this work, contact-rich manipulation tasks are tackled using a task-space, energy-safe framework, where reliable and safe task-space trajectories are generated through the combination of Proximal Policy Optimization (PPO) and movement primitives. Furthermore, an energy-aware Cartesian Impedance Controller objective is incorporated within the proposed framework to ensure safe interactions between the robot and the environment. Our experimental results demonstrate that the proposed framework outperforms existing methods in handling tasks on various types of surfaces in 3D environments, achieving high success rates as well as smooth trajectories and energy-safe interactions.",
    "published": "2025-11-17T15:05:23Z",
    "updated": "2025-11-17T15:05:23Z",
    "link": "http://arxiv.org/pdf/2511.13459v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Bingkun Huang",
      "Yuhe Gong",
      "Zewen Yang",
      "Tianyu Ren",
      "Luis Figueredo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13327v1",
    "title": "ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning",
    "summary": "Task-oriented dexterous grasping holds broad application prospects in robotic manipulation and human-object interaction. However, most existing methods still struggle to generalize across diverse objects and task instructions, as they heavily rely on costly labeled data to ensure task-specific semantic alignment. In this study, we propose \\textbf{ZeroDexGrasp}, a zero-shot task-oriented dexterous grasp synthesis framework integrating Multimodal Large Language Models with grasp refinement to generate human-like grasp poses that are well aligned with specific task objectives and object affordances. Specifically, ZeroDexGrasp employs prompt-based multi-stage semantic reasoning to infer initial grasp configurations and object contact information from task and object semantics, then exploits contact-guided grasp optimization to refine these poses for physical feasibility and task alignment. Experimental results demonstrate that ZeroDexGrasp enables high-quality zero-shot dexterous grasping on diverse unseen object categories and complex task requirements, advancing toward more generalizable and intelligent robotic grasping.",
    "published": "2025-11-17T13:02:10Z",
    "updated": "2025-11-17T13:02:10Z",
    "link": "http://arxiv.org/pdf/2511.13327v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Juntao Jian",
      "Yi-Lin Wei",
      "Chengjie Mou",
      "Yuhao Lin",
      "Xing Zhu",
      "Yujun Shen",
      "Wei-Shi Zheng",
      "Ruizhen Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13216v1",
    "title": "GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry",
    "summary": "Deployment of legged robots for navigating challenging terrains (e.g., stairs, slopes, and unstructured environments) has gained increasing preference over wheel-based platforms. In such scenarios, accurate odometry estimation is a preliminary requirement for stable locomotion, localization, and mapping. Traditional proprioceptive approaches, which rely on leg kinematics sensor modalities and inertial sensing, suffer from irrepressible vertical drift caused by frequent contact impacts, foot slippage, and vibrations, particularly affected by inaccurate roll and pitch estimation. Existing methods incorporate exteroceptive sensors such as LiDAR or cameras. Further enhancement has been introduced by leveraging gravity vector estimation to add additional observations on roll and pitch, thereby increasing the accuracy of vertical pose estimation. However, these approaches tend to degrade in feature-sparse or repetitive scenes and are prone to errors from double-integrated IMU acceleration. To address these challenges, we propose GaRLILEO, a novel gravity-aligned continuous-time radar-leg-inertial odometry framework. GaRLILEO decouples velocity from the IMU by building a continuous-time ego-velocity spline from SoC radar Doppler and leg kinematics information, enabling seamless sensor fusion which mitigates odometry distortion. In addition, GaRLILEO can reliably capture accurate gravity vectors leveraging a novel soft S2-constrained gravity factor, improving vertical pose accuracy without relying on LiDAR or cameras. Evaluated on a self-collected real-world dataset with diverse indoor-outdoor trajectories, GaRLILEO demonstrates state-of-the-art accuracy, particularly in vertical odometry estimation on stairs and slopes. We open-source both our dataset and algorithm to foster further research in legged robot odometry and SLAM. https://garlileo.github.io/GaRLILEO",
    "published": "2025-11-17T10:29:31Z",
    "updated": "2025-11-17T10:29:31Z",
    "link": "http://arxiv.org/pdf/2511.13216v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Chiyun Noh",
      "Sangwoo Jung",
      "Hanjun Kim",
      "Yafei Hu",
      "Laura Herlant",
      "Ayoung Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.17005v2",
    "title": "Sequential Autonomous Exploration-Based Precise Mapping for Mobile Robots through Stepwise and Consistent Motions",
    "summary": "This paper proposes a 2-D autonomous exploration and mapping framework for LiDAR-based SLAM mobile robots, designed to address the major challenges on low-cost platforms, including process instability, map drift, and increased risks of collisions and deadlocks. For frontier search, the local-global sampling architecture based on Rapidly-exploring Random Trees (RRTs) is employed. For local exploration, the proposed Self-Convergent RRT (SC-RRT) efficiently covers the reachable space within a finite time while the robot remains stationary, without relying on motion-induced sampling diversity. In addition, traversability checks during RRT expansion and global RRT pruning upon map updates eliminate unreachable frontiers, reducing potential collisions and deadlocks. For frontier point navigation, a stepwise consistent motion strategy is employed to generate motion trajectories that are more amenable to stable scan matching. The resulting straight-segment and in-place-rotation pattern improves scan-matching robustness and effectively suppresses map drift on resource-constrained platforms. For the process control, the framework serializes frontier point selection and navigation, avoiding oscillations caused by frequent goal changes in conventional parallelized processes. The waypoint retracing mechanism is incorporated to generate repeated observations, triggering loop closure detection and backend optimization in graph-based SLAM, thereby improving map consistency. Experiments in challenging simulated and real-world environments validate the effectiveness of the framework. Compared with baseline methods, the proposed framework achieves higher mapping success rates and stronger robustness on resource-constrained robots and maintains consistent mapping quality across various LiDAR field-of-view (FoV) configurations.",
    "published": "2025-03-21T10:10:04Z",
    "updated": "2025-11-17T10:24:28Z",
    "link": "http://arxiv.org/pdf/2503.17005v2.pdf",
    "category": [
      "cs.RO",
      "eess.SY"
    ],
    "authors": [
      "Muhua Zhang",
      "Lei Ma",
      "Ying Wu",
      "Kai Shen",
      "Yongkui Sun",
      "Henry Leung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2310.08045v6",
    "title": "Model Predictive Inferential Control of Neural State-Space Models for Autonomous Vehicle Motion Planning",
    "summary": "Model predictive control (MPC) has proven useful in enabling safe and optimal motion planning for autonomous vehicles. In this paper, we investigate how to achieve MPC-based motion planning when a neural state-space model represents the vehicle dynamics. As the neural state-space model will lead to highly complex, nonlinear and nonconvex optimization landscapes, mainstream gradient-based MPC methods will struggle to provide viable solutions due to heavy computational load. In a departure, we propose the idea of model predictive inferential control (MPIC), which seeks to infer the best control decisions from the control objectives and constraints. Following this idea, we convert the MPC problem for motion planning into a Bayesian state estimation problem. Then, we develop a new implicit particle filtering/smoothing approach to perform the estimation. This approach is implemented as banks of unscented Kalman filters/smoothers and offers high sampling efficiency, fast computation, and estimation accuracy. We evaluate the MPIC approach through a simulation study of autonomous driving in different scenarios, along with an exhaustive comparison with gradient-based MPC. The simulation results show that the MPIC approach has considerable computational efficiency despite complex neural network architectures and the capability to solve large-scale MPC problems for neural state-space models.",
    "published": "2023-10-12T05:39:13Z",
    "updated": "2025-11-17T10:09:31Z",
    "link": "http://arxiv.org/pdf/2310.08045v6.pdf",
    "category": [
      "cs.RO",
      "eess.SY"
    ],
    "authors": [
      "Iman Askari",
      "Ali Vaziri",
      "Xuemin Tu",
      "Shen Zeng",
      "Huazhen Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13188v1",
    "title": "Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control",
    "summary": "This paper presents an integrated navigation framework for Autonomous Mobile Robots (AMRs) that unifies environment representation, trajectory generation, and Model Predictive Control (MPC). The proposed approach incorporates a quadtree-based method to generate structured, axis-aligned collision-free regions from occupancy maps. These regions serve as both a basis for developing safe corridors and as linear constraints within the MPC formulation, enabling efficient and reliable navigation without requiring direct obstacle encoding. The complete pipeline combines safe-area extraction, connectivity graph construction, trajectory generation, and B-spline smoothing into one coherent system. Experimental results demonstrate consistent success and superior performance compared to baseline approaches across complex environments.",
    "published": "2025-11-17T09:51:32Z",
    "updated": "2025-11-17T09:51:32Z",
    "link": "http://arxiv.org/pdf/2511.13188v1.pdf",
    "category": [
      "cs.RO",
      "eess.SY"
    ],
    "authors": [
      "Osama Al Sheikh Ali",
      "Sotiris Koutsoftas",
      "Ze Zhang",
      "Knut Akesson",
      "Emmanuel Dean"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13120v1",
    "title": "Monolithic Units: Actuation, Sensing, and Simulation for Integrated Soft Robot Design",
    "summary": "This work introduces the Monolithic Unit (MU), an actuator-lattice-sensor building block for soft robotics. The MU integrates pneumatic actuation, a compliant lattice envelope, and candidate sites for optical waveguide sensing into a single printed body. In order to study reproducibility and scalability, a parametric design framework establishes deterministic rules linking actuator chamber dimensions to lattice unit cell size. Experimental homogenization of lattice specimens provides effective material properties for finite element simulation. Within this simulation environment, sensor placement is treated as a discrete optimization problem, where a finite set of candidate waveguide paths derived from lattice nodes is evaluated by introducing local stiffening, and the configuration minimizing deviation from baseline mechanical response is selected. Optimized models are fabricated and experimentally characterized, validating the preservation of mechanical performance while enabling embedded sensing. The workflow is further extended to scaled units and a two-finger gripper, demonstrating generality of the MU concept. This approach advances monolithic soft robotic design by combining reproducible co-design rules with simulation-informed sensor integration.",
    "published": "2025-11-17T08:18:18Z",
    "updated": "2025-11-17T08:18:18Z",
    "link": "http://arxiv.org/pdf/2511.13120v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Trevor Exley",
      "Anderson Brazil Nardin",
      "Petr Trunin",
      "Diana Cafiso",
      "Lucia Beccai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13100v1",
    "title": "Count Every Rotation and Every Rotation Counts: Exploring Drone Dynamics via Propeller Sensing",
    "summary": "As drone-based applications proliferate, paramount contactless sensing of airborne drones from the ground becomes indispensable. This work demonstrates concentrating on propeller rotational speed will substantially improve drone sensing performance and proposes an event-camera-based solution, \\sysname. \\sysname features two components: \\textit{Count Every Rotation} achieves accurate, real-time propeller speed estimation by mitigating ultra-high sensitivity of event cameras to environmental noise. \\textit{Every Rotation Counts} leverages these speeds to infer both internal and external drone dynamics. Extensive evaluations in real-world drone delivery scenarios show that \\sysname achieves a sensing latency of 3$ms$ and a rotational speed estimation error of merely 0.23\\%. Additionally, \\sysname infers drone flight commands with 96.5\\% precision and improves drone tracking accuracy by over 22\\% when combined with other sensing modalities. \\textit{ Demo: {\\color{blue}https://eventpro25.github.io/EventPro/.} }",
    "published": "2025-11-17T07:53:16Z",
    "updated": "2025-11-17T07:53:16Z",
    "link": "http://arxiv.org/pdf/2511.13100v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Xuecheng Chen",
      "Jingao Xu",
      "Wenhua Ding",
      "Haoyang Wang",
      "Xinyu Luo",
      "Ruiyang Duan",
      "Jialong Chen",
      "Xueqian Wang",
      "Yunhao Liu",
      "Xinlei Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13096v1",
    "title": "ResAlignNet: A Data-Driven Approach for INS/DVL Alignment",
    "summary": "Autonomous underwater vehicles rely on precise navigation systems that combine the inertial navigation system and the Doppler velocity log for successful missions in challenging environments where satellite navigation is unavailable. The effectiveness of this integration critically depends on accurate alignment between the sensor reference frames. Standard model-based alignment methods between these sensor systems suffer from lengthy convergence times, dependence on prescribed motion patterns, and reliance on external aiding sensors, significantly limiting operational flexibility. To address these limitations, this paper presents ResAlignNet, a data-driven approach using the 1D ResNet-18 architecture that transforms the alignment problem into deep neural network optimization, operating as an in-situ solution that requires only sensors on board without external positioning aids or complex vehicle maneuvers, while achieving rapid convergence in seconds. Additionally, the approach demonstrates the learning capabilities of Sim2Real transfer, enabling training in synthetic data while deploying in operational sensor measurements. Experimental validation using the Snapir autonomous underwater vehicle demonstrates that ResAlignNet achieves alignment accuracy within 0.8° using only 25 seconds of data collection, representing a 65\\% reduction in convergence time compared to standard velocity-based methods. The trajectory-independent solution eliminates motion pattern requirements and enables immediate vehicle deployment without lengthy pre-mission procedures, advancing underwater navigation capabilities through robust sensor-agnostic alignment that scales across different operational scenarios and sensor specifications.",
    "published": "2025-11-17T07:50:44Z",
    "updated": "2025-11-17T07:50:44Z",
    "link": "http://arxiv.org/pdf/2511.13096v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Guy Damari",
      "Itzik Klein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13048v1",
    "title": "Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments",
    "summary": "Practical global path planning is critical for commercializing cleaning robots working in semi-structured environments. In the literature, global path planning methods for free space usually focus on path length and neglect the traffic rule constraints of the environments, which leads to high-frequency re-planning and increases collision risks. In contrast, those for structured environments are developed mainly by strictly complying with the road network representing the traffic rule constraints, which may result in an overlong path that hinders the overall navigation efficiency. This article proposes a general and systematic approach to improve global path planning performance in semi-structured environments. A unidirectional road network is built to represent the traffic constraints in semi-structured environments and a hybrid strategy is proposed to achieve a guaranteed planning result.Cutting across the road at the starting and the goal points are allowed to achieve a shorter path. Especially, a two-layer potential map is proposed to achieve a guaranteed performance when the starting and the goal points are in complex intersections. Comparative experiments are carried out to validate the effectiveness of the proposed method. Quantitative experimental results show that, compared with the state-of-art, the proposed method guarantees a much better balance between path length and the consistency with the road network.",
    "published": "2025-11-17T06:52:41Z",
    "updated": "2025-11-17T06:52:41Z",
    "link": "http://arxiv.org/pdf/2511.13048v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yong Li",
      "Hui Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13042v1",
    "title": "APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation",
    "summary": "Paths generated by A* and other graph-search-based planners are widely used in the robotic field. Due to the restricted node-expansion directions, the resulting paths are usually not the shortest. Besides, unnecessary heading changes, or zig-zag patterns, exist even when no obstacle is nearby, which is inconsistent with the human intuition that the path segments should be straight in wide-open space due to the absence of obstacles. This article puts forward a general and systematic post-processing algorithm for A* and other graph-search-based planners. The A* post-processing algorithm, called APP, is developed based on the costmap, which is widely used in commercial service robots. First, a bidirectional vertices reduction algorithm is proposed to tackle the asymm- etry of the path and the environments. During the forward and backward vertices reduction, a thorough shortcut strategy is put forward to improve the path-shortening performance and avoid unnecessary heading changes. Second, an iterative path perturbation algorithm is adopted to locally reduce the number of unnecessary heading changes and improve the path smooth- ness. Comparative experiments are then carried out to validate the superiority of the proposed method. Quantitative performance indexes show that APP outperforms the existing methods in planning time, path length as well as the number of unnecessary heading changes. Finally, field navigation experiments are carried out to verify the practicability of APP.",
    "published": "2025-11-17T06:42:37Z",
    "updated": "2025-11-17T06:42:37Z",
    "link": "http://arxiv.org/pdf/2511.13042v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yong Li",
      "Hui Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.02761v2",
    "title": "TopAY: Efficient Trajectory Planning for Differential Drive Mobile Manipulators via Topological Paths Search and Arc Length-Yaw Parameterization",
    "summary": "Differential drive mobile manipulators combine the mobility of wheeled bases with the manipulation capability of multi-joint arms, enabling versatile applications but posing considerable challenges for trajectory planning due to their high-dimensional state space and nonholonomic constraints. This paper introduces TopAY, an optimization-based planning framework designed for efficient and safe trajectory generation for differential drive mobile manipulators. The framework employs a hierarchical initial value acquisition strategy, including topological paths search for the base and parallel sampling for the manipulator. A polynomial trajectory representation with arc length-yaw parameterization is also proposed to reduce optimization complexity while preserving dynamic feasibility. Extensive simulation and real-world experiments validate that TopAY achieves higher planning efficiency and success rates than state-of-the-art method in dense and complex scenarios. The source code is released at https://github.com/TopAY-Planner/TopAY .",
    "published": "2025-07-03T16:21:43Z",
    "updated": "2025-11-17T05:20:18Z",
    "link": "http://arxiv.org/pdf/2507.02761v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Long Xu",
      "Choilam Wong",
      "Mengke Zhang",
      "Junxiao Lin",
      "Jialiang Hou",
      "Fei Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12984v1",
    "title": "CUTE-Planner: Confidence-aware Uneven Terrain Exploration Planner",
    "summary": "Planetary exploration robots must navigate uneven terrain while building reliable maps for space missions. However, most existing methods incorporate traversability constraints but may not handle high uncertainty in elevation estimates near complex features like craters, do not consider exploration strategies for uncertainty reduction, and typically fail to address how elevation uncertainty affects navigation safety and map quality. To address the problems, we propose a framework integrating safe path generation, adaptive confidence updates, and confidence-aware exploration strategies. Using Kalman-based elevation estimation, our approach generates terrain traversability and confidence scores, then incorporates them into Graph-Based exploration Planner (GBP) to prioritize exploration of traversable low-confidence regions. We evaluate our framework through simulated lunar experiments using a novel low-confidence region ratio metric, achieving 69% uncertainty reduction compared to baseline GBP. In terms of mission success rate, our method achieves 100% while baseline GBP achieves 0%, demonstrating improvements in exploration safety and map reliability.",
    "published": "2025-11-17T05:14:05Z",
    "updated": "2025-11-17T05:14:05Z",
    "link": "http://arxiv.org/pdf/2511.12984v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Miryeong Park",
      "Dongjin Cho",
      "Sanghyun Kim",
      "Younggun Cho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12972v1",
    "title": "SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models",
    "summary": "The Instance Image Goal Navigation (IIN) problem requires mobile robots deployed in unknown environments to search for specific objects or people of interest using only a single reference goal image of the target. This problem can be especially challenging when: 1) the reference image is captured from an arbitrary viewpoint, and 2) the robot must operate with sparse-view scene reconstructions. In this paper, we address the IIN problem, by introducing SplatSearch, a novel architecture that leverages sparse-view 3D Gaussian Splatting (3DGS) reconstructions. SplatSearch renders multiple viewpoints around candidate objects using a sparse online 3DGS map, and uses a multi-view diffusion model to complete missing regions of the rendered images, enabling robust feature matching against the goal image. A novel frontier exploration policy is introduced which uses visual context from the synthesized viewpoints with semantic context from the goal image to evaluate frontier locations, allowing the robot to prioritize frontiers that are semantically and visually relevant to the goal image. Extensive experiments in photorealistic home and real-world environments validate the higher performance of SplatSearch against current state-of-the-art methods in terms of Success Rate and Success Path Length. An ablation study confirms the design choices of SplatSearch.",
    "published": "2025-11-17T04:49:28Z",
    "updated": "2025-11-17T04:49:28Z",
    "link": "http://arxiv.org/pdf/2511.12972v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Siddarth Narasimhan",
      "Matthew Lisondra",
      "Haitong Wang",
      "Goldie Nejat"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11520v2",
    "title": "Scalable Policy Evaluation with Video World Models",
    "summary": "Training generalist policies for robotic manipulation has shown great promise, as they enable language-conditioned, multi-task behaviors across diverse scenarios. However, evaluating these policies remains difficult because real-world testing is expensive, time-consuming, and labor-intensive. It also requires frequent environment resets and carries safety risks when deploying unproven policies on physical robots. Manually creating and populating simulation environments with assets for robotic manipulation has not addressed these issues, primarily due to the significant engineering effort required and the often substantial sim-to-real gap, both in terms of physics and rendering. In this paper, we explore the use of action-conditional video generation models as a scalable way to learn world models for policy evaluation. We demonstrate how to incorporate action conditioning into existing pre-trained video generation models. This allows leveraging internet-scale in-the-wild online videos during the pre-training stage, and alleviates the need for a large dataset of paired video-action data, which is expensive to collect for robotic manipulation. Our paper examines the effect of dataset diversity, pre-trained weight and common failure cases for the proposed evaluation pipeline. Our experiments demonstrate that, across various metrics, including policy ranking and the correlation between actual policy values and predicted policy values, these models offer a promising approach for evaluating policies without requiring real-world interactions.",
    "published": "2025-11-14T17:46:17Z",
    "updated": "2025-11-17T04:47:06Z",
    "link": "http://arxiv.org/pdf/2511.11520v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Wei-Cheng Tseng",
      "Jinwei Gu",
      "Qinsheng Zhang",
      "Hanzi Mao",
      "Ming-Yu Liu",
      "Florian Shkurti",
      "Lin Yen-Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12941v1",
    "title": "GUIDE: Gaussian Unified Instance Detection for Enhanced Obstacle Perception in Autonomous Driving",
    "summary": "In the realm of autonomous driving, accurately detecting surrounding obstacles is crucial for effective decision-making. Traditional methods primarily rely on 3D bounding boxes to represent these obstacles, which often fail to capture the complexity of irregularly shaped, real-world objects. To overcome these limitations, we present GUIDE, a novel framework that utilizes 3D Gaussians for instance detection and occupancy prediction. Unlike conventional occupancy prediction methods, GUIDE also offers robust tracking capabilities. Our framework employs a sparse representation strategy, using Gaussian-to-Voxel Splatting to provide fine-grained, instance-level occupancy data without the computational demands associated with dense voxel grids. Experimental validation on the nuScenes dataset demonstrates GUIDE's performance, with an instance occupancy mAP of 21.61, marking a 50\\% improvement over existing methods, alongside competitive tracking capabilities. GUIDE establishes a new benchmark in autonomous perception systems, effectively combining precision with computational efficiency to better address the complexities of real-world driving environments.",
    "published": "2025-11-17T03:50:48Z",
    "updated": "2025-11-17T03:50:48Z",
    "link": "http://arxiv.org/pdf/2511.12941v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Chunyong Hu",
      "Qi Luo",
      "Jianyun Xu",
      "Song Wang",
      "Qiang Li",
      "Sheng Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12912v1",
    "title": "DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping",
    "summary": "Transferring the depth-based end-to-end policy trained in simulation to physical robots can yield an efficient and robust grasping policy, yet sensor artifacts in real depth maps like voids and noise establish a significant sim2real gap that critically impedes policy transfer. Training-time strategies like procedural noise injection or learned mappings suffer from data inefficiency due to unrealistic noise simulation, which is often ineffective for grasping tasks that require fine manipulation or dependency on paired datasets heavily. Furthermore, leveraging foundation models to reduce the sim2real gap via intermediate representations fails to mitigate the domain shift fully and adds computational overhead during deployment. This work confronts dual challenges of data inefficiency and deployment complexity. We propose DiffuDepGrasp, a deploy-efficient sim2real framework enabling zero-shot transfer through simulation-exclusive policy training. Its core innovation, the Diffusion Depth Generator, synthesizes geometrically pristine simulation depth with learned sensor-realistic noise via two synergistic modules. The first Diffusion Depth Module leverages temporal geometric priors to enable sample-efficient training of a conditional diffusion model that captures complex sensor noise distributions, while the second Noise Grafting Module preserves metric accuracy during perceptual artifact injection. With only raw depth inputs during deployment, DiffuDepGrasp eliminates computational overhead and achieves a 95.7% average success rate on 12-object grasping with zero-shot transfer and strong generalization to unseen objects.Project website: https://diffudepgrasp.github.io/.",
    "published": "2025-11-17T02:59:37Z",
    "updated": "2025-11-17T02:59:37Z",
    "link": "http://arxiv.org/pdf/2511.12912v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yingting Zhou",
      "Wenbo Cui",
      "Weiheng Liu",
      "Guixing Chen",
      "Haoran Li",
      "Dongbin Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12910v1",
    "title": "TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints",
    "summary": "Differential-driven wheeled robots (DWR) represent the quintessential type of mobile robots and find extensive appli- cations across the robotic field. Most high-performance control approaches for DWR explicitly utilize the linear and angular velocities of the trajectory as control references. However, existing research on time-optimal path parameterization (TOPP) for mobile robots usually neglects the angular velocity and joint vel- ocity constraints, which can result in degraded control perfor- mance in practical applications. In this article, a systematic and practical TOPP algorithm named TOPP-DWR is proposed for DWR and other mobile robots. First, the non-uniform B-spline is adopted to represent the initial trajectory in the task space. Second, the piecewise-constant angular velocity, as well as joint velocity, linear velocity, and linear acceleration constraints, are incorporated into the TOPP problem. During the construction of the optimization problem, the aforementioned constraints are uniformly represented as linear velocity constraints. To boost the numerical computational efficiency, we introduce a slack variable to reformulate the problem into second-order-cone programming (SOCP). Subsequently, comparative experiments are conducted to validate the superiority of the proposed method. Quantitative performance indexes show that TOPP-DWR achieves TOPP while adhering to all constraints. Finally, field autonomous navigation experiments are carried out to validate the practicability of TOPP-DWR in real-world applications.",
    "published": "2025-11-17T02:58:53Z",
    "updated": "2025-11-17T02:58:53Z",
    "link": "http://arxiv.org/pdf/2511.12910v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yong Li",
      "Yujun Huang",
      "Yi Chen",
      "Hui Cheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12896v1",
    "title": "Air-Chamber Based Soft Six-Axis Force/Torque Sensor for Human-Robot Interaction",
    "summary": "Soft multi-axis force/torque sensors provide safe and precise force interaction. Capturing the complete degree-of-freedom of force is imperative for accurate force measurement with six-axis force/torque sensors. However, cross-axis coupling can lead to calibration issues and decreased accuracy. In this instance, developing a soft and accurate six-axis sensor is a challenging task. In this paper, a soft air-chamber type six-axis force/torque sensor with 16-channel barometers is introduced, which housed in hyper-elastic air chambers made of silicone rubber. Additionally, an effective decoupling method is proposed, based on a rigid-soft hierarchical structure, which reduces the six-axis decoupling problem to two three-axis decoupling problems. Finite element model simulation and experiments demonstrate the compatibility of the proposed approach with reality. The prototype's sensing performance is quantitatively measured in terms of static load response, dynamic load response and dynamic response characteristic. It possesses a measuring range of 50 N force and 1 Nm torque, and the average deviation, repeatability, non-linearity and hysteresis are 4.9$\\%$, 2.7$\\%$, 5.8$\\%$ and 6.7$\\%$, respectively. The results indicate that the prototype exhibits satisfactory sensing performance while maintaining its softness due to the presence of soft air chambers.",
    "published": "2025-11-17T02:37:30Z",
    "updated": "2025-11-17T02:37:30Z",
    "link": "http://arxiv.org/pdf/2511.12896v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jun Huo",
      "Hongge Ru",
      "Bo Yang",
      "Xingjian Chen",
      "Xi Li",
      "Jian Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.13664v4",
    "title": "A Skeleton-Based Topological Planner for Exploration in Complex Unknown Environments",
    "summary": "The capability of autonomous exploration in complex, unknown environments is important in many robotic applications. While recent research on autonomous exploration have achieved much progress, there are still limitations, e.g., existing methods relying on greedy heuristics or optimal path planning are often hindered by repetitive paths and high computational demands. To address such limitations, we propose a novel exploration framework that utilizes the global topology information of observed environment to improve exploration efficiency while reducing computational overhead. Specifically, global information is utilized based on a skeletal topological graph representation of the environment geometry. We first propose an incremental skeleton extraction method based on wavefront propagation, based on which we then design an approach to generate a lightweight topological graph that can effectively capture the environment's structural characteristics. Building upon this, we introduce a finite state machine that leverages the topological structure to efficiently plan coverage paths, which can substantially mitigate the back-and-forth maneuvers (BFMs) problem. Experimental results demonstrate the superiority of our method in comparison with state-of-the-art methods. The source code will be made publicly available at: https://github.com/Haochen-Niu/STGPlanner.",
    "published": "2024-12-18T09:45:46Z",
    "updated": "2025-11-17T02:13:26Z",
    "link": "http://arxiv.org/pdf/2412.13664v4.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Haochen Niu",
      "Xingwu Ji",
      "Lantao Zhang",
      "Fei Wen",
      "Rendong Ying",
      "Peilin Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12795v1",
    "title": "ActiveGrasp: Information-Guided Active Grasping with Calibrated Energy-based Model",
    "summary": "Grasping in a densely cluttered environment is a challenging task for robots. Previous methods tried to solve this problem by actively gathering multiple views before grasp pose generation. However, they either overlooked the importance of the grasp distribution for information gain estimation or relied on the projection of the grasp distribution, which ignores the structure of grasp poses on the SE(3) manifold. To tackle these challenges, we propose a calibrated energy-based model for grasp pose generation and an active view selection method that estimates information gain from grasp distribution. Our energy-based model captures the multi-modality nature of grasp distribution on the SE(3) manifold. The energy level is calibrated to the success rate of grasps so that the predicted distribution aligns with the real distribution. The next best view is selected by estimating the information gain for grasp from the calibrated distribution conditioned on the reconstructed environment, which could efficiently drive the robot to explore affordable parts of the target object. Experiments on simulated environments and real robot setups demonstrate that our model could successfully grasp objects in a cluttered environment with limited view budgets compared to previous state-of-the-art models. Our simulated environment can serve as a reproducible platform for future research on active grasping. The source code of our paper will be made public when the paper is released to the public.",
    "published": "2025-11-16T21:55:05Z",
    "updated": "2025-11-16T21:55:05Z",
    "link": "http://arxiv.org/pdf/2511.12795v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Boshu Lei",
      "Wen Jiang",
      "Kostas Daniilidis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12778v1",
    "title": "DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation",
    "summary": "We present DR. Nav (Dead-End Recovery-aware Navigation), a novel approach to autonomous navigation in scenarios where dead-end detection and recovery are critical, particularly in unstructured environments where robots must handle corners, vegetation occlusions, and blocked junctions. DR. Nav introduces a proactive strategy for navigation in unmapped environments without prior assumptions. Our method unifies dead-end prediction and recovery by generating a single, continuous, real-time semantic cost map. Specifically, DR. Nav leverages cross-modal RGB-LiDAR fusion with attention-based filtering to estimate per-cell dead-end likelihoods and recovery points, which are continuously updated through Bayesian inference to enhance robustness. Unlike prior mapping methods that only encode traversability, DR. Nav explicitly incorporates recovery-aware risk into the navigation cost map, enabling robots to anticipate unsafe regions and plan safer alternative trajectories. We evaluate DR. Nav across multiple dense indoor and outdoor scenarios and demonstrate an increase of 83.33% in accuracy in detection, a 52.4% reduction in time-to-goal (path efficiency), compared to state-of-the-art planners such as DWA, MPPI, and Nav2 DWB. Furthermore, the dead-end classifier functions",
    "published": "2025-11-16T21:04:08Z",
    "updated": "2025-11-16T21:04:08Z",
    "link": "http://arxiv.org/pdf/2511.12778v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Vignesh Rajagopal",
      "Kasun Weerakoon Kulathun Mudiyanselage",
      "Gershom Devake Seneviratne",
      "Pon Aswin Sankaralingam",
      "Mohamed Elnoor",
      "Jing Liang",
      "Rohan Chandra",
      "Dinesh Manocha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12756v1",
    "title": "Density-Driven Optimal Control for Non-Uniform Area Coverage in Decentralized Multi-Agent Systems Using Optimal Transport",
    "summary": "This paper addresses the fundamental problem of non-uniform area coverage in multi-agent systems, where different regions require varying levels of attention due to mission-dependent priorities. Existing uniform coverage strategies are insufficient for realistic applications, and many non-uniform approaches either lack optimality guarantees or fail to incorporate crucial real-world constraints such as agent dynamics, limited operation time, the number of agents, and decentralized execution.\n  To resolve these limitations, we propose a novel framework called Density-Driven Optimal Control (D2OC). The central idea of D2OC is the integration of optimal transport theory with multi-agent coverage control, enabling each agent to continuously adjust its trajectory to match a mission-specific reference density map. The proposed formulation establishes optimality by solving a constrained optimization problem that explicitly incorporates physical and operational constraints. The resulting control input is analytically derived from the Lagrangian of the objective function, yielding closed-form optimal solutions for linear systems and a generalizable structure for nonlinear systems. Furthermore, a decentralized data-sharing mechanism is developed to coordinate agents without reliance on global information.\n  Comprehensive simulation studies demonstrate that D2OC achieves significantly improved non-uniform area coverage performance compared to existing methods, while maintaining scalability and decentralized implementability.",
    "published": "2025-11-16T19:58:01Z",
    "updated": "2025-11-16T19:58:01Z",
    "link": "http://arxiv.org/pdf/2511.12756v1.pdf",
    "category": [
      "eess.SY",
      "cs.RO"
    ],
    "authors": [
      "Sungjun Seo",
      "Kooktae Lee"
    ]
  }
]