[
  {
    "id": "http://arxiv.org/abs/2511.19436v1",
    "title": "VDC-Agent: When Video Detailed Captioners Evolve Themselves via Agentic Self-Reflection",
    "summary": "We present VDC-Agent, a self-evolving framework for Video Detailed Captioning that requires neither human annotations nor larger teacher models. The agent forms a closed loop of caption generation, principle-guided scoring (score and textual suggestions), and prompt refinement. When caption quality regresses, a self-reflection path leverages the previous chain-of-thought to amend the update. Running this process on unlabeled videos produces trajectories of (caption, score) pairs. We convert the trajectories into preference tuples and filter out samples with JSON parsing errors, resulting in VDC-Agent-19K, which contains 18,886 automatically constructed pairs. We then fine-tune the base MLLM on this dataset using an easy-to-hard curriculum direct preference optimization. Built on Qwen2.5-VL-7B-Instruct, our VDC-Agent-7B attains state-of-the-art performance on the VDC benchmark with 49.08% average accuracy and 2.50 score, surpassing specialized video captioners and improving over the base model by +5.13% accuracy and +0.27 score at similar inference cost.",
    "published": "2025-11-24T18:59:56Z",
    "updated": "2025-11-24T18:59:56Z",
    "link": "http://arxiv.org/pdf/2511.19436v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "authors": [
      "Qiang Wang",
      "Xinyuan Gao",
      "SongLin Dong",
      "Jizhou Han",
      "Jiangyang Li",
      "Yuhang He",
      "Yihong Gong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19433v1",
    "title": "Mixture of Horizons in Action Chunking",
    "summary": "Vision-language-action (VLA) models have shown remarkable capabilities in robotic manipulation, but their performance is sensitive to the $\\textbf{action chunk length}$ used during training, termed $\\textbf{horizon}$. Our empirical study reveals an inherent trade-off: longer horizons provide stronger global foresight but degrade fine-grained accuracy, while shorter ones sharpen local control yet struggle on long-term tasks, implying fixed choice of single horizons being suboptimal. To mitigate the trade-off, we propose a $\\textbf{mixture of horizons (MoH)}$ strategy. MoH rearranges the action chunk into several segments with different horizons, processes them in parallel with a shared action transformer, and fuses outputs with a light linear gate. It has three appealing benefits. 1) MoH exploits long-term foresight and short-term precision jointly within a single model, improving both performance and generalizability to complex tasks. 2) MoH is plug-and-play for full-attention action modules with minimal training or inference overhead. 3) MoH enables dynamic inference with adaptive horizons, which selects stable actions through cross-horizon consensus, achieving 2.5$\\times$ higher throughput than baselines while preserving superior performance. Extensive experiments over flow-based policies $π_0$, $π_{0.5}$, and one-step regression policy $π_{\\text{reg}}$ demonstrate that MoH yields consistent and significant gains on both simulations and real-world tasks. Notably, under mixed-task setting, $π_{0.5}$ with MoH reaches a new state-of-the-art with 99$\\%$ average success rate on LIBERO after only $30k$ training iterations. Project page: https://github.com/Timsty1/MixtureOfHorizons",
    "published": "2025-11-24T18:59:51Z",
    "updated": "2025-11-24T18:59:51Z",
    "link": "http://arxiv.org/pdf/2511.19433v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Dong Jing",
      "Gang Wang",
      "Jiaqi Liu",
      "Weiliang Tang",
      "Zelong Sun",
      "Yunchao Yao",
      "Zhenyu Wei",
      "Yunhui Liu",
      "Zhiwu Lu",
      "Mingyu Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.16660v2",
    "title": "Cognitive Foundations for Reasoning and Their Manifestation in LLMs",
    "summary": "Large language models (LLMs) solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. To understand this gap, we synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning reasoning invariants, meta-cognitive controls, representations for organizing reasoning & knowledge, and transformation operations. We introduce a fine-grained evaluation framework and conduct the first large-scale empirical analysis of 192K traces from 18 models across text, vision, and audio, complemented by 54 human think-aloud traces, which we make publicly available. We find that models under-utilize cognitive elements correlated with success, narrowing to rigid sequential processing on ill-structured problems where diverse representations and meta-cognitive monitoring are critical. Human traces show more abstraction and conceptual processing, while models default to surface-level enumeration. Meta-analysis of 1.6K LLM reasoning papers reveals the research community concentrates on easily quantifiable elements (sequential organization: 55%, decomposition: 60%) but neglecting meta-cognitive controls (self-awareness: 16%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 66.7% on complex problems. By establishing a shared vocabulary between cognitive science and LLM research, our framework enables systematic diagnosis of reasoning failures and principled development of models that reason through robust cognitive mechanisms rather than spurious shortcuts, while providing tools to test theories of human cognition at scale.",
    "published": "2025-11-20T18:59:00Z",
    "updated": "2025-11-24T18:59:30Z",
    "link": "http://arxiv.org/pdf/2511.16660v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Priyanka Kargupta",
      "Shuyue Stella Li",
      "Haocheng Wang",
      "Jinu Lee",
      "Shan Chen",
      "Orevaoghene Ahia",
      "Dean Light",
      "Thomas L. Griffiths",
      "Max Kleiman-Weiner",
      "Jiawei Han",
      "Asli Celikyilmaz",
      "Yulia Tsvetkov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19427v1",
    "title": "Prompt Less, Smile More: MTP with Semantic Engineering in Lieu of Prompt Engineering",
    "summary": "AI-Integrated programming is emerging as a foundational paradigm for building intelligent systems with large language models (LLMs). Recent approaches such as Meaning Typed Programming (MTP) automate prompt generation by leveraging the semantics already present in code. However, many real-world applications depend on contextual cues, developer intent, and domain-specific reasoning that extend beyond what static code semantics alone can express. To address this limitation, we introduce Semantic Engineering, a lightweight method for enriching program semantics so that LLM-based systems can more accurately reflect developer intent without requiring full manual prompt design. We present Semantic Context Annotations (SemTexts), a language-level mechanism that allows developers to embed natural-language context directly into program constructs. Integrated into the Jac programming language, Semantic Engineering extends MTP to incorporate these enriched semantics during prompt generation. We further introduce a benchmark suite designed to reflect realistic AI-Integrated application scenarios. Our evaluation shows that Semantic Engineering substantially improves prompt fidelity, achieving performance comparable to Prompt Engineering while requiring significantly less developer effort.",
    "published": "2025-11-24T18:58:22Z",
    "updated": "2025-11-24T18:58:22Z",
    "link": "http://arxiv.org/pdf/2511.19427v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Jayanaka L. Dantanarayana",
      "Savini Kashmira",
      "Thakee Nathees",
      "Zichen Zhang",
      "Krisztian Flautner",
      "Lingjia Tang",
      "Jason Mars"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19423v1",
    "title": "Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic Enzyme Design",
    "summary": "We present Genie-CAT, a tool-augmented large-language-model (LLM) system designed to accelerate scientific hypothesis generation in protein design. Using metalloproteins (e.g., ferredoxins) as a case study, Genie-CAT integrates four capabilities -- literature-grounded reasoning through retrieval-augmented generation (RAG), structural parsing of Protein Data Bank files, electrostatic potential calculations, and machine-learning prediction of redox properties -- into a unified agentic workflow. By coupling natural-language reasoning with data-driven and physics-based computation, the system generates mechanistically interpretable, testable hypotheses linking sequence, structure, and function. In proof-of-concept demonstrations, Genie-CAT autonomously identifies residue-level modifications near [Fe--S] clusters that affect redox tuning, reproducing expert-derived hypotheses in a fraction of the time. The framework highlights how AI agents combining language models with domain-specific tools can bridge symbolic reasoning and numerical simulation, transforming LLMs from conversational assistants into partners for computational discovery.",
    "published": "2025-11-24T18:57:07Z",
    "updated": "2025-11-24T18:57:07Z",
    "link": "http://arxiv.org/pdf/2511.19423v1.pdf",
    "category": [
      "q-bio.QM",
      "cs.AI"
    ],
    "authors": [
      "Bruno Jacob",
      "Khushbu Agarwal",
      "Marcel Baer",
      "Peter Rice",
      "Simone Raugei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19422v1",
    "title": "SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning",
    "summary": "Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generation. In this work, we propose SLMFix, a novel code generation pipeline that leverages a small language model (SLM) finetuned using reinforcement learning (RL) techniques to fix syntactic errors in LLM-generated programs to improve the quality of LLM-generated programs for domain-specific languages (DSLs). In specific, we applied RL on the SLM for the program repair task using a reward calculated using both a static validator and a static semantic similarity metric. Our experimental results demonstrate the effectiveness and generalizability of our approach across multiple DSLs, achieving more than 95% pass rate on the static validator. Notably, SLMFix brings substantial improvement to the base model and outperforms supervised finetuning approach even for 7B models on a LRPL, showing the potential of our approach as an alternative to traditional finetuning approaches.",
    "published": "2025-11-24T18:56:47Z",
    "updated": "2025-11-24T18:56:47Z",
    "link": "http://arxiv.org/pdf/2511.19422v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "authors": [
      "David Jiahao Fu",
      "Aryan Gupta",
      "Aaron Councilman",
      "David Grove",
      "Yu-Xiong Wang",
      "Vikram Adve"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19418v1",
    "title": "Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens",
    "summary": "Vision-Language Models (VLMs) excel at reasoning in linguistic space but struggle with perceptual understanding that requires dense visual perception, e.g., spatial reasoning and geometric awareness. This limitation stems from the fact that current VLMs have limited mechanisms to capture dense visual information across spatial dimensions. We introduce Chain-of-Visual-Thought (COVT), a framework that enables VLMs to reason not only in words but also through continuous visual tokens-compact latent representations that encode rich perceptual cues. Within a small budget of roughly 20 tokens, COVT distills knowledge from lightweight vision experts, capturing complementary properties such as 2D appearance, 3D geometry, spatial layout, and edge structure. During training, the VLM with COVT autoregressively predicts these visual tokens to reconstruct dense supervision signals (e.g., depth, segmentation, edges, and DINO features). At inference, the model reasons directly in the continuous visual token space, preserving efficiency while optionally decoding dense predictions for interpretability. Evaluated across more than ten diverse perception benchmarks, including CV-Bench, MMVP, RealWorldQA, MMStar, WorldMedQA, and HRBench, integrating COVT into strong VLMs such as Qwen2.5-VL and LLaVA consistently improves performance by 3% to 16% and demonstrates that compact continuous visual thinking enables more precise, grounded, and interpretable multimodal intelligence.",
    "published": "2025-11-24T18:55:19Z",
    "updated": "2025-11-24T18:55:19Z",
    "link": "http://arxiv.org/pdf/2511.19418v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yiming Qin",
      "Bomin Wei",
      "Jiaxin Ge",
      "Konstantinos Kallidromitis",
      "Stephanie Fu",
      "Trevor Darrell",
      "Xudong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19417v1",
    "title": "Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in challenging, knowledge-intensive reasoning tasks. However, extending LLMs to perceive and reason over a new modality (e.g., vision), often requires costly development of large-scale vision language models (VLMs) with LLMs as backbones. Smaller VLMs are more efficient and adaptable but often lack the broad knowledge and reasoning capabilities of frontier LLMs. In this work, we propose BeMyEyes, a modular, multi-agent framework for extending LLMs to multimodal reasoning by orchestrating collaboration between efficient, adaptable VLMs as perceivers and powerful LLMs as reasoners through conversations. We then introduce a data synthesis and supervised fine-tuning pipeline to train the perceiver agent to effectively collaborate with the reasoner agent. By combining the complementary strengths of perception and reasoning agents, BeMyEyes avoids the need for training large-scale multimodal models, preserves the generalization and reasoning capabilities of LLMs, and allows flexible extension to new domains and modalities. Experiments show that our framework unlocks the multimodal reasoning capabilities for LLMs, enabling a lightweight and fully open-source solution, i.e. equipping text-only DeepSeek-R1 with Qwen2.5-VL-7B perceiver, to outperform large-scale proprietary VLMs such as GPT-4o on a wide range of knowledge-intensive multimodal tasks. These results demonstrate the effectiveness, modularity, and scalability of our multi-agent approach for building future multimodal reasoning systems.",
    "published": "2025-11-24T18:55:16Z",
    "updated": "2025-11-24T18:55:16Z",
    "link": "http://arxiv.org/pdf/2511.19417v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "James Y. Huang",
      "Sheng Zhang",
      "Qianchu Liu",
      "Guanghui Qin",
      "Tinghui Zhu",
      "Tristan Naumann",
      "Muhao Chen",
      "Hoifung Poon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.15846v3",
    "title": "The Loss of Control Playbook: Degrees, Dynamics, and Preparedness",
    "summary": "This research report addresses the absence of an actionable definition for Loss of Control (LoC) in AI systems by developing a novel taxonomy and preparedness framework. Despite increasing policy and research attention, existing LoC definitions vary significantly in scope and timeline, hindering effective LoC assessment and mitigation. To address this issue, we draw from an extensive literature review and propose a graded LoC taxonomy, based on the metrics of severity and persistence, that distinguishes between Deviation, Bounded LoC, and Strict LoC. We model pathways toward a societal state of vulnerability in which sufficiently advanced AI systems have acquired or could acquire the means to cause Bounded or Strict LoC once a catalyst, either misalignment or pure malfunction, materializes. We argue that this state becomes increasingly likely over time, absent strategic intervention, and propose a strategy to avoid reaching a state of vulnerability. Rather than focusing solely on intervening on AI capabilities and propensities potentially relevant for LoC or on preventing potential catalysts, we introduce a complementary framework that emphasizes three extrinsic factors: Deployment context, Affordances, and Permissions (the DAP framework). Compared to work on intrinsic factors and catalysts, this framework has the unfair advantage of being actionable today. Finally, we put forward a plan to maintain preparedness and prevent the occurrence of LoC outcomes should a state of societal vulnerability be reached, focusing on governance measures (threat modeling, deployment policies, emergency response) and technical controls (pre-deployment testing, control measures, monitoring) that could maintain a condition of perennial suspension.",
    "published": "2025-11-19T20:10:39Z",
    "updated": "2025-11-24T18:52:00Z",
    "link": "http://arxiv.org/pdf/2511.15846v3.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Charlotte Stix",
      "Annika Hallensleben",
      "Alejandro Ortega",
      "Matteo Pistillo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19413v1",
    "title": "UniGame: Turning a Unified Multimodal Model Into Its Own Adversary",
    "summary": "Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame",
    "published": "2025-11-24T18:50:01Z",
    "updated": "2025-11-24T18:50:01Z",
    "link": "http://arxiv.org/pdf/2511.19413v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Zhaolong Su",
      "Wang Lu",
      "Hao Chen",
      "Sharon Li",
      "Jindong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19401v1",
    "title": "In-Video Instructions: Visual Signals as Generative Control",
    "summary": "Large-scale video generative models have recently demonstrated strong visual capabilities, enabling the prediction of future frames that adhere to the logical and physical cues in the current observation. In this work, we investigate whether such capabilities can be harnessed for controllable image-to-video generation by interpreting visual signals embedded within the frames as instructions, a paradigm we term In-Video Instruction. In contrast to prompt-based control, which provides textual descriptions that are inherently global and coarse, In-Video Instruction encodes user guidance directly into the visual domain through elements such as overlaid text, arrows, or trajectories. This enables explicit, spatial-aware, and unambiguous correspondences between visual subjects and their intended actions by assigning distinct instructions to different objects. Extensive experiments on three state-of-the-art generators, including Veo 3.1, Kling 2.5, and Wan 2.2, show that video models can reliably interpret and execute such visually embedded instructions, particularly in complex multi-object scenarios.",
    "published": "2025-11-24T18:38:45Z",
    "updated": "2025-11-24T18:38:45Z",
    "link": "http://arxiv.org/pdf/2511.19401v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Gongfan Fang",
      "Xinyin Ma",
      "Xinchao Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19399v1",
    "title": "DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research",
    "summary": "Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.",
    "published": "2025-11-24T18:35:54Z",
    "updated": "2025-11-24T18:35:54Z",
    "link": "http://arxiv.org/pdf/2511.19399v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Rulin Shao",
      "Akari Asai",
      "Shannon Zejiang Shen",
      "Hamish Ivison",
      "Varsha Kishore",
      "Jingming Zhuo",
      "Xinran Zhao",
      "Molly Park",
      "Samuel G. Finlayson",
      "David Sontag",
      "Tyler Murray",
      "Sewon Min",
      "Pradeep Dasigi",
      "Luca Soldaini",
      "Faeze Brahman",
      "Wen-tau Yih",
      "Tongshuang Wu",
      "Luke Zettlemoyer",
      "Yoon Kim",
      "Hannaneh Hajishirzi",
      "Pang Wei Koh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19396v1",
    "title": "Real-Time Object Tracking with On-Device Deep Learning for Adaptive Beamforming in Dynamic Acoustic Environments",
    "summary": "Advances in object tracking and acoustic beamforming are driving new capabilities in surveillance, human-computer interaction, and robotics. This work presents an embedded system that integrates deep learning-based tracking with beamforming to achieve precise sound source localization and directional audio capture in dynamic environments. The approach combines single-camera depth estimation and stereo vision to enable accurate 3D localization of moving objects. A planar concentric circular microphone array constructed with MEMS microphones provides a compact, energy-efficient platform supporting 2D beam steering across azimuth and elevation. Real-time tracking outputs continuously adapt the array's focus, synchronizing the acoustic response with the target's position. By uniting learned spatial awareness with dynamic steering, the system maintains robust performance in the presence of multiple or moving sources. Experimental evaluation demonstrates significant gains in signal-to-interference ratio, making the design well-suited for teleconferencing, smart home devices, and assistive technologies.",
    "published": "2025-11-24T18:33:50Z",
    "updated": "2025-11-24T18:33:50Z",
    "link": "http://arxiv.org/pdf/2511.19396v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Jorge Ortigoso-Narro",
      "Jose A. Belloch",
      "Adrian Amor-Martin",
      "Sandra Roger",
      "Maximo Cobos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.02912v4",
    "title": "Communicating Plans, Not Percepts: Scalable Multi-Agent Coordination with Embodied World Models",
    "summary": "Robust coordination is critical for effective decision-making in multi-agent systems, especially under partial observability. A central question in Multi-Agent Reinforcement Learning (MARL) is whether to engineer communication protocols or learn them end-to-end. We investigate this dichotomy using embodied world models. We propose and compare two communication strategies for a cooperative task-allocation problem. The first, Learned Direct Communication (LDC), learns a protocol end-to-end. The second, Intention Communication, uses an engineered inductive bias: a compact, learned world model, the Imagined Trajectory Generation Module (ITGM), which uses the agent's own policy to simulate future states. A Message Generation Network (MGN) then compresses this plan into a message. We evaluate these approaches on goal-directed interaction in a grid world, a canonical abstraction for embodied AI problems, while scaling environmental complexity. Our experiments reveal that while emergent communication is viable in simple settings, the engineered, world model-based approach shows superior performance, sample efficiency, and scalability as complexity increases. These findings advocate for integrating structured, predictive models into MARL agents to enable active, goal-driven coordination.",
    "published": "2025-08-04T21:29:07Z",
    "updated": "2025-11-24T18:31:13Z",
    "link": "http://arxiv.org/pdf/2508.02912v4.pdf",
    "category": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "authors": [
      "Brennen A. Hill",
      "Mant Koh En Wei",
      "Thangavel Jishnuanandh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19390v1",
    "title": "Predicting partially observable dynamical systems via diffusion models with a multiscale inference scheme",
    "summary": "Conditional diffusion models provide a natural framework for probabilistic prediction of dynamical systems and have been successfully applied to fluid dynamics and weather prediction. However, in many settings, the available information at a given time represents only a small fraction of what is needed to predict future states, either due to measurement uncertainty or because only a small fraction of the state can be observed. This is true for example in solar physics, where we can observe the Sun's surface and atmosphere, but its evolution is driven by internal processes for which we lack direct measurements. In this paper, we tackle the probabilistic prediction of partially observable, long-memory dynamical systems, with applications to solar dynamics and the evolution of active regions. We show that standard inference schemes, such as autoregressive rollouts, fail to capture long-range dependencies in the data, largely because they do not integrate past information effectively. To overcome this, we propose a multiscale inference scheme for diffusion models, tailored to physical processes. Our method generates trajectories that are temporally fine-grained near the present and coarser as we move farther away, which enables capturing long-range temporal dependencies without increasing computational cost. When integrated into a diffusion model, we show that our inference scheme significantly reduces the bias of the predicted distributions and improves rollout stability.",
    "published": "2025-11-24T18:30:04Z",
    "updated": "2025-11-24T18:30:04Z",
    "link": "http://arxiv.org/pdf/2511.19390v1.pdf",
    "category": [
      "cs.LG",
      "astro-ph.SR",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "Rudy Morel",
      "Francesco Pio Ramunno",
      "Jeff Shen",
      "Alberto Bietti",
      "Kyunghyun Cho",
      "Miles Cranmer",
      "Siavash Golkar",
      "Olexandr Gugnin",
      "Geraud Krawezik",
      "Tanya Marwah",
      "Michael McCabe",
      "Lucas Meyer",
      "Payel Mukhopadhyay",
      "Ruben Ohana",
      "Liam Parker",
      "Helen Qu",
      "François Rozet",
      "K. D. Leka",
      "François Lanusse",
      "David Fouhey",
      "Shirley Ho"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.10100v4",
    "title": "Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics",
    "summary": "Learning robust and generalizable world models is crucial for enabling efficient and scalable robotic control in real-world environments. In this work, we introduce a novel framework for learning world models that accurately capture complex, partially observable, and stochastic dynamics. The proposed method employs a dual-autoregressive mechanism and self-supervised training to achieve reliable long-horizon predictions without relying on domain-specific inductive biases, ensuring adaptability across diverse robotic tasks. We further propose a policy optimization framework that leverages world models for efficient training in imagined environments and seamless deployment in real-world systems. This work advances model-based reinforcement learning by addressing the challenges of long-horizon prediction, error accumulation, and sim-to-real transfer. By providing a scalable and robust framework, the introduced methods pave the way for adaptive and efficient robotic systems in real-world applications.",
    "published": "2025-01-17T10:39:09Z",
    "updated": "2025-11-24T18:17:51Z",
    "link": "http://arxiv.org/pdf/2501.10100v4.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Chenhao Li",
      "Andreas Krause",
      "Marco Hutter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03469v2",
    "title": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification",
    "summary": "We introduce a novel framework for evaluating the alignment between natural language plans and their expected behavior by converting them into Kripke structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs) and performing model checking. We systematically evaluate this framework on a simplified version of the PlanBench plan verification dataset and report on metrics like Accuracy, Precision, Recall and F1 scores. Our experiments demonstrate that GPT-5 achieves excellent classification performance (F1 score of 96.3%) while almost always producing syntactically perfect formal representations that can act as guarantees. However, the synthesis of semantically perfect formal models remains an area for future exploration.",
    "published": "2025-10-03T19:46:55Z",
    "updated": "2025-11-24T18:17:27Z",
    "link": "http://arxiv.org/pdf/2510.03469v2.pdf",
    "category": [
      "cs.AI",
      "cs.LO"
    ],
    "authors": [
      "Keshav Ramani",
      "Vali Tawosi",
      "Salwa Alamir",
      "Daniel Borrajo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.03463v2",
    "title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework",
    "summary": "Multi-agent Large Language Model (LLM) systems have been leading the way in applied LLM research across a number of fields. One notable area is software development, where researchers have advanced the automation of code implementation, code testing, code maintenance, inter alia, using LLM agents. However, software development is a multifaceted environment that extends beyond just code. As such, a successful LLM system must factor in multiple stages of the software development life-cycle (SDLC). In this paper, we propose a vision for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework, which follows the above SDLC philosophy such that it may work within an agile software development team to perform several tasks end-to-end. ALMAS aligns its agents with agile roles, and can be used in a modular fashion to seamlessly integrate with human developers and their development environment. We showcase the progress towards ALMAS through our published works and a use case demonstrating the framework, where ALMAS is able to seamlessly generate an application and add a new feature.",
    "published": "2025-10-03T19:35:23Z",
    "updated": "2025-11-24T18:11:57Z",
    "link": "http://arxiv.org/pdf/2510.03463v2.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Vali Tawosi",
      "Keshav Ramani",
      "Salwa Alamir",
      "Xiaomo Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19367v1",
    "title": "An Anatomy Aware Hybrid Deep Learning Framework for Lung Cancer Tumor Stage Classification",
    "summary": "Accurate lung cancer tumor staging is crucial for prognosis and treatment planning. However, it remains challenging for end-to-end deep learning approaches, as such approaches often overlook spatial and anatomical information that are central to the tumor-node-metastasis system. The tumor stage depends on multiple quantitative criteria, including the tumor size and its proximity to the nearest anatomical structures, and small variations can alter the staging outcome. We propose a medically grounded hybrid pipeline that performs staging by explicitly measuring the tumor's size and distance properties rather than treating it as a pure image classification task. Our method employs specialized encoder-decoder networks to precisely segment the lung and adjacent anatomy, including the lobes, tumor, mediastinum, and diaphragm. Subsequently, we extract the necessary tumor properties, i.e. measure the largest tumor dimension and calculate the distance between the tumor and neighboring anatomical structures by a quantitative analysis of the segmentation masks. Finally, we apply rule-based tumor staging aligned with the medical guidelines. This novel framework has been evaluated on the Lung-PET-CT-Dx dataset, demonstrating superior performance compared to traditional deep learning models, achieving an overall classification accuracy of 91.36%. We report the per-stage F1-scores of 0.93 (T1), 0.89 (T2), 0.96 (T3), and 0.90 (T4), a critical evaluation aspect often omitted in prior literature. To our knowledge, this is the first study that embeds explicit clinical context into tumor stage classification. Unlike standard convolutional neural networks that operate in an uninterpretable \"black box\" manner, our method offers both state-of-the-art performance and transparent decision support.",
    "published": "2025-11-24T18:01:47Z",
    "updated": "2025-11-24T18:01:47Z",
    "link": "http://arxiv.org/pdf/2511.19367v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Saniah Kayenat Chowdhury",
      "Rusab Sarmun",
      "Muhammad E. H. Chowdhury",
      "Sohaib Bassam Zoghoul",
      "Israa Al-Hashimi",
      "Adam Mushtak",
      "Amith Khandakar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19365v1",
    "title": "DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation",
    "summary": "Pixel diffusion aims to generate images directly in pixel space in an end-to-end fashion. This approach avoids the limitations of VAE in the two-stage latent diffusion, offering higher model capacity. Existing pixel diffusion models suffer from slow training and inference, as they usually model both high-frequency signals and low-frequency semantics within a single diffusion transformer (DiT). To pursue a more efficient pixel diffusion paradigm, we propose the frequency-DeCoupled pixel diffusion framework. With the intuition to decouple the generation of high and low frequency components, we leverage a lightweight pixel decoder to generate high-frequency details conditioned on semantic guidance from the DiT. This thus frees the DiT to specialize in modeling low-frequency semantics. In addition, we introduce a frequency-aware flow-matching loss that emphasizes visually salient frequencies while suppressing insignificant ones. Extensive experiments show that DeCo achieves superior performance among pixel diffusion models, attaining FID of 1.62 (256x256) and 2.22 (512x512) on ImageNet, closing the gap with latent diffusion methods. Furthermore, our pretrained text-to-image model achieves a leading overall score of 0.86 on GenEval in system-level comparison. Codes are publicly available at https://github.com/Zehong-Ma/DeCo.",
    "published": "2025-11-24T17:59:06Z",
    "updated": "2025-11-24T17:59:06Z",
    "link": "http://arxiv.org/pdf/2511.19365v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Zehong Ma",
      "Longhui Wei",
      "Shuai Wang",
      "Shiliang Zhang",
      "Qi Tian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19355v1",
    "title": "Leveraging LLMs for reward function design in reinforcement learning control tasks",
    "summary": "The challenge of designing effective reward functions in reinforcement learning (RL) represents a significant bottleneck, often requiring extensive human expertise and being time-consuming. Previous work and recent advancements in large language models (LLMs) have demonstrated their potential for automating the generation of reward functions. However, existing methodologies often require preliminary evaluation metrics, human-engineered feedback for the refinement process, or the use of environmental source code as context. To address these limitations, this paper introduces LEARN-Opt (LLM-based Evaluator and Analyzer for Reward functioN Optimization). This LLM-based, fully autonomous, and model-agnostic framework eliminates the need for preliminary metrics and environmental source code as context to generate, execute, and evaluate reward function candidates from textual descriptions of systems and task objectives. LEARN-Opt's main contribution lies in its ability to autonomously derive performance metrics directly from the system description and the task objective, enabling unsupervised evaluation and selection of reward functions. Our experiments indicate that LEARN-Opt achieves performance comparable to or better to that of state-of-the-art methods, such as EUREKA, while requiring less prior knowledge. We find that automated reward design is a high-variance problem, where the average-case candidate fails, requiring a multi-run approach to find the best candidates. Finally, we show that LEARN-Opt can unlock the potential of low-cost LLMs to find high-performing candidates that are comparable to, or even better than, those of larger models. This demonstrated performance affirms its potential to generate high-quality reward functions without requiring any preliminary human-defined metrics, thereby reducing engineering overhead and enhancing generalizability.",
    "published": "2025-11-24T17:55:46Z",
    "updated": "2025-11-24T17:55:46Z",
    "link": "http://arxiv.org/pdf/2511.19355v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Franklin Cardenoso",
      "Wouter Caarls"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.00634v2",
    "title": "Node Preservation and its Effect on Crossover in Cartesian Genetic Programming",
    "summary": "While crossover is a critical and often indispensable component in other forms of Genetic Programming, such as Linear- and Tree-based, it has consistently been claimed that it deteriorates search performance in CGP. As a result, a mutation-alone $(1+λ)$ evolutionary strategy has become the canonical approach for CGP. Although several operators have been developed that demonstrate an increased performance over the canonical method, a general solution to the problem is still lacking. In this paper, we compare basic crossover methods, namely one-point and uniform, to variants in which nodes are ``preserved,'' including the subgraph crossover developed by Roman Kalkreuth, the difference being that when ``node preservation'' is active, crossover is not allowed to break apart instructions. We also compare a node mutation operator to the traditional point mutation; the former simply replaces an entire node with a new one. We find that node preservation in both mutation and crossover improves search using symbolic regression benchmark problems, moving the field towards a general solution to CGP crossover.",
    "published": "2025-11-01T17:26:56Z",
    "updated": "2025-11-24T17:55:01Z",
    "link": "http://arxiv.org/pdf/2511.00634v2.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Mark Kocherovsky",
      "Illya Bakurov",
      "Wolfgang Banzhaf"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19342v1",
    "title": "Explicit Tonal Tension Conditioning via Dual-Level Beam Search for Symbolic Music Generation",
    "summary": "State-of-the-art symbolic music generation models have recently achieved remarkable output quality, yet explicit control over compositional features, such as tonal tension, remains challenging. We propose a novel approach that integrates a computational tonal tension model, based on tonal interval vector analysis, into a Transformer framework. Our method employs a two-level beam search strategy during inference. At the token level, generated candidates are re-ranked using model probability and diversity metrics to maintain overall quality. At the bar level, a tension-based re-ranking is applied to ensure that the generated music aligns with a desired tension curve. Objective evaluations indicate that our approach effectively modulates tonal tension, and subjective listening tests confirm that the system produces outputs that align with the target tension. These results demonstrate that explicit tension conditioning through a dual-level beam search provides a powerful and intuitive tool to guide AI-generated music. Furthermore, our experiments demonstrate that our method can generate multiple distinct musical interpretations under the same tension condition.",
    "published": "2025-11-24T17:41:04Z",
    "updated": "2025-11-24T17:41:04Z",
    "link": "http://arxiv.org/pdf/2511.19342v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI"
    ],
    "authors": [
      "Maral Ebrahimzadeh",
      "Gilberto Bernardes",
      "Sebastian Stober"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19325v1",
    "title": "Generative Query Expansion with Multilingual LLMs for Cross-Lingual Information Retrieval",
    "summary": "Query expansion is the reformulation of a user query by adding semantically related information, and is an essential component of monolingual and cross-lingual information retrieval used to ensure that relevant documents are not missed. Recently, multilingual large language models (mLLMs) have shifted query expansion from semantic augmentation with synonyms and related words to pseudo-document generation. Pseudo-documents both introduce additional relevant terms and bridge the gap between short queries and long documents, which is particularly beneficial in dense retrieval. This study evaluates recent mLLMs and fine-tuned variants across several generative expansion strategies to identify factors that drive cross-lingual retrieval performance. Results show that query length largely determines which prompting technique is effective, and that more elaborate prompts often do not yield further gains. Substantial linguistic disparities persist: cross-lingual query expansion can produce the largest improvements for languages with the weakest baselines, yet retrieval is especially poor between languages written in different scripts. Fine-tuning is found to lead to performance gains only when the training and test data are of similar format. These outcomes underline the need for more balanced multilingual and cross-lingual training and evaluation resources.",
    "published": "2025-11-24T17:18:25Z",
    "updated": "2025-11-24T17:18:25Z",
    "link": "http://arxiv.org/pdf/2511.19325v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Olivia Macmillan-Scott",
      "Roksana Goworek",
      "Eda B. Özyiğit"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19324v1",
    "title": "What Drives Cross-lingual Ranking? Retrieval Approaches with Multilingual Language Models",
    "summary": "Cross-lingual information retrieval (CLIR) enables access to multilingual knowledge but remains challenging due to disparities in resources, scripts, and weak cross-lingual semantic alignment in embedding models. Existing pipelines often rely on translation and monolingual retrieval heuristics, which add computational overhead and noise, degrading performance. This work systematically evaluates four intervention types, namely document translation, multilingual dense retrieval with pretrained encoders, contrastive learning at word, phrase, and query-document levels, and cross-encoder re-ranking, across three benchmark datasets. We find that dense retrieval models trained specifically for CLIR consistently outperform lexical matching methods and derive little benefit from document translation. Contrastive learning mitigates language biases and yields substantial improvements for encoders with weak initial alignment, and re-ranking can be effective, but depends on the quality of the cross-encoder training data. Although high-resource languages still dominate overall performance, gains over lexical and document-translated baselines are most pronounced for low-resource and cross-script pairs. These findings indicate that cross-lingual search systems should prioritise semantic multilingual embeddings and targeted learning-based alignment over translation-based pipelines, particularly for cross-script and under-resourced languages.",
    "published": "2025-11-24T17:17:40Z",
    "updated": "2025-11-24T17:17:40Z",
    "link": "http://arxiv.org/pdf/2511.19324v1.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Roksana Goworek",
      "Olivia Macmillan-Scott",
      "Eda B. Özyiğit"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.13612v4",
    "title": "Entropic Time Schedulers for Generative Diffusion Models",
    "summary": "The practical performance of generative diffusion models depends on the appropriate choice of the noise scheduling function, which can also be equivalently expressed as a time reparameterization. In this paper, we present a time scheduler that selects sampling points based on entropy rather than uniform time spacing, ensuring that each point contributes an equal amount of information to the final generation. We prove that this time reparameterization does not depend on the initial choice of time. Furthermore, we provide a tractable exact formula to estimate this \\emph{entropic time} for a trained model using the training loss without substantial overhead. Alongside the entropic time, inspired by the optimality results, we introduce a rescaled entropic time. In our experiments with mixtures of Gaussian distributions and ImageNet, we show that using the (rescaled) entropic times greatly improves the inference performance of trained models. In particular, we found that the image quality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can be substantially increased by the rescaled entropic time reparameterization without increasing the number of function evaluations, with greater improvements in the few NFEs regime. Code is available at https://github.com/DejanStancevic/Entropic-Time-Schedulers-for-Generative-Diffusion-Models.",
    "published": "2025-04-18T10:35:19Z",
    "updated": "2025-11-24T17:16:26Z",
    "link": "http://arxiv.org/pdf/2504.13612v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Dejan Stancevic",
      "Florian Handke",
      "Luca Ambrogioni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.02995v3",
    "title": "The Geometry of Cortical Computation: Manifold Disentanglement and Predictive Dynamics in VCNet",
    "summary": "Despite their success, modern convolutional neural networks (CNNs) exhibit fundamental limitations, including data inefficiency, poor out-of-distribution generalization, and vulnerability to adversarial perturbations. These shortcomings can be traced to a lack of inductive biases that reflect the inherent geometric structure of the visual world. The primate visual system, in contrast, demonstrates superior efficiency and robustness, suggesting that its architectural and computational principles,which evolved to internalize these structures,may offer a blueprint for more capable artificial vision. This paper introduces Visual Cortex Network (VCNet), a novel neural network architecture whose design is informed by the macro-scale organization of the primate visual cortex. VCNet is framed as a geometric framework that emulates key biological mechanisms, including hierarchical processing across distinct cortical areas, dual-stream information segregation for learning disentangled representations, and top-down predictive feedback for representation refinement. We interpret these mechanisms through the lens of geometry and dynamical systems, positing that they guide the learning of structured, low-dimensional neural manifolds. We evaluate VCNet on two specialized benchmarks: the Spots-10 animal pattern dataset, which probes sensitivity to natural textures, and a light field image classification task, which requires processing higher-dimensional visual data. Our results show that VCNet achieves state-of-the-art accuracy of 92.1\\% on Spots-10 and 74.4\\% on the light field dataset, surpassing contemporary models of comparable size. This work demonstrates that integrating high-level neuroscientific principles, viewed through a geometric lens, can lead to more efficient and robust models, providing a promising direction for addressing long-standing challenges in machine learning.",
    "published": "2025-08-05T01:52:42Z",
    "updated": "2025-11-24T17:11:32Z",
    "link": "http://arxiv.org/pdf/2508.02995v3.pdf",
    "category": [
      "cs.NE",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Brennen A. Hill",
      "Zhang Xinyu",
      "Timothy Putra Prasetio"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19316v1",
    "title": "Evaluating Dataset Watermarking for Fine-tuning Traceability of Customized Diffusion Models: A Comprehensive Benchmark and Removal Approach",
    "summary": "Recent fine-tuning techniques for diffusion models enable them to reproduce specific image sets, such as particular faces or artistic styles, but also introduce copyright and security risks. Dataset watermarking has been proposed to ensure traceability by embedding imperceptible watermarks into training images, which remain detectable in outputs even after fine-tuning. However, current methods lack a unified evaluation framework. To address this, this paper establishes a general threat model and introduces a comprehensive evaluation framework encompassing Universality, Transmissibility, and Robustness. Experiments show that existing methods perform well in universality and transmissibility, and exhibit some robustness against common image processing operations, yet still fall short under real-world threat scenarios. To reveal these vulnerabilities, the paper further proposes a practical watermark removal method that fully eliminates dataset watermarks without affecting fine-tuning, highlighting a key challenge for future research.",
    "published": "2025-11-24T17:11:00Z",
    "updated": "2025-11-24T17:11:00Z",
    "link": "http://arxiv.org/pdf/2511.19316v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Xincheng Wang",
      "Hanchi Sun",
      "Wenjun Sun",
      "Kejun Xue",
      "Wangqiu Zhou",
      "Jianbo Zhang",
      "Wei Sun",
      "Dandan Zhu",
      "Xiongkuo Min",
      "Jun Jia",
      "Zhijun Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21505v2",
    "title": "How does Alignment Enhance LLMs' Multilingual Capabilities? A Language Neurons Perspective",
    "summary": "Multilingual Alignment is an effective and representative paradigm to enhance LLMs' multilingual capabilities, which transfers the capabilities from the high-resource languages to the low-resource languages. Meanwhile, some research on language-specific neurons provides a new perspective to analyze and understand LLMs' mechanisms. However, we find that there are many neurons that are shared by multiple but not all languages and cannot be correctly classified. In this work, we propose a ternary classification methodology that categorizes neurons into three types, including language-specific neurons, language-related neurons, and general neurons. And we propose a corresponding identification algorithm to distinguish these different types of neurons. Furthermore, based on the distributional characteristics of different types of neurons, we divide the LLMs' internal process for multilingual inference into four parts: (1) multilingual understanding, (2) shared semantic space reasoning, (3) multilingual output space transformation, and (4) vocabulary space outputting. Additionally, we systematically analyze the models before and after alignment with a focus on different types of neurons. We also analyze the phenomenon of ''Spontaneous Multilingual Alignment''. Overall, our work conducts a comprehensive investigation based on different types of neurons, providing empirical results and valuable insights to better understand multilingual alignment and multilingual capabilities of LLMs.",
    "published": "2025-05-27T17:59:52Z",
    "updated": "2025-11-24T17:10:38Z",
    "link": "http://arxiv.org/pdf/2505.21505v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Shimao Zhang",
      "Zhejian Lai",
      "Xiang Liu",
      "Shuaijie She",
      "Xiao Liu",
      "Yeyun Gong",
      "Shujian Huang",
      "Jiajun Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19314v1",
    "title": "PRInTS: Reward Modeling for Long-Horizon Information Seeking",
    "summary": "Information-seeking is a core capability for AI agents, requiring them to gather and reason over tool-generated information across long trajectories. However, such multi-step information-seeking tasks remain challenging for agents backed by language models. While process reward models (PRMs) can guide agents by ranking candidate steps at test-time, existing PRMs, designed for short reasoning with binary judgment, cannot capture richer dimensions of information-seeking steps, such as tool interactions and reasoning over tool outputs, nor handle the rapidly growing context in long-horizon tasks. To address these limitations, we introduce PRInTS, a generative PRM trained with dual capabilities: (1) dense scoring based on the PRM's reasoning across multiple step quality dimensions (e.g., interpretation of tool outputs, tool call informativeness) and (2) trajectory summarization that compresses the growing context while preserving essential information for step evaluation. Extensive evaluations across FRAMES, GAIA (levels 1-3), and WebWalkerQA (easy-hard) benchmarks on multiple models, along with ablations, reveal that best-of-n sampling with PRInTS enhances information-seeking abilities of open-source models as well as specialized agents, matching or surpassing the performance of frontier models with a much smaller backbone agent and outperforming other strong reward modeling baselines.",
    "published": "2025-11-24T17:09:43Z",
    "updated": "2025-11-24T17:09:43Z",
    "link": "http://arxiv.org/pdf/2511.19314v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jaewoo Lee",
      "Archiki Prasad",
      "Justin Chih-Yao Chen",
      "Zaid Khan",
      "Elias Stengel-Eskin",
      "Mohit Bansal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.15622v2",
    "title": "The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification",
    "summary": "Automated video analysis is critical for wildlife conservation. A foundational task in this domain is multi-animal tracking (MAT), which underpins applications such as individual re-identification and behavior recognition. However, existing datasets are limited in scale, constrained to a few species, or lack sufficient temporal and geographical diversity - leaving no suitable benchmark for training general-purpose MAT models applicable across wild animal populations. To address this, we introduce SA-FARI, the largest open-source MAT dataset for wild animals. It comprises 11,609 camera trap videos collected over approximately 10 years (2014-2024) from 741 locations across 4 continents, spanning 99 species categories. Each video is exhaustively annotated culminating in ~46 hours of densely annotated footage containing 16,224 masklet identities and 942,702 individual bounding boxes, segmentation masks, and species labels. Alongside the task-specific annotations, we publish anonymized camera trap locations for each video. Finally, we present comprehensive benchmarks on SA-FARI using state-of-the-art vision-language models for detection and tracking, including SAM 3, evaluated with both species-specific and generic animal prompts. We also compare against vision-only methods developed specifically for wildlife analysis. SA-FARI is the first large-scale dataset to combine high species diversity, multi-region coverage, and high-quality spatio-temporal annotations, offering a new foundation for advancing generalizable multianimal tracking in the wild. The dataset is available at https://www.conservationxlabs.com/sa-fari.",
    "published": "2025-11-19T17:07:08Z",
    "updated": "2025-11-24T17:02:04Z",
    "link": "http://arxiv.org/pdf/2511.15622v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Dante Francisco Wasmuht",
      "Otto Brookes",
      "Maximillian Schall",
      "Pablo Palencia",
      "Chris Beirne",
      "Tilo Burghardt",
      "Majid Mirmehdi",
      "Hjalmar Kühl",
      "Mimi Arandjelovic",
      "Sam Pottie",
      "Peter Bermant",
      "Brandon Asheim",
      "Yi Jin Toh",
      "Adam Elzinga",
      "Jason Holmberg",
      "Andrew Whitworth",
      "Eleanor Flatt",
      "Laura Gustafson",
      "Chaitanya Ryali",
      "Yuan-Ting Hu",
      "Baishan Guo",
      "Andrew Westbury",
      "Kate Saenko",
      "Didac Suris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19304v1",
    "title": "AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning",
    "summary": "Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv.",
    "published": "2025-11-24T16:54:23Z",
    "updated": "2025-11-24T16:54:23Z",
    "link": "http://arxiv.org/pdf/2511.19304v1.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Jiayi Zhang",
      "Yiran Peng",
      "Fanqi Kong",
      "Yang Cheng",
      "Yifan Wu",
      "Zhaoyang Yu",
      "Jinyu Xiang",
      "Jianhao Ruan",
      "Jinlin Wang",
      "Maojia Song",
      "HongZhang Liu",
      "Xiangru Tang",
      "Bang Liu",
      "Chenglin Wu",
      "Yuyu Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.10750v2",
    "title": "AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition",
    "summary": "Thanks to the availability of massive amounts of data, computing resources, and advanced algorithms, AI has entered nearly every sector. This has sparked significant investment and interest, particularly in building data centers with the necessary hardware and software to develop and operate AI models and AI-based workflows. In this technical review article, we present energy consumption scenarios of data centers and impact on GHG emissions, considering both near-term projections (up to 2030) and long-term outlook (2035 and beyond). We address the quintessential question of whether AI will have a net positive, neutral, or negative impact on CO2 emissions by 2035. Additionally, we discuss AI's potential to automate, create efficient and disruptive workflows across various fields related to energy production, supply and consumption. In the near-term scenario, the growing demand for AI will likely strain computing resources, lead to increase in electricity consumption and therefore associated CO2 emissions. This is due to the power-hungry nature of big data centers and the requirements for training and running of large and complex AI models, as well as the penetration of AI assistant search and applications for public use. However, the long-term outlook could be more promising. AI has the potential to be a game-changer in CO2 reduction. Its ability to further automate and optimize processes across industries, from energy production to logistics, could significantly decrease our carbon footprint. This positive impact is anticipated to outweigh the initial emissions bump, creating value for businesses and society in areas where traditional solutions have fallen short. In essence, AI might cause some initial growing pains for the environment, but it has the potential to support climate mitigation efforts.",
    "published": "2025-07-14T19:16:27Z",
    "updated": "2025-11-24T16:52:12Z",
    "link": "http://arxiv.org/pdf/2507.10750v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Pandu Devarakota",
      "Nicolas Tsesmetzis",
      "Faruk O. Alpak",
      "Apurva Gala",
      "Detlef Hohl"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19299v1",
    "title": "Open-weight genome language model safeguards: Assessing robustness via adversarial fine-tuning",
    "summary": "Novel deep learning architectures are increasingly being applied to biological data, including genetic sequences. These models, referred to as genomic language mod- els (gLMs), have demonstrated impressive predictive and generative capabilities, raising concerns that such models may also enable misuse, for instance via the generation of genomes for human-infecting viruses. These concerns have catalyzed calls for risk mitigation measures. The de facto mitigation of choice is filtering of pretraining data (i.e., removing viral genomic sequences from training datasets) in order to limit gLM performance on virus-related tasks. However, it is not currently known how robust this approach is for securing open-source models that can be fine-tuned using sensitive pathogen data. Here, we evaluate a state-of-the-art gLM, Evo 2, and perform fine-tuning using sequences from 110 harmful human-infecting viruses to assess the rescue of misuse-relevant predictive capabilities. The fine- tuned model exhibited reduced perplexity on unseen viral sequences relative to 1) the pretrained model and 2) a version fine-tuned on bacteriophage sequences. The model fine-tuned on human-infecting viruses also identified immune escape variants from SARS-CoV-2 (achieving an AUROC of 0.6), despite having no expo- sure to SARS-CoV-2 sequences during fine-tuning. This work demonstrates that data exclusion might be circumvented by fine-tuning approaches that can, to some degree, rescue misuse-relevant capabilities of gLMs. We highlight the need for safety frameworks for gLMs and outline further work needed on evaluations and mitigation measures to enable the safe deployment of gLMs.",
    "published": "2025-11-24T16:46:44Z",
    "updated": "2025-11-24T16:46:44Z",
    "link": "http://arxiv.org/pdf/2511.19299v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "James R. M. Black",
      "Moritz S. Hanke",
      "Aaron Maiwald",
      "Tina Hernandez-Boussard",
      "Oliver M. Crook",
      "Jaspreet Pannu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.27280v2",
    "title": "FOCUS: Efficient Keyframe Selection for Long Video Understanding",
    "summary": "Multimodal large language models (MLLMs) represent images and video frames as visual tokens. Scaling from single images to hour-long videos, however, inflates the token budget far beyond practical limits. Popular pipelines therefore either uniformly subsample or apply keyframe selection with retrieval-style scoring using smaller vision-language models. However, these keyframe selection methods still rely on pre-filtering before selection to reduce the inference cost and can miss the most informative moments. We propose FOCUS, Frame-Optimistic Confidence Upper-bound Selection, a training-free, model-agnostic keyframe selection module that selects query-relevant frames under a strict token budget. FOCUS formulates keyframe selection as a combinatorial pure-exploration (CPE) problem in multi-armed bandits: it treats short temporal clips as arms, and uses empirical means and Bernstein confidence radius to identify informative regions while preserving exploration of uncertain areas. The resulting two-stage exploration-exploitation procedure reduces from a sequential policy with theoretical guarantees, first identifying high-value temporal regions, then selecting top-scoring frames within each region. On two long-video question-answering benchmarks, FOCUS delivers substantial accuracy improvements while processing less than 2% of video frames. For videos longer than 20 minutes, it achieves an 11.9% gain in accuracy on LongVideoBench, demonstrating its effectiveness as a keyframe selection method and providing a simple and general solution for scalable long-video understanding with MLLMs. Code is available at https://github.com/NUS-HPC-AI-Lab/FOCUS.",
    "published": "2025-10-31T08:41:13Z",
    "updated": "2025-11-24T16:40:06Z",
    "link": "http://arxiv.org/pdf/2510.27280v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zirui Zhu",
      "Hailun Xu",
      "Yang Luo",
      "Yong Liu",
      "Kanchan Sarkar",
      "Zhenheng Yang",
      "Yang You"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.01285v2",
    "title": "BioDisco: Multi-agent hypothesis generation with dual-mode evidence, iterative feedback and temporal evaluation",
    "summary": "Identifying novel hypotheses is essential to scientific research, yet this process risks being overwhelmed by the sheer volume and complexity of available information. Existing automated methods often struggle to generate novel and evidence-grounded hypotheses, lack robust iterative refinement and rarely undergo rigorous temporal evaluation for future discovery potential. To address this, we propose BioDisco, a multi-agent framework that draws upon language model-based reasoning and a dual-mode evidence system (biomedical knowledge graphs and automated literature retrieval) for grounded novelty, integrates an internal scoring and feedback loop for iterative refinement, and validates performance through pioneering temporal and human evaluations and a Bradley-Terry paired comparison model to provide statistically-grounded assessment. Our evaluations demonstrate superior novelty and significance over ablated configurations and generalist biomedical agents. Designed for flexibility and modularity, BioDisco allows seamless integration of custom language models or knowledge graphs, and can be run with just a few lines of code.",
    "published": "2025-08-02T09:32:52Z",
    "updated": "2025-11-24T16:36:29Z",
    "link": "http://arxiv.org/pdf/2508.01285v2.pdf",
    "category": [
      "cs.AI",
      "cs.IR",
      "stat.AP"
    ],
    "authors": [
      "Yujing Ke",
      "Kevin George",
      "Kathan Pandya",
      "David Blumenthal",
      "Maximilian Sprang",
      "Gerrit Großmann",
      "Sebastian Vollmer",
      "David Antony Selby"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.10727v2",
    "title": "Word-level Annotation of GDPR Transparency Compliance in Privacy Policies using Large Language Models",
    "summary": "Ensuring transparency of data practices related to personal information is a core requirement of the General Data Protection Regulation (GDPR). However, large-scale compliance assessment remains challenging due to the complexity and diversity of privacy policy language. Manual audits are labour-intensive and inconsistent, while current automated methods often lack the granularity required to capture nuanced transparency disclosures.\n  In this paper, we present a modular large language model (LLM)-based pipeline for fine-grained word-level annotation of privacy policies with respect to GDPR transparency requirements. Our approach integrates LLM-driven annotation with passage-level classification, retrieval-augmented generation, and a self-correction mechanism to deliver scalable, context-aware annotations across 21 GDPR-derived transparency requirements. To support empirical evaluation, we compile a corpus of 703,791 English-language privacy policies and generate a ground-truth sample of 200 manually annotated policies based on a comprehensive, GDPR-aligned annotation scheme.\n  We propose a two-tiered evaluation methodology capturing both passage-level classification and span-level annotation quality and conduct a comparative analysis of seven state-of-the-art LLMs on two annotation schemes, including the widely used OPP-115 dataset. The results of our evaluation show that decomposing the annotation task and integrating targeted retrieval and classification components significantly improve annotation accuracy, particularly for well-structured requirements. Our work provides new empirical resources and methodological foundations for advancing automated transparency compliance assessment at scale.",
    "published": "2025-03-13T11:41:25Z",
    "updated": "2025-11-24T16:34:25Z",
    "link": "http://arxiv.org/pdf/2503.10727v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Thomas Cory",
      "Wolf Rieder",
      "Julia Krämer",
      "Philip Raschke",
      "Patrick Herbke",
      "Axel Küpper"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19283v1",
    "title": "Data Flows and Colonial Regimes in Africa: A Critical Analysis of the Colonial Futurities Embedded in AI Ecosystems",
    "summary": "This chapter seeks to frame the elemental and invisible problems of AI and big data in the African context by examining digital sites and infrastructure through the lens of power and interests. It will present reflections on how these sites are using AI recommendation algorithms to recreate new digital societies in the region, how they have the potential to propagate algorithmic colonialism and negative gender norms, and what this means for the regional sustainable development agenda. The chapter proposes adopting business models that embrace response-ability and consider the existence of alternative socio-material worlds of AI. These reflections will mainly come from ongoing discussions with Kenyan social media users in this authors' user space talks, personal experiences and six months of active participant observations done by the authors.",
    "published": "2025-11-24T16:31:50Z",
    "updated": "2025-11-24T16:31:50Z",
    "link": "http://arxiv.org/pdf/2511.19283v1.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Ndaka. A",
      "Avila-Acosta. F",
      "Mbula-Ndaka. H",
      "Amera. C",
      "Chauke. S",
      "Majiwa. E"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10016v3",
    "title": "A Survey of Generative Categories and Techniques in Multimodal Generative Models",
    "summary": "Multimodal Generative Models (MGMs) have rapidly evolved beyond text generation, now spanning diverse output modalities including images, music, video, human motion, and 3D objects, by integrating language with other sensory modalities under unified architectures. This survey categorises six primary generative modalities and examines how foundational techniques, namely Self-Supervised Learning (SSL), Mixture of Experts (MoE), Reinforcement Learning from Human Feedback (RLHF), and Chain-of-Thought (CoT) prompting, enable cross-modal capabilities. We analyze key models, architectural trends, and emergent cross-modal synergies, while highlighting transferable techniques and unresolved challenges. Building on a common taxonomy of models and training recipes, we propose a unified evaluation framework centred on faithfulness, compositionality, and robustness, and synthesise evidence from benchmarks and human studies across modalities. We further analyse trustworthiness, safety, and ethical risks, including multimodal bias, privacy leakage, and the misuse of high-fidelity media generation for deepfakes, disinformation, and copyright infringement in music and 3D assets, together with emerging mitigation strategies. Finally, we discuss how architectural trends, evaluation protocols, and governance mechanisms can be co-designed to close current capability and safety gaps, outlining critical paths toward more general-purpose, controllable, and accountable multimodal generative systems.",
    "published": "2025-05-29T12:29:39Z",
    "updated": "2025-11-24T16:26:13Z",
    "link": "http://arxiv.org/pdf/2506.10016v3.pdf",
    "category": [
      "cs.MM",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Longzhen Han",
      "Awes Mubarak",
      "Almas Baimagambetov",
      "Nikolaos Polatidis",
      "Thar Baker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19275v1",
    "title": "Dynamic Multi-Species Bird Soundscape Generation with Acoustic Patterning and 3D Spatialization",
    "summary": "Generation of dynamic, scalable multi-species bird soundscapes remains a significant challenge in computer music and algorithmic sound design. Birdsongs involve rapid frequency-modulated chirps, complex amplitude envelopes, distinctive acoustic patterns, overlapping calls, and dynamic inter-bird interactions, all of which require precise temporal and spatial control in 3D environments. Existing approaches, whether Digital Signal Processing (DSP)-based or data-driven, typically focus only on single species modeling, static call structures, or synthesis directly from recordings, and often suffer from noise, limited flexibility, or large data needs. To address these challenges, we present a novel, fully algorithm-driven framework that generates dynamic multi-species bird soundscapes using DSP-based chirp generation and 3D spatialization, without relying on recordings or training data. Our approach simulates multiple independently-moving birds per species along different moving 3D trajectories, supporting controllable chirp sequences, overlapping choruses, and realistic 3D motion in scalable soundscapes while preserving species-specific acoustic patterns. A visualization interface provides bird trajectories, spectrograms, activity timelines, and sound waves for analytical and creative purposes. Both visual and audio evaluations demonstrate the ability of the system to generate dense, immersive, and ecologically inspired soundscapes, highlighting its potential for computer music, interactive virtual environments, and computational bioacoustics research.",
    "published": "2025-11-24T16:25:55Z",
    "updated": "2025-11-24T16:25:55Z",
    "link": "http://arxiv.org/pdf/2511.19275v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "eess.SP"
    ],
    "authors": [
      "Ellie L. Zhang",
      "Duoduo Liao",
      "Callie C. Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06725v2",
    "title": "WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making",
    "summary": "Large Language Models (LLMs) possess general world knowledge but often struggle to generate precise predictions in structured, domain-specific contexts such as simulations. These limitations arise from their inability to ground their broad, unstructured understanding in specific environments. To address this, we present WorldLLM, a framework that enhances LLM-based world modeling by combining Bayesian inference and autonomous active exploration with reinforcement learning. WorldLLM leverages the in-context learning abilities of LLMs to guide an LLM-based world model's predictions using natural language hypotheses given in its prompt. These hypotheses are iteratively refined through a Bayesian inference framework that leverages a second LLM as the proposal distribution given collected evidence. This evidence is collected using a curiosity-driven reinforcement learning policy that explores the environment to find transitions with a low log-likelihood under our LLM-based predictive model using the current hypotheses. By alternating between refining hypotheses and collecting new evidence, our framework autonomously drives continual improvement of the predictions. Our experiments demonstrate the effectiveness of WorldLLM in a textual game environment that requires agents to manipulate and combine objects. The framework not only enhances predictive accuracy, but also generates human-interpretable theories of environment dynamics.",
    "published": "2025-06-07T09:13:34Z",
    "updated": "2025-11-24T16:18:31Z",
    "link": "http://arxiv.org/pdf/2506.06725v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Guillaume Levy",
      "Cedric Colas",
      "Pierre-Yves Oudeyer",
      "Thomas Carta",
      "Clement Romac"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.01558v2",
    "title": "VideoLights: Feature Refinement and Cross-Task Alignment Transformer for Joint Video Highlight Detection and Moment Retrieval",
    "summary": "Prevailing joint prediction transformers for Video Highlight Detection and Moment Retrieval (HD/MR) exhibit deficiencies in handling cross-task dynamics, achieving robust video-text alignment, and utilizing effective attention mechanisms, with the potential of Large Language/Vision-Language Models (LLMs/LVLMs) being largely untapped. This paper introduces VideoLights, a novel HD/MR framework addressing these limitations by incorporating: (i) Convolutional Projection and Feature Refinement modules with an alignment loss for enhanced video-text feature congruity; (ii) a Bi-Directional Cross-Modal Fusion network for strongly coupled query-aware representations; (iii) a Uni-directional joint-task feedback mechanism for synergistic task improvement; (iv) hard positive/negative losses for adaptive learning; and (v) the leveraging of LVLMs (e.g., BLIP-2) for superior multimodal feature integration and intelligent pre-training with synthetic data. Comprehensive evaluations on QVHighlights, TVSum, and Charades-STA benchmarks demonstrate that VideoLights significantly surpasses existing baselines, establishing new state-of-the-art performances. Codes and model checkpoints are available at https://github.com/dpaul06/VideoLights .",
    "published": "2024-12-02T14:45:53Z",
    "updated": "2025-11-24T16:17:57Z",
    "link": "http://arxiv.org/pdf/2412.01558v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Dhiman Paul",
      "Md Rizwan Parvez",
      "Nabeel Mohammed",
      "Shafin Rahman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19264v1",
    "title": "Interpreting GFlowNets for Drug Discovery: Extracting Actionable Insights for Medicinal Chemistry",
    "summary": "Generative Flow Networks, or GFlowNets, offer a promising framework for molecular design, but their internal decision policies remain opaque. This limits adoption in drug discovery, where chemists require clear and interpretable rationales for proposed structures. We present an interpretability framework for SynFlowNet, a GFlowNet trained on documented chemical reactions and purchasable starting materials that generates both molecules and the synthetic routes that produce them. Our approach integrates three complementary components. Gradient based saliency combined with counterfactual perturbations identifies which atomic environments influence reward and how structural edits change molecular outcomes. Sparse autoencoders reveal axis aligned latent factors that correspond to physicochemical properties such as polarity, lipophilicity, and molecular size. Motif probes show that functional groups including aromatic rings and halogens are explicitly encoded and linearly decodable from the internal embeddings. Together, these results expose the chemical logic inside SynFlowNet and provide actionable and mechanistic insight that supports transparent and controllable molecular design.",
    "published": "2025-11-24T16:16:18Z",
    "updated": "2025-11-24T16:16:18Z",
    "link": "http://arxiv.org/pdf/2511.19264v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "authors": [
      "Amirtha Varshini A S",
      "Duminda S. Ranasinghe",
      "Hok Hei Tam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19263v1",
    "title": "Solar-GECO: Perovskite Solar Cell Property Prediction with Geometric-Aware Co-Attention",
    "summary": "Perovskite solar cells are promising candidates for next-generation photovoltaics. However, their performance as multi-scale devices is determined by complex interactions between their constituent layers. This creates a vast combinatorial space of possible materials and device architectures, making the conventional experimental-based screening process slow and expensive. Machine learning models try to address this problem, but they only focus on individual material properties or neglect the important geometric information of the perovskite crystal. To address this problem, we propose to predict perovskite solar cell power conversion efficiency with a geometric-aware co-attention (Solar-GECO) model. Solar-GECO combines a geometric graph neural network (GNN) - that directly encodes the atomic structure of the perovskite absorber - with language model embeddings that process the textual strings representing the chemical compounds of the transport layers and other device components. Solar-GECO also integrates a co-attention module to capture intra-layer dependencies and inter-layer interactions, while a probabilistic regression head predicts both power conversion efficiency (PCE) and its associated uncertainty. Solar-GECO achieves state-of-the-art performance, significantly outperforming several baselines, reducing the mean absolute error (MAE) for PCE prediction from 3.066 to 2.936 compared to semantic GNN (the previous state-of-the-art model). Solar-GECO demonstrates that integrating geometric and textual information provides a more powerful and accurate framework for PCE prediction.",
    "published": "2025-11-24T16:15:41Z",
    "updated": "2025-11-24T16:15:41Z",
    "link": "http://arxiv.org/pdf/2511.19263v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Lucas Li",
      "Jean-Baptiste Puel",
      "Florence Carton",
      "Dounya Barrit",
      "Jhony H. Giraldo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19262v1",
    "title": "Psychometric Tests for AI Agents and Their Moduli Space",
    "summary": "We develop a moduli-theoretic view of psychometric test batteries for AI agents and connect it explicitly to the AAI score developed previously. First, we make precise the notion of an AAI functional on a battery and set out axioms that any reasonable autonomy/general intelligence score should satisfy. Second, we show that the composite index ('AAI-Index') defined previously is a special case of our AAI functional. Third, we introduce the notion of a cognitive core of an agent relative to a battery and define the associated AAI$_{\\textrm{core}}$ score as the restriction of an AAI functional to that core. Finally, we use these notions to describe invariants of batteries under evaluation-preserving symmetries and outline how moduli of equivalent batteries are organized.",
    "published": "2025-11-24T16:15:08Z",
    "updated": "2025-11-24T16:15:08Z",
    "link": "http://arxiv.org/pdf/2511.19262v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "math.ST"
    ],
    "authors": [
      "Przemyslaw Chojecki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19260v1",
    "title": "A Nutrition Multimodal Photoplethysmography Language Model",
    "summary": "Hunger and satiety dynamics shape dietary behaviors and metabolic health, yet remain difficult to capture in everyday settings. We present a Nutrition Photoplethysmography Language Model (NPLM), integrating continuous photoplethysmography (PPG) from wearables with meal descriptions. NPLM projects PPG into embeddings interpretable by language models, enabling joint reasoning over physiology and meal context. Trained on 19,340 participants and 1.1 million meal-PPG pairs, the model improved daily caloric intake prediction by 11% over text-only baselines, with accuracy maintained when 80% of meal text was removed. In an independent validation study (n=140) with controlled dining and detailed meal information, the model replicated these findings. These results demonstrate the value of integrating physiological measurements from consumer wearables with meal information for noninvasive dietary monitoring at scale.",
    "published": "2025-11-24T16:12:03Z",
    "updated": "2025-11-24T16:12:03Z",
    "link": "http://arxiv.org/pdf/2511.19260v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Kyle Verrier",
      "Achille Nazaret",
      "Joseph Futoma",
      "Andrew C. Miller",
      "Guillermo Sapiro"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19257v1",
    "title": "Medusa: Cross-Modal Transferable Adversarial Attacks on Multimodal Medical Retrieval-Augmented Generation",
    "summary": "With the rapid advancement of retrieval-augmented vision-language models, multimodal medical retrieval-augmented generation (MMed-RAG) systems are increasingly adopted in clinical decision support. These systems enhance medical applications by performing cross-modal retrieval to integrate relevant visual and textual evidence for tasks, e.g., report generation and disease diagnosis. However, their complex architecture also introduces underexplored adversarial vulnerabilities, particularly via visual input perturbations. In this paper, we propose Medusa, a novel framework for crafting cross-modal transferable adversarial attacks on MMed-RAG systems under a black-box setting. Specifically, Medusa formulates the attack as a perturbation optimization problem, leveraging a multi-positive InfoNCE loss (MPIL) to align adversarial visual embeddings with medically plausible but malicious textual targets, thereby hijacking the retrieval process. To enhance transferability, we adopt a surrogate model ensemble and design a dual-loop optimization strategy augmented with invariant risk minimization (IRM). Extensive experiments on two real-world medical tasks, including medical report generation and disease diagnosis, demonstrate that Medusa achieves over 90% average attack success rate across various generation models and retrievers under appropriate parameter configuration, while remaining robust against four mainstream defenses, outperforming state-of-the-art baselines. Our results reveal critical vulnerabilities in the MMed-RAG systems and highlight the necessity of robustness benchmarking in safety-critical medical applications. The code and data are available at https://anonymous.4open.science/r/MMed-RAG-Attack-F05A.",
    "published": "2025-11-24T16:11:01Z",
    "updated": "2025-11-24T16:11:01Z",
    "link": "http://arxiv.org/pdf/2511.19257v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yingjia Shang",
      "Yi Liu",
      "Huimin Wang",
      "Furong Li",
      "Wenfang Sun",
      "Wu Chengyu",
      "Yefeng Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19256v1",
    "title": "SimDiff: Simpler Yet Better Diffusion Model for Time Series Point Forecasting",
    "summary": "Diffusion models have recently shown promise in time series forecasting, particularly for probabilistic predictions. However, they often fail to achieve state-of-the-art point estimation performance compared to regression-based methods. This limitation stems from difficulties in providing sufficient contextual bias to track distribution shifts and in balancing output diversity with the stability and precision required for point forecasts. Existing diffusion-based approaches mainly focus on full-distribution modeling under probabilistic frameworks, often with likelihood maximization objectives, while paying little attention to dedicated strategies for high-accuracy point estimation. Moreover, other existing point prediction diffusion methods frequently rely on pre-trained or jointly trained mature models for contextual bias, sacrificing the generative flexibility of diffusion models.\n  To address these challenges, we propose SimDiff, a single-stage, end-to-end framework. SimDiff employs a single unified Transformer network carefully tailored to serve as both denoiser and predictor, eliminating the need for external pre-trained or jointly trained regressors. It achieves state-of-the-art point estimation performance by leveraging intrinsic output diversity and improving mean squared error accuracy through multiple inference ensembling. Key innovations, including normalization independence and the median-of-means estimator, further enhance adaptability and stability. Extensive experiments demonstrate that SimDiff significantly outperforms existing methods in time series point forecasting.",
    "published": "2025-11-24T16:09:55Z",
    "updated": "2025-11-24T16:09:55Z",
    "link": "http://arxiv.org/pdf/2511.19256v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Hang Ding",
      "Xue Wang",
      "Tian Zhou",
      "Tao Yao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19254v1",
    "title": "Adversarial Patch Attacks on Vision-Based Cargo Occupancy Estimation via Differentiable 3D Simulation",
    "summary": "Computer vision systems are increasingly adopted in modern logistics operations, including the estimation of trailer occupancy for planning, routing, and billing. Although effective, such systems may be vulnerable to physical adversarial attacks, particularly adversarial patches that can be printed and placed on interior surfaces. In this work, we study the feasibility of such attacks on a convolutional cargo-occupancy classifier using fully simulated 3D environments. Using Mitsuba 3 for differentiable rendering, we optimize patch textures across variations in geometry, lighting, and viewpoint, and compare their effectiveness to a 2D compositing baseline. Our experiments demonstrate that 3D-optimized patches achieve high attack success rates, especially in a denial-of-service scenario (empty to full), where success reaches 84.94 percent. Concealment attacks (full to empty) prove more challenging but still reach 30.32 percent. We analyze the factors influencing attack success, discuss implications for the security of automated logistics pipelines, and highlight directions for strengthening physical robustness. To our knowledge, this is the first study to investigate adversarial patch attacks for cargo-occupancy estimation in physically realistic, fully simulated 3D scenes.",
    "published": "2025-11-24T16:05:40Z",
    "updated": "2025-11-24T16:05:40Z",
    "link": "http://arxiv.org/pdf/2511.19254v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Mohamed Rissal Hedna",
      "Sesugh Samuel Nder"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19253v1",
    "title": "MAESTRO: Multi-Agent Environment Shaping through Task and Reward Optimization",
    "summary": "Cooperative Multi-Agent Reinforcement Learning (MARL) faces two major design bottlenecks: crafting dense reward functions and constructing curricula that avoid local optima in high-dimensional, non-stationary environments. Existing approaches rely on fixed heuristics or use Large Language Models (LLMs) directly in the control loop, which is costly and unsuitable for real-time systems. We propose MAESTRO (Multi-Agent Environment Shaping through Task and Reward Optimization), a framework that moves the LLM outside the execution loop and uses it as an offline training architect. MAESTRO introduces two generative components: (i) a semantic curriculum generator that creates diverse, performance-driven traffic scenarios, and (ii) an automated reward synthesizer that produces executable Python reward functions adapted to evolving curriculum difficulty. These components guide a standard MARL backbone (MADDPG) without increasing inference cost at deployment. We evaluate MAESTRO on large-scale traffic signal control (Hangzhou, 16 intersections) and conduct controlled ablations. Results show that combining LLM-generated curricula with LLM-generated reward shaping yields improved performance and stability. Across four seeds, the full system achieves +4.0% higher mean return (163.26 vs. 156.93) and 2.2% better risk-adjusted performance (Sharpe 1.53 vs. 0.70) over a strong curriculum baseline. These findings highlight LLMs as effective high-level designers for cooperative MARL training.",
    "published": "2025-11-24T16:05:37Z",
    "updated": "2025-11-24T16:05:37Z",
    "link": "http://arxiv.org/pdf/2511.19253v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Boyuan Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13646v3",
    "title": "Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?",
    "summary": "Large Language Models (LLMs) are reshaping almost all industries, including software engineering. In recent years, a number of LLM agents have been proposed to solve real-world software problems. Such software agents are typically equipped with a suite of coding tools and can autonomously decide the next actions to form complete trajectories to solve end-to-end software tasks. While promising, they typically require dedicated design and may still be suboptimal, since it can be extremely challenging and costly to exhaust the entire agent scaffold design space. Recognizing that software agents are inherently software themselves that can be further refined/modified, researchers have proposed a number of self-improving software agents recently, including the Darwin-Gödel Machine (DGM). Meanwhile, such self-improving agents require costly offline training on specific benchmarks and may not generalize well across different LLMs or benchmarks. In this paper, we propose Live-SWE-agent, the first live software agent that can autonomously and continuously evolve itself on-the-fly during runtime when solving real-world software problems. More specifically, Live-SWE-agent starts with the most basic agent scaffold with only access to bash tools (e.g., mini-SWE-agent), and autonomously evolves its own scaffold implementation while solving real-world software problems. Our evaluation on the widely studied SWE-bench Verified benchmark shows that LIVE-SWE-AGENT can achieve an impressive solve rate of 77.4% without test-time scaling, outperforming all existing software agents, including the best proprietary solution. Moreover, Live-SWE-agent outperforms state-of-the-art manually crafted software agents on the recent SWE-Bench Pro benchmark, achieving the best-known solve rate of 45.8%.",
    "published": "2025-11-17T17:58:18Z",
    "updated": "2025-11-24T15:55:51Z",
    "link": "http://arxiv.org/pdf/2511.13646v3.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Chunqiu Steven Xia",
      "Zhe Wang",
      "Yan Yang",
      "Yuxiang Wei",
      "Lingming Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19246v1",
    "title": "Neural Architecture Search for Quantum Autoencoders",
    "summary": "In recent years, machine learning and deep learning have driven advances in domains such as image classification, speech recognition, and anomaly detection by leveraging multi-layer neural networks to model complex data. Simultaneously, quantum computing (QC) promises to address classically intractable problems via quantum parallelism, motivating research in quantum machine learning (QML). Among QML techniques, quantum autoencoders show promise for compressing high-dimensional quantum and classical data. However, designing effective quantum circuit architectures for quantum autoencoders remains challenging due to the complexity of selecting gates, arranging circuit layers, and tuning parameters.\n  This paper proposes a neural architecture search (NAS) framework that automates the design of quantum autoencoders using a genetic algorithm (GA). By systematically evolving variational quantum circuit (VQC) configurations, our method seeks to identify high-performing hybrid quantum-classical autoencoders for data reconstruction without becoming trapped in local minima. We demonstrate effectiveness on image datasets, highlighting the potential of quantum autoencoders for efficient feature extraction within a noise-prone, near-term quantum era. Our approach lays a foundation for broader application of genetic algorithms to quantum architecture search, aiming for a robust, automated method that can adapt to varied data and hardware constraints.",
    "published": "2025-11-24T15:55:44Z",
    "updated": "2025-11-24T15:55:44Z",
    "link": "http://arxiv.org/pdf/2511.19246v1.pdf",
    "category": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "authors": [
      "Hibah Agha",
      "Samuel Yen-Chi Chen",
      "Huan-Hsin Tseng",
      "Shinjae Yoo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19241v1",
    "title": "Local Entropy Search over Descent Sequences for Bayesian Optimization",
    "summary": "Searching large and complex design spaces for a global optimum can be infeasible and unnecessary. A practical alternative is to iteratively refine the neighborhood of an initial design using local optimization methods such as gradient descent. We propose local entropy search (LES), a Bayesian optimization paradigm that explicitly targets the solutions reachable by the descent sequences of iterative optimizers. The algorithm propagates the posterior belief over the objective through the optimizer, resulting in a probability distribution over descent sequences. It then selects the next evaluation by maximizing mutual information with that distribution, using a combination of analytic entropy calculations and Monte-Carlo sampling of descent sequences. Empirical results on high-complexity synthetic objectives and benchmark problems show that LES achieves strong sample efficiency compared to existing local and global Bayesian optimization methods.",
    "published": "2025-11-24T15:52:17Z",
    "updated": "2025-11-24T15:52:17Z",
    "link": "http://arxiv.org/pdf/2511.19241v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "authors": [
      "David Stenger",
      "Armin Lindicke",
      "Alexander von Rohr",
      "Sebastian Trimpe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19236v1",
    "title": "SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control",
    "summary": "Existing humanoid control systems often rely on teleoperation or modular generation pipelines that separate language understanding from physical execution. However, the former is entirely human-driven, and the latter lacks tight alignment between language commands and physical behaviors. In this paper, we present SENTINEL, a fully end-to-end language-action model for humanoid whole-body control. We construct a large-scale dataset by tracking human motions in simulation using a pretrained whole body controller, combined with their text annotations. The model directly maps language commands and proprioceptive inputs to low-level actions without any intermediate representation. The model generates action chunks using flow matching, which can be subsequently refined by a residual action head for real-world deployment. Our method exhibits strong semantic understanding and stable execution on humanoid robots in both simulation and real-world deployment, and also supports multi-modal extensions by converting inputs into texts.",
    "published": "2025-11-24T15:48:59Z",
    "updated": "2025-11-24T15:48:59Z",
    "link": "http://arxiv.org/pdf/2511.19236v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Yuxuan Wang",
      "Haobin Jiang",
      "Shiqing Yao",
      "Ziluo Ding",
      "Zongqing Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.13292v2",
    "title": "Automatic Multi-View X-Ray/CT Registration Using Bone Substructure Contours",
    "summary": "Purpose: Accurate intraoperative X-ray/CT registration is essential for surgical navigation in orthopedic procedures. However, existing methods struggle with consistently achieving sub-millimeter accuracy, robustness under broad initial pose estimates or need manual key-point annotations. This work aims to address these challenges by proposing a novel multi-view X-ray/CT registration method for intraoperative bone registration. Methods: The proposed registration method consists of a multi-view, contour-based iterative closest point (ICP) optimization. Unlike previous methods, which attempt to match bone contours across the entire silhouette in both imaging modalities, we focus on matching specific subcategories of contours corresponding to bone substructures. This leads to reduced ambiguity in the ICP matches, resulting in a more robust and accurate registration solution. This approach requires only two X-ray images and operates fully automatically. Additionally, we contribute a dataset of 5 cadaveric specimens, including real X-ray images, X-ray image poses and the corresponding CT scans. Results: The proposed registration method is evaluated on real X-ray images using mean reprojection error (mRPD). The method consistently achieves sub-millimeter accuracy with a mRPD 0.67mm compared to 5.35mm by a commercial solution requiring manual intervention. Furthermore, the method offers improved practical applicability, being fully automatic. Conclusion: Our method offers a practical, accurate, and efficient solution for multi-view X-ray/CT registration in orthopedic surgeries, which can be easily combined with tracking systems. By improving registration accuracy and minimizing manual intervention, it enhances intraoperative navigation, contributing to more accurate and effective surgical outcomes in computer-assisted surgery (CAS).",
    "published": "2025-06-16T09:33:37Z",
    "updated": "2025-11-24T15:46:09Z",
    "link": "http://arxiv.org/pdf/2506.13292v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Roman Flepp",
      "Leon Nissen",
      "Bastian Sigrist",
      "Arend Nieuwland",
      "Nicola Cavalcanti",
      "Philipp Fürnstahl",
      "Thomas Dreher",
      "Lilian Calvet"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19232v1",
    "title": "In Machina N400: Pinpointing Where a Causal Language Model Detects Semantic Violations",
    "summary": "How and where does a transformer notice that a sentence has gone semantically off the rails? To explore this question, we evaluated the causal language model (phi-2) using a carefully curated corpus, with sentences that concluded plausibly or implausibly. Our analysis focused on the hidden states sampled at each model layer. To investigate how violations are encoded, we utilized two complementary probes. First, we conducted a per-layer detection using a linear probe. Our findings revealed that a simple linear decoder struggled to distinguish between plausible and implausible endings in the lowest third of the model's layers. However, its accuracy sharply increased in the middle blocks, reaching a peak just before the top layers. Second, we examined the effective dimensionality of the encoded violation. Initially, the violation widens the representational subspace, followed by a collapse after a mid-stack bottleneck. This might indicate an exploratory phase that transitions into rapid consolidation. Taken together, these results contemplate the idea of alignment with classical psycholinguistic findings in human reading, where semantic anomalies are detected only after syntactic resolution, occurring later in the online processing sequence.",
    "published": "2025-11-24T15:43:56Z",
    "updated": "2025-11-24T15:43:56Z",
    "link": "http://arxiv.org/pdf/2511.19232v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Christos-Nikolaos Zacharopoulos",
      "Revekka Kyriakoglou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19229v1",
    "title": "Learning Plug-and-play Memory for Guiding Video Diffusion Models",
    "summary": "Diffusion Transformer(DiT) based video generation models have recently achieved impressive visual quality and temporal coherence, but they still frequently violate basic physical laws and commonsense dynamics, revealing a lack of explicit world knowledge. In this work, we explore how to equip them with a plug-and-play memory that injects useful world knowledge. Motivated by in-context memory in Transformer-based LLMs, we conduct empirical studies to show that DiT can be steered via interventions on its hidden states, and simple low-pass and high-pass filters in the embedding space naturally disentangle low-level appearance and high-level physical/semantic cues, enabling targeted guidance. Building on these observations, we propose a learnable memory encoder DiT-Mem, composed of stacked 3D CNNs, low-/high-pass filters, and self-attention layers. The encoder maps reference videos into a compact set of memory tokens, which are concatenated as the memory within the DiT self-attention layers. During training, we keep the diffusion backbone frozen, and only optimize the memory encoder. It yields a rather efficient training process on few training parameters (150M) and 10K data samples, and enables plug-and-play usage at inference time. Extensive experiments on state-of-the-art models demonstrate the effectiveness of our method in improving physical rule following and video fidelity. Our code and data are publicly released here: https://thrcle421.github.io/DiT-Mem-Web/.",
    "published": "2025-11-24T15:42:23Z",
    "updated": "2025-11-24T15:42:23Z",
    "link": "http://arxiv.org/pdf/2511.19229v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Selena Song",
      "Ziming Xu",
      "Zijun Zhang",
      "Kun Zhou",
      "Jiaxian Guo",
      "Lianhui Qin",
      "Biwei Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19220v1",
    "title": "Are Large Vision Language Models Truly Grounded in Medical Images? Evidence from Italian Clinical Visual Question Answering",
    "summary": "Large vision language models (VLMs) have achieved impressive performance on medical visual question answering benchmarks, yet their reliance on visual information remains unclear. We investigate whether frontier VLMs demonstrate genuine visual grounding when answering Italian medical questions by testing four state-of-the-art models: Claude Sonnet 4.5, GPT-4o, GPT-5-mini, and Gemini 2.0 flash exp. Using 60 questions from the EuropeMedQA Italian dataset that explicitly require image interpretation, we substitute correct medical images with blank placeholders to test whether models truly integrate visual and textual information. Our results reveal striking variability in visual dependency: GPT-4o shows the strongest visual grounding with a 27.9pp accuracy drop (83.2% [74.6%, 91.7%] to 55.3% [44.1%, 66.6%]), while GPT-5-mini, Gemini, and Claude maintain high accuracy with modest drops of 8.5pp, 2.4pp, and 5.6pp respectively. Analysis of model-generated reasoning reveals confident explanations for fabricated visual interpretations across all models, suggesting varying degrees of reliance on textual shortcuts versus genuine visual analysis. These findings highlight critical differences in model robustness and the need for rigorous evaluation before clinical deployment.",
    "published": "2025-11-24T15:26:58Z",
    "updated": "2025-11-24T15:26:58Z",
    "link": "http://arxiv.org/pdf/2511.19220v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Federico Felizzi",
      "Olivia Riccomi",
      "Michele Ferramola",
      "Francesco Andrea Causio",
      "Manuel Del Medico",
      "Vittorio De Vita",
      "Lorenzo De Mori",
      "Alessandra Piscitelli Pietro Eric Risuleo",
      "Bianca Destro Castaniti",
      "Antonio Cristiano Alessia Longo",
      "Luigi De Angelis",
      "Mariapia Vassalli",
      "Marcello Di Pumpo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19218v1",
    "title": "Adversarial Attack-Defense Co-Evolution for LLM Safety Alignment via Tree-Group Dual-Aware Search and Optimization",
    "summary": "Large Language Models (LLMs) have developed rapidly in web services, delivering unprecedented capabilities while amplifying societal risks. Existing works tend to focus on either isolated jailbreak attacks or static defenses, neglecting the dynamic interplay between evolving threats and safeguards in real-world web contexts. To mitigate these challenges, we propose ACE-Safety (Adversarial Co-Evolution for LLM Safety), a novel framework that jointly optimize attack and defense models by seamlessly integrating two key innovative procedures: (1) Group-aware Strategy-guided Monte Carlo Tree Search (GS-MCTS), which efficiently explores jailbreak strategies to uncover vulnerabilities and generate diverse adversarial samples; (2) Adversarial Curriculum Tree-aware Group Policy Optimization (AC-TGPO), which jointly trains attack and defense LLMs with challenging samples via curriculum reinforcement learning, enabling robust mutual improvement. Evaluations across multiple benchmarks demonstrate that our method outperforms existing attack and defense approaches, and provides a feasible pathway for developing LLMs that can sustainably support responsible AI ecosystems.",
    "published": "2025-11-24T15:23:41Z",
    "updated": "2025-11-24T15:23:41Z",
    "link": "http://arxiv.org/pdf/2511.19218v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Xurui Li",
      "Kaisong Song",
      "Rui Zhu",
      "Pin-Yu Chen",
      "Haixu Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.13223v3",
    "title": "Distributionally Robust Free Energy Principle for Decision-Making",
    "summary": "Despite their groundbreaking performance, autonomous agents can misbehave when training and environmental conditions become inconsistent, with minor mismatches leading to undesirable behaviors or even catastrophic failures. Robustness towards these training-environment ambiguities is a core requirement for intelligent agents and its fulfillment is a long-standing challenge towards their real-world deployments. Here, we introduce a Distributionally Robust Free Energy model (DR-FREE) that instills this core property by design. Combining a robust extension of the free energy principle with a resolution engine, DR-FREE wires robustness into the agent decision-making mechanisms. Across benchmark experiments, DR-FREE enables the agents to complete the task even when, in contrast, state-of-the-art models fail. This milestone may inspire both deployments in multi-agent settings and, at a perhaps deeper level, the quest for an explanation of how natural agents -- with little or no training -- survive in capricious environments.",
    "published": "2025-03-17T14:36:08Z",
    "updated": "2025-11-24T15:19:30Z",
    "link": "http://arxiv.org/pdf/2503.13223v3.pdf",
    "category": [
      "cs.AI",
      "eess.SY",
      "math.OC"
    ],
    "authors": [
      "Allahkaram Shafiei",
      "Hozefa Jesawada",
      "Karl Friston",
      "Giovanni Russo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19199v1",
    "title": "CLASH: A Benchmark for Cross-Modal Contradiction Detection",
    "summary": "Contradictory multimodal inputs are common in real-world settings, yet existing benchmarks typically assume input consistency and fail to evaluate cross-modal contradiction detection - a fundamental capability for preventing hallucinations and ensuring reliability. We introduce CLASH, a novel benchmark for multimodal contradiction detection, featuring COCO images paired with contradictory captions containing controlled object-level or attribute-level contradictions. The samples include targeted questions evaluated in both multiple-choice and open-ended formats. The benchmark provides an extensive fine-tuning set filtered through automated quality checks, alongside a smaller human-verified diagnostic set. Our analysis of state-of-the-art models reveals substantial limitations in recognizing cross-modal conflicts, exposing systematic modality biases and category-specific weaknesses. Furthermore, we empirically demonstrate that targeted fine-tuning on CLASH substantially enhances conflict detection capabilities.",
    "published": "2025-11-24T15:09:07Z",
    "updated": "2025-11-24T15:09:07Z",
    "link": "http://arxiv.org/pdf/2511.19199v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Teodora Popordanoska",
      "Jiameng Li",
      "Matthew B. Blaschko"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.16356v2",
    "title": "Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health",
    "summary": "Mobile health (mHealth) programs utilize automated voice messages to deliver health information, particularly targeting underserved communities, demonstrating the effectiveness of using mobile technology to disseminate crucial health information to these populations, improving health outcomes through increased awareness and behavioral change. India's Kilkari program delivers vital maternal health information via weekly voice calls to millions of mothers. However, the current random call scheduling often results in missed calls and reduced message delivery. This study presents a field trial of a collaborative bandit algorithm designed to optimize call timing by learning individual mothers' preferred call times. We deployed the algorithm with around $6500$ Kilkari participants as a pilot study, comparing its performance to the baseline random calling approach. Our results demonstrate a statistically significant improvement in call pick-up rates with the bandit algorithm, indicating its potential to enhance message delivery and impact millions of mothers across India. This research highlights the efficacy of personalized scheduling in mobile health interventions and underscores the potential of machine learning to improve maternal health outreach at scale.",
    "published": "2025-07-22T08:42:17Z",
    "updated": "2025-11-24T15:04:04Z",
    "link": "http://arxiv.org/pdf/2507.16356v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Arpan Dasgupta",
      "Mizhaan Maniyar",
      "Awadhesh Srivastava",
      "Sanat Kumar",
      "Amrita Mahale",
      "Aparna Hegde",
      "Arun Suggala",
      "Karthikeyan Shanmugam",
      "Aparna Taneja",
      "Milind Tambe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.01632v3",
    "title": "Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions",
    "summary": "The robustness of deep neural networks is a crucial factor in safety-critical applications, particularly in complex and dynamic environments (e.g., medical or driving scenarios) where localized corruptions can arise. While previous studies have evaluated the robustness of semantic segmentation (SS) models under whole-image natural or adversarial corruptions, a comprehensive investigation into the spatial robustness of dense vision models under localized corruptions remains underexplored. This paper fills this gap by introducing novel, region-aware metrics for benchmarking the spatial robustness of segmentation models, along with an evaluation framework to assess the impact of natural localized corruptions. Furthermore, it uncovers the inherent complexity of evaluating worst-case spatial robustness using only a single localized adversarial attack. To address this, the work proposes a region-aware multi-attack adversarial analysis to systematically assess model robustness across specific image regions. The proposed metrics and analysis were exploited to evaluate 14 segmentation models in driving scenarios, uncovering key insights into the effects of localized corruption in both natural and adversarial forms. The results reveal that models respond to these two types of threats differently; for instance, transformer-based segmentation models demonstrate notable robustness to localized natural corruptions but are highly vulnerable to adversarial ones, and vice versa for CNN-based models. Consequently, we also address the challenge of balancing robustness to both natural and adversarial localized corruptions by means of ensemble models, thereby achieving a broader threat coverage and improved reliability for dense vision tasks.",
    "published": "2025-04-02T11:37:39Z",
    "updated": "2025-11-24T14:54:55Z",
    "link": "http://arxiv.org/pdf/2504.01632v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Giulia Marchiori Pietrosanti",
      "Giulio Rossolini",
      "Alessandro Biondi",
      "Giorgio Buttazzo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19184v1",
    "title": "Torsion-Space Diffusion for Protein Backbone Generation with Geometric Refinement",
    "summary": "Designing new protein structures is fundamental to computational biology, enabling advances in therapeutic molecule discovery and enzyme engineering. Existing diffusion-based generative models typically operate in Cartesian coordinate space, where adding noise disrupts strict geometric constraints such as fixed bond lengths and angles, often producing physically invalid structures. To address this limitation, we propose a Torsion-Space Diffusion Model that generates protein backbones by denoising torsion angles, ensuring perfect local geometry by construction. A differentiable forward-kinematics module reconstructs 3D coordinates with fixed 3.8 Angstrom backbone bond lengths while a constrained post-processing refinement optimizes global compactness via Radius of Gyration (Rg) correction, without violating bond constraints. Experiments on standard PDB proteins demonstrate 100% bond-length accuracy and significantly improved structural compactness, reducing Rg error from 70% to 18.6% compared to Cartesian diffusion baselines. Overall, this hybrid torsion-diffusion plus geometric-refinement framework generates physically valid and compact protein backbones, providing a promising path toward full-atom protein generation.",
    "published": "2025-11-24T14:51:29Z",
    "updated": "2025-11-24T14:51:29Z",
    "link": "http://arxiv.org/pdf/2511.19184v1.pdf",
    "category": [
      "q-bio.BM",
      "cs.AI"
    ],
    "authors": [
      "Lakshaditya Singh",
      "Adwait Shelke",
      "Divyansh Agrawal"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.01047v2",
    "title": "In-Situ Tweedie Discrete Diffusion Models",
    "summary": "While diffusion models excel at generating continuous data such as images, adapting them to discrete tasks has relied on indirect approaches that either operate in continuous embedding spaces or use token masking mechanisms, both of which deviate from modeling the true discrete data distribution that can be theoretically guaranteed by Tweedie's formula. We propose in-situ Tweedie Discrete Diffusion (TDD), a framework that performs diffusion guaranteed by Tweedie's formula directly within the discrete one-hot space, hence \"in-situ.\" Unlike prior methods that diffuse continuous embeddings or mask tokens, TDD directly corrupts one-hot vectors with Gaussian noise and performs iterative denoising through a timestep-conditioned cross-entropy objective rather than mean-squared-error reconstruction. At each denoising step, the model predicts class probabilities, applies argmax to obtain discrete predictions, converts them to one-hot vectors, and feeds them into the next iteration with progressively reduced noise. This process naturally unifies discriminative classification and generative modeling under a single framework. Experiments demonstrate that TDD achieves strong performance on both image classification and text generation tasks, with extensive ablation studies confirming the effectiveness of each design component. Our work establishes a principled approach to discrete diffusion that preserves the core characteristics of diffusion models while operating natively in discrete space.",
    "published": "2025-10-01T15:51:10Z",
    "updated": "2025-11-24T14:42:41Z",
    "link": "http://arxiv.org/pdf/2510.01047v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Xiao Li",
      "Jiaqi Zhang",
      "Shuxiang Zhang",
      "Tianshui Chen",
      "Liang Lin",
      "Guangrun Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19175v1",
    "title": "LLM-Based Agentic Negotiation for 6G: Addressing Uncertainty Neglect and Tail-Event Risk",
    "summary": "A critical barrier to the trustworthiness of sixth-generation (6G) agentic autonomous networks is the uncertainty neglect bias; a cognitive tendency for large language model (LLM)-powered agents to make high-stakes decisions based on simple averages while ignoring the tail risk of extreme events. This paper proposes an unbiased, risk-aware framework for agentic negotiation, designed to ensure robust resource allocation in 6G network slicing. Specifically, agents leverage Digital Twins (DTs) to predict full latency distributions, which are then evaluated using a formal framework from extreme value theory, namely, Conditional Value-at-Risk (CVaR). This approach fundamentally shifts the agent's objective from reasoning over the mean to reasoning over the tail, thereby building a statistically-grounded buffer against worst-case outcomes. Furthermore, our framework ensures full uncertainty awareness by requiring agents to quantify epistemic uncertainty -- confidence in their own DTs predictions -- and propagate this meta-verification to make robust decisions, preventing them from acting on unreliable data. We validate this framework in a 6G inter-slice negotiation use-case between an eMBB and a URLLC agent. The results demonstrate the profound failure of the biased, mean-based baseline, which consistently fails its SLAs with a 25\\% rate. Our unbiased, CVaR-aware agent successfully mitigates this bias, eliminating SLA violations and reducing the URLLC and eMBB p99.999 latencies by around 11\\%. We show this reliability comes at the rational and quantifiable cost of slightly reduced energy savings to 17\\%, exposing the false economy of the biased approach. This work provides a concrete methodology for building the trustworthy autonomous systems required for 6G.",
    "published": "2025-11-24T14:36:11Z",
    "updated": "2025-11-24T14:36:11Z",
    "link": "http://arxiv.org/pdf/2511.19175v1.pdf",
    "category": [
      "cs.NI",
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Hatim Chergui",
      "Farhad Rezazadeh",
      "Mehdi Bennis",
      "Merouane Debbah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.07751v3",
    "title": "AbstRaL: Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking",
    "summary": "Recent studies have shown that large language models (LLMs), especially smaller ones, often lack robustness in grade school math (GSM) reasoning. In particular, they tend to experience performance drops when faced with distribution shifts, such as changes to numerical or nominal variables, or insertions of distracting clauses. A possible strategy to address this involves generating synthetic data to further \"instantiate\" reasoning problems on potential variations. In this work, we instead focuses on the strategy of \"abstracting\" reasoning problems. This not only helps counteract distribution shifts but also facilitates the connection to symbolic tools for deriving solutions. Focusing on GSM, we find that this abstraction process is better acquired through reinforcement learning (RL) than just supervised fine-tuning, which often fails to produce faithful abstractions. Our method, AbstRaL -- which promotes abstract reasoning in LLMs using RL on granular abstraction data -- significantly mitigates performance degradation on recent GSM perturbation benchmarks. Besides, improving GSM robustness via AbstRaL is shown to also implicitly benefit LLMs' capabilities on OOD mathematical and general reasoning tasks, indicating that abstract thinking broadly enables better generalizability.",
    "published": "2025-06-09T13:34:50Z",
    "updated": "2025-11-24T14:29:20Z",
    "link": "http://arxiv.org/pdf/2506.07751v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.SC"
    ],
    "authors": [
      "Silin Gao",
      "Antoine Bosselut",
      "Samy Bengio",
      "Emmanuel Abbe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19156v1",
    "title": "Information Physics of Intelligence: Unifying Logical Depth and Entropy under Thermodynamic Constraints",
    "summary": "The rapid scaling of artificial intelligence models has revealed a fundamental tension between model capacity (storage) and inference efficiency (computation). While classical information theory focuses on transmission and storage limits, it lacks a unified physical framework to quantify the thermodynamic costs of generating information from compressed laws versus retrieving it from memory. In this paper, we propose a theoretical framework that treats information processing as an enabling mapping from ontological states to carrier states. We introduce a novel metric, Derivation Entropy, which quantifies the effective work required to compute a target state from a given logical depth. By analyzing the interplay between Shannon entropy (storage) and computational complexity (time/energy), we demonstrate the existence of a critical phase transition point. Below this threshold, memory retrieval is thermodynamically favorable; above it, generative computation becomes the optimal strategy. This \"Energy-Time-Space\" conservation law provides a physical explanation for the efficiency of generative models and offers a rigorous mathematical bound for designing next-generation, energy-efficient AI architectures. Our findings suggest that the minimization of Derivation Entropy is a governing principle for the evolution of both biological and artificial intelligence.",
    "published": "2025-11-24T14:24:08Z",
    "updated": "2025-11-24T14:24:08Z",
    "link": "http://arxiv.org/pdf/2511.19156v1.pdf",
    "category": [
      "cs.IT",
      "cs.AI",
      "cs.LO"
    ],
    "authors": [
      "Jianfeng Xu",
      "Zeyan Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19155v1",
    "title": "EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based Sleep Stage Prediction",
    "summary": "Sleep stage classification based on electroencephalography (EEG) is fundamental for assessing sleep quality and diagnosing sleep-related disorders. However, most traditional machine learning methods rely heavily on prior knowledge and handcrafted features, while existing deep learning models still struggle to jointly capture fine-grained time-frequency patterns and achieve clinical interpretability. Recently, vision-language models (VLMs) have made significant progress in the medical domain, yet their performance remains constrained when applied to physiological waveform data, especially EEG signals, due to their limited visual understanding and insufficient reasoning capability. To address these challenges, we propose EEG-VLM, a hierarchical vision-language framework that integrates multi-level feature alignment with visually enhanced language-guided reasoning for interpretable EEG-based sleep stage classification. Specifically, a specialized visual enhancement module constructs high-level visual tokens from intermediate-layer features to extract rich semantic representations of EEG images. These tokens are further aligned with low-level CLIP features through a multi-level alignment mechanism, enhancing the VLM's image-processing capability. In addition, a Chain-of-Thought (CoT) reasoning strategy decomposes complex medical inference into interpretable logical steps, effectively simulating expert-like decision-making. Experimental results demonstrate that the proposed method significantly improves both the accuracy and interpretability of VLMs in EEG-based sleep stage classification, showing promising potential for automated and explainable EEG analysis in clinical settings.",
    "published": "2025-11-24T14:23:42Z",
    "updated": "2025-11-24T14:23:42Z",
    "link": "http://arxiv.org/pdf/2511.19155v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Xihe Qiu",
      "Gengchen Ma",
      "Haoyu Wang",
      "Chen Zhan",
      "Xiaoyu Tan",
      "Shuo Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.16822v2",
    "title": "ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification",
    "summary": "Coral reefs are rapidly declining due to anthropogenic pressures such as climate change, underscoring the urgent need for scalable, automated monitoring. We introduce ReefNet, a large public coral reef image dataset with point-label annotations mapped to the World Register of Marine Species (WoRMS). ReefNet aggregates imagery from 76 curated CoralNet sources and an additional site from Al Wajh in the Red Sea, totaling approximately 925000 genus-level hard coral annotations with expert-verified labels. Unlike prior datasets, which are often limited by size, geography, or coarse labels and are not ML-ready, ReefNet offers fine-grained, taxonomically mapped labels at a global scale to WoRMS. We propose two evaluation settings: (i) a within-source benchmark that partitions each source's images for localized evaluation, and (ii) a cross-source benchmark that withholds entire sources to test domain generalization. We analyze both supervised and zero-shot classification performance on ReefNet and find that while supervised within-source performance is promising, supervised performance drops sharply across domains, and performance is low across the board for zero-shot models, especially for rare and visually similar genera. This provides a challenging benchmark intended to catalyze advances in domain generalization and fine-grained coral classification. We will release our dataset, benchmarking code, and pretrained models to advance robust, domain-adaptive, global coral reef monitoring and conservation.",
    "published": "2025-10-19T13:18:44Z",
    "updated": "2025-11-24T14:18:04Z",
    "link": "http://arxiv.org/pdf/2510.16822v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yahia Battach",
      "Abdulwahab Felemban",
      "Faizan Farooq Khan",
      "Yousef A. Radwan",
      "Xiang Li",
      "Fabio Marchese",
      "Sara Beery",
      "Burton H. Jones",
      "Francesca Benzoni",
      "Mohamed Elhoseiny"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19149v1",
    "title": "From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation",
    "summary": "This paper introduces the retrieval-augmented framework for automatic fashion caption and hashtag generation, combining multi-garment detection, attribute reasoning, and Large Language Model (LLM) prompting. The system aims to produce visually grounded, descriptive, and stylistically interesting text for fashion imagery, overcoming the limitations of end-to-end captioners that have problems with attribute fidelity and domain generalization. The pipeline combines a YOLO-based detector for multi-garment localization, k-means clustering for dominant color extraction, and a CLIP-FAISS retrieval module for fabric and gender attribute inference based on a structured product index. These attributes, together with retrieved style examples, create a factual evidence pack that is used to guide an LLM to generate human-like captions and contextually rich hashtags. A fine-tuned BLIP model is used as a supervised baseline model for comparison. Experimental results show that the YOLO detector is able to obtain a mean Average Precision (mAP@0.5) of 0.71 for nine categories of garments. The RAG-LLM pipeline generates expressive attribute-aligned captions and achieves mean attribute coverage of 0.80 with full coverage at the 50% threshold in hashtag generation, whereas BLIP gives higher lexical overlap and lower generalization. The retrieval-augmented approach exhibits better factual grounding, less hallucination, and great potential for scalable deployment in various clothing domains. These results demonstrate the use of retrieval-augmented generation as an effective and interpretable paradigm for automated and visually grounded fashion content generation.",
    "published": "2025-11-24T14:13:57Z",
    "updated": "2025-11-24T14:13:57Z",
    "link": "http://arxiv.org/pdf/2511.19149v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Moazzam Umer Gondal",
      "Hamad Ul Qudous",
      "Daniya Siddiqui",
      "Asma Ahmad Farhan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.07078v4",
    "title": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?",
    "summary": "Large Language Models (LLMs) have recently been leveraged for asset pricing tasks and stock trading applications, enabling AI agents to generate investment decisions from unstructured financial data. However, most evaluations of LLM timing-based investing strategies are conducted on narrow timeframes and limited stock universes, overstating effectiveness due to survivorship and data-snooping biases. We critically assess their generalizability and robustness by proposing FINSABER, a backtesting framework evaluating timing-based strategies across longer periods and a larger universe of symbols. Systematic backtests over two decades and 100+ symbols reveal that previously reported LLM advantages deteriorate significantly under broader cross-section and over a longer-term evaluation. Our market regime analysis further demonstrates that LLM strategies are overly conservative in bull markets, underperforming passive benchmarks, and overly aggressive in bear markets, incurring heavy losses. These findings highlight the need to develop LLM strategies that are able to prioritise trend detection and regime-aware risk controls over mere scaling of framework complexity.",
    "published": "2025-05-11T18:02:21Z",
    "updated": "2025-11-24T14:03:22Z",
    "link": "http://arxiv.org/pdf/2505.07078v4.pdf",
    "category": [
      "q-fin.TR",
      "cs.AI",
      "cs.CE"
    ],
    "authors": [
      "Weixian Waylon Li",
      "Hyeonjun Kim",
      "Mihai Cucuringu",
      "Tiejun Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19124v1",
    "title": "Uncertainty-Aware Deep Learning Framework for Remaining Useful Life Prediction in Turbofan Engines with Learned Aleatoric Uncertainty",
    "summary": "Accurate Remaining Useful Life (RUL) prediction coupled with uncertainty quantification remains a critical challenge in aerospace prognostics. This research introduces a novel uncertainty-aware deep learning framework that learns aleatoric uncertainty directly through probabilistic modeling, an approach unexplored in existing CMAPSS-based literature. Our hierarchical architecture integrates multi-scale Inception blocks for temporal pattern extraction, bidirectional Long Short-Term Memory networks for sequential modeling, and a dual-level attention mechanism operating simultaneously on sensor and temporal dimensions. The innovation lies in the Bayesian output layer that predicts both mean RUL and variance, enabling the model to learn data-inherent uncertainty. Comprehensive preprocessing employs condition-aware clustering, wavelet denoising, and intelligent feature selection. Experimental validation on NASA CMAPSS benchmarks (FD001-FD004) demonstrates competitive overall performance with RMSE values of 16.22, 19.29, 16.84, and 19.98 respectively. Remarkably, our framework achieves breakthrough critical zone performance (RUL <= 30 cycles) with RMSE of 5.14, 6.89, 5.27, and 7.16, representing 25-40 percent improvements over conventional approaches and establishing new benchmarks for safety-critical predictions. The learned uncertainty provides well-calibrated 95 percent confidence intervals with coverage ranging from 93.5 percent to 95.2 percent, enabling risk-aware maintenance scheduling previously unattainable in CMAPSS literature.",
    "published": "2025-11-24T13:53:31Z",
    "updated": "2025-11-24T13:53:31Z",
    "link": "http://arxiv.org/pdf/2511.19124v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Krishang Sharma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19120v1",
    "title": "On the Optimality of Discrete Object Naming: a Kinship Case Study",
    "summary": "The structure of naming systems in natural languages hinges on a trade-off between high informativeness and low complexity. Prior work capitalizes on information theory to formalize these notions; however, these studies generally rely on two simplifications: (i) optimal listeners, and (ii) universal communicative need across languages. Here, we address these limitations by introducing an information-theoretic framework for discrete object naming systems, and we use it to prove that an optimal trade-off is achievable if and only if the listener's decoder is equivalent to the Bayesian decoder of the speaker. Adopting a referential game setup from emergent communication, and focusing on the semantic domain of kinship, we show that our notion of optimality is not only theoretically achievable but also emerges empirically in learned communication systems.",
    "published": "2025-11-24T13:49:31Z",
    "updated": "2025-11-24T13:49:31Z",
    "link": "http://arxiv.org/pdf/2511.19120v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Phong Le",
      "Mees Lindeman",
      "Raquel G. Alhama"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19115v1",
    "title": "AI Consciousness and Existential Risk",
    "summary": "In AI, the existential risk denotes the hypothetical threat posed by an artificial system that would possess both the capability and the objective, either directly or indirectly, to eradicate humanity. This issue is gaining prominence in scientific debate due to recent technical advancements and increased media coverage. In parallel, AI progress has sparked speculation and studies about the potential emergence of artificial consciousness. The two questions, AI consciousness and existential risk, are sometimes conflated, as if the former entailed the latter. Here, I explain that this view stems from a common confusion between consciousness and intelligence. Yet these two properties are empirically and theoretically distinct. Arguably, while intelligence is a direct predictor of an AI system's existential threat, consciousness is not. There are, however, certain incidental scenarios in which consciousness could influence existential risk, in either direction. Consciousness could be viewed as a means towards AI alignment, thereby lowering existential risk; or, it could be a precondition for reaching certain capabilities or levels of intelligence, and thus positively related to existential risk. Recognizing these distinctions can help AI safety researchers and public policymakers focus on the most pressing issues.",
    "published": "2025-11-24T13:48:02Z",
    "updated": "2025-11-24T13:48:02Z",
    "link": "http://arxiv.org/pdf/2511.19115v1.pdf",
    "category": [
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Rufin VanRullen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19114v1",
    "title": "Physics-informed Neural Operator Learning for Nonlinear Grad-Shafranov Equation",
    "summary": "As artificial intelligence emerges as a transformative enabler for fusion energy commercialization, fast and accurate solvers become increasingly critical. In magnetic confinement nuclear fusion, rapid and accurate solution of the Grad-Shafranov equation (GSE) is essential for real-time plasma control and analysis. Traditional numerical solvers achieve high precision but are computationally prohibitive, while data-driven surrogates infer quickly but fail to enforce physical laws and generalize poorly beyond training distributions. To address this challenge, we present a Physics-Informed Neural Operator (PINO) that directly learns the GSE solution operator, mapping shape parameters of last closed flux surface to equilibrium solutions for realistic nonlinear current profiles. Comprehensive benchmarking of five neural architectures identifies the novel Transformer-KAN (Kolmogorov-Arnold Network) Neural Operator (TKNO) as achieving highest accuracy (0.25% mean L2 relative error) under supervised training (only data-driven). However, all data-driven models exhibit large physics residuals, indicating poor physical consistency. Our unsupervised training can reduce the residuals by nearly four orders of magnitude through embedding physics-based loss terms without labeled data. Critically, semi-supervised learning--integrating sparse labeled data (100 interior points) with physics constraints--achieves optimal balance: 0.48% interpolation error and the most robust extrapolation performance (4.76% error, 8.9x degradation factor vs 39.8x for supervised models). Accelerated by TensorRT optimization, our models enable millisecond-level inference, establishing PINO as a promising pathway for next-generation fusion control systems.",
    "published": "2025-11-24T13:46:38Z",
    "updated": "2025-11-24T13:46:38Z",
    "link": "http://arxiv.org/pdf/2511.19114v1.pdf",
    "category": [
      "physics.plasm-ph",
      "cs.AI"
    ],
    "authors": [
      "Siqi Ding",
      "Zitong Zhang",
      "Guoyang Shi",
      "Xingyu Li",
      "Xiang Gu",
      "Yanan Xu",
      "Huasheng Xie",
      "Hanyue Zhao",
      "Yuejiang Shi",
      "Tianyuan Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.18670v3",
    "title": "MoveGPT: Scaling Mobility Foundation Models with Spatially-Aware Mixture of Experts",
    "summary": "The success of foundation models in language has inspired a new wave of general-purpose models for human mobility. However, existing approaches struggle to scale effectively due to two fundamental limitations: a failure to use meaningful basic units to represent movement, and an inability to capture the vast diversity of patterns found in large-scale data. In this work, we develop MoveGPT, a large-scale foundation model specifically architected to overcome these barriers. MoveGPT is built upon two key innovations: (1) a unified location encoder that maps geographically disjoint locations into a shared semantic space, enabling pre-training on a global scale; and (2) a Spatially-Aware Mixture-of-Experts Transformer that develops specialized experts to efficiently capture diverse mobility patterns. Pre-trained on billion-scale datasets, MoveGPT establishes a new state-of-the-art across a wide range of downstream tasks, achieving performance gains of up to 35% on average. It also demonstrates strong generalization capabilities to unseen cities. Crucially, our work provides empirical evidence of scaling ability in human mobility, validating a clear path toward building increasingly capable foundation models in this domain.",
    "published": "2025-05-24T12:17:47Z",
    "updated": "2025-11-24T13:44:50Z",
    "link": "http://arxiv.org/pdf/2505.18670v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Chonghua Han",
      "Yuan Yuan",
      "Jingtao Ding",
      "Jie Feng",
      "Fanjin Meng",
      "Yong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19107v1",
    "title": "The Core in Max-Loss Non-Centroid Clustering Can Be Empty",
    "summary": "We study core stability in non-centroid clustering under the max-loss objective, where each agent's loss is the maximum distance to other members of their cluster. We prove that for all $k\\geq 3$ there exist metric instances with $n\\ge 9$ agents, with $n$ divisible by $k$, for which no clustering lies in the $α$-core for any $α<2^{\\frac{1}{5}}\\sim 1.148$. The bound is tight for our construction. Using a computer-aided proof, we also identify a two-dimensional Euclidean point set whose associated lower bound is slightly smaller than that of our general construction. This is, to our knowledge, the first impossibility result showing that the core can be empty in non-centroid clustering under the max-loss objective.",
    "published": "2025-11-24T13:42:43Z",
    "updated": "2025-11-24T13:42:43Z",
    "link": "http://arxiv.org/pdf/2511.19107v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "stat.ML"
    ],
    "authors": [
      "Robert Bredereck",
      "Eva Deltl",
      "Leon Kellerhals",
      "Jannik Peters"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19100v1",
    "title": "Extracting Robust Register Automata from Neural Networks over Data Sequences",
    "summary": "Automata extraction is a method for synthesising interpretable surrogates for black-box neural models that can be analysed symbolically. Existing techniques assume a finite input alphabet, and thus are not directly applicable to data sequences drawn from continuous domains. We address this challenge with deterministic register automata (DRAs), which extend finite automata with registers that store and compare numeric values. Our main contribution is a framework for robust DRA extraction from black-box models: we develop a polynomial-time robustness checker for DRAs with a fixed number of registers, and combine it with passive and active automata learning algorithms. This combination yields surrogate DRAs with statistical robustness and equivalence guarantees. As a key application, we use the extracted automata to assess the robustness of neural networks: for a given sequence and distance metric, the DRA either certifies local robustness or produces a concrete counterexample. Experiments on recurrent neural networks and transformer architectures show that our framework reliably learns accurate automata and enables principled robustness evaluation. Overall, our results demonstrate that robust DRA extraction effectively bridges neural network interpretability and formal reasoning without requiring white-box access to the underlying network.",
    "published": "2025-11-24T13:36:45Z",
    "updated": "2025-11-24T13:36:45Z",
    "link": "http://arxiv.org/pdf/2511.19100v1.pdf",
    "category": [
      "cs.AI",
      "cs.FL",
      "cs.LG"
    ],
    "authors": [
      "Chih-Duo Hong",
      "Hongjian Jiang",
      "Anthony W. Lin",
      "Oliver Markgraf",
      "Julian Parsert",
      "Tony Tan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19087v1",
    "title": "EnfoPath: Energy-Informed Analysis of Generative Trajectories in Flow Matching",
    "summary": "Flow-based generative models synthesize data by integrating a learned velocity field from a reference distribution to the target data distribution. Prior work has focused on endpoint metrics (e.g., fidelity, likelihood, perceptual quality) while overlooking a deeper question: what do the sampling trajectories reveal? Motivated by classical mechanics, we introduce kinetic path energy (KPE), a simple yet powerful diagnostic that quantifies the total kinetic effort along each generation path of ODE-based samplers. Through comprehensive experiments on CIFAR-10 and ImageNet-256, we uncover two key phenomena: ({i}) higher KPE predicts stronger semantic quality, indicating that semantically richer samples require greater kinetic effort, and ({ii}) higher KPE inversely correlates with data density, with informative samples residing in sparse, low-density regions. Together, these findings reveal that semantically informative samples naturally reside on the sparse frontier of the data distribution, demanding greater generative effort. Our results suggest that trajectory-level analysis offers a physics-inspired and interpretable framework for understanding generation difficulty and sample characteristics.",
    "published": "2025-11-24T13:27:41Z",
    "updated": "2025-11-24T13:27:41Z",
    "link": "http://arxiv.org/pdf/2511.19087v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Ziyun Li",
      "Ben Dai",
      "Huancheng Hu",
      "Henrik Boström",
      "Soon Hoe Lim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19078v1",
    "title": "GraphMind: Theorem Selection and Conclusion Generation Framework with Dynamic GNN for LLM Reasoning",
    "summary": "Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, including multi-step reasoning such as mathematical proving. However, existing approaches often lack an explicit and dynamic mechanism to structurally represent and evolve intermediate reasoning states, which limits their ability to perform context-aware theorem selection and iterative conclusion generation. To address these challenges, we propose GraphMind, a novel dynamic graph-based framework that integrates the graph neural network (GNN) with LLMs to iteratively select theorems and generate intermediate conclusions for multi-step reasoning. Our method models the reasoning process as a heterogeneous evolving graph, where nodes represent conditions, theorems, and conclusions, while edges capture logical dependencies between nodes. By encoding the current reasoning state with GNN and leveraging semantic matching for theorem selection, our framework enables context-aware, interpretable, and structured reasoning in a closed-loop manner. Experiments on various question-answering (QA) datasets demonstrate that our proposed GraphMind method achieves consistent performance improvements and significantly outperforms existing baselines in multi-step reasoning, validating the effectiveness and generalizability of our approach.",
    "published": "2025-11-24T13:18:21Z",
    "updated": "2025-11-24T13:18:21Z",
    "link": "http://arxiv.org/pdf/2511.19078v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yutong Li",
      "Yitian Zhou",
      "Xudong Wang",
      " GuoChen",
      "Caiyan Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.10510v2",
    "title": "Chat with AI: The Surprising Turn of Real-time Video Communication from Human to AI",
    "summary": "AI Video Chat emerges as a new paradigm for Real-time Communication (RTC), where one peer is not a human, but a Multimodal Large Language Model (MLLM). This makes interaction between humans and AI more intuitive, as if chatting face-to-face with a real person. However, this poses significant challenges to latency, because the MLLM inference takes up most of the response time, leaving very little time for video streaming. Due to network uncertainty, transmission latency becomes a critical bottleneck preventing AI from being like a real person. To address this, we call for AI-oriented RTC research, exploring the network requirement shift from \"humans watching video\" to \"AI understanding video\". We begin by recognizing the main differences between AI Video Chat and traditional RTC. Then, through prototype measurements, we identify that ultra-low bitrate is a key factor for low latency. To reduce bitrate dramatically while maintaining MLLM accuracy, we propose Context-Aware Video Streaming that recognizes the importance of each video region for chat and allocates bitrate almost exclusively to chat-important regions. To evaluate the impact of video streaming quality on MLLM accuracy, we build the first benchmark, named Degraded Video Understanding Benchmark (DeViBench). Finally, we discuss some open questions and ongoing solutions for AI Video Chat. DeViBench is open-sourced at: https://github.com/pku-netvideo/DeViBench.",
    "published": "2025-07-14T17:34:49Z",
    "updated": "2025-11-24T13:08:12Z",
    "link": "http://arxiv.org/pdf/2507.10510v2.pdf",
    "category": [
      "cs.NI",
      "cs.AI",
      "cs.HC",
      "cs.MM"
    ],
    "authors": [
      "Jiangkai Wu",
      "Zhiyuan Ren",
      "Liming Liu",
      "Xinggong Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19067v1",
    "title": "DynaMix: Generalizable Person Re-identification via Dynamic Relabeling and Mixed Data Sampling",
    "summary": "Generalizable person re-identification (Re-ID) aims to recognize individuals across unseen cameras and environments. While existing methods rely heavily on limited labeled multi-camera data, we propose DynaMix, a novel method that effectively combines manually labeled multi-camera and large-scale pseudo-labeled single-camera data. Unlike prior works, DynaMix dynamically adapts to the structure and noise of the training data through three core components: (1) a Relabeling Module that refines pseudo-labels of single-camera identities on-the-fly; (2) an Efficient Centroids Module that maintains robust identity representations under a large identity space; and (3) a Data Sampling Module that carefully composes mixed data mini-batches to balance learning complexity and intra-batch diversity. All components are specifically designed to operate efficiently at scale, enabling effective training on millions of images and hundreds of thousands of identities. Extensive experiments demonstrate that DynaMix consistently outperforms state-of-the-art methods in generalizable person Re-ID.",
    "published": "2025-11-24T13:01:32Z",
    "updated": "2025-11-24T13:01:32Z",
    "link": "http://arxiv.org/pdf/2511.19067v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Timur Mamedov",
      "Anton Konushin",
      "Vadim Konushin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19066v1",
    "title": "Mitigating Participation Imbalance Bias in Asynchronous Federated Learning",
    "summary": "In Asynchronous Federated Learning (AFL), the central server immediately updates the global model with each arriving client's contribution. As a result, clients perform their local training on different model versions, causing information staleness (delay). In federated environments with non-IID local data distributions, this asynchronous pattern amplifies the adverse effect of client heterogeneity (due to different data distribution, local objectives, etc.), as faster clients contribute more frequent updates, biasing the global model. We term this phenomenon heterogeneity amplification. Our work provides a theoretical analysis that maps AFL design choices to their resulting error sources when heterogeneity amplification occurs. Guided by our analysis, we propose ACE (All-Client Engagement AFL), which mitigates participation imbalance through immediate, non-buffered updates that use the latest information available from all clients. We also introduce a delay-aware variant, ACED, to balance client diversity against update staleness. Experiments on different models for different tasks across diverse heterogeneity and delay settings validate our analysis and demonstrate the robust performance of our approaches.",
    "published": "2025-11-24T13:01:18Z",
    "updated": "2025-11-24T13:01:18Z",
    "link": "http://arxiv.org/pdf/2511.19066v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xiangyu Chang",
      "Manyi Yao",
      "Srikanth V. Krishnamurthy",
      "Christian R. Shelton",
      "Anirban Chakraborty",
      "Ananthram Swami",
      "Samet Oymak",
      "Amit Roy-Chowdhury"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19065v1",
    "title": "Understanding, Accelerating, and Improving MeanFlow Training",
    "summary": "MeanFlow promises high-quality generative modeling in few steps, by jointly learning instantaneous and average velocity fields. Yet, the underlying training dynamics remain unclear. We analyze the interaction between the two velocities and find: (i) well-established instantaneous velocity is a prerequisite for learning average velocity; (ii) learning of instantaneous velocity benefits from average velocity when the temporal gap is small, but degrades as the gap increases; and (iii) task-affinity analysis indicates that smooth learning of large-gap average velocities, essential for one-step generation, depends on the prior formation of accurate instantaneous and small-gap average velocities. Guided by these observations, we design an effective training scheme that accelerates the formation of instantaneous velocity, then shifts emphasis from short- to long-interval average velocity. Our enhanced MeanFlow training yields faster convergence and significantly better few-step generation: With the same DiT-XL backbone, our method reaches an impressive FID of 2.87 on 1-NFE ImageNet 256x256, compared to 3.43 for the conventional MeanFlow baseline. Alternatively, our method matches the performance of the MeanFlow baseline with 2.5x shorter training time, or with a smaller DiT-L backbone.",
    "published": "2025-11-24T12:59:27Z",
    "updated": "2025-11-24T12:59:27Z",
    "link": "http://arxiv.org/pdf/2511.19065v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jin-Young Kim",
      "Hyojun Go",
      "Lea Bogensperger",
      "Julius Erbach",
      "Nikolai Kalischek",
      "Federico Tombari",
      "Konrad Schindler",
      "Dominik Narnhofer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11480v2",
    "title": "Inferring response times of perceptual decisions with Poisson variational autoencoders",
    "summary": "Many properties of perceptual decision making are well-modeled by deep neural networks. However, such architectures typically treat decisions as instantaneous readouts, overlooking the temporal dynamics of the decision process. We present an image-computable model of perceptual decision making in which choices and response times arise from efficient sensory encoding and Bayesian decoding of neural spiking activity. We use a Poisson variational autoencoder to learn unsupervised representations of visual stimuli in a population of rate-coded neurons, modeled as independent homogeneous Poisson processes. A task-optimized decoder then continually infers an approximate posterior over actions conditioned on incoming spiking activity. Combining these components with an entropy-based stopping rule yields a principled and image-computable model of perceptual decisions capable of generating trial-by-trial patterns of choices and response times. Applied to MNIST digit classification, the model reproduces key empirical signatures of perceptual decision making, including stochastic variability, right-skewed response time distributions, logarithmic scaling of response times with the number of alternatives (Hick's law), and speed-accuracy trade-offs.",
    "published": "2025-11-14T16:58:04Z",
    "updated": "2025-11-24T12:53:25Z",
    "link": "http://arxiv.org/pdf/2511.11480v2.pdf",
    "category": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Hayden R. Johnson",
      "Anastasia N. Krouglova",
      "Hadi Vafaii",
      "Jacob L. Yates",
      "Pedro J. Gonçalves"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19055v1",
    "title": "Large Language Model-Assisted Planning of Electric Vehicle Charging Infrastructure with Real-World Case Study",
    "summary": "The growing demand for electric vehicle (EV) charging infrastructure presents significant planning challenges, requiring efficient strategies for investment and operation to deliver cost-effective charging services. However, the potential benefits of EV charging assignment, particularly in response to varying spatial-temporal patterns of charging demand, remain under-explored in infrastructure planning. This paper proposes an integrated approach that jointly optimizes investment decisions and charging assignments while accounting for spatial-temporal demand dynamics and their interdependencies. To support efficient model development, we leverage a large language model (LLM) to assist in generating and refining the mathematical formulation from structured natural-language descriptions, significantly reducing the modeling burden. The resulting optimization model enables optimal joint decision-making for investment and operation. Additionally, we propose a distributed optimization algorithm based on the Alternating Direction Method of Multipliers (ADMM) to address computational complexity in high-dimensional scenarios, which can be executed on standard computing platforms. We validate our approach through a case study using 1.5 million real-world travel records from Chengdu, China, demonstrating a 30% reduction in total cost compared to a baseline without EV assignment.",
    "published": "2025-11-24T12:45:10Z",
    "updated": "2025-11-24T12:45:10Z",
    "link": "http://arxiv.org/pdf/2511.19055v1.pdf",
    "category": [
      "eess.SY",
      "cs.AI",
      "math.OC"
    ],
    "authors": [
      "Xinda Zheng",
      "Canchen Jiang",
      "Hao Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19046v1",
    "title": "MedSAM3: Delving into Segment Anything with Medical Concepts",
    "summary": "Medical image segmentation is fundamental for biomedical discovery. Existing methods lack generalizability and demand extensive, time-consuming manual annotation for new clinical application. Here, we propose MedSAM-3, a text promptable medical segmentation model for medical image and video segmentation. By fine-tuning the Segment Anything Model (SAM) 3 architecture on medical images paired with semantic conceptual labels, our MedSAM-3 enables medical Promptable Concept Segmentation (PCS), allowing precise targeting of anatomical structures via open-vocabulary text descriptions rather than solely geometric prompts. We further introduce the MedSAM-3 Agent, a framework that integrates Multimodal Large Language Models (MLLMs) to perform complex reasoning and iterative refinement in an agent-in-the-loop workflow. Comprehensive experiments across diverse medical imaging modalities, including X-ray, MRI, Ultrasound, CT, and video, demonstrate that our approach significantly outperforms existing specialist and foundation models. We will release our code and model at https://github.com/Joey-S-Liu/MedSAM3.",
    "published": "2025-11-24T12:34:38Z",
    "updated": "2025-11-24T12:34:38Z",
    "link": "http://arxiv.org/pdf/2511.19046v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Anglin Liu",
      "Rundong Xue",
      "Xu R. Cao",
      "Yifan Shen",
      "Yi Lu",
      "Xiang Li",
      "Qianqian Chen",
      "Jintai Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19035v1",
    "title": "CSD: Change Semantic Detection with only Semantic Change Masks for Damage Assessment in Conflict Zones",
    "summary": "Accurately and swiftly assessing damage from conflicts is crucial for humanitarian aid and regional stability. In conflict zones, damaged zones often share similar architectural styles, with damage typically covering small areas and exhibiting blurred boundaries. These characteristics lead to limited data, annotation difficulties, and significant recognition challenges, including high intra-class similarity and ambiguous semantic changes. To address these issues, we introduce a pre-trained DINOv3 model and propose a multi-scale cross-attention difference siamese network (MC-DiSNet). The powerful visual representation capability of the DINOv3 backbone enables robust and rich feature extraction from bi-temporal remote sensing images. We also release a new Gaza-change dataset containing high-resolution satellite image pairs from 2023-2024 with pixel-level semantic change annotations. It is worth emphasizing that our annotations only include semantic pixels of changed areas. Unlike conventional semantic change detection (SCD), our approach eliminates the need for large-scale semantic annotations of bi-temporal images, instead focusing directly on the changed regions. We term this new task change semantic detection (CSD). The CSD task represents a direct extension of binary change detection (BCD). Due to the limited spatial extent of semantic regions, it presents greater challenges than traditional SCD tasks. We evaluated our method under the CSD framework on both the Gaza-Change and SECOND datasets. Experimental results demonstrate that our proposed approach effectively addresses the CSD task, and its outstanding performance paves the way for practical applications in rapid damage assessment across conflict zones.",
    "published": "2025-11-24T12:16:21Z",
    "updated": "2025-11-24T12:16:21Z",
    "link": "http://arxiv.org/pdf/2511.19035v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Kai Zhenga",
      "Zhenkai Wu",
      "Fupeng Wei",
      "Miaolan Zhou",
      "Kai Lie",
      "Haitao Guo",
      "Lei Ding",
      "Wei Zhang",
      "Hang-Cheng Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19024v1",
    "title": "Life-IQA: Boosting Blind Image Quality Assessment through GCN-enhanced Layer Interaction and MoE-based Feature Decoupling",
    "summary": "Blind image quality assessment (BIQA) plays a crucial role in evaluating and optimizing visual experience. Most existing BIQA approaches fuse shallow and deep features extracted from backbone networks, while overlooking the unequal contributions to quality prediction. Moreover, while various vision encoder backbones are widely adopted in BIQA, the effective quality decoding architectures remain underexplored. To address these limitations, this paper investigates the contributions of shallow and deep features to BIQA, and proposes a effective quality feature decoding framework via GCN-enhanced \\underline{l}ayer\\underline{i}nteraction and MoE-based \\underline{f}eature d\\underline{e}coupling, termed \\textbf{(Life-IQA)}. Specifically, the GCN-enhanced layer interaction module utilizes the GCN-enhanced deepest-layer features as query and the penultimate-layer features as key, value, then performs cross-attention to achieve feature interaction. Moreover, a MoE-based feature decoupling module is proposed to decouple fused representations though different experts specialized for specific distortion types or quality dimensions. Extensive experiments demonstrate that Life-IQA shows more favorable balance between accuracy and cost than a vanilla Transformer decoder and achieves state-of-the-art performance on multiple BIQA benchmarks.The code is available at: \\href{https://github.com/TANGLONG2/Life-IQA/tree/main}{\\texttt{Life-IQA}}.",
    "published": "2025-11-24T11:59:55Z",
    "updated": "2025-11-24T11:59:55Z",
    "link": "http://arxiv.org/pdf/2511.19024v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Long Tang",
      "Guoquan Zhen",
      "Jie Hao",
      "Jianbo Zhang",
      "Huiyu Duan",
      "Liang Yuan",
      "Guangtao Zhai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19023v1",
    "title": "OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs",
    "summary": "Preference learning has recently emerged as a pivotal strategy for post-training alignment of Multimodal Large Language Models (MLLMs). However, existing approaches predominantly rely on external human-annotated preference data, which is costly and labor-intensive to collect. In this work, we propose OrdMoE, a novel preference alignment framework that bypasses the reliance on external human preferences entirely by leveraging intrinsic signals within Mixture-of-Experts (MoE) architectures. Specifically, we observe that the router's expert selection scores implicitly encode a quality-aware ranking of responses (i.e. higher-scoring experts consistently generate higher-quality outputs). Building on this insight, OrdMoE constructs an internal preference hierarchy by grouping experts into ranked tiers based on their per-token routing scores and activating each tier separately to produce a sequence of responses with increasing quality. This yields a zero-cost, self-supervised preference ordering over generated responses, which can be directly optimized using standard preference learning objectives. Extensive experiments across multiple multimodal benchmarks demnstrate that OrdMoE significantly enhances both alignment and overall performance of multimodal Mixture-of-Experts LLMs, achieving competitive results without requiring any human-annotated preference data.",
    "published": "2025-11-24T11:59:31Z",
    "updated": "2025-11-24T11:59:31Z",
    "link": "http://arxiv.org/pdf/2511.19023v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yuting Gao",
      "Weihao Chen",
      "Lan Wang",
      "Ruihan Xu",
      "Qingpei Guo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.06345v2",
    "title": "PRAGMA: A Profiling-Reasoned Multi-Agent Framework for Automatic Kernel Optimization",
    "summary": "Designing high-performance kernels requires expert-level tuning and a deep understanding of hardware characteristics. Recent advances in large language models (LLMs) have enabled automated kernel generation, yet most existing systems rely solely on correctness or execution time feedback, lacking the ability to reason about low-level performance bottlenecks. In this paper, we introduce PRAGMA, a profile-guided AI kernel generation framework that integrates execution feedback and fine-grained hardware profiling into the reasoning loop. PRAGMA enables LLMs to identify performance bottlenecks, preserve historical best versions, and iteratively refine code quality. We evaluate PRAGMA on KernelBench, covering GPU and CPU backends. Results show that PRAGMA consistently outperforms baseline AIKG without profiling enabled and achieves 2.81$\\times$ and 2.30$\\times$ averaged speedups against Torch on CPU and GPU platforms, respectively.",
    "published": "2025-11-09T12:01:43Z",
    "updated": "2025-11-24T11:46:50Z",
    "link": "http://arxiv.org/pdf/2511.06345v2.pdf",
    "category": [
      "cs.DC",
      "cs.AI"
    ],
    "authors": [
      "Kelun Lei",
      "Hailong Yang",
      "Huaitao Zhang",
      "Xin You",
      "Kaige Zhang",
      "Zhongzhi Luan",
      "Yi Liu",
      "Depei Qian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.06852v4",
    "title": "Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment",
    "summary": "Safety alignment instills in Large Language Models (LLMs) a critical capacity to refuse malicious requests. Prior works have modeled this refusal mechanism as a single linear direction in the activation space. We posit that this is an oversimplification that conflates two functionally distinct neural processes: the detection of harm and the execution of a refusal. In this work, we deconstruct this single representation into a Harm Detection Direction and a Refusal Execution Direction. Leveraging this fine-grained model, we introduce Differentiated Bi-Directional Intervention (DBDI), a new white-box framework that precisely neutralizes the safety alignment at critical layer. DBDI applies adaptive projection nullification to the refusal execution direction while suppressing the harm detection direction via direct steering. Extensive experiments demonstrate that DBDI outperforms prominent jailbreaking methods, achieving up to a 97.88\\% attack success rate on models such as Llama-2. By providing a more granular and mechanistic framework, our work offers a new direction for the in-depth understanding of LLM safety alignment.",
    "published": "2025-11-10T08:52:34Z",
    "updated": "2025-11-24T11:44:59Z",
    "link": "http://arxiv.org/pdf/2511.06852v4.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "authors": [
      "Peng Zhang",
      "Peijie Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19005v1",
    "title": "Introducing Visual Scenes and Reasoning: A More Realistic Benchmark for Spoken Language Understanding",
    "summary": "Spoken Language Understanding (SLU) consists of two sub-tasks: intent detection (ID) and slot filling (SF). Given its broad range of real-world applications, enhancing SLU for practical deployment is increasingly critical. Profile-based SLU addresses ambiguous user utterances by incorporating context awareness (CA), user profiles (UP), and knowledge graphs (KG) to support disambiguation, thereby advancing SLU research toward real-world applicability. However, existing SLU datasets still fall short in representing real-world scenarios. Specifically, (1) CA uses one-hot vectors for representation, which is overly idealized, and (2) models typically focuses solely on predicting intents and slot labels, neglecting the reasoning process that could enhance performance and interpretability. To overcome these limitations, we introduce VRSLU, a novel SLU dataset that integrates both Visual images and explicit Reasoning. For over-idealized CA, we use GPT-4o and FLUX.1-dev to generate images reflecting users' environments and statuses, followed by human verification to ensure quality. For reasoning, GPT-4o is employed to generate explanations for predicted labels, which are then refined by human annotators to ensure accuracy and coherence. Additionally, we propose an instructional template, LR-Instruct, which first predicts labels and then generates corresponding reasoning. This two-step approach helps mitigate the influence of reasoning bias on label prediction. Experimental results confirm the effectiveness of incorporating visual information and highlight the promise of explicit reasoning in advancing SLU.",
    "published": "2025-11-24T11:32:24Z",
    "updated": "2025-11-24T11:32:24Z",
    "link": "http://arxiv.org/pdf/2511.19005v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Di Wu",
      "Liting Jiang",
      "Ruiyu Fang",
      " Bianjing",
      "Hongyan Xie",
      "Haoxiang Su",
      "Hao Huang",
      "Zhongjiang He",
      "Shuangyong Song",
      "Xuelong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18999v1",
    "title": "Enhancing low energy reconstruction and classification in KM3NeT/ORCA with transformers",
    "summary": "The current KM3NeT/ORCA neutrino telescope, still under construction, has not yet reached its full potential in neutrino reconstruction capability. When training any deep learning model, no explicit information about the physics or the detector is provided, thus they remain unknown to the model. This study leverages the strengths of transformers by incorporating attention masks inspired by the physics and detector design, making the model understand both the telescope design and the neutrino physics measured on it. The study also shows the efficacy of transformers on retaining valuable information between detectors when doing fine-tuning from one configurations to another.",
    "published": "2025-11-24T11:25:30Z",
    "updated": "2025-11-24T11:25:30Z",
    "link": "http://arxiv.org/pdf/2511.18999v1.pdf",
    "category": [
      "hep-ex",
      "astro-ph.IM",
      "cs.AI"
    ],
    "authors": [
      "Iván Mozún Mateo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.18337v3",
    "title": "Warm Chat: Diffuse Emotion-aware Interactive Talking Head Avatar with Tree-Structured Guidance",
    "summary": "Generative models have advanced rapidly, enabling impressive talking head generation that brings AI to life. However, most existing methods focus solely on one-way portrait animation. Even the few that support bidirectional conversational interactions lack precise emotion-adaptive capabilities, significantly limiting their practical applicability. In this paper, we propose Warm Chat, a novel emotion-aware talking head generation framework for dyadic interactions. Leveraging the dialogue generation capability of large language models (LLMs, e.g., GPT-4), our method produces temporally consistent virtual avatars with rich emotional variations that seamlessly transition between speaking and listening states. Specifically, we design a Transformer-based head mask generator that learns temporally consistent motion features in a latent mask space, capable of generating arbitrary-length, temporally consistent mask sequences to constrain head motions. Furthermore, we introduce an interactive talking tree structure to represent dialogue state transitions, where each tree node contains information such as child/parent/sibling nodes and the current character's emotional state. By performing reverse-level traversal, we extract rich historical emotional cues from the current node to guide expression synthesis. Extensive experiments demonstrate the superior performance and effectiveness of our method.",
    "published": "2025-08-25T13:07:03Z",
    "updated": "2025-11-24T11:19:05Z",
    "link": "http://arxiv.org/pdf/2508.18337v3.pdf",
    "category": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "authors": [
      "Haijie Yang",
      "Zhenyu Zhang",
      "Hao Tang",
      "Jianjun Qian",
      "Jian Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18992v1",
    "title": "Classification EM-PCA for clustering and embedding",
    "summary": "The mixture model is undoubtedly one of the greatest contributions to clustering. For continuous data, Gaussian models are often used and the Expectation-Maximization (EM) algorithm is particularly suitable for estimating parameters from which clustering is inferred. If these models are particularly popular in various domains including image clustering, they however suffer from the dimensionality and also from the slowness of convergence of the EM algorithm. However, the Classification EM (CEM) algorithm, a classifying version, offers a fast convergence solution while dimensionality reduction still remains a challenge. Thus we propose in this paper an algorithm combining simultaneously and non-sequentially the two tasks --Data embedding and Clustering-- relying on Principal Component Analysis (PCA) and CEM. We demonstrate the interest of such approach in terms of clustering and data embedding. We also establish different connections with other clustering approaches.",
    "published": "2025-11-24T11:18:59Z",
    "updated": "2025-11-24T11:18:59Z",
    "link": "http://arxiv.org/pdf/2511.18992v1.pdf",
    "category": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Zineddine Tighidet",
      "Lazhar Labiod",
      "Mohamed Nadif"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.04363v3",
    "title": "Causally Reliable Concept Bottleneck Models",
    "summary": "Concept-based models are an emerging paradigm in deep learning that constrains the inference process to operate through human-interpretable variables, facilitating explainability and human interaction. However, these architectures, on par with popular opaque neural models, fail to account for the true causal mechanisms underlying the target phenomena represented in the data. This hampers their ability to support causal reasoning tasks, limits out-of-distribution generalization, and hinders the implementation of fairness constraints. To overcome these issues, we propose Causally reliable Concept Bottleneck Models (C$^2$BMs), a class of concept-based architectures that enforce reasoning through a bottleneck of concepts structured according to a model of the real-world causal mechanisms. We also introduce a pipeline to automatically learn this structure from observational data and unstructured background knowledge (e.g., scientific literature). Experimental evidence suggests that C$^2$BMs are more interpretable, causally reliable, and improve responsiveness to interventions w.r.t. standard opaque and concept-based models, while maintaining their accuracy.",
    "published": "2025-03-06T12:06:54Z",
    "updated": "2025-11-24T11:18:03Z",
    "link": "http://arxiv.org/pdf/2503.04363v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Giovanni De Felice",
      "Arianna Casanova Flores",
      "Francesco De Santis",
      "Silvia Santini",
      "Johannes Schneider",
      "Pietro Barbiero",
      "Alberto Termine"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18989v1",
    "title": "Rethinking Plant Disease Diagnosis: Bridging the Academic-Practical Gap with Vision Transformers and Zero-Shot Learning",
    "summary": "Recent advances in deep learning have enabled significant progress in plant disease classification using leaf images. Much of the existing research in this field has relied on the PlantVillage dataset, which consists of well-centered plant images captured against uniform, uncluttered backgrounds. Although models trained on this dataset achieve high accuracy, they often fail to generalize to real-world field images, such as those submitted by farmers to plant diagnostic systems. This has created a significant gap between published studies and practical application requirements, highlighting the necessity of investigating and addressing this issue. In this study, we investigate whether attention-based architectures and zero-shot learning approaches can bridge the gap between curated academic datasets and real-world agricultural conditions in plant disease classification. We evaluate three model categories: Convolutional Neural Networks (CNNs), Vision Transformers, and Contrastive Language-Image Pre-training (CLIP)-based zero-shot models. While CNNs exhibit limited robustness under domain shift, Vision Transformers demonstrate stronger generalization by capturing global contextual features. Most notably, CLIP models classify diseases directly from natural language descriptions without any task-specific training, offering strong adaptability and interpretability. These findings highlight the potential of zero-shot learning as a practical and scalable domain adaptation strategy for plant health diagnosis in diverse field environments.",
    "published": "2025-11-24T11:08:01Z",
    "updated": "2025-11-24T11:08:01Z",
    "link": "http://arxiv.org/pdf/2511.18989v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Wassim Benabbas",
      "Mohammed Brahimi",
      "Samir Akhrouf",
      "Bilal Fortas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.12104v4",
    "title": "Teacher Encoder-Student Decoder Denoising Guided Segmentation Network for Anomaly Detection",
    "summary": "Visual anomaly detection is a highly challenging task, often categorized as a one-class classification and segmentation problem. Recent studies have demonstrated that the student-teacher (S-T) framework effectively addresses this challenge. However, most S-T frameworks rely solely on pre-trained teacher networks to guide student networks in learning multi-scale similar features, overlooking the potential of the student networks to enhance learning through multi-scale feature fusion. In this study, we propose a novel model named PFADSeg, which integrates a pre-trained teacher network, a denoising student network with multi-scale feature fusion, and a guided anomaly segmentation network into a unified framework. By adopting a unique teacher-encoder and student-decoder denoising mode, the model improves the student network's ability to learn from teacher network features. Furthermore, an adaptive feature fusion mechanism is introduced to train a self-supervised segmentation network that synthesizes anomaly masks autonomously, significantly increasing detection performance. Rigorous evaluations on the widely-used MVTec AD dataset demonstrate that PFADSeg exhibits excellent performance, achieving an image-level AUC of 98.9%, a pixel-level mean precision of 76.4%, and an instance-level mean precision of 78.7%.",
    "published": "2025-01-21T12:55:04Z",
    "updated": "2025-11-24T11:06:07Z",
    "link": "http://arxiv.org/pdf/2501.12104v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Shixuan Song",
      "Hao Chen",
      "Shu Hu",
      "Xin Wang",
      "Jinrong Hu",
      "Xi Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18987v1",
    "title": "Dynamic Mixture of Experts Against Severe Distribution Shifts",
    "summary": "The challenge of building neural networks that can continuously learn and adapt to evolving data streams is central to the fields of continual learning (CL) and reinforcement learning (RL). This lifelong learning problem is often framed in terms of the plasticity-stability dilemma, focusing on issues like loss of plasticity and catastrophic forgetting. Unlike neural networks, biological brains maintain plasticity through capacity growth, inspiring researchers to explore similar approaches in artificial networks, such as adding capacity dynamically. Prior solutions often lack parameter efficiency or depend on explicit task indices, but Mixture-of-Experts (MoE) architectures offer a promising alternative by specializing experts for distinct distributions. This paper aims to evaluate a DynamicMoE approach for continual and reinforcement learning environments and benchmark its effectiveness against existing network expansion methods.",
    "published": "2025-11-24T11:00:32Z",
    "updated": "2025-11-24T11:00:32Z",
    "link": "http://arxiv.org/pdf/2511.18987v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Donghu Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.09782v2",
    "title": "Q-SAM2: Accurate Quantization for Segment Anything Model 2",
    "summary": "The Segment Anything Model 2 (SAM2) is a powerful foundation model for promptable segmentation. However, its high computational and memory costs are a major barrier to deployment on resource-constrained devices. In this paper, we present Q-SAM2, an accurate low-bit quantization method that achieves high compression and high fidelity. To address performance degradation arising from challenging weight and activation distributions during quantization, Q-SAM2 introduces two novel contributions: Variance-Reduced Calibration (VRC), an initialization method that reduces weight statistical variance by minimizing the Frobenius norm over a small calibration batch; and Learnable Statistical Clipping (LSC), a Quantization-Aware Training (QAT) method that learns momentum-stabilized clipping factors to manage outliers in weights and activations. Comprehensive experiments demonstrate that Q-SAM2 achieves highly accurate inference with substantial efficiency gains, significantly surpassing state-of-the-art general QAT schemes, particularly in the ultra-low 2-bit regime. Specifically, Q-SAM2 achieves an accuracy gain of up to 9.7 ppt in J&F on the video segmentation benchmark and 7.3 ppt in mIoU for instance segmentation over the best competing QAT model, all while achieving an 8x reduction in model size compared to the BF16 baseline.",
    "published": "2025-06-11T14:21:38Z",
    "updated": "2025-11-24T10:55:38Z",
    "link": "http://arxiv.org/pdf/2506.09782v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Nicola Farronato",
      "Florian Scheidegger",
      "Mattia Rigotti",
      "Cristiano Malossi",
      "Michele Magno",
      "Haotong Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18980v1",
    "title": "MOCLIP: A Foundation Model for Large-Scale Nanophotonic Inverse Design",
    "summary": "Foundation models (FM) are transforming artificial intelligence by enabling generalizable, data-efficient solutions across different domains for a broad range of applications. However, the lack of large and diverse datasets limits the development of FM in nanophotonics. This work presents MOCLIP (Metasurface Optics Contrastive Learning Pretrained), a nanophotonic foundation model that integrates metasurface geometry and spectra within a shared latent space. MOCLIP employs contrastive learning to align geometry and spectral representations using an experimentally acquired dataset with a sample density comparable to ImageNet-1K. The study demonstrates MOCLIP inverse design capabilities for high-throughput zero-shot prediction at a rate of 0.2 million samples per second, enabling the design of a full 4-inch wafer populated with high-density metasurfaces in minutes. It also shows generative latent-space optimization reaching 97 percent accuracy. Finally, we introduce an optical information storage concept that uses MOCLIP to achieve a density of 0.1 Gbit per square millimeter at the resolution limit, exceeding commercial optical media by a factor of six. These results position MOCLIP as a scalable and versatile platform for next-generation photonic design and data-driven applications.",
    "published": "2025-11-24T10:54:19Z",
    "updated": "2025-11-24T10:54:19Z",
    "link": "http://arxiv.org/pdf/2511.18980v1.pdf",
    "category": [
      "physics.optics",
      "cs.AI"
    ],
    "authors": [
      "S. Rodionov",
      "A. Burguete-Lopez",
      "M. Makarenko",
      "Q. Wang",
      "F. Getman",
      "A. Fratalocchi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.18662v2",
    "title": "M2R2: MultiModal Robotic Representation for Temporal Action Segmentation",
    "summary": "Temporal action segmentation (TAS) has long been a key area of research in both robotics and computer vision. In robotics, algorithms have primarily focused on leveraging proprioceptive information to determine skill boundaries, with recent approaches in surgical robotics incorporating vision. In contrast, computer vision typically relies on exteroceptive sensors, such as cameras. Existing multimodal TAS models in robotics integrate feature fusion within the model, making it difficult to reuse learned features across different models. Meanwhile, pretrained vision-only feature extractors commonly used in computer vision struggle in scenarios with limited object visibility. In this work, we address these challenges by proposing M2R2, a multimodal feature extractor tailored for TAS, which combines information from both proprioceptive and exteroceptive sensors. We introduce a novel pretraining strategy that enables the reuse of learned features across multiple TAS models. Our method achieves state-of-the-art performance on the REASSEMBLE dataset, a challenging multimodal robotic assembly dataset, outperforming existing robotic action segmentation models by 46.6%. Additionally, we conduct an extensive ablation study to evaluate the contribution of different modalities in robotic TAS tasks.",
    "published": "2025-04-25T19:36:17Z",
    "updated": "2025-11-24T10:52:11Z",
    "link": "http://arxiv.org/pdf/2504.18662v2.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Daniel Sliwowski",
      "Dongheui Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18977v1",
    "title": "FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning",
    "summary": "Pruning is an effective method for compressing Large Language Models, but finding an optimal, non-uniform layer-wise sparsity allocation remains a key challenge. While heuristic methods are fast but yield suboptimal performance, more powerful search-based approaches like Reinforcement Learning are often hindered by prohibitive computational costs on large-scale models. To overcome this efficiency barrier, we propose FastForward Pruning. Its core is a decoupled, single-step RL framework that separates policy optimization from the complex budget satisfaction problem. Such a decoupling is crucial for efficiently searching the vast policy space of LLMs. This curriculum-based strategy begins with low-cost, simple tasks and gradually increases in complexity, significantly reducing the search's computational overhead. Evaluated on the LLaMA, Mistral, and OPT model families, our framework discovers pruning policies that achieve superior performance over strong heuristic baselines. Crucially, when compared to other search-based algorithms, our method achieves competitive or superior results at a fraction of the computational cost, demonstrating a clear advantage in search efficiency.",
    "published": "2025-11-24T10:47:55Z",
    "updated": "2025-11-24T10:47:55Z",
    "link": "http://arxiv.org/pdf/2511.18977v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Xin Yuan",
      "Siqi Li",
      "Jiateng Wei",
      "Chengrui Zhu",
      "Yanming Wu",
      "Qingpeng Li",
      "Jiajun Lv",
      "Xiaoke Lan",
      "Jun Chen",
      "Yong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17421v2",
    "title": "Preventing Shortcut Learning in Medical Image Analysis through Intermediate Layer Knowledge Distillation from Specialist Teachers",
    "summary": "Deep learning models are prone to learning shortcut solutions to problems using spuriously correlated yet irrelevant features of their training data. In high-risk applications such as medical image analysis, this phenomenon may prevent models from using clinically meaningful features when making predictions, potentially leading to poor robustness and harm to patients. We demonstrate that different types of shortcuts (those that are diffuse and spread throughout the image, as well as those that are localized to specific areas) manifest distinctly across network layers and can, therefore, be more effectively targeted through mitigation strategies that target the intermediate layers. We propose a novel knowledge distillation framework that leverages a teacher network fine-tuned on a small subset of task-relevant data to mitigate shortcut learning in a student network trained on a large dataset corrupted with a bias feature. Through extensive experiments on CheXpert, ISIC 2017, and SimBA datasets using various architectures (ResNet-18, AlexNet, DenseNet-121, and 3D CNNs), we demonstrate consistent improvements over traditional Empirical Risk Minimization, augmentation-based bias-mitigation, and group-based bias-mitigation approaches. In many cases, we achieve comparable performance with a baseline model trained on bias-free data, even on out-of-distribution test data. Our results demonstrate the practical applicability of our approach to real-world medical imaging scenarios where bias annotations are limited and shortcut features are difficult to identify a priori.",
    "published": "2025-11-21T17:18:35Z",
    "updated": "2025-11-24T10:32:57Z",
    "link": "http://arxiv.org/pdf/2511.17421v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Christopher Boland",
      "Sotirios Tsaftaris",
      "Sonia Dahdouh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18966v1",
    "title": "LLM-CSEC: Empirical Evaluation of Security in C/C++ Code Generated by Large Language Models",
    "summary": "The security of code generated by large language models (LLMs) is a significant concern, as studies indicate that such code often contains vulnerabilities and lacks essential defensive programming constructs. This work focuses on examining and evaluating the security of LLM-generated code, particularly in the context of C/C++. We categorized known vulnerabilities using the Common Weakness Enumeration (CWE) and, to study their criticality, mapped them to CVEs. We used ten different LLMs for code generation and analyzed the outputs through static analysis. The amount of CWEs present in AI-generated code is concerning. Our findings highlight the need for developers to be cautious when using LLM-generated code. This study provides valuable insights to advance automated code generation and encourage further research in this domain.",
    "published": "2025-11-24T10:31:53Z",
    "updated": "2025-11-24T10:31:53Z",
    "link": "http://arxiv.org/pdf/2511.18966v1.pdf",
    "category": [
      "cs.AI",
      "cs.CR"
    ],
    "authors": [
      "Muhammad Usman Shahid",
      "Chuadhry Mujeeb Ahmed",
      "Rajiv Ranjan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18964v1",
    "title": "Synthesizing Visual Concepts as Vision-Language Programs",
    "summary": "Vision-Language models (VLMs) achieve strong performance on multimodal tasks but often fail at systematic visual reasoning tasks, leading to inconsistent or illogical outputs. Neuro-symbolic methods promise to address this by inducing interpretable logical rules, though they exploit rigid, domain-specific perception modules. We propose Vision-Language Programs (VLP), which combine the perceptual flexibility of VLMs with systematic reasoning of program synthesis. Rather than embedding reasoning inside the VLM, VLP leverages the model to produce structured visual descriptions that are compiled into neuro-symbolic programs. The resulting programs execute directly on images, remain consistent with task constraints, and provide human-interpretable explanations that enable easy shortcut mitigation. Experiments on synthetic and real-world datasets demonstrate that VLPs outperform direct and structured prompting, particularly on tasks requiring complex logical reasoning.",
    "published": "2025-11-24T10:30:33Z",
    "updated": "2025-11-24T10:30:33Z",
    "link": "http://arxiv.org/pdf/2511.18964v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Antonia Wüst",
      "Wolfgang Stammer",
      "Hikaru Shindo",
      "Lukas Helff",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18958v1",
    "title": "Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation",
    "summary": "As graph-structured data grow increasingly large, evaluating their robustness under adversarial attacks becomes computationally expensive and difficult to scale. To address this challenge, we propose to compress graphs into compact representations that preserve both topological structure and robustness profile, enabling efficient and reliable evaluation.We propose Cutter, a dual-agent reinforcement learning framework composed of a Vital Detection Agent (VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify structurally vital and redundant nodes for guided compression. Cutter incorporates three key strategies to enhance learning efficiency and compression quality: trajectory-level reward shaping to transform sparse trajectory returns into dense, policy-equivalent learning signals; prototype-based shaping to guide decisions using behavioral patterns from both highand low-return trajectories; and cross-agent imitation to enable safer and more transferable exploration. Experiments on multiple real-world graphs demonstrate that Cutter generates compressed graphs that retain essential static topological properties and exhibit robustness degradation trends highly consistent with the original graphs under various attack scenarios, thereby significantly improving evaluation efficiency without compromising assessment fidelity.",
    "published": "2025-11-24T10:19:58Z",
    "updated": "2025-11-24T10:19:58Z",
    "link": "http://arxiv.org/pdf/2511.18958v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Qisen Chai",
      "Yansong Wang",
      "Junjie Huang",
      "Tao Jia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18955v1",
    "title": "Active Inference is a Subtype of Variational Inference",
    "summary": "Automated decision-making under uncertainty requires balancing exploitation and exploration. Classical methods treat these separately using heuristics, while Active Inference unifies them through Expected Free Energy (EFE) minimization. However, EFE minimization is computationally expensive, limiting scalability. We build on recent theory recasting EFE minimization as variational inference, formally unifying it with Planning-as-Inference and showing the epistemic drive as a unique entropic contribution. Our main contribution is a novel message-passing scheme for this unified objective, enabling scalable Active Inference in factored-state MDPs and overcoming high-dimensional planning intractability.",
    "published": "2025-11-24T10:14:09Z",
    "updated": "2025-11-24T10:14:09Z",
    "link": "http://arxiv.org/pdf/2511.18955v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Wouter W. L. Nuijten",
      "Mykola Lukashchuk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2312.00326v21",
    "title": "Agent-OM: Leveraging LLM Agents for Ontology Matching",
    "summary": "Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM (Agent for Ontology Matching), consisting of two Siamese agents for retrieval and matching, with a set of OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve results very close to the long-standing best performance on simple OM tasks and can significantly improve the performance on complex and few-shot OM tasks.",
    "published": "2023-12-01T03:44:54Z",
    "updated": "2025-11-24T10:10:51Z",
    "link": "http://arxiv.org/pdf/2312.00326v21.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Zhangcheng Qiang",
      "Weiqing Wang",
      "Kerry Taylor"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.08227v2",
    "title": "OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution",
    "summary": "Denoising Diffusion Probabilistic Models (DDPMs) show promising potential in one-step Real-World Image Super-Resolution (Real-ISR). Current one-step Real-ISR methods typically inject the low-quality (LQ) image latent representation at the start or end timestep of the DDPM scheduler. Recent studies have begun to note that the LQ image latent and the pre-trained noisy latent representations are intuitively closer at a mid-timestep. However, a quantitative analysis of these latent representations remains lacking. Considering these latent representations can be decomposed into signal and noise, we propose a method based on the Signal-to-Noise Ratio (SNR) to pre-compute an average optimal mid-timestep for injection. To better approximate the pre-trained noisy latent representation, we further introduce the Latent Representation Refinement (LRR) loss via a LoRA-enhanced VAE encoder. We also fine-tune the backbone of the DDPM-based generative model using LoRA to perform one-step denoising at the average optimal mid-timestep. Based on these components, we present OMGSR, a GAN-based Real-ISR framework that employs a DDPM-based generative model as the generator and a DINOv3-ConvNeXt model with multi-level discriminator heads as the discriminator. We also propose the DINOv3-ConvNeXt DISTS (Dv3CD) loss, which is enhanced for structural perception at varying resolutions. Within the OMGSR framework, we develop OMGSR-S based on SD2.1-base. An ablation study confirms that our pre-computation strategy and LRR loss significantly improve the baseline. Comparative studies demonstrate that OMGSR-S achieves state-of-the-art performance across multiple metrics. Code is available at \\hyperlink{Github}{https://github.com/wuer5/OMGSR}.",
    "published": "2025-08-11T17:44:59Z",
    "updated": "2025-11-24T09:55:44Z",
    "link": "http://arxiv.org/pdf/2508.08227v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Zhiqiang Wu",
      "Zhaomang Sun",
      "Tong Zhou",
      "Bingtao Fu",
      "Ji Cong",
      "Yitong Dong",
      "Huaqi Zhang",
      "Xuan Tang",
      "Mingsong Chen",
      "Xian Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.08641v2",
    "title": "Developing an Algorithm Selector for Green Configuration in Scheduling Problems",
    "summary": "The Job Shop Scheduling Problem (JSP) is central to operations research, primarily optimizing energy efficiency due to its profound environmental and economic implications. Efficient scheduling enhances production metrics and mitigates energy consumption, thus effectively balancing productivity and sustainability objectives. Given the intricate and diverse nature of JSP instances, along with the array of algorithms developed to tackle these challenges, an intelligent algorithm selection tool becomes paramount. This paper introduces a framework designed to identify key problem features that characterize its complexity and guide the selection of suitable algorithms. Leveraging machine learning techniques, particularly XGBoost, the framework recommends optimal solvers such as GUROBI, CPLEX, and GECODE for efficient JSP scheduling. GUROBI excels with smaller instances, while GECODE demonstrates robust scalability for complex scenarios. The proposed algorithm selector achieves an accuracy of 84.51\\% in recommending the best algorithm for solving new JSP instances, highlighting its efficacy in algorithm selection. By refining feature extraction methodologies, the framework aims to broaden its applicability across diverse JSP scenarios, thereby advancing efficiency and sustainability in manufacturing logistics.",
    "published": "2024-09-13T08:58:24Z",
    "updated": "2025-11-24T09:52:56Z",
    "link": "http://arxiv.org/pdf/2409.08641v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Carlos March",
      "Christian Perez",
      "Miguel A. Salido"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11043v2",
    "title": "Autonomous Vehicle Path Planning by Searching With Differentiable Simulation",
    "summary": "Planning allows an agent to safely refine its actions before executing them in the real world. In autonomous driving, this is crucial to avoid collisions and navigate in complex, dense traffic scenarios. One way to plan is to search for the best action sequence. However, this is challenging when all necessary components - policy, next-state predictor, and critic - have to be learned. Here we propose Differentiable Simulation for Search (DSS), a framework that leverages the differentiable simulator Waymax as both a next state predictor and a critic. It relies on the simulator's hardcoded dynamics, making state predictions highly accurate, while utilizing the simulator's differentiability to effectively search across action sequences. Our DSS agent optimizes its actions using gradient descent over imagined future trajectories. We show experimentally that DSS - the combination of planning gradients and stochastic search - significantly improves tracking and path planning accuracy compared to sequence prediction, imitation learning, model-free RL, and other planning methods.",
    "published": "2025-11-14T07:56:34Z",
    "updated": "2025-11-24T09:43:11Z",
    "link": "http://arxiv.org/pdf/2511.11043v2.pdf",
    "category": [
      "cs.AI",
      "cs.RO"
    ],
    "authors": [
      "Asen Nachkov",
      "Jan-Nico Zaech",
      "Danda Pani Paudel",
      "Xi Wang",
      "Luc Van Gool"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18936v1",
    "title": "SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression",
    "summary": "Large Language Models (LLMs) face a significant bottleneck during autoregressive inference due to the massive memory footprint of the Key-Value (KV) cache. Existing compression techniques like token eviction, quantization, or other low-rank methods often risk information loss, have fixed limits, or introduce significant computational overhead from explicit decompression steps. In this work, we introduce SWAN, a novel, fine-tuning-free framework that eliminates this overhead. Our method uses an offline orthogonal matrix to rotate and prune the KV-cache, which is then used directly in the attention computation without any reconstruction. Our extensive experiments demonstrate that SWAN, augmented with a small dense buffer, offers a robust trade-off, maintaining performance close to the uncompressed baseline even at aggressive 50-60% memory savings per-token on KV-cache. A key advantage is its runtime-tunable compression level, allowing operators to dynamically adjust the memory footprint, a flexibility absent in methods requiring fixed offline configurations. This combination of a decompression-free design, high performance under compression, and adaptability makes SWAN a practical and efficient solution for serving LLMs with long contexts.",
    "published": "2025-11-24T09:41:24Z",
    "updated": "2025-11-24T09:41:24Z",
    "link": "http://arxiv.org/pdf/2511.18936v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Santhosh G S",
      "Saurav Prakash",
      "Balaraman Ravindran"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18934v1",
    "title": "Skeletons Matter: Dynamic Data Augmentation for Text-to-Query",
    "summary": "The task of translating natural language questions into query languages has long been a central focus in semantic parsing. Recent advancements in Large Language Models (LLMs) have significantly accelerated progress in this field. However, existing studies typically focus on a single query language, resulting in methods with limited generalizability across different languages. In this paper, we formally define the Text-to-Query task paradigm, unifying semantic parsing tasks across various query languages. We identify query skeletons as a shared optimization target of Text-to-Query tasks, and propose a general dynamic data augmentation framework that explicitly diagnoses model-specific weaknesses in handling these skeletons to synthesize targeted training data. Experiments on four Text-to-Query benchmarks demonstrate that our method achieves state-of-the-art performance using only a small amount of synthesized data, highlighting the efficiency and generality of our approach and laying a solid foundation for unified research on Text-to-Query tasks. We release our code at https://github.com/jjjycaptain/Skeletron.",
    "published": "2025-11-24T09:39:03Z",
    "updated": "2025-11-24T09:39:03Z",
    "link": "http://arxiv.org/pdf/2511.18934v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "authors": [
      "Yuchen Ji",
      "Bo Xu",
      "Jie Shi",
      "Jiaqing Liang",
      "Deqing Yang",
      "Yu Mao",
      "Hai Chen",
      "Yanghua Xiao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17443v2",
    "title": "GRAPHIC--Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity",
    "summary": "Artificial Intelligence (AI) has been increasingly applied to creative domains, leading to the development of systems that collaborate with humans in design processes. In Graphic Design, integrating computational systems into co-creative workflows presents specific challenges, as it requires balancing scientific rigour with the subjective and visual nature of design practice. Following the PRISMA methodology, we identified 872 articles, resulting in a final corpus of 71 publications describing 68 unique systems. Based on this review, we introduce GRAPHIC (Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity), a framework for analysing computational systems applied to Graphic Design. Its goal is to understand how current systems support human-AI collaboration in the Graphic Design discipline. The framework comprises main dimensions, which our analysis revealed to be essential across diverse system types: (1) Collaborative Panorama, (2) Processes and Modalities, and (3) Graphic Design Principles. Its application revealed research gaps, including the need to balance initiative and control between agents, improve communication through explainable interaction models, and promote systems that support transformational creativity grounded in core design principles.",
    "published": "2025-11-21T17:42:09Z",
    "updated": "2025-11-24T09:38:31Z",
    "link": "http://arxiv.org/pdf/2511.17443v2.pdf",
    "category": [
      "cs.HC",
      "cs.AI",
      "cs.GR"
    ],
    "authors": [
      "Joana Rovira Martins",
      "Pedro Martins",
      "Ana Boavida"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18933v1",
    "title": "Defending Large Language Models Against Jailbreak Exploits with Responsible AI Considerations",
    "summary": "Large Language Models (LLMs) remain susceptible to jailbreak exploits that bypass safety filters and induce harmful or unethical behavior. This work presents a systematic taxonomy of existing jailbreak defenses across prompt-level, model-level, and training-time interventions, followed by three proposed defense strategies. First, a Prompt-Level Defense Framework detects and neutralizes adversarial inputs through sanitization, paraphrasing, and adaptive system guarding. Second, a Logit-Based Steering Defense reinforces refusal behavior through inference-time vector steering in safety-sensitive layers. Third, a Domain-Specific Agent Defense employs the MetaGPT framework to enforce structured, role-based collaboration and domain adherence. Experiments on benchmark datasets show substantial reductions in attack success rate, achieving full mitigation under the agent-based defense. Overall, this study highlights how jailbreaks pose a significant security threat to LLMs and identifies key intervention points for prevention, while noting that defense strategies often involve trade-offs between safety, performance, and scalability. Code is available at: https://github.com/Kuro0911/CS5446-Project",
    "published": "2025-11-24T09:38:11Z",
    "updated": "2025-11-24T09:38:11Z",
    "link": "http://arxiv.org/pdf/2511.18933v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Ryan Wong",
      "Hosea David Yu Fei Ng",
      "Dhananjai Sharma",
      "Glenn Jun Jie Ng",
      "Kavishvaran Srinivasan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18931v1",
    "title": "Look It Up: Analysing Internal Web Search Capabilities of Modern LLMs",
    "summary": "Modern large language models integrate web search to provide real-time answers, yet it remains unclear whether they are efficiently calibrated to use search when it is actually needed. We introduce a benchmark evaluating both the necessity and effectiveness of web access across commercial models with no access to internal states or parameters. The dataset includes a static split of 783 temporally anchored questions answerable from pre-cutoff knowledge, aimed at testing whether models invoke search based on low internal confidence, and a dynamic split of 288 post-cutoff queries designed to test whether models recognise when search is required and retrieve updated information. Web access substantially improves static accuracy for GPT-5-mini and Claude Haiku 4.5, though confidence calibration worsens. On dynamic queries, both models frequently invoke search yet remain below 70 percent accuracy due to weak query formulation. Costs per accuracy-improving call remain low, but returns diminish once initial retrieval fails. Selective invocation helps, but models become overconfident and inconsistent after search. Overall, built-in web search meaningfully improves factual accuracy and can be invoked selectively, yet models remain overconfident, skip retrieval when it is essential, and falter once initial search queries underperform. Taken together, internal web search works better as a good low-latency verification layer than a reliable analytical tool, with clear room for improvement.",
    "published": "2025-11-24T09:37:43Z",
    "updated": "2025-11-24T09:37:43Z",
    "link": "http://arxiv.org/pdf/2511.18931v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Sahil Kale"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18930v1",
    "title": "Learning Solution Operators for Partial Differential Equations via Monte Carlo-Type Approximation",
    "summary": "The Monte Carlo-type Neural Operator (MCNO) introduces a lightweight architecture for learning solution operators for parametric PDEs by directly approximating the kernel integral using a Monte Carlo approach. Unlike Fourier Neural Operators, MCNO makes no spectral or translation-invariance assumptions. The kernel is represented as a learnable tensor over a fixed set of randomly sampled points. This design enables generalization across multiple grid resolutions without relying on fixed global basis functions or repeated sampling during training. Experiments on standard 1D PDE benchmarks show that MCNO achieves competitive accuracy with low computational cost, providing a simple and practical alternative to spectral and graph-based neural operators.",
    "published": "2025-11-24T09:35:10Z",
    "updated": "2025-11-24T09:35:10Z",
    "link": "http://arxiv.org/pdf/2511.18930v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Salah Eddine Choutri",
      "Prajwal Chauhan",
      "Othmane Mazhar",
      "Saif Eddin Jabari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18926v1",
    "title": "MoodBench 1.0: An Evaluation Benchmark for Emotional Companionship Dialogue Systems",
    "summary": "With the rapid development of Large Language Models, dialogue systems are shifting from information tools to emotional companions, heralding the era of Emotional Companionship Dialogue Systems (ECDs) that provide personalized emotional support for users. However, the field lacks clear definitions and systematic evaluation standards for ECDs. To address this, we first propose a definition of ECDs with formal descriptions. Then, based on this theory and the design principle of \"Ability Layer-Task Layer (three level)-Data Layer-Method Layer\", we design and implement the first ECD evaluation benchmark - MoodBench 1.0. Through extensive evaluations of 30 mainstream models, we demonstrate that MoodBench 1.0 has excellent discriminant validity and can effectively quantify the differences in emotional companionship abilities among models. Furthermore, the results reveal current models' shortcomings in deep emotional companionship, guiding future technological optimization and significantly aiding developers in enhancing ECDs' user experience.",
    "published": "2025-11-24T09:32:02Z",
    "updated": "2025-11-24T09:32:02Z",
    "link": "http://arxiv.org/pdf/2511.18926v1.pdf",
    "category": [
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Haifeng Jing",
      "Yujie Hou",
      "Junfei Liu",
      "Rui Xie",
      "alan Xu",
      "Jinlong Ma",
      "Qichun Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18924v1",
    "title": "LLM-Driven Kernel Evolution: Automating Driver Updates in Linux",
    "summary": "Linux kernel evolution breaks drivers through API/ABI changes, semantic shifts, and security-hardening updates. We introduce DRIVEBENCH, an executable corpus of kernel$\\rightarrow$driver co-evolution cases, and AUTODRIVER, a closed-loop, LLM-driven system for automating driver maintenance. The system integrates prompt engineering, multi-agent collaboration, static analysis, and iterative validation to ensure that generated patches are not only syntactically correct but also functionally and semantically consistent with kernel conventions. The corpus spans v5.10-v6.10 with 235 validated cases drawn from 612 candidates. In evaluation across 55 cases, AUTODRIVER achieves 56.4% compilation success; QEMU-based boot verification indicates that compiled patches preserve driver initialization in most instances. By releasing DRIVEBENCH and tooling, we enable reproducible research and a practical route to continuous, safe co-evolution of drivers with the Linux kernel.",
    "published": "2025-11-24T09:31:52Z",
    "updated": "2025-11-24T09:31:52Z",
    "link": "http://arxiv.org/pdf/2511.18924v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Arina Kharlamova",
      "Jiawen Liu",
      "Tianyi Zhang",
      "Xinrui Yang",
      "Humaid Alqasimi",
      "Youcheng Sun",
      "Chun Jason Xue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18919v1",
    "title": "Learning What to Trust: Bayesian Prior-Guided Optimization for Visual Generation",
    "summary": "Group Relative Policy Optimization (GRPO) has emerged as an effective and lightweight framework for post-training visual generative models. However, its performance is fundamentally limited by the ambiguity of textual visual correspondence: a single prompt may validly describe diverse visual outputs, and a single image or video may support multiple equally correct interpretations. This many to many relationship leads reward models to generate uncertain and weakly discriminative signals, causing GRPO to underutilize reliable feedback and overfit noisy ones. We introduce Bayesian Prior-Guided Optimization (BPGO), a novel extension of GRPO that explicitly models reward uncertainty through a semantic prior anchor. BPGO adaptively modulates optimization trust at two levels: inter-group Bayesian trust allocation emphasizes updates from groups consistent with the prior while down-weighting ambiguous ones, and intra-group prior-anchored renormalization sharpens sample distinctions by expanding confident deviations and compressing uncertain scores. Across both image and video generation tasks, BPGO delivers consistently stronger semantic alignment, enhanced perceptual fidelity, and faster convergence than standard GRPO and recent variants.",
    "published": "2025-11-24T09:29:30Z",
    "updated": "2025-11-24T09:29:30Z",
    "link": "http://arxiv.org/pdf/2511.18919v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ruiying Liu",
      "Yuanzhi Liang",
      "Haibin Huang",
      "Tianshu Yu",
      "Chi Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.16088v2",
    "title": "Future-Back Threat Modeling: A Foresight-Driven Security Framework",
    "summary": "Traditional threat modeling remains reactive-focused on known TTPs and past incident data, while threat prediction and forecasting frameworks are often disconnected from operational or architectural artifacts. This creates a fundamental weakness: the most serious cyber threats often do not arise from what is known, but from what is assumed, overlooked, or not yet conceived, and frequently originate from the future, such as artificial intelligence, information warfare, and supply chain attacks, where adversaries continuously develop new exploits that can bypass defenses built on current knowledge. To address this mental gap, this paper introduces the theory and methodology of Future-Back Threat Modeling (FBTM). This predictive approach begins with envisioned future threat states and works backward to identify assumptions, gaps, blind spots, and vulnerabilities in the current defense architecture, providing a clearer and more accurate view of impending threats so that we can anticipate their emergence and shape the future we want through actions taken now. The proposed methodology further aims to reveal known unknowns and unknown unknowns, including tactics, techniques, and procedures that are emerging, anticipated, and plausible. This enhances the predictability of adversary behavior, particularly under future uncertainty, helping security leaders make informed decisions today that shape more resilient security postures for the future.",
    "published": "2025-11-20T06:26:01Z",
    "updated": "2025-11-24T09:21:12Z",
    "link": "http://arxiv.org/pdf/2511.16088v2.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Vu Van Than"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18903v1",
    "title": "How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining",
    "summary": "Due to the scarcity of high-quality data, large language models (LLMs) are often trained on mixtures of data with varying quality levels, even after sophisticated data curation. A natural approach to better leverage high-quality data is curriculum-based pretraining, where the model is trained on data sorted in ascending order of quality as determined by a quality metric. However, prior studies have reported limited improvements from such curriculum-based pretraining strategies. This work identifies a critical factor constraining these methods: the incompatibility between the ascending data quality order and the decaying learning rate (LR) schedule. We find that while curriculum-based training substantially outperforms random shuffling when using a constant LR, its advantage diminishes under standard LR decay schedules. Our experiments show this incompatibility can be mitigated by two simple strategies: (1) employing a more moderate LR decay schedule, where the final LR is only moderately smaller than the peak LR, and (2) replacing LR decay with model averaging, i.e., computing a weighted average of the final few checkpoints. By combining these strategies, we improve the average score on a suite of standard benchmarks by 1.64% over random shuffling, without additional data refinement. Validated on 1.5B-parameter models trained over 30B tokens with various data-quality metrics, our findings call for a re-evaluation of curriculum-based LLM pretraining and underscore the potential of co-designing data curricula with optimization methods.",
    "published": "2025-11-24T09:03:49Z",
    "updated": "2025-11-24T09:03:49Z",
    "link": "http://arxiv.org/pdf/2511.18903v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Kairong Luo",
      "Zhenbo Sun",
      "Haodong Wen",
      "Xinyu Shi",
      "Jiarui Cui",
      "Chenyi Dang",
      "Kaifeng Lyu",
      "Wenguang Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18902v1",
    "title": "VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL",
    "summary": "Group-based policy optimization methods like GRPO and GSPO have become standard for training multimodal models, leveraging group-wise rollouts and relative advantage estimation. However, they suffer from a critical \\emph{gradient vanishing} problem when all responses within a group receive identical rewards, causing advantage estimates to collapse and training signals to diminish. Existing attempts to mitigate this issue fall into two paradigms: filtering-based and sampling-based methods. Filtering-based methods first generate rollouts broadly and then retroactively filter out uninformative groups, leading to substantial computational overhead. Sampling-based methods proactively select effective samples before rollout but rely on static criteria or prior dataset knowledge, lacking real-time adaptability. To address these issues, we propose \\textbf{VADE}, a \\textbf{V}ariance-\\textbf{A}ware \\textbf{D}ynamic sampling framework via online sample-level difficulty \\textbf{E}stimation. Our framework integrates three key components: online sample-level difficulty estimation using Beta distributions, a Thompson sampler that maximizes information gain through the estimated correctness probability, and a two-scale prior decay mechanism that maintains robust estimation under policy evolution. This three components design enables VADE to dynamically select the most informative samples, thereby amplifying training signals while eliminating extra rollout costs. Extensive experiments on multimodal reasoning benchmarks show that VADE consistently outperforms strong baselines in both performance and sample efficiency, while achieving a dramatic reduction in computational overhead. More importantly, our framework can serves as a plug-and-play component to be seamlessly integrated into existing group-based RL algorithms. Code and models are available at https://VADE-RL.github.io.",
    "published": "2025-11-24T08:59:54Z",
    "updated": "2025-11-24T08:59:54Z",
    "link": "http://arxiv.org/pdf/2511.18902v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Zengjie Hu",
      "Jiantao Qiu",
      "Tianyi Bai",
      "Haojin Yang",
      "Binhang Yuan",
      "Qi Jing",
      "Conghui He",
      "Wentao Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18894v1",
    "title": "MetaDCSeg: Robust Medical Image Segmentation via Meta Dynamic Center Weighting",
    "summary": "Medical image segmentation is crucial for clinical applications, but it is frequently disrupted by noisy annotations and ambiguous anatomical boundaries, which lead to instability in model training. Existing methods typically rely on global noise assumptions or confidence-based sample selection, which inadequately mitigate the performance degradation caused by annotation noise, especially in challenging boundary regions. To address this issue, we propose MetaDCSeg, a robust framework that dynamically learns optimal pixel-wise weights to suppress the influence of noisy ground-truth labels while preserving reliable annotations. By explicitly modeling boundary uncertainty through a Dynamic Center Distance (DCD) mechanism, our approach utilizes weighted feature distances for foreground, background, and boundary centers, directing the model's attention toward hard-to-segment pixels near ambiguous boundaries. This strategy enables more precise handling of structural boundaries, which are often overlooked by existing methods, and significantly enhances segmentation performance. Extensive experiments across four benchmark datasets with varying noise levels demonstrate that MetaDCSeg consistently outperforms existing state-of-the-art methods.",
    "published": "2025-11-24T08:51:02Z",
    "updated": "2025-11-24T08:51:02Z",
    "link": "http://arxiv.org/pdf/2511.18894v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Chenyu Mu",
      "Guihai Chen",
      "Xun Yang",
      "Erkun Yang",
      "Cheng Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13590v2",
    "title": "Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World Text-to-SQL Translation",
    "summary": "Text-to-SQL datasets are essential for training and evaluating text-to-SQL models, but existing datasets often suffer from limited coverage and fail to capture the diversity of real-world applications. To address this, we propose a novel taxonomy for text-to-SQL classification based on dimensions including core intents, statement types, syntax structures, and key actions. Using this taxonomy, we evaluate widely used public text-to-SQL datasets (e.g., Spider and Bird) and reveal limitations in their coverage and diversity. We then introduce a taxonomy-guided dataset synthesis pipeline, yielding a new dataset named SQL-Synth. This approach combines the taxonomy with Large Language Models (LLMs) to ensure the dataset reflects the breadth and complexity of real-world text-to-SQL applications. Extensive analysis and experimental results validate the effectiveness of our taxonomy, as SQL-Synth exhibits greater diversity and coverage compared to existing benchmarks. Moreover, we uncover that existing LLMs typically fall short in adequately capturing the full range of scenarios, resulting in limited performance on SQL-Synth. However, fine-tuning can substantially improve their performance in these scenarios. The proposed taxonomy has significant potential impact, as it not only enables comprehensive analysis of datasets and the performance of different LLMs, but also guides the construction of training data for LLMs.",
    "published": "2025-11-17T16:52:19Z",
    "updated": "2025-11-24T08:48:39Z",
    "link": "http://arxiv.org/pdf/2511.13590v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Hao Wang",
      "Yuanfeng Song",
      "Xiaoming Yin",
      "Xing Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18890v1",
    "title": "Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models",
    "summary": "Efficient deployment of small language models (SLMs) is essential for numerous real-world applications with stringent latency constraints. While previous work on SLM design has primarily focused on reducing the number of parameters to achieve parameter-optimal SLMs, parameter efficiency does not necessarily translate into proportional real-device speed-ups. This work aims to identify the key determinants of SLMs' real-device latency and offer generalizable principles and methodologies for SLM design and training when real-device latency is the primary consideration. Specifically, we identify two central architectural factors: depth-width ratios and operator choices. The former is crucial for small-batch-size latency, while the latter affects both latency and large-batch-size throughput. In light of this, we first study latency-optimal depth-width ratios, with the key finding that although deep-thin models generally achieve better accuracy under the same parameter budget, they may not lie on the accuracy-latency trade-off frontier. Next, we explore emerging efficient attention alternatives to evaluate their potential as candidate building operators. Using the identified promising operators, we construct an evolutionary search framework to automatically discover latency-optimal combinations of these operators within hybrid SLMs, thereby advancing the accuracy-latency frontier. In addition to architectural improvements, we further enhance SLM training using a weight normalization technique that enables more effective weight updates and improves final convergence. Combining these methods, we introduce a new family of hybrid SLMs, called Nemotron-Flash, which significantly advances the accuracy-efficiency frontier of state-of-the-art SLMs, e.g., achieving over +5.5% average accuracy, 1.3x/1.9x lower latency, and 18.7x/45.6x higher throughput compared to Qwen3-1.7B/0.6B, respectively.",
    "published": "2025-11-24T08:46:36Z",
    "updated": "2025-11-24T08:46:36Z",
    "link": "http://arxiv.org/pdf/2511.18890v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yonggan Fu",
      "Xin Dong",
      "Shizhe Diao",
      "Matthijs Van keirsbilck",
      "Hanrong Ye",
      "Wonmin Byeon",
      "Yashaswi Karnati",
      "Lucas Liebenwein",
      "Hannah Zhang",
      "Nikolaus Binder",
      "Maksim Khadkevich",
      "Alexander Keller",
      "Jan Kautz",
      "Yingyan Celine Lin",
      "Pavlo Molchanov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18889v1",
    "title": "CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation",
    "summary": "Data contamination poses a significant challenge to the fairness of LLM evaluations in natural language processing tasks by inadvertently exposing models to test data during training. Current studies attempt to mitigate this issue by modifying existing datasets or generating new ones from freshly collected information. However, these methods fall short of ensuring contamination-resilient evaluation, as they fail to fully eliminate pre-existing knowledge from models or preserve the semantic complexity of the original datasets. To address these limitations, we propose \\textbf{CoreEval}, a \\textbf{Co}ntamination-\\textbf{re}silient \\textbf{Eval}uation strategy for automatically updating data with real-world knowledge. This approach begins by extracting entity relationships from the original data and leveraging the GDELT database to retrieve relevant, up-to-date knowledge. The retrieved knowledge is then recontextualized and integrated with the original data, which is refined and restructured to ensure semantic coherence and enhanced task relevance. Ultimately, a robust data reflection mechanism is employed to iteratively verify and refine labels, ensuring consistency between the updated and original datasets. Extensive experiments on updated datasets validate the robustness of CoreEval, demonstrating its effectiveness in mitigating performance overestimation caused by data contamination.",
    "published": "2025-11-24T08:44:29Z",
    "updated": "2025-11-24T08:44:29Z",
    "link": "http://arxiv.org/pdf/2511.18889v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Jingqian Zhao",
      "Bingbing Wang",
      "Geng Tu",
      "Yice Zhang",
      "Qianlong Wang",
      "Bin Liang",
      "Jing Li",
      "Ruifeng Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.11357v3",
    "title": "On the dimension of pullback attractors in recurrent neural networks",
    "summary": "Recurrent Neural Networks (RNNs) are high-dimensional state space models capable of learning functions on sequence data. Recently, it has been conjectured that reservoir computers, a particular class of RNNs, trained on observations of a dynamical systems can be interpreted as embeddings. This result has been established for the case of linear reservoir systems. In this work, we use a nonautonomous dynamical systems approach to establish an upper bound for the fractal dimension of the subset of reservoir state space approximated during training and prediction phase. We prove that when the input sequences comes from an Nin-dimensional invertible dynamical system, the fractal dimension of this set is bounded above by Nin. The result obtained here are useful in dimensionality reduction of computation in RNNs as well as estimating fractal dimensions of dynamical systems from limited observations of their time series. It is also a step towards understanding embedding properties of reservoir computers.",
    "published": "2025-01-20T09:38:30Z",
    "updated": "2025-11-24T08:40:40Z",
    "link": "http://arxiv.org/pdf/2501.11357v3.pdf",
    "category": [
      "math.DS",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Muhammed Fadera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14299v2",
    "title": "DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning",
    "summary": "In today's data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.",
    "published": "2025-11-18T09:54:13Z",
    "updated": "2025-11-24T08:37:38Z",
    "link": "http://arxiv.org/pdf/2511.14299v2.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "authors": [
      "Xiaochuan Liu",
      "Yuanfeng Song",
      "Xiaoming Yin",
      "Xing Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18878v1",
    "title": "Accelerating Reinforcement Learning via Error-Related Human Brain Signals",
    "summary": "In this work, we investigate how implicit neural feed back can accelerate reinforcement learning in complex robotic manipulation settings. While prior electroencephalogram (EEG) guided reinforcement learning studies have primarily focused on navigation or low-dimensional locomotion tasks, we aim to understand whether such neural evaluative signals can improve policy learning in high-dimensional manipulation tasks involving obstacles and precise end-effector control. We integrate error related potentials decoded from offline-trained EEG classifiers into reward shaping and systematically evaluate the impact of human-feedback weighting. Experiments on a 7-DoF manipulator in an obstacle-rich reaching environment show that neural feedback accelerates reinforcement learning and, depending on the human-feedback weighting, can yield task success rates that at times exceed those of sparse-reward baselines. Moreover, when applying the best-performing feedback weighting across all sub jects, we observe consistent acceleration of reinforcement learning relative to the sparse-reward setting. Furthermore, leave-one subject-out evaluations confirm that the proposed framework remains robust despite the intrinsic inter-individual variability in EEG decodability. Our findings demonstrate that EEG-based reinforcement learning can scale beyond locomotion tasks and provide a viable pathway for human-aligned manipulation skill acquisition.",
    "published": "2025-11-24T08:33:47Z",
    "updated": "2025-11-24T08:33:47Z",
    "link": "http://arxiv.org/pdf/2511.18878v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Suzie Kim",
      "Hye-Bin Shin",
      "Hyo-Jeong Jang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18874v1",
    "title": "GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction",
    "summary": "Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.",
    "published": "2025-11-24T08:28:42Z",
    "updated": "2025-11-24T08:28:42Z",
    "link": "http://arxiv.org/pdf/2511.18874v1.pdf",
    "category": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MA",
      "cs.RO",
      "cs.SI"
    ],
    "authors": [
      "Yuzhi Chen",
      "Yuanchang Xie",
      "Lei Zhao",
      "Pan Liu",
      "Yajie Zou",
      "Chen Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.06567v2",
    "title": "Human Cognition Inspired RAG with Knowledge Graph for Complex Problem Solving",
    "summary": "Large Language Models (LLMs) have demonstrated significant potential across various domains. However, they often struggle with integrating external knowledge and performing complex reasoning, leading to hallucinations and unreliable outputs. Retrieval Augmented Generation (RAG) has emerged as a promising paradigm to mitigate these issues by incorporating external knowledge. Yet, conventional RAG approaches, especially those based on vector similarity, fail to effectively capture relational dependencies and support multi-step reasoning. In this work, we propose CogGRAG, a human cognition-inspired, graph-based RAG framework designed for Knowledge Graph Question Answering (KGQA). CogGRAG models the reasoning process as a tree-structured mind map that decomposes the original problem into interrelated subproblems and explicitly encodes their semantic relationships. This structure not only provides a global view to guide subsequent retrieval and reasoning but also enables self-consistent verification across reasoning paths. The framework operates in three stages: (1) top-down problem decomposition via mind map construction, (2) structured retrieval of both local and global knowledge from external Knowledge Graphs (KGs), and (3) bottom-up reasoning with dual-process self-verification. Unlike previous tree-based decomposition methods such as MindMap or Graph-CoT, CogGRAG unifies problem decomposition, knowledge retrieval, and reasoning under a single graph-structured cognitive framework, allowing early integration of relational knowledge and adaptive verification. Extensive experiments demonstrate that CogGRAG achieves superior accuracy and reliability compared to existing methods.",
    "published": "2025-03-09T11:50:39Z",
    "updated": "2025-11-24T08:27:31Z",
    "link": "http://arxiv.org/pdf/2503.06567v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yao Cheng",
      "Yibo Zhao",
      "Jiapeng Zhu",
      "Yao Liu",
      "Xing Sun",
      "Xiang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.11443v2",
    "title": "COLI: A Hierarchical Efficient Compressor for Large Images",
    "summary": "The escalating adoption of high-resolution, large-field-of-view imagery amplifies the need for efficient compression methodologies. Conventional techniques frequently fail to preserve critical image details, while data-driven approaches exhibit limited generalizability. Implicit Neural Representations (INRs) present a promising alternative by learning continuous mappings from spatial coordinates to pixel intensities for individual images, thereby storing network weights rather than raw pixels and avoiding the generalization problem. However, INR-based compression of large images faces challenges including slow compression speed and suboptimal compression ratios. To address these limitations, we introduce COLI (Compressor for Large Images), a novel framework leveraging Neural Representations for Videos (NeRV). First, recognizing that INR-based compression constitutes a training process, we accelerate its convergence through a pretraining-finetuning paradigm, mixed-precision training, and reformulation of the sequential loss into a parallelizable objective. Second, capitalizing on INRs' transformation of image storage constraints into weight storage, we implement Hyper-Compression, a novel post-training technique to substantially enhance compression ratios while maintaining minimal output distortion. Evaluations across two medical imaging datasets demonstrate that COLI consistently achieves competitive or superior PSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while accelerating NeRV training by up to 4 times.",
    "published": "2025-07-15T16:07:07Z",
    "updated": "2025-11-24T08:27:03Z",
    "link": "http://arxiv.org/pdf/2507.11443v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Haoran Wang",
      "Hanyu Pei",
      "Yang Lyu",
      "Kai Zhang",
      "Li Li",
      "Feng-Lei Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.16123v2",
    "title": "Gradient Propagation in Retrosynthetic Space: An Efficient Framework for Synthesis Plan Generation",
    "summary": "Retrosynthesis, which aims to identify viable synthetic pathways for target molecules by decomposing them into simpler precursors, is often treated as a search problem. However, its complexity arises from multi-branched tree-structured pathways rather than linear paths. Some algorithms have been successfully applied in this task, but they either overlook the uncertainties inherent in chemical space or face limitations in practical application scenarios. To address these challenges, this paper introduces a novel gradient-propagation-based algorithmic framework for retrosynthetic route exploration. The proposed framework obtains the contributions of different nodes to the target molecule's success probability through gradient propagation and then guides the algorithm to greedily select the node with the highest contribution for expansion, thereby conducting efficient search in the chemical space. Experimental validations demonstrate that our algorithm achieves broad applicability across diverse molecular targets and exhibits superior computational efficiency compared to existing methods.",
    "published": "2024-05-25T08:23:40Z",
    "updated": "2025-11-24T08:23:34Z",
    "link": "http://arxiv.org/pdf/2405.16123v2.pdf",
    "category": [
      "cs.AI",
      "q-bio.BM"
    ],
    "authors": [
      "Chengyang Tian",
      "Yuhang Chang",
      "Yangpeng Zhang",
      "Yang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18871v1",
    "title": "Periodic Asynchrony: An Effective Method for Accelerating On-Policy Reinforcement Learning",
    "summary": "Since the introduction of the GRPO algorithm, reinforcement learning (RL) has attracted increasing attention, with growing efforts to reproduce and apply it. However, training efficiency remains a critical challenge. In mainstream RL frameworks, inference and training are typically deployed on the same devices. While this approach reduces costs through resource consolidation, its synchronous execution imposes a computational coupling that prevents concurrent inference and training. In this study, we are returning to the strategy of separating inference and training deployment, and by introducing improvements in the data loader, we transform the conventional synchronous architecture into a periodically asynchronous framework, which allows for demand-driven, independent, and elastic scaling of each component, while the accuracy of the algorithm remains completely equivalent to the synchronization method, with both belonging to the on-policy strategy. It is worth emphasizing that we apply a unified tri-model architecture in the training phase, and we also proposed a shared-prompt attention mask to reduce repetitive computation. In practice, these works have achieved at least a threefold overall performance improvement in RL training on NPU platforms, indicating its potential for widespread application.",
    "published": "2025-11-24T08:22:50Z",
    "updated": "2025-11-24T08:22:50Z",
    "link": "http://arxiv.org/pdf/2511.18871v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Jian Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.04645v3",
    "title": "Pathway to Relevance: How Cross-Encoders Implement a Semantic Variant of BM25",
    "summary": "Mechanistic interpretation has greatly contributed to a more detailed understanding of generative language models, enabling significant progress in identifying structures that implement key behaviors through interactions between internal components. In contrast, interpretability in information retrieval (IR) remains relatively coarse-grained, and much is still unknown as to how IR models determine whether a document is relevant to a query. In this work, we address this gap by mechanistically analyzing how one commonly used model, a cross-encoder, estimates relevance. We find that the model extracts traditional relevance signals, such as term frequency and inverse document frequency, in early-to-middle layers. These concepts are then combined in later layers, similar to the well-known probabilistic ranking function, BM25. Overall, our analysis offers a more nuanced understanding of how IR models compute relevance. Isolating these components lays the groundwork for future interventions that could enhance transparency, mitigate safety risks, and improve scalability.",
    "published": "2025-02-07T04:08:57Z",
    "updated": "2025-11-24T08:22:00Z",
    "link": "http://arxiv.org/pdf/2502.04645v3.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Meng Lu",
      "Catherine Chen",
      "Carsten Eickhoff"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18869v1",
    "title": "Multidimensional Music Aesthetic Evaluation via Semantically Consistent C-Mixup Augmentation",
    "summary": "Evaluating the aesthetic quality of generated songs is challenging due to the multi-dimensional nature of musical perception. We propose a robust music aesthetic evaluation framework that combines (1) multi-source multi-scale feature extraction to obtain complementary segment- and track-level representations, (2) a hierarchical audio augmentation strategy to enrich training data, and (3) a hybrid training objective that integrates regression and ranking losses for accurate scoring and reliable top-song identification. Experiments on the ICASSP 2026 SongEval benchmark demonstrate that our approach consistently outperforms baseline methods across correlation and top-tier metrics.",
    "published": "2025-11-24T08:12:33Z",
    "updated": "2025-11-24T08:12:33Z",
    "link": "http://arxiv.org/pdf/2511.18869v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "authors": [
      "Shuyang Liu",
      "Yuan Jin",
      "Rui Lin",
      "Shizhe Chen",
      "Junyu Dai",
      "Tao Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18868v1",
    "title": "KernelBand: Boosting LLM-based Kernel Optimization with a Hierarchical and Hardware-aware Multi-armed Bandit",
    "summary": "High quality kernels are critical for reducing training and inference costs of Large Language Models (LLMs), yet they traditionally require significant expertise in hardware architecture and software optimization. While recent advances in LLM-based code generation show promise for complex optimization, existing methods struggle with the vast optimization space due to insufficient hardware domain knowledge, failing to effectively balance exploration and exploitation. We present KernelBand, a novel framework that formulates kernel optimization as a hierarchical multi-armed bandit problem, enabling LLM agents to strategically navigate the optimization space by treating kernel selection and optimization strategy application as sequential decision-making processes. Our approach leverages hardware profiling information to identify promising optimization strategies and employs runtime behavior clustering to reduce exploration overhead across kernel candidates. Extensive experiments on TritonBench demonstrate that KernelBand significantly outperforms state-of-the-art methods, achieving superior performance with fewer tokens while exhibiting consistent improvement without saturation as computational resources increase.",
    "published": "2025-11-24T08:11:50Z",
    "updated": "2025-11-24T08:11:50Z",
    "link": "http://arxiv.org/pdf/2511.18868v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Dezhi Ran",
      "Shuxiao Xie",
      "Mingfang Ji",
      "Ziyue Hua",
      "Mengzhou Wu",
      "Yuan Cao",
      "Yuzhe Guo",
      "Yu Hao",
      "Linyi Li",
      "Yitao Hu",
      "Tao Xie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.15668v2",
    "title": "Preprint: Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid Planning Problems",
    "summary": "Explaining unsolvability of planning problems is of significant research interest in Explainable AI Planning. AI planning literature has reported several research efforts on generating explanations of solutions to planning problems. However, explaining the unsolvability of planning problems remains a largely open and understudied problem. A widely practiced approach to plan generation and automated problem solving, in general, is to decompose tasks into sub-problems that help progressively converge towards the goal. In this paper, we propose to adopt the same philosophy of sub-problem identification as a mechanism for analyzing and explaining unsolvability of planning problems in hybrid systems. In particular, for a given unsolvable planning problem, we propose to identify common waypoints, which are universal obstacles to plan existence; in other words, they appear on every plan from the source to the planning goal. This work envisions such waypoints as sub-problems of the planning problem and the unreachability of any of these waypoints as an explanation for the unsolvability of the original planning problem. We propose a novel method of waypoint identification by casting the problem as an instance of the longest common subsequence problem, a widely popular problem in computer science, typically considered as an illustrative example for the dynamic programming paradigm. Once the waypoints are identified, we perform symbolic reachability analysis on them to identify the earliest unreachable waypoint and report it as the explanation of unsolvability. We present experimental results on unsolvable planning problems in hybrid domains.",
    "published": "2025-04-22T07:45:30Z",
    "updated": "2025-11-24T08:07:47Z",
    "link": "http://arxiv.org/pdf/2504.15668v2.pdf",
    "category": [
      "cs.AI",
      "cs.FL"
    ],
    "authors": [
      "Mir Md Sajid Sarwar",
      "Rajarshi Ray"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18860v1",
    "title": "Generating Reading Comprehension Exercises with Large Language Models for Educational Applications",
    "summary": "With the rapid development of large language models (LLMs), the applications of LLMs have grown substantially. In the education domain, LLMs demonstrate significant potential, particularly in automatic text generation, which enables the creation of intelligent and adaptive learning content. This paper proposes a new LLMs framework, which is named as Reading Comprehension Exercise Generation (RCEG). It can generate high-quality and personalized English reading comprehension exercises automatically. Firstly, RCEG uses fine-tuned LLMs to generate content candidates. Then, it uses a discriminator to select the best candidate. Finally, the quality of the generated content has been improved greatly. To evaluate the performance of RCEG, a dedicated dataset for English reading comprehension is constructed to perform the experiments, and comprehensive evaluation metrics are used to analyze the experimental results. These metrics include content diversity, factual accuracy, linguistic toxicity, and pedagogical alignment. Experimental results show that RCEG significantly improves the relevance and cognitive appropriateness of the generated exercises.",
    "published": "2025-11-24T08:00:48Z",
    "updated": "2025-11-24T08:00:48Z",
    "link": "http://arxiv.org/pdf/2511.18860v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Xingyu Huang",
      "Fei Jiang",
      "Jianli Xiao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.16712v2",
    "title": "PairHuman: A High-Fidelity Photographic Dataset for Customized Dual-Person Generation",
    "summary": "Personalized dual-person portrait customization has considerable potential applications, such as preserving emotional memories and facilitating wedding photography planning. However, the absence of a benchmark dataset hinders the pursuit of high-quality customization in dual-person portrait generation. In this paper, we propose the PairHuman dataset, which is the first large-scale benchmark dataset specifically designed for generating dual-person portraits that meet high photographic standards. The PairHuman dataset contains more than 100K images that capture a variety of scenes, attire, and dual-person interactions, along with rich metadata, including detailed image descriptions, person localization, human keypoints, and attribute tags. We also introduce DHumanDiff, which is a baseline specifically crafted for dual-person portrait generation that features enhanced facial consistency and simultaneously balances in personalized person generation and semantic-driven scene creation. Finally, the experimental results demonstrate that our dataset and method produce highly customized portraits with superior visual quality that are tailored to human preferences. Our dataset is publicly available at https://github.com/annaoooo/PairHuman.",
    "published": "2025-11-20T08:56:46Z",
    "updated": "2025-11-24T07:58:20Z",
    "link": "http://arxiv.org/pdf/2511.16712v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ting Pan",
      "Ye Wang",
      "Peiguang Jing",
      "Rui Ma",
      "Zili Yi",
      "Yu Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.21996v2",
    "title": "AlphaBeta is not as good as you think: a simple random games model for a better analysis of deterministic game-solving algorithms",
    "summary": "Deterministic game-solving algorithms are conventionally analyzed in the light of their average-case complexity against a distribution of random game-trees, where leaf values are independently sampled from a fixed distribution. This simplified model enables uncluttered mathematical analysis, revealing two key properties: root value distributions asymptotically collapse to a single fixed value for finite-valued trees, and all reasonable algorithms achieve global optimality. However, these findings are artifacts of the model's design: its long criticized independence assumption strips games of structural complexity, producing trivial instances where no algorithm faces meaningful challenges. To address this limitation, we introduce a simple probabilistic model that incrementally constructs game-trees using a fixed level-wise conditional distribution. By enforcing ancestor dependencies, a critical structural feature of real-world games, our framework generates problems with adjustable difficulty while retaining some form of analytical tractability. For several algorithms, including AlphaBeta and Scout, we derive recursive formulas characterizing their average-case complexities under this model. These allow us to rigorously compare algorithms on deep game-trees, where Monte-Carlo simulations are no longer feasible. While asymptotically, all algorithms seem to converge to identical branching factor (a result analogous to that of independence-based models), deep finite trees reveal stark differences: AlphaBeta incurs a significantly larger constant multiplicative factor compared to algorithms like Scout, leading to a substantial practical slowdown. Our framework sheds new light on classical game-solving algorithms, offering rigorous evidence and analytical tools to advance the understanding of these methods under a richer, more challenging, and yet tractable model.",
    "published": "2025-06-27T08:07:17Z",
    "updated": "2025-11-24T07:52:48Z",
    "link": "http://arxiv.org/pdf/2506.21996v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Raphaël Boige",
      "Amine Boumaza",
      "Bruno Scherrer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18856v1",
    "title": "Deep Hybrid Model for Region of Interest Detection in Omnidirectional Videos",
    "summary": "The main goal of the project is to design a new model that predicts regions of interest in 360$^{\\circ}$ videos. The region of interest (ROI) plays an important role in 360$^{\\circ}$ video streaming. For example, ROIs are used to predict view-ports, intelligently cut the videos for live streaming, etc so that less bandwidth is used. Detecting view-ports in advance helps reduce the movement of the head while streaming and watching a video via the head-mounted device. Whereas, intelligent cuts of the videos help improve the efficiency of streaming the video to users and enhance the quality of their viewing experience. This report illustrates the secondary task to identify ROIs, in which, we design, train, and test a hybrid saliency model. In this work, we refer to saliency regions to represent the regions of interest. The method includes the processes as follows: preprocessing the video to obtain frames, developing a hybrid saliency model for predicting the region of interest, and finally post-processing the output predictions of the hybrid saliency model to obtain the output region of interest for each frame. Then, we compare the performance of the proposed method with the subjective annotations of the 360RAT dataset.",
    "published": "2025-11-24T07:52:06Z",
    "updated": "2025-11-24T07:52:06Z",
    "link": "http://arxiv.org/pdf/2511.18856v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Sana Alamgeer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18854v1",
    "title": "Time Travel: LLM-Assisted Semantic Behavior Localization with Git Bisect",
    "summary": "We present a novel framework that integrates Large Language Models (LLMs) into the Git bisect process for semantic fault localization. Traditional bisect assumes deterministic predicates and binary failure states assumptions often violated in modern software development due to flaky tests, nonmonotonic regressions, and semantic divergence from upstream repositories. Our system augments bisect traversal with structured chain of thought reasoning, enabling commit by commit analysis under noisy conditions. We evaluate multiple open source and proprietary LLMs for their suitability and fine tune DeepSeekCoderV2 using QLoRA on a curated dataset of semantically labeled diffs. We adopt a weak supervision workflow to reduce annotation overhead, incorporating human in the loop corrections and self consistency filtering. Experiments across multiple open source projects show a 6.4 point absolute gain in success rate from 74.2 to 80.6 percent, leading to significantly fewer failed traversals and by experiment up to 2x reduction in average bisect time. We conclude with discussions on temporal reasoning, prompt design, and finetuning strategies tailored for commit level behavior analysis.",
    "published": "2025-11-24T07:49:59Z",
    "updated": "2025-11-24T07:49:59Z",
    "link": "http://arxiv.org/pdf/2511.18854v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Yujing Wang",
      "Weize Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.15065v2",
    "title": "Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks",
    "summary": "Video Models have achieved remarkable success in high-fidelity video generation with coherent motion dynamics. Analogous to the development from text generation to text-based reasoning in language modeling, the development of video models motivates us to ask: Can video models reason via video generation? Compared with the discrete text corpus, video grounds reasoning in explicit spatial layouts and temporal continuity, which serves as an ideal substrate for spatial reasoning. In this work, we explore the reasoning via video paradigm and introduce VR-Bench -- a comprehensive benchmark designed to systematically evaluate video models' reasoning capabilities. Grounded in maze-solving tasks that inherently require spatial planning and multi-step reasoning, VR-Bench contains 7,920 procedurally generated videos across five maze types and diverse visual styles. Our empirical analysis demonstrates that SFT can efficiently elicit the reasoning ability of video model. Video models exhibit stronger spatial perception during reasoning, outperforming leading VLMs and generalizing well across diverse scenarios, tasks, and levels of complexity. We further discover a test-time scaling effect, where diverse sampling during inference improves reasoning reliability by 10--20%. These findings highlight the unique potential and scalability of reasoning via video for spatial reasoning tasks.",
    "published": "2025-11-19T03:18:29Z",
    "updated": "2025-11-24T07:46:09Z",
    "link": "http://arxiv.org/pdf/2511.15065v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Cheng Yang",
      "Haiyuan Wan",
      "Yiran Peng",
      "Xin Cheng",
      "Zhaoyang Yu",
      "Jiayi Zhang",
      "Junchi Yu",
      "Xinlei Yu",
      "Xiawu Zheng",
      "Dongzhan Zhou",
      "Chenglin Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2406.08426v8",
    "title": "Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL",
    "summary": "Generating accurate SQL from users' natural language questions (text-to-SQL) remains a long-standing challenge due to the complexities involved in user question understanding, database schema comprehension, and SQL generation. Traditional text-to-SQL systems, which combine human engineering and deep neural networks, have made significant progress. Subsequently, pre-trained language models (PLMs) have been developed for text-to-SQL tasks, achieving promising results. However, as modern databases and user questions grow more complex, PLMs with a limited parameter size often produce incorrect SQL. This necessitates more sophisticated and tailored optimization methods, which restricts the application of PLM-based systems. Recently, large language models (LLMs) have shown significant capabilities in natural language understanding as model scale increases. Thus, integrating LLM-based solutions can bring unique opportunities, improvements, and solutions to text-to-SQL research. In this survey, we provide a comprehensive review of existing LLM-based text-to-SQL studies. Specifically, we offer a brief overview of the technical challenges and evolutionary process of text-to-SQL. Next, we introduce the datasets and metrics designed to evaluate text-to-SQL systems. Subsequently, we present a systematic analysis of recent advances in LLM-based text-to-SQL. Finally, we make a summarization and discuss the remaining challenges in this field and suggest expectations for future research directions. All the related resources of LLM-based, including research papers, benchmarks, and open-source projects, are collected for the community in our repository: https://github.com/DEEP-PolyU/Awesome-LLM-based-Text2SQL.",
    "published": "2024-06-12T17:13:17Z",
    "updated": "2025-11-24T07:43:14Z",
    "link": "http://arxiv.org/pdf/2406.08426v8.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "authors": [
      "Zijin Hong",
      "Zheng Yuan",
      "Qinggang Zhang",
      "Hao Chen",
      "Junnan Dong",
      "Feiran Huang",
      "Xiao Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18849v1",
    "title": "Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming",
    "summary": "Large Language Models (LLMs) are increasingly integrated into code editors to provide AI-powered code suggestions. Yet many of these suggestions are ignored, resulting in wasted computation, increased latency, and unnecessary interruptions. We introduce a lightweight pre-filtering model that predicts the likelihood of suggestion acceptance before invoking the LLM, using only real-time developer telemetry such as typing speed, file navigation, and editing activity. Deployed in a production-grade Visual Studio Code plugin over four months of naturalistic use, our approach nearly doubled acceptance rates (18.4% -> 34.2%) while suppressing 35% of low-value LLM calls. These findings demonstrate that behavioral signals alone can meaningfully improve both user experience and system efficiency in LLM-assisted programming, highlighting the value of timing-aware, privacy-preserving adaptation mechanisms. The filter operates solely on pre-invocation editor telemetry and never inspects code or prompts.",
    "published": "2025-11-24T07:42:07Z",
    "updated": "2025-11-24T07:42:07Z",
    "link": "http://arxiv.org/pdf/2511.18849v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Mohammad Nour Al Awad",
      "Sergey Ivanov",
      "Olga Tikhonova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18847v1",
    "title": "Personalized Federated Segmentation with Shared Feature Aggregation and Boundary-Focused Calibration",
    "summary": "Personalized federated learning (PFL) possesses the unique capability of preserving data confidentiality among clients while tackling the data heterogeneity problem of non-independent and identically distributed (Non-IID) data. Its advantages have led to widespread adoption in domains such as medical image segmentation. However, the existing approaches mostly overlook the potential benefits of leveraging shared features across clients, where each client contains segmentation data of different organs. In this work, we introduce a novel personalized federated approach for organ agnostic tumor segmentation (FedOAP), that utilizes cross-attention to model long-range dependencies among the shared features of different clients and a boundary-aware loss to improve segmentation consistency. FedOAP employs a decoupled cross-attention (DCA), which enables each client to retain local queries while attending to globally shared key-value pairs aggregated from all clients, thereby capturing long-range inter-organ feature dependencies. Additionally, we introduce perturbed boundary loss (PBL) which focuses on the inconsistencies of the predicted mask's boundary for each client, forcing the model to localize the margins more precisely. We evaluate FedOAP on diverse tumor segmentation tasks spanning different organs. Extensive experiments demonstrate that FedOAP consistently outperforms existing state-of-the-art federated and personalized segmentation methods.",
    "published": "2025-11-24T07:40:04Z",
    "updated": "2025-11-24T07:40:04Z",
    "link": "http://arxiv.org/pdf/2511.18847v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ishmam Tashdeed",
      "Md. Atiqur Rahman",
      "Sabrina Islam",
      "Md. Azam Hossain"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18846v1",
    "title": "WaveTuner: Comprehensive Wavelet Subband Tuning for Time Series Forecasting",
    "summary": "Due to the inherent complexity, temporal patterns in real-world time series often evolve across multiple intertwined scales, including long-term periodicity, short-term fluctuations, and abrupt regime shifts. While existing literature has designed many sophisticated decomposition approaches based on the time or frequency domain to partition trend-seasonality components and high-low frequency components, an alternative line of approaches based on the wavelet domain has been proposed to provide a unified multi-resolution representation with precise time-frequency localization. However, most wavelet-based methods suffer from a persistent bias toward recursively decomposing only low-frequency components, severely underutilizing subtle yet informative high-frequency components that are pivotal for precise time series forecasting. To address this problem, we propose WaveTuner, a Wavelet decomposition framework empowered by full-spectrum subband Tuning for time series forecasting. Concretely, WaveTuner comprises two key modules: (i) Adaptive Wavelet Refinement module, that transforms time series into time-frequency coefficients, utilizes an adaptive router to dynamically assign subband weights, and generates subband-specific embeddings to support refinement; and (ii) Multi-Branch Specialization module, that employs multiple functional branches, each instantiated as a flexible Kolmogorov-Arnold Network (KAN) with a distinct functional order to model a specific spectral subband. Equipped with these modules, WaveTuner comprehensively tunes global trends and local variations within a unified time-frequency framework. Extensive experiments on eight real-world datasets demonstrate WaveTuner achieves state-of-the-art forecasting performance in time series forecasting.",
    "published": "2025-11-24T07:33:35Z",
    "updated": "2025-11-24T07:33:35Z",
    "link": "http://arxiv.org/pdf/2511.18846v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yubo Wang",
      "Hui He",
      "Chaoxi Niu",
      "Zhendong Niu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18845v1",
    "title": "UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model",
    "summary": "Vision-and-Language Navigation (VLN) requires agents to autonomously navigate complex environments via visual images and natural language instruction--remains highly challenging. Recent research on enhancing language-guided navigation reasoning using pre-trained large language models (LLMs) has shown promising prospects. However, the reasoning of such methods is limited to the linguistic modality, lacking visual reasoning capabilities. Moreover, existing reasoning modules are optimized separately from navigation policies, leading to incompatibility and potential conflicts in optimization objectives. To tackle these challenges, we introduce UNeMo, a novel framework designed for the collaborative optimization of visual state reasoning and navigational decision-making. It introduces a Multimodal World Model (MWM) that takes visual features, language instructions, and navigational actions as inputs to jointly predict subsequent visual states, enabling cross-modal reasoning. Via a Hierarchical Prediction-Feedback (HPN) mechanism, MWM collaborates with navigation policies: the first layer generates actions using current vision-and-language features; MWM then infers post-action visual states to guide the second layer's fine-grained decisions. This forms a dynamic bidirectional promotion mechanism where MWM reasoning optimizes navigation policies, while policy decisions feedback to improve MWM's reasoning accuracy. Experiments on R2R and REVERIE datasets show UNeMo outperforms state-of-the-art methods by 2.1% and 0.7% in navigation accuracy for unseen scenes, validating its effectiveness.",
    "published": "2025-11-24T07:31:58Z",
    "updated": "2025-11-24T07:31:58Z",
    "link": "http://arxiv.org/pdf/2511.18845v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Changxin Huang",
      "Lv Tang",
      "Zhaohuan Zhan",
      "Lisha Yu",
      "Runhao Zeng",
      "Zun Liu",
      "Zhengjie Wang",
      "Jianqiang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18842v1",
    "title": "Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds",
    "summary": "Large Language Models (LLMs) have transformed code auto-completion by generating context-aware suggestions. Yet, deciding when to present these suggestions remains underexplored, often leading to interruptions or wasted inference calls. We propose an adaptive timing mechanism that dynamically adjusts the delay before offering a suggestion based on real-time developer feedback. Our suggested method combines a logistic transform of recent acceptance rates with a bounded delay range, anchored by a high-level binary prediction of the developer's cognitive state. In a two-month deployment with professional developers, our system improved suggestion acceptance from 4.9% with no delay to 15.4% with static delays, and to 18.6% with adaptive timing-while reducing blind rejections (rejections without being read) from 8.3% to 0.36%. Together, these improvements increase acceptance and substantially reduce wasted inference calls by 75%, making LLM-based code assistants more efficient and cost-effective in practice.",
    "published": "2025-11-24T07:29:15Z",
    "updated": "2025-11-24T07:29:15Z",
    "link": "http://arxiv.org/pdf/2511.18842v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "authors": [
      "Mohammad Nour Al Awad",
      "Sergey Ivanov",
      "Olga Tikhonova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18841v1",
    "title": "Federated style aware transformer aggregation of representations",
    "summary": "Personalized Federated Learning (PFL) faces persistent challenges, including domain heterogeneity from diverse client data, data imbalance due to skewed participation, and strict communication constraints. Traditional federated learning often lacks personalization, as a single global model cannot capture client-specific characteristics, leading to biased predictions and poor generalization, especially for clients with highly divergent data distributions.\n  To address these issues, we propose FedSTAR, a style-aware federated learning framework that disentangles client-specific style factors from shared content representations. FedSTAR aggregates class-wise prototypes using a Transformer-based attention mechanism, allowing the server to adaptively weight client contributions while preserving personalization.\n  Furthermore, by exchanging compact prototypes and style vectors instead of full model parameters, FedSTAR significantly reduces communication overhead. Experimental results demonstrate that combining content-style disentanglement with attention-driven prototype aggregation improves personalization and robustness in heterogeneous environments without increasing communication cost.",
    "published": "2025-11-24T07:24:09Z",
    "updated": "2025-11-24T07:24:09Z",
    "link": "http://arxiv.org/pdf/2511.18841v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "authors": [
      "Mincheol Jeon",
      "Euinam Huh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18840v1",
    "title": "Addressing Situated Teaching Needs: A Multi-Agent Framework for Automated Slide Adaptation",
    "summary": "The adaptation of teaching slides to instructors' situated teaching needs, including pedagogical styles and their students' context, is a critical yet time-consuming task for educators. Through a series of educator interviews, we first identify and systematically categorize the key friction points that impede this adaptation process. Grounded in these findings, we introduce a novel multi-agent framework designed to automate slide adaptation based on high-level instructor specifications. An evaluation involving 16 modification requests across 8 real-world courses validates our approach. The framework's output consistently achieved high scores in intent alignment, content coherence and factual accuracy, and performed on par with baseline methods regarding visual clarity, while also demonstrating appropriate timeliness and a high operational agreement with human experts, achieving an F1 score of 0.89. This work heralds a new paradigm where AI agents handle the logistical burdens of instructional design, liberating educators to focus on the creative and strategic aspects of teaching.",
    "published": "2025-11-24T07:22:41Z",
    "updated": "2025-11-24T07:22:41Z",
    "link": "http://arxiv.org/pdf/2511.18840v1.pdf",
    "category": [
      "cs.MA",
      "cs.AI"
    ],
    "authors": [
      "Binglin Liu",
      "Yucheng Wang",
      "Zheyuan Zhang",
      "Jiyuan Lu",
      "Shen Yang",
      "Daniel Zhang-Li",
      "Huiqin Liu",
      "Jifan Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18834v1",
    "title": "FlowSteer: Guiding Few-Step Image Synthesis with Authentic Trajectories",
    "summary": "With the success of flow matching in visual generation, sampling efficiency remains a critical bottleneck for its practical application. Among flow models' accelerating methods, ReFlow has been somehow overlooked although it has theoretical consistency with flow matching. This is primarily due to its suboptimal performance in practical scenarios compared to consistency distillation and score distillation. In this work, we investigate this issue within the ReFlow framework and propose FlowSteer, a method unlocks the potential of ReFlow-based distillation by guiding the student along teacher's authentic generation trajectories. We first identify that Piecewised ReFlow's performance is hampered by a critical distribution mismatch during the training and propose Online Trajectory Alignment(OTA) to resolve it. Then, we introduce a adversarial distillation objective applied directly on the ODE trajectory, improving the student's adherence to the teacher's generation trajectory. Furthermore, we find and fix a previously undiscovered flaw in the widely-used FlowMatchEulerDiscreteScheduler that largely degrades few-step inference quality. Our experiment result on SD3 demonstrates our method's efficacy.",
    "published": "2025-11-24T07:13:23Z",
    "updated": "2025-11-24T07:13:23Z",
    "link": "http://arxiv.org/pdf/2511.18834v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Lei Ke",
      "Hubery Yin",
      "Gongye Liu",
      "Zhengyao Lv",
      "Jingcai Guo",
      "Chen Li",
      "Wenhan Luo",
      "Yujiu Yang",
      "Jing Lyu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.13334v4",
    "title": "BiasJailbreak:Analyzing Ethical Biases and Jailbreak Vulnerabilities in Large Language Models",
    "summary": "Although large language models (LLMs) demonstrate impressive proficiency in various tasks, they present potential safety risks, such as `jailbreaks', where malicious inputs can coerce LLMs into generating harmful content bypassing safety alignments. In this paper, we delve into the ethical biases in LLMs and examine how those biases could be exploited for jailbreaks. Notably, these biases result in a jailbreaking success rate in GPT-4o models that differs by 20\\% between non-binary and cisgender keywords and by 16\\% between white and black keywords, even when the other parts of the prompts are identical. We introduce the concept of BiasJailbreak, highlighting the inherent risks posed by these safety-induced biases. BiasJailbreak generates biased keywords automatically by asking the target LLM itself, and utilizes the keywords to generate harmful output. Additionally, we propose an efficient defense method BiasDefense, which prevents jailbreak attempts by injecting defense prompts prior to generation. BiasDefense stands as an appealing alternative to Guard Models, such as Llama-Guard, that require additional inference cost after text generation. Our findings emphasize that ethical biases in LLMs can actually lead to generating unsafe output, and suggest a method to make the LLMs more secure and unbiased. To enable further research and improvements, we open-source our code and artifacts of BiasJailbreak, providing the community with tools to better understand and mitigate safety-induced biases in LLMs.",
    "published": "2024-10-17T08:46:09Z",
    "updated": "2025-11-24T07:12:09Z",
    "link": "http://arxiv.org/pdf/2410.13334v4.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Isack Lee",
      "Haebin Seong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18828v1",
    "title": "Solving a Research Problem in Mathematical Statistics with AI Assistance",
    "summary": "Over the last few months, AI models including large language models have improved greatly. There are now several documented examples where they have helped professional mathematical scientists prove new results, sometimes even helping resolve known open problems. In this short note, we add another example to the list, by documenting how we were able to solve a previously unsolved research problem in robust mathematical statistics with crucial help from GPT-5. Our problem concerns robust density estimation, where the observations are perturbed by Wasserstein-bounded contaminations.In a previous preprint (Chao and Dobriban, 2023, arxiv:2308.01853v2), we have obtained upper and lower bounds on the minimax optimal estimation error; which were, however, not sharp.\n  Starting in October 2025, making significant use of GPT-5 Pro, we were able to derive the minimax optimal error rate (reported in version 3 of the above arxiv preprint). GPT-5 provided crucial help along the way, including by suggesting calculations that we did not think of, and techniques that were not familiar to us, such as the dynamic Benamou-Brenier formulation, for key steps in the analysis. Working with GPT-5 took a few weeks of effort, and we estimate that it could have taken several months to get the same results otherwise. At the same time, there are still areas where working with GPT-5 was challenging: it sometimes provided incorrect references, and glossed over details that sometimes took days of work to fill in. We outline our workflow and steps taken to mitigate issues. Overall, our work can serve as additional documentation for a new age of human-AI collaborative work in mathematical science.",
    "published": "2025-11-24T07:03:56Z",
    "updated": "2025-11-24T07:03:56Z",
    "link": "http://arxiv.org/pdf/2511.18828v1.pdf",
    "category": [
      "math.ST",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Edgar Dobriban"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.05321v2",
    "title": "VALUE: Value-Aware Large Language Model for Query Rewriting via Weighted Trie in Sponsored Search",
    "summary": "Query-to-bidword(i.e., bidding keyword) rewriting is fundamental to sponsored search, transforming noisy user queries into semantically relevant and commercially valuable keywords. Recent advances in large language models (LLMs) improve semantic relevance through generative retrieval frameworks, but they rarely encode the commercial value of keywords. As a result, rewrites are often semantically correct yet economically suboptimal, and a reinforcement learning from human feedback (RLHF) stage is usually added after supervised fine-tuning(SFT) to mitigate this deficiency. However, conventional preference alignment frequently overemphasize the ordering of bidword values and is susceptible to overfitting, which degrades rewrite quality. In addition, bidword value changes rapidly, while existing generative methods do not respond to these fluctuations. To address this shortcoming, we introduce VALUE(Value-Aware Large language model for qUery rewriting via wEighted trie), a framework that integrates value awareness directly into generation and enhances value alignment during training. VALUE employs the Weighted Trie, a novel variant of the classical trie that stores real-time value signals for each token. During decoding, the framework adjusts the LLM's token probabilities with these signals, constraining the search space and steering generation toward high-value rewrites. The alignment stage uses a fine-grained preference learning strategy that emphasizes stable, high-value differences and down-weights noisy or transient fluctuations, thereby improving robustness and reducing overfitting. Offline experiments show that VALUE significantly outperforms baselines in both semantic matching and value-centric metrics. VALUE has been deployed on our advertising system since October 2024 and served the Double Eleven promotions, the biggest shopping carnival in China.",
    "published": "2025-02-25T08:34:16Z",
    "updated": "2025-11-24T06:50:38Z",
    "link": "http://arxiv.org/pdf/2504.05321v2.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Xiao Zhang",
      "Guanyu Chen",
      "Boyang Zuo",
      "Feng Li",
      "Pengjie Wang",
      "Jian Xu",
      "Bo Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.07742v2",
    "title": "A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases",
    "summary": "Repair-based semantics have been extensively studied as a means of obtaining meaningful answers to queries posed over inconsistent knowledge bases (KBs). While several works have considered how to exploit a priority relation between facts to select optimal repairs, the question of how to specify such preferences remains largely unaddressed. This motivates us to introduce a declarative rule-based framework for specifying and computing a priority relation between conflicting facts. As the expressed preferences may contain undesirable cycles, we consider the problem of determining when a set of preference rules always yields an acyclic relation, and we also explore a pragmatic approach that extracts an acyclic relation by applying various cycle removal techniques. Towards an end-to-end system for querying inconsistent KBs, we present a preliminary implementation and experimental evaluation of the framework, which employs answer set programming to evaluate the preference rules, apply the desired cycle resolution techniques to obtain a priority relation, and answer queries under prioritized-repair semantics.",
    "published": "2025-08-11T08:21:02Z",
    "updated": "2025-11-24T06:49:36Z",
    "link": "http://arxiv.org/pdf/2508.07742v2.pdf",
    "category": [
      "cs.LO",
      "cs.AI",
      "cs.DB"
    ],
    "authors": [
      "Meghyn Bienvenu",
      "Camille Bourgaux",
      "Katsumi Inoue",
      "Robin Jean"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18811v1",
    "title": "Mitigating Long-Tail Bias in HOI Detection via Adaptive Diversity Cache",
    "summary": "Human-Object Interaction (HOI) detection is a fundamental task in computer vision, empowering machines to comprehend human-object relationships in diverse real-world scenarios. Recent advances in VLMs have significantly improved HOI detection by leveraging rich cross-modal representations. However, most existing VLM-based approaches rely heavily on additional training or prompt tuning, resulting in substantial computational overhead and limited scalability, particularly in long-tailed scenarios where rare interactions are severely underrepresented. In this paper, we propose the Adaptive Diversity Cache (ADC) module, a novel training-free and plug-and-play mechanism designed to mitigate long-tail bias in HOI detection. ADC constructs class-specific caches that accumulate high-confidence and diverse feature representations during inference. The method incorporates frequency-aware cache adaptation that favors rare categories and is designed to enable robust prediction calibration without requiring additional training or fine-tuning. Extensive experiments on HICO-DET and V-COCO datasets show that ADC consistently improves existing HOI detectors, achieving up to +8.57\\% mAP gain on rare categories and +4.39\\% on the full dataset, demonstrating its effectiveness in mitigating long-tail bias while preserving overall performance.",
    "published": "2025-11-24T06:30:08Z",
    "updated": "2025-11-24T06:30:08Z",
    "link": "http://arxiv.org/pdf/2511.18811v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuqiu Jiang",
      "Xiaozhen Qiao",
      "Tianyu Mei",
      "Haojian Huang",
      "Yifan Chen",
      "Ye Zheng",
      "Zhe Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18808v1",
    "title": "HyperbolicRAG: Enhancing Retrieval-Augmented Generation with Hyperbolic Representations",
    "summary": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to access external knowledge, helping mitigate hallucinations and enhance domain-specific expertise. Graph-based RAG enhances structural reasoning by introducing explicit relational organization that enables information propagation across semantically connected text units. However, these methods typically rely on Euclidean embeddings that capture semantic similarity but lack a geometric notion of hierarchical depth, limiting their ability to represent abstraction relationships inherent in complex knowledge graphs. To capture both fine-grained semantics and global hierarchy, we propose HyperbolicRAG, a retrieval framework that integrates hyperbolic geometry into graph-based RAG. HyperbolicRAG introduces three key designs: (1) a depth-aware representation learner that embeds nodes within a shared Poincare manifold to align semantic similarity with hierarchical containment, (2) an unsupervised contrastive regularization that enforces geometric consistency across abstraction levels, and (3) a mutual-ranking fusion mechanism that jointly exploits retrieval signals from Euclidean and hyperbolic spaces, emphasizing cross-space agreement during inference. Extensive experiments across multiple QA benchmarks demonstrate that HyperbolicRAG outperforms competitive baselines, including both standard RAG and graph-augmented baselines.",
    "published": "2025-11-24T06:27:58Z",
    "updated": "2025-11-24T06:27:58Z",
    "link": "http://arxiv.org/pdf/2511.18808v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Cao Linxiao",
      "Wang Ruitao",
      "Li Jindong",
      "Zhou Zhipeng",
      "Yang Menglin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.23210v4",
    "title": "FedRef: Communication-Efficient Bayesian Fine-Tuning using a Reference Model",
    "summary": "Federated learning (FL) collaboratively trains artificial intelligence (AI) models to ensure user data privacy. Sharing only model updates generated from local training on client data with the server enhances user data privacy. However, model performance may suffer due to data and system heterogeneity among clients in FL scenarios. Previous studies have proposed model optimization, fine-tuning, and personalization to achieve improved model performance. Despite these efforts, models resulting from FL scenarios often exhibit catastrophic forgetting, which increases the communication and computational costs of clients for model optimization and raises energy consumption. To address these challenges, we propose a reference model-based fine-tuning method for federated learning that overcomes catastrophic forgetting in each round. Our method is derived from Bayesian parameter-efficient transfer learning and includes an proximal term. It employs a reference model that incorporates previous model parameters and reviews previous global features in the model optimization step to mitigate catastrophic forgetting. As a result, our method achieves higher model performance and lower communication and computational costs for clients than existing methods.",
    "published": "2025-06-29T12:41:11Z",
    "updated": "2025-11-24T06:24:33Z",
    "link": "http://arxiv.org/pdf/2506.23210v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "authors": [
      "Taehwan Yoon",
      "Bongjun Choi",
      "Wesley De Neve"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20613v3",
    "title": "REAL-Prover: Retrieval Augmented Lean Prover for Mathematical Reasoning",
    "summary": "Nowadays, formal theorem provers have made monumental progress on high-school and competition-level mathematics, but few of them generalize to more advanced mathematics. In this paper, we present REAL-Prover, a new open-source stepwise theorem prover for Lean 4 to push this boundary. This prover, based on our fine-tuned large language model (REAL-Prover-v1) and integrated with a retrieval system (Leansearch-PS), notably boosts performance on solving college-level mathematics problems. To train REAL-Prover-v1, we developed HERALD-AF, a data extraction pipeline that converts natural language math problems into formal statements, and a new open-source Lean 4 interactive environment (Jixia-interactive) to facilitate synthesis data collection. In our experiments, our prover using only supervised fine-tune achieves competitive results with a 23.7% success rate (Pass@64) on the ProofNet dataset-comparable to state-of-the-art (SOTA) models. To further evaluate our approach, we introduce FATE-M, a new benchmark focused on algebraic problems, where our prover achieves a SOTA success rate of 56.7% (Pass@64).",
    "published": "2025-05-27T01:26:11Z",
    "updated": "2025-11-24T06:18:18Z",
    "link": "http://arxiv.org/pdf/2505.20613v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "authors": [
      "Ziju Shen",
      "Naohao Huang",
      "Fanyi Yang",
      "Yutong Wang",
      "Guoxiong Gao",
      "Tianyi Xu",
      "Jiedong Jiang",
      "Wanyi He",
      "Pu Yang",
      "Mengzhou Sun",
      "Haocheng Ju",
      "Peihao Wu",
      "Bryan Dai",
      "Bin Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.13837v5",
    "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning performance of large language models (LLMs), particularly on mathematics and programming tasks. Similar to how traditional RL helps agents explore and learn new strategies, RLVR is believed to enable LLMs to continuously self-improve, thus acquiring novel reasoning abilities beyond those of the corresponding base models. In this study we critically examine the current state of RLVR by systematically probing the reasoning capability boundaries of RLVR-trained LLMs across various model families, RL algorithms, and math, coding, and visual reasoning benchmarks, using pass@k at large k values as the evaluation metric. Surprisingly, we find that the current training setup does not elicit fundamentally new reasoning patterns. While RLVR-trained models outperform their base models at small k (e.g., k = 1), the base models achieve a higher pass@k score when k is large. Coverage and perplexity analyses show that the observed reasoning abilities originate from and are bounded by the base model. Treating the base model as an upper bound, our quantitative analysis shows that six popular RLVR algorithms perform similarly and remain far from optimal in leveraging the potential of the base model. By contrast, we find that distillation can introduce new reasoning patterns from the teacher and genuinely expand the model's reasoning capabilities. Overall, our findings suggest that current RLVR methods have not yet realized the potential of RL to elicit truly novel reasoning abilities in LLMs. This highlights the need for improved RL paradigms, such as continual scaling and multi-turn agent-environment interaction, to unlock this potential.",
    "published": "2025-04-18T17:59:56Z",
    "updated": "2025-11-24T06:11:04Z",
    "link": "http://arxiv.org/pdf/2504.13837v5.pdf",
    "category": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Yang Yue",
      "Zhiqi Chen",
      "Rui Lu",
      "Andrew Zhao",
      "Zhaokai Wang",
      "Yang Yue",
      "Shiji Song",
      "Gao Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.00763v2",
    "title": "How Focused Are LLMs? A Quantitative Study via Repetitive Deterministic Prediction Tasks",
    "summary": "We investigate the performance of large language models on repetitive deterministic prediction tasks and study how the sequence accuracy rate scales with output length. Each such task involves repeating the same operation n times. Examples include letter replacement in strings following a given rule, integer addition, and multiplication of string operators in many body quantum mechanics. If the model performs the task through a simple repetition algorithm, the success rate should decay exponentially with sequence length. In contrast, our experiments on leading large language models reveal a sharp double exponential drop beyond a characteristic length scale, forming an accuracy cliff that marks the transition from reliable to unstable generation. This indicates that the models fail to execute each operation independently. To explain this phenomenon, we propose a statistical physics inspired model that captures the competition between external conditioning from the prompt and internal interference among generated tokens. The model quantitatively reproduces the observed crossover and provides an interpretable link between attention induced interference and sequence level failure. Fitting the model to empirical results across multiple models and tasks yields effective parameters that characterize the intrinsic error rate and error accumulation factor for each model task pair, offering a principled framework for understanding the limits of deterministic accuracy in large language models.",
    "published": "2025-11-02T01:42:08Z",
    "updated": "2025-11-24T06:11:01Z",
    "link": "http://arxiv.org/pdf/2511.00763v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Wanda Hou",
      "Leon Zhou",
      "Hong-Ye Hu",
      "Yubei Chen",
      "Yi-Zhuang You",
      "Xiao-Liang Qi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18793v1",
    "title": "NEZHA: A Zero-sacrifice and Hyperspeed Decoding Architecture for Generative Recommendations",
    "summary": "Generative Recommendation (GR), powered by Large Language Models (LLMs), represents a promising new paradigm for industrial recommender systems. However, their practical application is severely hindered by high inference latency, which makes them infeasible for high-throughput, real-time services and limits their overall business impact. While Speculative Decoding (SD) has been proposed to accelerate the autoregressive generation process, existing implementations introduce new bottlenecks: they typically require separate draft models and model-based verifiers, requiring additional training and increasing the latency overhead. In this paper, we address these challenges with NEZHA, a novel architecture that achieves hyperspeed decoding for GR systems without sacrificing recommendation quality. Specifically, NEZHA integrates a nimble autoregressive draft head directly into the primary model, enabling efficient self-drafting. This design, combined with a specialized input prompt structure, preserves the integrity of sequence-to-sequence generation. Furthermore, to tackle the critical problem of hallucination, a major source of performance degradation, we introduce an efficient, model-free verifier based on a hash set. We demonstrate the effectiveness of NEZHA through extensive experiments on public datasets and have successfully deployed the system on Taobao since October 2025, driving the billion-level advertising revenue and serving hundreds of millions of daily active users.",
    "published": "2025-11-24T05:53:46Z",
    "updated": "2025-11-24T05:53:46Z",
    "link": "http://arxiv.org/pdf/2511.18793v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yejing Wang",
      "Shengyu Zhou",
      "Jinyu Lu",
      "Ziwei Liu",
      "Langming Liu",
      "Maolin Wang",
      "Wenlin Zhang",
      "Feng Li",
      "Wenbo Su",
      "Pengjie Wang",
      "Jian Xu",
      "Xiangyu Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17068v2",
    "title": "ReBrain: Brain MRI Reconstruction from Sparse CT Slice via Retrieval-Augmented Diffusion",
    "summary": "Magnetic Resonance Imaging (MRI) plays a crucial role in brain disease diagnosis, but it is not always feasible for certain patients due to physical or clinical constraints. Recent studies attempt to synthesize MRI from Computed Tomography (CT) scans; however, low-dose protocols often result in highly sparse CT volumes with poor through-plane resolution, making accurate reconstruction of the full brain MRI volume particularly challenging. To address this, we propose ReBrain, a retrieval-augmented diffusion framework for brain MRI reconstruction. Given any 3D CT scan with limited slices, we first employ a Brownian Bridge Diffusion Model (BBDM) to synthesize MRI slices along the 2D dimension. Simultaneously, we retrieve structurally and pathologically similar CT slices from a comprehensive prior database via a fine-tuned retrieval model. These retrieved slices are used as references, incorporated through a ControlNet branch to guide the generation of intermediate MRI slices and ensure structural continuity. We further account for rare retrieval failures when the database lacks suitable references and apply spherical linear interpolation to provide supplementary guidance. Extensive experiments on SynthRAD2023 and BraTS demonstrate that ReBrain achieves state-of-the-art performance in cross-modal reconstruction under sparse conditions.",
    "published": "2025-11-21T09:18:35Z",
    "updated": "2025-11-24T05:52:53Z",
    "link": "http://arxiv.org/pdf/2511.17068v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Junming Liu",
      "Yifei Sun",
      "Weihua Cheng",
      "Yujin Kang",
      "Yirong Chen",
      "Ding Wang",
      "Guosun Zeng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.11009v2",
    "title": "SproutBench: A Benchmark for Safe and Ethical Large Language Models for Youth",
    "summary": "The rapid proliferation of large language models (LLMs) in applications targeting children and adolescents necessitates a fundamental reassessment of prevailing AI safety frameworks, which are largely tailored to adult users and neglect the distinct developmental vulnerabilities of minors. This paper highlights key deficiencies in existing LLM safety benchmarks, including their inadequate coverage of age-specific cognitive, emotional, and social risks spanning early childhood (ages 0--6), middle childhood (7--12), and adolescence (13--18). To bridge these gaps, we introduce SproutBench, an innovative evaluation suite comprising 1,283 developmentally grounded adversarial prompts designed to probe risks such as emotional dependency, privacy violations, and imitation of hazardous behaviors. Through rigorous empirical evaluation of 47 diverse LLMs, we uncover substantial safety vulnerabilities, corroborated by robust inter-dimensional correlations (e.g., between Safety and Risk Prevention) and a notable inverse relationship between Interactivity and Age Appropriateness. These insights yield practical guidelines for advancing child-centric AI design and deployment.",
    "published": "2025-08-14T18:21:39Z",
    "updated": "2025-11-24T05:52:00Z",
    "link": "http://arxiv.org/pdf/2508.11009v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Wenpeng Xing",
      "Lanyi Wei",
      "Haixiao Hu",
      "Rongchang Li",
      "Mohan Li",
      "Changting Lin",
      "Meng Han"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.05264v4",
    "title": "SGDFuse: SAM-Guided Diffusion for High-Fidelity Infrared and Visible Image Fusion",
    "summary": "Infrared and visible image fusion (IVIF) aims to combine the thermal radiation information from infrared images with the rich texture details from visible images to enhance perceptual capabilities for downstream visual tasks. However, existing methods often fail to preserve key targets due to a lack of deep semantic understanding of the scene, while the fusion process itself can also introduce artifacts and detail loss, severely compromising both image quality and task performance. To address these issues, this paper proposes SGDFuse, a conditional diffusion model guided by the Segment Anything Model (SAM), to achieve high-fidelity and semantically-aware image fusion. The core of our method is to utilize high-quality semantic masks generated by SAM as explicit priors to guide the optimization of the fusion process via a conditional diffusion model. Specifically, the framework operates in a two-stage process: it first performs a preliminary fusion of multi-modal features, and then utilizes the semantic masks from SAM jointly with the preliminary fused image as a condition to drive the diffusion model's coarse-to-fine denoising generation. This ensures the fusion process not only has explicit semantic directionality but also guarantees the high fidelity of the final result. Extensive experiments demonstrate that SGDFuse achieves state-of-the-art performance in both subjective and objective evaluations, as well as in its adaptability to downstream tasks, providing a powerful solution to the core challenges in image fusion. The code of SGDFuse is available at https://github.com/boshizhang123/SGDFuse.",
    "published": "2025-08-07T10:58:52Z",
    "updated": "2025-11-24T05:44:55Z",
    "link": "http://arxiv.org/pdf/2508.05264v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Xiaoyang Zhang",
      "jinjiang Li",
      "Guodong Fan",
      "Yakun Ju",
      "Linwei Fan",
      "Jun Liu",
      "Alex C. Kot"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.16114v2",
    "title": "GFlowGR: Fine-tuning Generative Recommendation Frameworks with Generative Flow Networks",
    "summary": "Generative recommendations (GR), which usually include item tokenizers and generative Large Language Models (LLMs), have demonstrated remarkable success across a wide range of scenarios. The majority of existing research efforts primarily concentrate on developing powerful item tokenizers or advancing LLM decoding strategies to attain superior performance. However, the critical fine-tuning step in GR frameworks, which is essential for adapting LLMs to recommendation data, remains largely unexplored. Current approaches predominantly rely on either the next-token prediction loss of supervised fine-tuning (SFT) or recommendationspecific direct preference optimization (DPO) strategies. Both methods ignore the exploration of possible positive unobserved samples, which is commonly referred to as the exposure bias problem. To mitigate this problem, this paper treats the GR as a multi-step generation task and constructs a GFlowNets-based fine-tuning framework (GFlowGR). The proposed framework integrates collaborative knowledge from traditional recommender systems to create an adaptive trajectory sampler and a comprehensive reward model. Leveraging the diverse generation property of GFlowNets, along with sampling and heuristic weighting techniques, GFlowGR emerges as a promising approach to mitigate the exposure bias problem. Extensive empirical results on two real-world datasets and with two different GR backbones highlight the effectiveness and robustness of GFlowGR.",
    "published": "2025-06-19T08:04:31Z",
    "updated": "2025-11-24T05:43:01Z",
    "link": "http://arxiv.org/pdf/2506.16114v2.pdf",
    "category": [
      "cs.IR",
      "cs.AI"
    ],
    "authors": [
      "Yejing Wang",
      "Shengyu Zhou",
      "Jinyu Lu",
      "Qidong Liu",
      "Xinhang Li",
      "Wenlin Zhang",
      "Feng Li",
      "Pengjie Wang",
      "Jian Xu",
      "Bo Zheng",
      "Xiangyu Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18781v1",
    "title": "A Novel Dual-Stream Framework for dMRI Tractography Streamline Classification with Joint dMRI and fMRI Data",
    "summary": "Streamline classification is essential to identify anatomically meaningful white matter tracts from diffusion MRI (dMRI) tractography. However, current streamline classification methods rely primarily on the geometric features of the streamline trajectory, failing to distinguish between functionally distinct fiber tracts with similar pathways. To address this, we introduce a novel dual-stream streamline classification framework that jointly analyzes dMRI and functional MRI (fMRI) data to enhance the functional coherence of tract parcellation. We design a novel network that performs streamline classification using a pretrained backbone model for full streamline trajectories, while augmenting with an auxiliary network that processes fMRI signals from fiber endpoint regions. We demonstrate our method by parcellating the corticospinal tract (CST) into its four somatotopic subdivisions. Experimental results from ablation studies and comparisons with state-of-the-art methods demonstrate our approach's superior performance.",
    "published": "2025-11-24T05:31:47Z",
    "updated": "2025-11-24T05:31:47Z",
    "link": "http://arxiv.org/pdf/2511.18781v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Haotian Yan",
      "Bocheng Guo",
      "Jianzhong He",
      "Nir A. Sochen",
      "Ofer Pasternak",
      "Lauren J O'Donnell",
      "Fan Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18780v1",
    "title": "ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection",
    "summary": "Recent progress in video generative models has enabled the creation of high-quality videos from multimodal prompts that combine text and images. While these systems offer enhanced controllability, they also introduce new safety risks, as harmful content can emerge from individual modalities or their interaction. Existing safety methods are often text-only, require prior knowledge of the risk category, or operate as post-generation auditors, struggling to proactively mitigate such compositional, multimodal risks. To address this challenge, we present ConceptGuard, a unified safeguard framework for proactively detecting and mitigating unsafe semantics in multimodal video generation. ConceptGuard operates in two stages: First, a contrastive detection module identifies latent safety risks by projecting fused image-text inputs into a structured concept space; Second, a semantic suppression mechanism steers the generative process away from unsafe concepts by intervening in the prompt's multimodal conditioning. To support the development and rigorous evaluation of this framework, we introduce two novel benchmarks: ConceptRisk, a large-scale dataset for training on multimodal risks, and T2VSafetyBench-TI2V, the first benchmark adapted from T2VSafetyBench for the Text-and-Image-to-Video (TI2V) safety setting. Comprehensive experiments on both benchmarks show that ConceptGuard consistently outperforms existing baselines, achieving state-of-the-art results in both risk detection and safe video generation.",
    "published": "2025-11-24T05:27:05Z",
    "updated": "2025-11-24T05:27:05Z",
    "link": "http://arxiv.org/pdf/2511.18780v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Ruize Ma",
      "Minghong Cai",
      "Yilei Jiang",
      "Jiaming Han",
      "Yi Feng",
      "Yingshui Tan",
      "Xiaoyong Zhu",
      "Bo Zhang",
      "Bo Zheng",
      "Xiangyu Yue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18775v1",
    "title": "Rethinking Garment Conditioning in Diffusion-based Virtual Try-On",
    "summary": "Virtual Try-On (VTON) is the task of synthesizing an image of a person wearing a target garment, conditioned on a person image and a garment image. While diffusion-based VTON models featuring a Dual UNet architecture demonstrate superior fidelity compared to single UNet models, they incur substantial computational and memory overhead due to their heavy structure. In this study, through visualization analysis and theoretical analysis, we derived three hypotheses regarding the learning of context features to condition the denoising process. Based on these hypotheses, we developed Re-CatVTON, an efficient single UNet model that achieves high performance. We further enhance the model by introducing a modified classifier-free guidance strategy tailored for VTON's spatial concatenation conditioning, and by directly injecting the ground-truth garment latent derived from the clean garment latent to prevent the accumulation of prediction error. The proposed Re-CatVTON significantly improves performance compared to its predecessor (CatVTON) and requires less computation and memory than the high-performance Dual UNet model, Leffa. Our results demonstrate improved FID, KID, and LPIPS scores, with only a marginal decrease in SSIM, establishing a new efficiency-performance trade-off for single UNet VTON models.",
    "published": "2025-11-24T05:19:44Z",
    "updated": "2025-11-24T05:19:44Z",
    "link": "http://arxiv.org/pdf/2511.18775v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Kihyun Na",
      "Jinyoung Choi",
      "Injung Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18772v1",
    "title": "Re-Key-Free, Risky-Free: Adaptable Model Usage Control",
    "summary": "Deep neural networks (DNNs) have become valuable intellectual property of model owners, due to the substantial resources required for their development. To protect these assets in the deployed environment, recent research has proposed model usage control mechanisms to ensure models cannot be used without proper authorization. These methods typically lock the utility of the model by embedding an access key into its parameters. However, they often assume static deployment, and largely fail to withstand continual post-deployment model updates, such as fine-tuning or task-specific adaptation. In this paper, we propose ADALOC, to endow key-based model usage control with adaptability during model evolution. It strategically selects a subset of weights as an intrinsic access key, which enables all model updates to be confined to this key throughout the evolution lifecycle. ADALOC enables using the access key to restore the keyed model to the latest authorized states without redistributing the entire network (i.e., adaptation), and frees the model owner from full re-keying after each model update (i.e., lock preservation). We establish a formal foundation to underpin ADALOC, providing crucial bounds such as the errors introduced by updates restricted to the access key. Experiments on standard benchmarks, such as CIFAR-100, Caltech-256, and Flowers-102, and modern architectures, including ResNet, DenseNet, and ConvNeXt, demonstrate that ADALOC achieves high accuracy under significant updates while retaining robust protections. Specifically, authorized usages consistently achieve strong task-specific performance, while unauthorized usage accuracy drops to near-random guessing levels (e.g., 1.01% on CIFAR-100), compared to up to 87.01% without ADALOC. This shows that ADALOC can offer a practical solution for adaptive and protected DNN deployment in evolving real-world scenarios.",
    "published": "2025-11-24T05:13:45Z",
    "updated": "2025-11-24T05:13:45Z",
    "link": "http://arxiv.org/pdf/2511.18772v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI"
    ],
    "authors": [
      "Zihan Wang",
      "Zhongkui Ma",
      "Xinguo Feng",
      "Chuan Yan",
      "Dongge Liu",
      "Ruoxi Sun",
      "Derui Wang",
      "Minhui Xue",
      "Guangdong Bai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.10638v3",
    "title": "Studying Classifier(-Free) Guidance From a Classifier-Centric Perspective",
    "summary": "Classifier-free guidance has become a staple for conditional generation with denoising diffusion models. However, a comprehensive understanding of classifier-free guidance is still missing. In this work, we carry out an empirical study to provide a fresh perspective on classifier-free guidance. Concretely, instead of solely focusing on classifier-free guidance, we trace back to the root, i.e., classifier guidance, pinpoint the key assumption for the derivation, and conduct a systematic study to understand the role of the classifier. On 1D data, we find that both classifier guidance and classifier-free guidance achieve conditional generation by pushing the denoising diffusion trajectories away from decision boundaries, i.e., areas where conditional information is usually entangled and is hard to learn. To validate this classifier-centric perspective on high-dimensional data, we assess whether a flow-matching postprocessing step that is designed to narrow the gap between a pre-trained diffusion model's learned distribution and the real data distribution, especially near decision boundaries, can improve the performance. Experiments on various datasets verify our classifier-centric understanding.",
    "published": "2025-03-13T17:59:59Z",
    "updated": "2025-11-24T05:01:32Z",
    "link": "http://arxiv.org/pdf/2503.10638v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Xiaoming Zhao",
      "Alexander G. Schwing"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18766v1",
    "title": "Unsupervised Multi-View Visual Anomaly Detection via Progressive Homography-Guided Alignment",
    "summary": "Unsupervised visual anomaly detection from multi-view images presents a significant challenge: distinguishing genuine defects from benign appearance variations caused by viewpoint changes. Existing methods, often designed for single-view inputs, treat multiple views as a disconnected set of images, leading to inconsistent feature representations and a high false-positive rate. To address this, we introduce ViewSense-AD (VSAD), a novel framework that learns viewpoint-invariant representations by explicitly modeling geometric consistency across views. At its core is our Multi-View Alignment Module (MVAM), which leverages homography to project and align corresponding feature regions between neighboring views. We integrate MVAM into a View-Align Latent Diffusion Model (VALDM), enabling progressive and multi-stage alignment during the denoising process. This allows the model to build a coherent and holistic understanding of the object's surface from coarse to fine scales. Furthermore, a lightweight Fusion Refiner Module (FRM) enhances the global consistency of the aligned features, suppressing noise and improving discriminative power. Anomaly detection is performed by comparing multi-level features from the diffusion model against a learned memory bank of normal prototypes. Extensive experiments on the challenging RealIAD and MANTA datasets demonstrate that VSAD sets a new state-of-the-art, significantly outperforming existing methods in pixel, view, and sample-level visual anomaly proving its robustness to large viewpoint shifts and complex textures.",
    "published": "2025-11-24T05:01:16Z",
    "updated": "2025-11-24T05:01:16Z",
    "link": "http://arxiv.org/pdf/2511.18766v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Xintao Chen",
      "Xiaohao Xu",
      "Bozhong Zheng",
      "Yun Liu",
      "Yingna Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.21519v4",
    "title": "Provable Scaling Laws of Feature Emergence from Learning Dynamics of Grokking",
    "summary": "While the phenomenon of grokking, i.e., delayed generalization, has been studied extensively, it remains an open problem whether there is a mathematical framework that characterizes what kind of features will emerge, how and in which conditions it happens, and is closely related to the gradient dynamics of the training, for complex structured inputs. We propose a novel framework, named $\\mathbf{Li}_2$, that captures three key stages for the grokking behavior of 2-layer nonlinear networks: (I) Lazy learning, (II) independent feature learning and (III) interactive feature learning. At the lazy learning stage, top layer overfits to random hidden representation and the model appears to memorize. Thanks to lazy learning and weight decay, the backpropagated gradient $G_F$ from the top layer now carries information about the target label, with a specific structure that enables each hidden node to learn their representation independently. Interestingly, the independent dynamics follows exactly the gradient ascent of an energy function $E$, and its local maxima are precisely the emerging features. We study whether these local-optima induced features are generalizable, their representation power, and how they change on sample size, in group arithmetic tasks. When hidden nodes start to interact in the later stage of learning, we provably show how $G_F$ changes to focus on missing features that need to be learned. Our study sheds lights on roles played by key hyperparameters such as weight decay, learning rate and sample sizes in grokking, leads to provable scaling laws of feature emergence, memorization and generalization, and reveals why recent optimizers such as Muon can be effective, from the first principles of gradient dynamics. Our analysis can be extended to multi-layers. The code is available at https://github.com/yuandong-tian/understanding/tree/main/ssl/real-dataset/cogo.",
    "published": "2025-09-25T20:08:09Z",
    "updated": "2025-11-24T04:59:04Z",
    "link": "http://arxiv.org/pdf/2509.21519v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Yuandong Tian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25522v4",
    "title": "Comparative Study of UNet-based Architectures for Liver Tumor Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography",
    "summary": "Segmentation of liver structures in multi-phase contrast-enhanced computed tomography (CECT) plays a crucial role in computer-aided diagnosis and treatment planning for liver diseases, including tumor detection. In this study, we investigate the performance of UNet-based architectures for liver tumor segmentation, starting from the original UNet and extending to UNet3+ with various backbone networks. We evaluate ResNet, Transformer-based, and State-space (Mamba) backbones, all initialized with pretrained weights. Surprisingly, despite the advances in modern architecture, ResNet-based models consistently outperform Transformer- and Mamba-based alternatives across multiple evaluation metrics. To further improve segmentation quality, we introduce attention mechanisms into the backbone and observe that incorporating the Convolutional Block Attention Module (CBAM) yields the best performance. ResNetUNet3+ with CBAM module not only produced the best overlap metrics with a Dice score of 0.755 and IoU of 0.662, but also achieved the most precise boundary delineation, evidenced by the lowest HD95 distance of 77.911. The model's superiority was further cemented by its leading overall accuracy of 0.925 and specificity of 0.926, showcasing its robust capability in accurately identifying both lesion and healthy tissue. To further enhance interpretability, Grad-CAM visualizations were employed to highlight the region's most influential predictions, providing insights into its decision-making process. These findings demonstrate that classical ResNet architecture, when combined with modern attention modules, remain highly competitive for medical image segmentation tasks, offering a promising direction for liver tumor detection in clinical practice.",
    "published": "2025-10-29T13:46:19Z",
    "updated": "2025-11-24T04:55:39Z",
    "link": "http://arxiv.org/pdf/2510.25522v4.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Doan-Van-Anh Ly",
      "Thi-Thu-Hien Pham",
      "Thanh-Hai Le"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18760v1",
    "title": "HERMES: Towards Efficient and Verifiable Mathematical Reasoning in LLMs",
    "summary": "Informal mathematics has been central to modern large language model (LLM) reasoning, offering flexibility and enabling efficient construction of arguments. However, purely informal reasoning is prone to logical gaps and subtle errors that are difficult to detect and correct. In contrast, formal theorem proving provides rigorous, verifiable mathematical reasoning, where each inference step is checked by a trusted compiler in systems such as Lean, but lacks the exploratory freedom of informal problem solving. This mismatch leaves current LLM-based math agents without a principled way to combine the strengths of both paradigms. In this work, we introduce Hermes, the first tool-assisted agent that explicitly interleaves informal reasoning with formally verified proof steps in Lean. The framework performs intermediate formal checking to prevent reasoning drift and employs a memory module that maintains proof continuity across long, multi-step reasoning chains, enabling both exploration and verification within a single workflow. We evaluate Hermes on four challenging mathematical reasoning benchmarks using LLMs of varying parameter scales, from small models to state-of-the-art systems. Across all settings, Hermes reliably improves the reasoning accuracy of base models while substantially reducing token usage and computational cost compared to reward-based approaches. On difficult datasets such as AIME'25, Hermes achieves up to a 67% accuracy improvement while using 80% fewer total inference FLOPs. The implementation and codebase are publicly available at https://github.com/aziksh-ospanov/HERMES.",
    "published": "2025-11-24T04:50:18Z",
    "updated": "2025-11-24T04:50:18Z",
    "link": "http://arxiv.org/pdf/2511.18760v1.pdf",
    "category": [
      "cs.AI",
      "cs.FL"
    ],
    "authors": [
      "Azim Ospanov",
      "Zijin Feng",
      "Jiacheng Sun",
      "Haoli Bai",
      "Xin Shen",
      "Farzan Farnia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.15289v5",
    "title": "SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage",
    "summary": "Large language models (LLMs) have made significant advancements across various tasks, but their safety alignment remain a major concern. Exploring jailbreak prompts can expose LLMs' vulnerabilities and guide efforts to secure them. Existing methods primarily design sophisticated instructions for the LLM to follow, or rely on multiple iterations, which could hinder the performance and efficiency of jailbreaks. In this work, we propose a novel jailbreak paradigm, Simple Assistive Task Linkage (SATA), which can effectively circumvent LLM safeguards and elicit harmful responses. Specifically, SATA first masks harmful keywords within a malicious query to generate a relatively benign query containing one or multiple [MASK] special tokens. It then employs a simple assistive task such as a masked language model task or an element lookup by position task to encode the semantics of the masked keywords. Finally, SATA links the assistive task with the masked query to jointly perform the jailbreak. Extensive experiments show that SATA achieves state-of-the-art performance and outperforms baselines by a large margin. Specifically, on AdvBench dataset, with mask language model (MLM) assistive task, SATA achieves an overall attack success rate (ASR) of 85% and harmful score (HS) of 4.57, and with element lookup by position (ELP) assistive task, SATA attains an overall ASR of 76% and HS of 4.43.",
    "published": "2024-12-19T05:57:37Z",
    "updated": "2025-11-24T04:42:27Z",
    "link": "http://arxiv.org/pdf/2412.15289v5.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Xiaoning Dong",
      "Wenbo Hu",
      "Wei Xu",
      "Tianxing He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2402.14268v2",
    "title": "Can Large Language Models Detect Misinformation in Scientific News Reporting?",
    "summary": "Scientific facts are often spun in the popular press with the intent to influence public opinion and action, as was evidenced during the COVID-19 pandemic. Automatic detection of misinformation in the scientific domain is challenging because of the distinct styles of writing in these two media types and is still in its nascence. Most research on the validity of scientific reporting treats this problem as a claim verification challenge. In doing so, significant expert human effort is required to generate appropriate claims. Our solution bypasses this step and addresses a more real-world scenario where such explicit, labeled claims may not be available. The central research question of this paper is whether it is possible to use large language models (LLMs) to detect misinformation in scientific reporting. To this end, we first present a new labeled dataset SciNews, containing 2.4k scientific news stories drawn from trusted and untrustworthy sources, paired with related abstracts from the CORD-19 database. Our dataset includes both human-written and LLM-generated news articles, making it more comprehensive in terms of capturing the growing trend of using LLMs to generate popular press articles. Then, we identify dimensions of scientific validity in science news articles and explore how this can be integrated into the automated detection of scientific misinformation. We propose several baseline architectures using LLMs to automatically detect false representations of scientific findings in the popular press. For each of these architectures, we use several prompt engineering strategies including zero-shot, few-shot, and chain-of-thought prompting. We also test these architectures and prompting strategies on GPT-3.5, GPT-4, and Llama2-7B, Llama2-13B.",
    "published": "2024-02-22T04:07:00Z",
    "updated": "2025-11-24T04:39:03Z",
    "link": "http://arxiv.org/pdf/2402.14268v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "authors": [
      "Yupeng Cao",
      "Aishwarya Muralidharan Nair",
      "Nastaran Jamalipour Soofi",
      "Elyon Eyimife",
      "K. P. Subbalakshmi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18746v1",
    "title": "Any4D: Open-Prompt 4D Generation from Natural Language and Images",
    "summary": "While video-generation-based embodied world models have gained increasing attention, their reliance on large-scale embodied interaction data remains a key bottleneck. The scarcity, difficulty of collection, and high dimensionality of embodied data fundamentally limit the alignment granularity between language and actions and exacerbate the challenge of long-horizon video generation--hindering generative models from achieving a \\textit{\"GPT moment\"} in the embodied domain. There is a naive observation: \\textit{the diversity of embodied data far exceeds the relatively small space of possible primitive motions}. Based on this insight, we propose \\textbf{Primitive Embodied World Models} (PEWM), which restricts video generation to fixed shorter horizons, our approach \\textit{1) enables} fine-grained alignment between linguistic concepts and visual representations of robotic actions, \\textit{2) reduces} learning complexity, \\textit{3) improves} data efficiency in embodied data collection, and \\textit{4) decreases} inference latency. By equipping with a modular Vision-Language Model (VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further enables flexible closed-loop control and supports compositional generalization of primitive-level policies over extended, complex tasks. Our framework leverages the spatiotemporal vision priors in video models and the semantic awareness of VLMs to bridge the gap between fine-grained physical interaction and high-level reasoning, paving the way toward scalable, interpretable, and general-purpose embodied intelligence.",
    "published": "2025-11-24T04:17:26Z",
    "updated": "2025-11-24T04:17:26Z",
    "link": "http://arxiv.org/pdf/2511.18746v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Hao Li",
      "Qiao Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.13558v7",
    "title": "Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life",
    "summary": "Battery degradation significantly impacts the reliability and efficiency of energy storage systems, particularly in electric vehicles and industrial applications. Predicting the remaining useful life (RUL) of lithium-ion batteries is crucial for optimizing maintenance schedules, reducing costs, and improving safety. Traditional RUL prediction methods often struggle with nonlinear degradation patterns and uncertainty quantification. To address these challenges, we propose a hybrid survival analysis framework integrating survival data reconstruction, survival model learning, and survival probability estimation. Our approach transforms battery voltage time series into time-to-failure data using path signatures. The multiple Cox-based survival models and machine-learning-based methods, such as DeepHit and MTLR, are learned to predict battery failure-free probabilities over time. Experiments conducted on the Toyota battery and NASA battery datasets demonstrate the effectiveness of our approach, achieving high time-dependent AUC and concordance index (C-Index) while maintaining a low integrated Brier score.",
    "published": "2025-03-17T02:49:34Z",
    "updated": "2025-11-24T04:17:23Z",
    "link": "http://arxiv.org/pdf/2503.13558v7.pdf",
    "category": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Jingyuan Xue",
      "Xiaozhen Zhao",
      "Dongjing Jiang",
      "Qingchong Jiao",
      "Redouane EL Bouchtaoui",
      "Jianfei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18743v1",
    "title": "RhinoInsight: Improving Deep Research through Control Mechanisms for Model Behavior and Context",
    "summary": "Large language models are evolving from single-turn responders into tool-using agents capable of sustained reasoning and decision-making for deep research. Prevailing systems adopt a linear pipeline of plan to search to write to a report, which suffers from error accumulation and context rot due to the lack of explicit control over both model behavior and context. We introduce RhinoInsight, a deep research framework that adds two control mechanisms to enhance robustness, traceability, and overall quality without parameter updates. First, a Verifiable Checklist module transforms user requirements into traceable and verifiable sub-goals, incorporates human or LLM critics for refinement, and compiles a hierarchical outline to anchor subsequent actions and prevent non-executable planning. Second, an Evidence Audit module structures search content, iteratively updates the outline, and prunes noisy context, while a critic ranks and binds high-quality evidence to drafted content to ensure verifiability and reduce hallucinations. Our experiments demonstrate that RhinoInsight achieves state-of-the-art performance on deep research tasks while remaining competitive on deep search tasks.",
    "published": "2025-11-24T04:12:41Z",
    "updated": "2025-11-24T04:12:41Z",
    "link": "http://arxiv.org/pdf/2511.18743v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yu Lei",
      "Shuzheng Si",
      "Wei Wang",
      "Yifei Wu",
      "Gang Chen",
      "Fanchao Qi",
      "Maosong Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18742v1",
    "title": "ProxT2I: Efficient Reward-Guided Text-to-Image Generation via Proximal Diffusion",
    "summary": "Diffusion models have emerged as a dominant paradigm for generative modeling across a wide range of domains, including prompt-conditional generation. The vast majority of samplers, however, rely on forward discretization of the reverse diffusion process and use score functions that are learned from data. Such forward and explicit discretizations can be slow and unstable, requiring a large number of sampling steps to produce good-quality samples. In this work we develop a text-to-image (T2I) diffusion model based on backward discretizations, dubbed ProxT2I, relying on learned and conditional proximal operators instead of score functions. We further leverage recent advances in reinforcement learning and policy optimization to optimize our samplers for task-specific rewards. Additionally, we develop a new large-scale and open-source dataset comprising 15 million high-quality human images with fine-grained captions, called LAION-Face-T2I-15M, for training and evaluation. Our approach consistently enhances sampling efficiency and human-preference alignment compared to score-based baselines, and achieves results on par with existing state-of-the-art and open-source text-to-image models while requiring lower compute and smaller model size, offering a lightweight yet performant solution for human text-to-image generation.",
    "published": "2025-11-24T04:10:53Z",
    "updated": "2025-11-24T04:10:53Z",
    "link": "http://arxiv.org/pdf/2511.18742v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Zhenghan Fang",
      "Jian Zheng",
      "Qiaozi Gao",
      "Xiaofeng Gao",
      "Jeremias Sulam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18739v1",
    "title": "A Problem-Oriented Taxonomy of Evaluation Metrics for Time Series Anomaly Detection",
    "summary": "Time series anomaly detection is widely used in IoT and cyber-physical systems, yet its evaluation remains challenging due to diverse application objectives and heterogeneous metric assumptions. This study introduces a problem-oriented framework that reinterprets existing metrics based on the specific evaluation challenges they are designed to address, rather than their mathematical forms or output structures. We categorize over twenty commonly used metrics into six dimensions: 1) basic accuracy-driven evaluation; 2) timeliness-aware reward mechanisms; 3) tolerance to labeling imprecision; 4) penalties reflecting human-audit cost; 5) robustness against random or inflated scores; and 6) parameter-free comparability for cross-dataset benchmarking. Comprehensive experiments are conducted to examine metric behavior under genuine, random, and oracle detection scenarios. By comparing their resulting score distributions, we quantify each metric's discriminative ability -- its capability to distinguish meaningful detections from random noise. The results show that while most event-level metrics exhibit strong separability, several widely used metrics (e.g., NAB, Point-Adjust) demonstrate limited resistance to random-score inflation. These findings reveal that metric suitability must be inherently task-dependent and aligned with the operational objectives of IoT applications. The proposed framework offers a unified analytical perspective for understanding existing metrics and provides practical guidance for selecting or developing more context-aware, robust, and fair evaluation methodologies for time series anomaly detection.",
    "published": "2025-11-24T04:09:04Z",
    "updated": "2025-11-24T04:09:04Z",
    "link": "http://arxiv.org/pdf/2511.18739v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Kaixiang Yang",
      "Jiarong Liu",
      "Yupeng Song",
      "Shuanghua Yang",
      "Yujue Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13219v2",
    "title": "FoleyBench: A Benchmark For Video-to-Audio Models",
    "summary": "Video-to-audio generation (V2A) is of increasing importance in domains such as film post-production, AR/VR, and sound design, particularly for the creation of Foley sound effects synchronized with on-screen actions. Foley requires generating audio that is both semantically aligned with visible events and temporally aligned with their timing. Yet, there is a mismatch between evaluation and downstream applications due to the absence of a benchmark tailored to Foley-style scenarios. We find that 74% of videos from past evaluation datasets have poor audio-visual correspondence. Moreover, they are dominated by speech and music, domains that lie outside the use case for Foley. To address this gap, we introduce FoleyBench, the first large-scale benchmark explicitly designed for Foley-style V2A evaluation. FoleyBench contains 5,000 (video, ground-truth audio, text caption) triplets, each featuring visible sound sources with audio causally tied to on-screen events. The dataset is built using an automated, scalable pipeline applied to in-the-wild internet videos from YouTube-based and Vimeo-based sources. Compared to past datasets, we show that videos from FoleyBench have stronger coverage of sound categories from a taxonomy specifically designed for Foley sound. Each clip is further labeled with metadata capturing source complexity, UCS/AudioSet category, and video length, enabling fine-grained analysis of model performance and failure modes. We benchmark several state-of-the-art V2A models, evaluating them on audio quality, audio-video alignment, temporal synchronization, and audio-text consistency. Samples are available at: https://gclef-cmu.org/foleybench",
    "published": "2025-11-17T10:34:59Z",
    "updated": "2025-11-24T04:08:20Z",
    "link": "http://arxiv.org/pdf/2511.13219v2.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "authors": [
      "Satvik Dixit",
      "Koichi Saito",
      "Zhi Zhong",
      "Yuki Mitsufuji",
      "Chris Donahue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18735v1",
    "title": "Thinking Ahead: Foresight Intelligence in MLLMs and World Models",
    "summary": "In this work, we define Foresight Intelligence as the capability to anticipate and interpret future events-an ability essential for applications such as autonomous driving, yet largely overlooked by existing research. To bridge this gap, we introduce FSU-QA, a new Visual Question-Answering (VQA) dataset specifically designed to elicit and evaluate Foresight Intelligence. Using FSU-QA, we conduct the first comprehensive study of state-of-the-art Vision-Language Models (VLMs) under foresight-oriented tasks, revealing that current models still struggle to reason about future situations. Beyond serving as a benchmark, FSU-QA also enables the assessment of world models by measuring the semantic coherence of their generated predictions, quantified through performance gains when VLMs are augmented with such outputs. Our experiments further demonstrate that FSU-QA can effectively enhance foresight reasoning: even small VLMs fine-tuned on FSU-QA surpass much larger, advanced models by a substantial margin. Together, these findings position FSU-QA as a principled foundation for developing next-generation models capable of truly anticipating and understanding future events.",
    "published": "2025-11-24T04:04:59Z",
    "updated": "2025-11-24T04:04:59Z",
    "link": "http://arxiv.org/pdf/2511.18735v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Zhantao Gong",
      "Liaoyuan Fan",
      "Qing Guo",
      "Xun Xu",
      "Xulei Yang",
      "Shijie Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18734v1",
    "title": "Yo'City: Personalized and Boundless 3D Realistic City Scene Generation via Self-Critic Expansion",
    "summary": "Realistic 3D city generation is fundamental to a wide range of applications, including virtual reality and digital twins. However, most existing methods rely on training a single diffusion model, which limits their ability to generate personalized and boundless city-scale scenes. In this paper, we present Yo'City, a novel agentic framework that enables user-customized and infinitely expandable 3D city generation by leveraging the reasoning and compositional capabilities of off-the-shelf large models. Specifically, Yo'City first conceptualize the city through a top-down planning strategy that defines a hierarchical \"City-District-Grid\" structure. The Global Planner determines the overall layout and potential functional districts, while the Local Designer further refines each district with detailed grid-level descriptions. Subsequently, the grid-level 3D generation is achieved through a \"produce-refine-evaluate\" isometric image synthesis loop, followed by image-to-3D generation. To simulate continuous city evolution, Yo'City further introduces a user-interactive, relationship-guided expansion mechanism, which performs scene graph-based distance- and semantics-aware layout optimization, ensuring spatially coherent city growth. To comprehensively evaluate our method, we construct a diverse benchmark dataset and design six multi-dimensional metrics that assess generation quality from the perspectives of semantics, geometry, texture, and layout. Extensive experiments demonstrate that Yo'City consistently outperforms existing state-of-the-art methods across all evaluation aspects.",
    "published": "2025-11-24T04:02:48Z",
    "updated": "2025-11-24T04:02:48Z",
    "link": "http://arxiv.org/pdf/2511.18734v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Keyang Lu",
      "Sifan Zhou",
      "Hongbin Xu",
      "Gang Xu",
      "Zhifei Yang",
      "Yikai Wang",
      "Zhen Xiao",
      "Jieyi Long",
      "Ming Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.20840v3",
    "title": "Learning Primitive Embodied World Models: Towards Scalable Robotic Learning",
    "summary": "While video-generation-based embodied world models have gained increasing attention, their reliance on large-scale embodied interaction data remains a key bottleneck. The scarcity, difficulty of collection, and high dimensionality of embodied data fundamentally limit the alignment granularity between language and actions and exacerbate the challenge of long-horizon video generation--hindering generative models from achieving a \"GPT moment\" in the embodied domain. There is a naive observation: the diversity of embodied data far exceeds the relatively small space of possible primitive motions. Based on this insight, we propose a novel paradigm for world modeling--Primitive Embodied World Models (PEWM). By restricting video generation to fixed short horizons, our approach 1) enables fine-grained alignment between linguistic concepts and visual representations of robotic actions, 2) reduces learning complexity, 3) improves data efficiency in embodied data collection, and 4) decreases inference latency. By equipping with a modular Vision-Language Model (VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further enables flexible closed-loop control and supports compositional generalization of primitive-level policies over extended, complex tasks. Our framework leverages the spatiotemporal vision priors in video models and the semantic awareness of VLMs to bridge the gap between fine-grained physical interaction and high-level reasoning, paving the way toward scalable, interpretable, and general-purpose embodied intelligence.",
    "published": "2025-08-28T14:31:48Z",
    "updated": "2025-11-24T03:42:01Z",
    "link": "http://arxiv.org/pdf/2508.20840v3.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.MM"
    ],
    "authors": [
      "Qiao Sun",
      "Liujia Yang",
      "Wei Tang",
      "Wei Huang",
      "Kaixin Xu",
      "Yongchao Chen",
      "Mingyu Liu",
      "Jiange Yang",
      "Haoyi Zhu",
      "Yating Wang",
      "Tong He",
      "Yilun Chen",
      "Xili Dai",
      "Nanyang Ye",
      "Qinying Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.16216v4",
    "title": "GMoE: Empowering LLMs Fine-Tuning via MoE Graph Collaboration",
    "summary": "The sparse Mixture-of-Experts (MoE) architecture of large language models (LLMs) confronts an inherent issue of load imbalance arising from the simplistic linear router strategy, which ultimately causes the instability and inefficient learning of LLMs. To address this challenge, we introduce a novel MoE graph-based framework $\\textbf{GMoE}$, aimed at enhancing the collaboration among multiple experts. In GMoE, a graph router function is designed to capture the collaboration signals among experts. This enables all experts to dynamically allocate information derived from input data by sharing information with their neighboring experts. Moreover, we put forward two coordination strategies in GMoE: the $\\textit{Poisson distribution-based distinction strategy}$ and the $\\textit{Normal distribution-based balance strategy}$, to further release the capacity of each expert and increase the model stability in the fine-tuning of LLMs. Specifically, we leverage a parameter-efficient fine-tuning technique, i.e., Low-Rank Adaptation (LoRA), to implement the graph MoE architecture. Extensive experiments on four real-world benchmark datasets demonstrate the effectiveness of GMoE, showing the benefits of facilitating collaborations of multiple experts in LLM fine-tuning. The code of experimental implementation is available at https://github.com/BAI-LAB/GMoE",
    "published": "2024-12-18T02:18:57Z",
    "updated": "2025-11-24T03:37:48Z",
    "link": "http://arxiv.org/pdf/2412.16216v4.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Ting Bai",
      "Yue Yu",
      "Le Huang",
      "Zenan Xu",
      "Chuan Shi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.06659v3",
    "title": "DriveSuprim: Towards Precise Trajectory Selection for End-to-End Planning",
    "summary": "Autonomous vehicles must navigate safely in complex driving environments. Imitating a single expert trajectory, as in regression-based approaches, usually does not explicitly assess the safety of the predicted trajectory. Selection-based methods address this by generating and scoring multiple trajectory candidates and predicting the safety score for each. However, they face optimization challenges in precisely selecting the best option from thousands of candidates and distinguishing subtle but safety-critical differences, especially in rare and challenging scenarios. We propose DriveSuprim to overcome these challenges and advance the selection-based paradigm through a coarse-to-fine paradigm for progressive candidate filtering, a rotation-based augmentation method to improve robustness in out-of-distribution scenarios, and a self-distillation framework to stabilize training. DriveSuprim achieves state-of-the-art performance, reaching 93.5% PDMS in NAVSIM v1 and 87.1% EPDMS in NAVSIM v2 without extra data, with 83.02 Driving Score and 60.00 Success Rate on the Bench2Drive benchmark, demonstrating superior planning capabilities in various driving scenarios.",
    "published": "2025-06-07T04:39:06Z",
    "updated": "2025-11-24T03:32:51Z",
    "link": "http://arxiv.org/pdf/2506.06659v3.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Wenhao Yao",
      "Zhenxin Li",
      "Shiyi Lan",
      "Zi Wang",
      "Xinglong Sun",
      "Jose M. Alvarez",
      "Zuxuan Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.16685v2",
    "title": "Ellipsoid-Based Decision Boundaries for Open Intent Classification",
    "summary": "Textual open intent classification is crucial for real-world dialogue systems, enabling robust detection of unknown user intents without prior knowledge and contributing to the robustness of the system. While adaptive decision boundary methods have shown great potential by eliminating manual threshold tuning, existing approaches assume isotropic distributions of known classes, restricting boundaries to balls and overlooking distributional variance along different directions. To address this limitation, we propose EliDecide, a novel method that learns ellipsoid decision boundaries with varying scales along different feature directions. First, we employ supervised contrastive learning to obtain a discriminative feature space for known samples. Second, we apply learnable matrices to parameterize ellipsoids as the boundaries of each known class, offering greater flexibility than spherical boundaries defined solely by centers and radii. Third, we optimize the boundaries via a novelly designed dual loss function that balances empirical and open-space risks: expanding boundaries to cover known samples while contracting them against synthesized pseudo-open samples. Our method achieves state-of-the-art performance on multiple text intent benchmarks and further on a question classification dataset. The flexibility of the ellipsoids demonstrates superior open intent detection capability and strong potential for generalization to more text classification tasks in diverse complex open-world scenarios.",
    "published": "2025-11-13T11:31:14Z",
    "updated": "2025-11-24T03:32:27Z",
    "link": "http://arxiv.org/pdf/2511.16685v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yuetian Zou",
      "Hanlei Zhang",
      "Hua Xu",
      "Songze Li",
      "Long Xiao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18723v1",
    "title": "N2N: A Parallel Framework for Large-Scale MILP under Distributed Memory",
    "summary": "Parallelization has emerged as a promising approach for accelerating MILP solving. However, the complexity of the branch-and-bound (B&B) framework and the numerous effective algorithm components in MILP solvers make it difficult to parallelize. In this study, a scalable parallel framework, N2N (a node-to-node framework that maps the B&B nodes to distributed computing nodes), was proposed to solve large-scale problems in a distributed memory computing environment. Both deterministic and nondeterministic modes are supported, and the framework is designed to be easily integrated with existing solvers. Regarding the deterministic mode, a novel sliding-window-based algorithm was designed and implemented to ensure that tasks are generated and solved in a deterministic order. Moreover, several advanced techniques, such as the utilization of CP search and general primal heuristics, have been developed to fully utilize distributed computing resources and capabilities of base solvers. Adaptive solving and data communication optimization were also investigated. A popular open-source MILP solver, SCIP, was integrated into N2N as the base solver, yielding N2N-SCIP. Extensive computational experiments were conducted to evaluate the performance of N2N-SCIP compared to ParaSCIP, which is a state-of-the-art distributed parallel MILP solver under the UG framework. The nondeterministic N2N-SCIP achieves speedups of 22.52 and 12.71 with 1,000 MPI processes on the Kunpeng and x86 computing clusters, which is 1.98 and 2.08 times faster than ParaSCIP, respectively. In the deterministic mode, N2N-SCIP also shows significant performance improvements over ParaSCIP across different process numbers and computing clusters. To validate the generality of N2N, HiGHS, another open-source solver, was integrated into N2N. The related results are analyzed, and the requirements of N2N on base solvers are also concluded.",
    "published": "2025-11-24T03:29:55Z",
    "updated": "2025-11-24T03:29:55Z",
    "link": "http://arxiv.org/pdf/2511.18723v1.pdf",
    "category": [
      "cs.AI",
      "cs.DC",
      "math.OC"
    ],
    "authors": [
      "Longfei Wang",
      "Junyan Liu",
      "Fan Zhang",
      "Jiangwen Wei",
      "Yuanhua Tang",
      "Jie Sun",
      "Xiaodong Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.20990v2",
    "title": "FinAudio: A Benchmark for Audio Large Language Models in Financial Applications",
    "summary": "Audio Large Language Models (AudioLLMs) have received widespread attention and have significantly improved performance on audio tasks such as conversation, audio understanding, and automatic speech recognition (ASR). Despite these advancements, there is an absence of a benchmark for assessing AudioLLMs in financial scenarios, where audio data, such as earnings conference calls and CEO speeches, are crucial resources for financial analysis and investment decisions. In this paper, we introduce \\textsc{FinAudio}, the first benchmark designed to evaluate the capacity of AudioLLMs in the financial domain. We first define three tasks based on the unique characteristics of the financial domain: 1) ASR for short financial audio, 2) ASR for long financial audio, and 3) summarization of long financial audio. Then, we curate two short and two long audio datasets, respectively, and develop a novel dataset for financial audio summarization, comprising the \\textsc{FinAudio} benchmark. Then, we evaluate seven prevalent AudioLLMs on \\textsc{FinAudio}. Our evaluation reveals the limitations of existing AudioLLMs in the financial domain and offers insights for improving AudioLLMs. All datasets and codes will be released.",
    "published": "2025-03-26T21:07:51Z",
    "updated": "2025-11-24T03:22:59Z",
    "link": "http://arxiv.org/pdf/2503.20990v2.pdf",
    "category": [
      "cs.CE",
      "cs.AI",
      "cs.MM"
    ],
    "authors": [
      "Yupeng Cao",
      "Haohang Li",
      "Yangyang Yu",
      "Shashidhar Reddy Javaji",
      "Yueru He",
      "Jimin Huang",
      "Qianqian Xie",
      "Xiao-yang Liu",
      "K. P. Subbalakshmi",
      "Meikang Qiu",
      "Sophia Ananiadou",
      "Jian-Yun Nie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18718v1",
    "title": "AIRHILT: A Human-in-the-Loop Testbed for Multimodal Conflict Detection in Aviation",
    "summary": "We introduce AIRHILT (Aviation Integrated Reasoning, Human-in-the-Loop Testbed), a modular and lightweight simulation environment designed to evaluate multimodal pilot and air traffic control (ATC) assistance systems for aviation conflict detection. Built on the open-source Godot engine, AIRHILT synchronizes pilot and ATC radio communications, visual scene understanding from camera streams, and ADS-B surveillance data within a unified, scalable platform. The environment supports pilot- and controller-in-the-loop interactions, providing a comprehensive scenario suite covering both terminal area and en route operational conflicts, including communication errors and procedural mistakes. AIRHILT offers standardized JSON-based interfaces that enable researchers to easily integrate, swap, and evaluate automatic speech recognition (ASR), visual detection, decision-making, and text-to-speech (TTS) models. We demonstrate AIRHILT through a reference pipeline incorporating fine-tuned Whisper ASR, YOLO-based visual detection, ADS-B-based conflict logic, and GPT-OSS-20B structured reasoning, and present preliminary results from representative runway-overlap scenarios, where the assistant achieves an average time-to-first-warning of approximately 7.7 s, with average ASR and vision latencies of approximately 5.9 s and 0.4 s, respectively. The AIRHILT environment and scenario suite are openly available, supporting reproducible research on multimodal situational awareness and conflict detection in aviation; code and scenarios are available at https://github.com/ogarib3/airhilt.",
    "published": "2025-11-24T03:18:55Z",
    "updated": "2025-11-24T03:18:55Z",
    "link": "http://arxiv.org/pdf/2511.18718v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "authors": [
      "Omar Garib",
      "Jayaprakash D. Kambhampaty",
      "Olivia J. Pinon Fischer",
      "Dimitri N. Mavris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18715v1",
    "title": "HuggingR$^{4}$: A Progressive Reasoning Framework for Discovering Optimal Model Companions",
    "summary": "Large Language Models (LLMs) have made remarkable progress in their ability to interact with external interfaces. Selecting reasonable external interfaces has thus become a crucial step in constructing LLM agents. In contrast to invoking API tools, directly calling AI models across different modalities from the community (e.g., HuggingFace) poses challenges due to the vast scale (> 10k), metadata gaps, and unstructured descriptions. Current methods for model selection often involve incorporating entire model descriptions into prompts, resulting in prompt bloat, wastage of tokens and limited scalability. To address these issues, we propose HuggingR$^4$, a novel framework that combines Reasoning, Retrieval, Refinement, and Reflection, to efficiently select models. Specifically, We first perform multiple rounds of reasoning and retrieval to get a coarse list of candidate models. Then, we conduct fine-grained refinement by analyzing candidate model descriptions, followed by reflection to assess results and determine if retrieval scope expansion is necessary. This method reduces token consumption considerably by decoupling user query processing from complex model description handling. Through a pre-established vector database, complex model descriptions are stored externally and retrieved on-demand, allowing the LLM to concentrate on interpreting user intent while accessing only relevant candidate models without prompt bloat. In the absence of standardized benchmarks, we construct a multimodal human-annotated dataset comprising 14,399 user requests across 37 tasks and conduct a thorough evaluation. HuggingR$^4$ attains a workability rate of 92.03% and a reasonability rate of 82.46%, surpassing existing method by 26.51% and 33.25% respectively on GPT-4o-mini.",
    "published": "2025-11-24T03:13:45Z",
    "updated": "2025-11-24T03:13:45Z",
    "link": "http://arxiv.org/pdf/2511.18715v1.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Shaoyin Ma",
      "Jie Song",
      "Huiqiong Wang",
      "Li Sun",
      "Mingli Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18714v1",
    "title": "MAGMA-Edu: Multi-Agent Generative Multimodal Framework for Text-Diagram Educational Question Generation",
    "summary": "Educational illustrations play a central role in communicating abstract concepts, yet current multimodal large language models (MLLMs) remain limited in producing pedagogically coherent and semantically consistent educational visuals. We introduce MAGMA-Edu, a self-reflective multi-agent framework that unifies textual reasoning and diagrammatic synthesis for structured educational problem generation. Unlike existing methods that treat text and image generation independently, MAGMA-Edu employs a two-stage co-evolutionary pipeline: (1) a generation-verification-reflection loop that iteratively refines question statements and solutions for mathematical accuracy, and (2) a code-based intermediate representation that enforces geometric fidelity and semantic alignment during image rendering. Both stages are guided by internal self-reflection modules that evaluate and revise outputs until domain-specific pedagogical constraints are met. Extensive experiments on multimodal educational benchmarks demonstrate the superiority of MAGMA-Edu over state-of-the-art MLLMs. Compared to GPT-4o, MAGMA-Edu improves the average textual metric from 57.01 to 92.31 (+35.3 pp) and boosts image-text consistency (ITC) from 13.20 to 85.24 (+72 pp). Across all model backbones, MAGMA-Edu achieves the highest scores (Avg-Text 96.20, ITC 99.12), establishing a new state of the art for multimodal educational content generation and demonstrating the effectiveness of self-reflective multi-agent collaboration in pedagogically aligned vision-language reasoning.",
    "published": "2025-11-24T03:13:26Z",
    "updated": "2025-11-24T03:13:26Z",
    "link": "http://arxiv.org/pdf/2511.18714v1.pdf",
    "category": [
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Zhenyu Wu",
      "Jian Li",
      "Hua Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18711v1",
    "title": "Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain Adaptation",
    "summary": "In this paper, we study the challenging task of Few-Shot Video Domain Adaptation (FSVDA). The multimodal nature of videos introduces unique challenges, necessitating the simultaneous consideration of both domain alignment and modality collaboration in a few-shot scenario, which is ignored in previous literature. We observe that, under the influence of domain shift, the generalization performance on the target domain of each individual modality, as well as that of fused multimodal features, is constrained. Because each modality is comprised of coupled features with multiple components that exhibit different domain shifts. This variability increases the complexity of domain adaptation, thereby reducing the effectiveness of multimodal feature integration. To address these challenges, we introduce a novel framework of Modality-Collaborative LowRank Decomposers (MC-LRD) to decompose modality-unique and modality-shared features with different domain shift levels from each modality that are more friendly for domain alignment. The MC-LRD comprises multiple decomposers for each modality and Multimodal Decomposition Routers (MDR). Each decomposer has progressively shared parameters across different modalities. The MDR is leveraged to selectively activate the decomposers to produce modality-unique and modality-shared features. To ensure efficient decomposition, we apply orthogonal decorrelation constraints separately to decomposers and subrouters, enhancing their diversity. Furthermore, we propose a cross-domain activation consistency loss to guarantee that target and source samples of the same category exhibit consistent activation preferences of the decomposers, thereby facilitating domain alignment. Extensive experimental results on three public benchmarks demonstrate that our model achieves significant improvements over existing methods.",
    "published": "2025-11-24T03:09:59Z",
    "updated": "2025-11-24T03:09:59Z",
    "link": "http://arxiv.org/pdf/2511.18711v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yuyang Wanyan",
      "Xiaoshan Yang",
      "Weiming Dong",
      "Changsheng Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.15253v2",
    "title": "PresentCoach: Dual-Agent Presentation Coaching through Exemplars and Interactive Feedback",
    "summary": "Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided slides into model presentation videos by combining slide processing, visual-language analysis, narration script generation, personalized voice synthesis, and synchronized video assembly. The Coach Agent then evaluates user-recorded presentations against these exemplars, conducting multimodal speech analysis and delivering structured feedback in an Observation-Impact-Suggestion (OIS) format. To enhance the authenticity of the learning experience, the Coach Agent incorporates an Audience Agent, which simulates the perspective of a human listener and provides humanized feedback reflecting audience reactions and engagement. Together, these agents form a closed loop of observation, practice, and feedback. Implemented on a robust backend with multi-model integration, voice cloning, and error handling mechanisms, the system demonstrates how AI-driven agents can provide engaging, human-centered, and scalable support for presentation skill development in both educational and professional contexts.",
    "published": "2025-11-19T09:15:21Z",
    "updated": "2025-11-24T02:51:05Z",
    "link": "http://arxiv.org/pdf/2511.15253v2.pdf",
    "category": [
      "cs.HC",
      "cs.AI"
    ],
    "authors": [
      "Sirui Chen",
      "Jinsong Zhou",
      "Xinli Xu",
      "Xiaoyu Yang",
      "Litao Guo",
      "Ying-Cong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18701v1",
    "title": "ObjectAlign: Neuro-Symbolic Object Consistency Verification and Correction",
    "summary": "Video editing and synthesis often introduce object inconsistencies, such as frame flicker and identity drift that degrade perceptual quality. To address these issues, we introduce ObjectAlign, a novel framework that seamlessly blends perceptual metrics with symbolic reasoning to detect, verify, and correct object-level and temporal inconsistencies in edited video sequences. The novel contributions of ObjectAlign are as follows: First, we propose learnable thresholds for metrics characterizing object consistency (i.e. CLIP-based semantic similarity, LPIPS perceptual distance, histogram correlation, and SAM-derived object-mask IoU). Second, we introduce a neuro-symbolic verifier that combines two components: (a) a formal, SMT-based check that operates on masked object embeddings to provably guarantee that object identity does not drift, and (b) a temporal fidelity check that uses a probabilistic model checker to verify the video's formal representation against a temporal logic specification. A frame transition is subsequently deemed \"consistent\" based on a single logical assertion that requires satisfying both the learned metric thresholds and this unified neuro-symbolic constraint, ensuring both low-level stability and high-level temporal correctness. Finally, for each contiguous block of flagged frames, we propose a neural network based interpolation for adaptive frame repair, dynamically choosing the interpolation depth based on the number of frames to be corrected. This enables reconstruction of the corrupted frames from the last valid and next valid keyframes. Our results show up to 1.4 point improvement in CLIP Score and up to 6.1 point improvement in warp error compared to SOTA baselines on the DAVIS and Pexels video datasets.",
    "published": "2025-11-24T02:50:01Z",
    "updated": "2025-11-24T02:50:01Z",
    "link": "http://arxiv.org/pdf/2511.18701v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.FL",
      "cs.LG"
    ],
    "authors": [
      "Mustafa Munir",
      "Harsh Goel",
      "Xiwen Wei",
      "Minkyu Choi",
      "Sahil Shah",
      "Kartikeya Bhardwaj",
      "Paul Whatmough",
      "Sandeep Chinchali",
      "Radu Marculescu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17405v2",
    "title": "Beyond Multiple Choice: Verifiable OpenQA for Robust Vision-Language RFT",
    "summary": "Multiple-choice question answering (MCQA) has been a popular format for evaluating and reinforcement fine-tuning (RFT) of modern multimodal language models. Its constrained output format allows for simplified, deterministic automatic verification. However, we find that the options may leak exploitable signals, which makes the accuracy metrics unreliable for indicating real capabilities and encourages explicit or implicit answer guessing behaviors during RFT. We propose ReVeL (Rewrite and Verify by LLM), a framework that rewrites multiple-choice questions into open-form questions while keeping answers verifiable whenever possible. The framework categorizes questions according to different answer types, apply different rewriting and verification schemes, respectively. When applied for RFT, we converted 20k MCQA examples and use GRPO to finetune Qwen2.5-VL models. Models trained on ReVeL-OpenQA match MCQA accuracy on multiple-choice benchmarks and improve OpenQA accuracy by about six percentage points, indicating better data efficiency and more robust reward signals than MCQA-based training. When used for evaluation, ReVeL also reveals up to 20 percentage points of score inflation in MCQA benchmarks (relative to OpenQA), improves judging accuracy, and reduces both cost and latency. We will release code and data publicly.",
    "published": "2025-11-21T17:06:37Z",
    "updated": "2025-11-24T02:45:02Z",
    "link": "http://arxiv.org/pdf/2511.17405v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Yesheng Liu",
      "Hao Li",
      "Haiyu Xu",
      "Baoqi Pei",
      "Jiahao Wang",
      "Mingxuan Zhao",
      "Jingshu Zheng",
      "Zheqi He",
      "JG Yao",
      "Bowen Qin",
      "Xi Yang",
      "Jiajun Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18698v1",
    "title": "Multimodal Real-Time Anomaly Detection and Industrial Applications",
    "summary": "This paper presents the design, implementation, and evolution of a comprehensive multimodal room-monitoring system that integrates synchronized video and audio processing for real-time activity recognition and anomaly detection. We describe two iterations of the system: an initial lightweight implementation using YOLOv8, ByteTrack, and the Audio Spectrogram Transformer (AST), and an advanced version that incorporates multi-model audio ensembles, hybrid object detection, bidirectional cross-modal attention, and multi-method anomaly detection. The evolution demonstrates significant improvements in accuracy, robustness, and industrial applicability. The advanced system combines three audio models (AST, Wav2Vec2, and HuBERT) for comprehensive audio understanding, dual object detectors (YOLO and DETR) for improved accuracy, and sophisticated fusion mechanisms for enhanced cross-modal learning. Experimental evaluation shows the system's effectiveness in general monitoring scenarios as well as specialized industrial safety applications, achieving real-time performance on standard hardware while maintaining high accuracy.",
    "published": "2025-11-24T02:43:19Z",
    "updated": "2025-11-24T02:43:19Z",
    "link": "http://arxiv.org/pdf/2511.18698v1.pdf",
    "category": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "authors": [
      "Aman Verma",
      "Keshav Samdani",
      "Mohd. Samiuddin Shafi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18696v1",
    "title": "Empathetic Cascading Networks: A Multi-Stage Prompting Technique for Reducing Social Biases in Large Language Models",
    "summary": "This report presents the Empathetic Cascading Networks (ECN) framework, a multi-stage prompting method designed to enhance the empathetic and inclusive capabilities of large language models. ECN employs four stages: Perspective Adoption, Emotional Resonance, Reflective Understanding, and Integrative Synthesis, to guide models toward generating emotionally resonant and contextually aware responses. Experimental results demonstrate that ECN achieves the highest Empathy Quotient (EQ) scores across GPT-3.5-turbo and GPT-4, while maintaining competitive Regard and Perplexity metrics. These findings emphasize ECN's potential for applications requiring empathy and inclusivity in conversational AI.",
    "published": "2025-11-24T02:32:20Z",
    "updated": "2025-11-24T02:32:20Z",
    "link": "http://arxiv.org/pdf/2511.18696v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Wangjiaxuan Xin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18694v1",
    "title": "Stable Multi-Drone GNSS Tracking System for Marine Robots",
    "summary": "Accurate localization is essential for marine robotics, yet Global Navigation Satellite System (GNSS) signals are unreliable or unavailable even at a very short distance below the water surface. Traditional alternatives, such as inertial navigation, Doppler Velocity Loggers (DVL), SLAM, and acoustic methods, suffer from error accumulation, high computational demands, or infrastructure dependence. In this work, we present a scalable multi-drone GNSS-based tracking system for surface and near-surface marine robots. Our approach combines efficient visual detection, lightweight multi-object tracking, GNSS-based triangulation, and a confidence-weighted Extended Kalman Filter (EKF) to provide stable GNSS estimation in real time. We further introduce a cross-drone tracking ID alignment algorithm that enforces global consistency across views, enabling robust multi-robot tracking with redundant aerial coverage. We validate our system in diversified complex settings to show the scalability and robustness of the proposed algorithm.",
    "published": "2025-11-24T02:28:31Z",
    "updated": "2025-11-24T02:28:31Z",
    "link": "http://arxiv.org/pdf/2511.18694v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Shuo Wen",
      "Edwin Meriaux",
      "Mariana Sosa Guzmán",
      "Zhizun Wang",
      "Junming Shi",
      "Gregory Dudek"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11483v2",
    "title": "ImAgent: A Unified Multimodal Agent Framework for Test-Time Scalable Image Generation",
    "summary": "Recent text-to-image (T2I) models have made remarkable progress in generating visually realistic and semantically coherent images. However, they still suffer from randomness and inconsistency with the given prompts, particularly when textual descriptions are vague or underspecified. Existing approaches, such as prompt rewriting, best-of-N sampling, and self-refinement, can mitigate these issues but usually require additional modules and operate independently, hindering test-time scaling efficiency and increasing computational overhead. In this paper, we introduce ImAgent, a training-free unified multimodal agent that integrates reasoning, generation, and self-evaluation within a single framework for efficient test-time scaling. Guided by a policy controller, multiple generation actions dynamically interact and self-organize to enhance image fidelity and semantic alignment without relying on external models. Extensive experiments on image generation and editing tasks demonstrate that ImAgent consistently improves over the backbone and even surpasses other strong baselines where the backbone model fails, highlighting the potential of unified multimodal agents for adaptive and efficient image generation under test-time scaling.",
    "published": "2025-11-14T17:00:29Z",
    "updated": "2025-11-24T02:28:18Z",
    "link": "http://arxiv.org/pdf/2511.11483v2.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Kaishen Wang",
      "Ruibo Chen",
      "Tong Zheng",
      "Heng Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18692v1",
    "title": "VLM in a flash: I/O-Efficient Sparsification of Vision-Language Model via Neuron Chunking",
    "summary": "Edge deployment of large Vision-Language Models (VLMs) increasingly relies on flash-based weight offloading, where activation sparsification is used to reduce I/O overhead. However, conventional sparsification remains model-centric, selecting neurons solely by activation magnitude and neglecting how access patterns influence flash performance. We present Neuron Chunking, an I/O-efficient sparsification strategy that operates on chunks (i.e., groups of contiguous neurons in memory) and couples neuron importance with storage access cost. The method models I/O latency through a lightweight abstraction of access contiguity and selects chunks with high utility, defined as neuron importance normalized by estimated latency. By aligning sparsification decisions with the underlying storage behavior, Neuron Chunking improves I/O efficiency by up to 4.65x and 5.76x on Jetson Orin Nano and Jetson AGX Orin, respectively.",
    "published": "2025-11-24T02:27:19Z",
    "updated": "2025-11-24T02:27:19Z",
    "link": "http://arxiv.org/pdf/2511.18692v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.PF"
    ],
    "authors": [
      "Kichang Yang",
      "Seonjun Kim",
      "Minjae Kim",
      "Nairan Zhang",
      "Chi Zhang",
      "Youngki Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.00493v3",
    "title": "Visual Anagrams Reveal Hidden Differences in Holistic Shape Processing Across Vision Models",
    "summary": "Humans are able to recognize objects based on both local texture cues and the configuration of object parts, yet contemporary vision models primarily harvest local texture cues, yielding brittle, non-compositional features. Work on shape-vs-texture bias has pitted shape and texture representations in opposition, measuring shape relative to texture, ignoring the possibility that models (and humans) can simultaneously rely on both types of cues, and obscuring the absolute quality of both types of representation. We therefore recast shape evaluation as a matter of absolute configural competence, operationalized by the Configural Shape Score (CSS), which (i) measures the ability to recognize both images in Object-Anagram pairs that preserve local texture while permuting global part arrangement to depict different object categories. Across 86 convolutional, transformer, and hybrid models, CSS (ii) uncovers a broad spectrum of configural sensitivity with fully self-supervised and language-aligned transformers -- exemplified by DINOv2, SigLIP2 and EVA-CLIP -- occupying the top end of the CSS spectrum. Mechanistic probes reveal that (iii) high-CSS networks depend on long-range interactions: radius-controlled attention masks abolish performance showing a distinctive U-shaped integration profile, and representational-similarity analyses expose a mid-depth transition from local to global coding. A BagNet control remains at chance (iv), ruling out \"border-hacking\" strategies. Finally, (v) we show that configural shape score also predicts other shape-dependent evals. Overall, we propose that the path toward truly robust, generalizable, and human-like vision systems may not lie in forcing an artificial choice between shape and texture, but rather in architectural and learning frameworks that seamlessly integrate both local-texture and global configural shape.",
    "published": "2025-07-01T07:08:56Z",
    "updated": "2025-11-24T02:16:08Z",
    "link": "http://arxiv.org/pdf/2507.00493v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Fenil R. Doshi",
      "Thomas Fel",
      "Talia Konkle",
      "George Alvarez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.09598v6",
    "title": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference",
    "summary": "This paper introduces an infrastructure-aware benchmarking framework for quantifying the environmental footprint of LLM inference across 30 state-of-the-art models in commercial datacenters. The framework combines public API performance data with company-specific environmental multipliers and statistical inference of hardware configurations. We additionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank models by performance relative to environmental cost and provide a dynamically updated dashboard that visualizes model-level energy, water, and carbon metrics. Results show the most energy-intensive models exceed 29 Wh per long prompt, over 65 times the most efficient systems. Even a 0.42 Wh short query, when scaled to 700M queries/day, aggregates to annual electricity comparable to 35{,}000 U.S. homes, evaporative freshwater equal to the annual drinking needs of 1.2M people, and carbon emissions requiring a Chicago-sized forest to offset. These findings highlight a growing paradox: as AI becomes cheaper and faster, global adoption drives disproportionate resource consumption. Our methodology offers a standardized, empirically grounded basis for sustainability benchmarking and accountability in AI deployment.",
    "published": "2025-05-14T17:47:00Z",
    "updated": "2025-11-24T02:12:44Z",
    "link": "http://arxiv.org/pdf/2505.09598v6.pdf",
    "category": [
      "cs.CY",
      "cs.AI"
    ],
    "authors": [
      "Nidhal Jegham",
      "Marwan Abdelatti",
      "Chan Young Koh",
      "Lassad Elmoubarki",
      "Abdeltawab Hendawi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.16825v3",
    "title": "KANO: Kolmogorov-Arnold Neural Operator",
    "summary": "We introduce Kolmogorov--Arnold Neural Operator (KANO), a dual-domain neural operator jointly parameterized by both spectral and spatial bases with intrinsic symbolic interpretability. We theoretically demonstrate that KANO overcomes the pure-spectral bottleneck of Fourier Neural Operator (FNO): KANO remains expressive over generic position-dependent dynamics (variable coefficient PDEs) for any physical input, whereas FNO stays practical only for spectrally sparse operators and strictly imposes a fast-decaying input Fourier tail. We verify our claims empirically on position-dependent differential operators, for which KANO robustly generalizes but FNO fails to. In the quantum Hamiltonian learning benchmark, KANO reconstructs ground-truth Hamiltonians in closed-form symbolic representations accurate to the fourth decimal place in coefficients and attains $\\approx 6\\times10^{-6}$ state infidelity from projective measurement data, substantially outperforming that of the FNO trained with ideal full wave function data, $\\approx 1.5\\times10^{-2}$, by orders of magnitude.",
    "published": "2025-09-20T22:32:58Z",
    "updated": "2025-11-24T02:11:34Z",
    "link": "http://arxiv.org/pdf/2509.16825v3.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "authors": [
      "Jin Lee",
      "Ziming Liu",
      "Xinling Yu",
      "Yixuan Wang",
      "Haewon Jeong",
      "Murphy Yuezhen Niu",
      "Zheng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18676v1",
    "title": "MedVision: Dataset and Benchmark for Quantitative Medical Image Analysis",
    "summary": "Current vision-language models (VLMs) in medicine are primarily designed for categorical question answering (e.g., \"Is this normal or abnormal?\") or qualitative descriptive tasks. However, clinical decision-making often relies on quantitative assessments, such as measuring the size of a tumor or the angle of a joint, from which physicians draw their own diagnostic conclusions. This quantitative reasoning capability remains underexplored and poorly supported in existing VLMs. In this work, we introduce MedVision, a large-scale dataset and benchmark specifically designed to evaluate and improve VLMs on quantitative medical image analysis. MedVision spans 22 public datasets covering diverse anatomies and modalities, with 30.8 million image-annotation pairs. We focus on three representative quantitative tasks: (1) detection of anatomical structures and abnormalities, (2) tumor/lesion (T/L) size estimation, and (3) angle/distance (A/D) measurement. Our benchmarks show that current off-the-shelf VLMs perform poorly on these tasks. However, with supervised fine-tuning on MedVision, we significantly enhance their performance across detection, T/L estimation, and A/D measurement, demonstrating reduced error rates and improved precision. This work provides a foundation for developing VLMs with robust quantitative reasoning capabilities in medical imaging. Code and data are available at https://medvision-vlm.github.io.",
    "published": "2025-11-24T01:26:07Z",
    "updated": "2025-11-24T01:26:07Z",
    "link": "http://arxiv.org/pdf/2511.18676v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Yongcheng Yao",
      "Yongshuo Zong",
      "Raman Dutt",
      "Yongxin Yang",
      "Sotirios A Tsaftaris",
      "Timothy Hospedales"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.10646v3",
    "title": "CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance",
    "summary": "Programming assistants powered by large language models have improved dramatically, yet existing benchmarks still evaluate them in narrow code-generation settings. Recent efforts such as InfiBench and StackEval rely on Stack Overflow questions and remain limited to single-turn interactions, manually curated data, and isolated snippets rather than full project environments. We introduce CodeAssistBench (CAB), the first benchmark for evaluating multi-turn, project-grounded programming assistance at scale. CAB automatically constructs datasets from GitHub issues tagged as questions, using an LLM-driven pipeline that filters noise, extracts runnable contexts, builds executable containers, and verifies environment correctness. This enables continuous, automated expansion across diverse repositories without manual intervention. Using CAB, we create a testbed of 3,286 real-world issues across 214 repositories, spanning seven languages. Evaluating state-of-the-art models reveals a substantial gap: while models achieve 70-83% accuracy on Stack Overflow-style questions, they solve only 16.49% of CAB issues from post-training-cutoff repositories. On a manually validated subset of 149 issues, top models such as Claude Sonnet 4.5 reach only 12.08% correctness. These results highlight a fundamental challenge: current LLMs struggle to provide assistance in realistic, project-specific contexts despite strong performance on traditional Q&A benchmarks. CAB provides a scalable, reproducible framework for advancing research in multi-turn, codebase-grounded programming agents. The benchmark and pipeline are fully automated and publicly available at https://github.com/amazon-science/CodeAssistBench/.",
    "published": "2025-07-14T17:19:00Z",
    "updated": "2025-11-24T01:18:11Z",
    "link": "http://arxiv.org/pdf/2507.10646v3.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Myeongsoo Kim",
      "Shweta Garg",
      "Baishakhi Ray",
      "Varun Kumar",
      "Anoop Deoras"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.07061v3",
    "title": "Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and Curriculum Learning",
    "summary": "Emotion Recognition in Conversation (ERC) is a crucial task for understanding human emotions and enabling natural human-computer interaction. Although Large Language Models (LLMs) have recently shown great potential in this field, their ability to capture the intrinsic connections between explicit and implicit emotions remains limited. We propose a novel ERC training framework, PRC-Emo, which integrates Prompt engineering, demonstration Retrieval, and Curriculum learning, with the goal of exploring whether LLMs can effectively perceive emotions in conversational contexts. Specifically, we design emotion-sensitive prompt templates based on both explicit and implicit emotional cues to better guide the model in understanding the speaker's psychological states. We construct the first dedicated demonstration retrieval repository for ERC, which includes training samples from widely used datasets, as well as high-quality dialogue examples generated by LLMs and manually verified. Moreover, we introduce a curriculum learning strategy into the LoRA fine-tuning process, incorporating weighted emotional shifts between same-speaker and different-speaker utterances to assign difficulty levels to dialogue samples, which are then organized in an easy-to-hard training sequence. Experimental results on two benchmark datasets -- IEMOCAP and MELD -- show that our method achieves new state-of-the-art (SOTA) performance, demonstrating the effectiveness and generalizability of our approach in improving LLM-based emotional understanding.",
    "published": "2025-11-10T12:52:11Z",
    "updated": "2025-11-24T01:17:15Z",
    "link": "http://arxiv.org/pdf/2511.07061v3.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Xinran Li",
      "Yu Liu",
      "Jiaqi Qiao",
      "Xiujuan Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18674v1",
    "title": "Low-Rank GEMM: Efficient Matrix Multiplication via Low-Rank Approximation with FP8 Acceleration",
    "summary": "Large matrix multiplication is a cornerstone of modern machine learning workloads, yet traditional approaches suffer from cubic computational complexity (e.g., $\\mathcal{O}(n^3)$ for a matrix of size $n\\times n$). We present Low-Rank GEMM, a novel approach that leverages low-rank matrix approximations to achieve sub-quadratic complexity while maintaining hardware-accelerated performance through FP8 precision and intelligent kernel selection. On a NVIDIA RTX 4090, our implementation achieves up to 378 TFLOPS on matrices up to $N=20480$, providing 75\\% memory savings and $7.8\\times$ speedup over PyTorch FP32 for large matrices. The system automatically adapts to hardware capabilities, selecting optimal decomposition methods (SVD, randomized SVD) and precision levels based on matrix characteristics and available accelerators. Comprehensive benchmarking on NVIDIA RTX 4090 demonstrates that Low-Rank GEMM becomes the fastest approach for matrices $N\\geq10240$, surpassing traditional cuBLAS implementations through memory bandwidth optimization rather than computational shortcuts.",
    "published": "2025-11-24T01:13:52Z",
    "updated": "2025-11-24T01:13:52Z",
    "link": "http://arxiv.org/pdf/2511.18674v1.pdf",
    "category": [
      "cs.PF",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "authors": [
      "Alfredo Metere"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.12109v3",
    "title": "Personalized LLM Decoding via Contrasting Personal Preference",
    "summary": "As large language models (LLMs) are progressively deployed in various real-world applications, personalization of LLMs has become increasingly important. While various approaches to LLM personalization such as prompt-based and training-based methods have been actively explored, the development of effective decoding-time algorithms remains largely overlooked, despite their demonstrated potential. In this paper, we propose CoPe (Contrasting Personal Preference), a novel decoding-time approach applied after performing parameter-efficient fine-tuning (PEFT) on user-specific data. Our core idea is to leverage reward-guided decoding specifically for personalization by maximizing each user's implicit reward signal. We evaluate CoPe across five open-ended personalized text generation tasks. Our empirical results demonstrate that CoPe achieves strong performance, improving personalization by an average of 10.57% in ROUGE-L, without relying on external reward models or additional training procedures.",
    "published": "2025-06-13T09:12:44Z",
    "updated": "2025-11-24T00:58:45Z",
    "link": "http://arxiv.org/pdf/2506.12109v3.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Hyungjune Bu",
      "Chanjoo Jung",
      "Minjae Kang",
      "Jaehyung Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18670v1",
    "title": "Deterministic Continuous Replacement: Fast and Stable Module Replacement in Pretrained Transformers",
    "summary": "Replacing modules in pretrained models, especially swapping quadratic self-attention for efficient attention alternatives, poses a hard optimization problem: cold-start reinitialization destabilizes frozen backbones. We isolate this core stability challenge in a controlled study. Deterministic Continuous Replacement (DCR) blends teacher and student outputs with a deterministic, annealed weight. Theoretically, DCR eliminates gate-induced gradient variance inherent to stochastic replacement. In a single-seed study, DCR attains faster convergence and stronger alignment than stochastic gating and distillation baselines on controlled attention replacement, establishing a foundation for heterogeneous operator swaps.",
    "published": "2025-11-24T00:55:14Z",
    "updated": "2025-11-24T00:55:14Z",
    "link": "http://arxiv.org/pdf/2511.18670v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "authors": [
      "Rowan Bradbury",
      "Aniket Srinivasan Ashok",
      "Sai Ram Kasanagottu",
      "Gunmay Jhingran",
      "Shuai Meng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.15015v2",
    "title": "Dynamic Expert Quantization for Scalable Mixture-of-Experts Inference",
    "summary": "Mixture-of-Experts (MoE) models scale LLM capacity efficiently, but deployment on consumer GPUs is limited by the large memory footprint of inactive experts. Static post-training quantization reduces storage costs but cannot adapt to shifting activation patterns, causing accuracy loss under aggressive compression. So we present DynaExq, a runtime system that treats expert precision as a first-class, dynamically managed resource. DynaExq combines (1) a hotness-aware precision controller that continuously aligns expert bit-widths with long-term activation statistics, (2) a fully asynchronous precision-switching pipeline that overlaps promotion and demotion with MoE computation, and (3) a fragmentation-free memory pooling mechanism that supports hybrid-precision experts with deterministic allocation. Together, these components enable stable, non-blocking precision transitions under strict HBM budgets.\n  Across Qwen3-30B and Qwen3-80B MoE models and six representative benchmarks, DynaExq deploys large LLMs on single RTX 5090 and A6000 GPUs and improves accuracy by up to 4.03 points over static low-precision baselines. The results show that adaptive, workload-aware quantization is an effective strategy for memory-constrained MoE serving.",
    "published": "2025-11-19T01:27:54Z",
    "updated": "2025-11-24T00:36:49Z",
    "link": "http://arxiv.org/pdf/2511.15015v2.pdf",
    "category": [
      "cs.PF",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Kexin Chu",
      "Dawei Xiang",
      "Zixu Shen",
      "Yiwei Yang",
      "Zecheng Liu",
      "Wei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.00062v3",
    "title": "Scaffold Diffusion: Sparse Multi-Category Voxel Structure Generation with Discrete Diffusion",
    "summary": "Generating realistic sparse multi-category 3D voxel structures is difficult due to the cubic memory scaling of voxel structures and moreover the significant class imbalance caused by sparsity. We introduce Scaffold Diffusion, a generative model designed for sparse multi-category 3D voxel structures. By treating voxels as tokens, Scaffold Diffusion uses a discrete diffusion language model to generate 3D voxel structures. We show that discrete diffusion language models can be extended beyond inherently sequential domains such as text to generate spatially coherent 3D structures. We evaluate on Minecraft house structures from the 3D-Craft dataset and demonstrate that, unlike prior baselines and an auto-regressive formulation, Scaffold Diffusion produces realistic and coherent structures even when trained on data with over 98% sparsity. We provide an interactive viewer where readers can visualize generated samples and the generation process: https://scaffold.deepexploration.org/",
    "published": "2025-08-26T04:57:32Z",
    "updated": "2025-11-24T00:03:47Z",
    "link": "http://arxiv.org/pdf/2509.00062v3.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Justin Jung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23518v2",
    "title": "TRAP: Targeted Redirecting of Agentic Preferences",
    "summary": "Autonomous agentic AI systems powered by vision-language models (VLMs) are rapidly advancing toward real-world deployment, yet their cross-modal reasoning capabilities introduce new attack surfaces for adversarial manipulation that exploit semantic reasoning across modalities. Existing adversarial attacks typically rely on visible pixel perturbations or require privileged model or environment access, making them impractical for stealthy, real-world exploitation. We introduce TRAP, a novel generative adversarial framework that manipulates the agent's decision-making using diffusion-based semantic injections into the vision-language embedding space. Our method combines negative prompt-based degradation with positive semantic optimization, guided by a Siamese semantic network and layout-aware spatial masking. Without requiring access to model internals, TRAP produces visually natural images yet induces consistent selection biases in agentic AI systems. We evaluate TRAP on the Microsoft Common Objects in Context (COCO) dataset, building multi-candidate decision scenarios. Across these scenarios, TRAP consistently induces decision-level preference redirection on leading models, including LLaVA-34B, Gemma3, GPT-4o, and Mistral-3.2, significantly outperforming existing baselines such as SPSA, Bandit, and standard diffusion approaches. These findings expose a critical, generalized vulnerability: autonomous agents can be consistently misled through visually subtle, semantically-guided cross-modal manipulations. Overall, our results show the need for defense strategies beyond pixel-level robustness to address semantic vulnerabilities in cross-modal decision-making. The code for TRAP is accessible on GitHub at https://github.com/uiuc-focal-lab/TRAP.",
    "published": "2025-05-29T14:57:16Z",
    "updated": "2025-11-24T00:01:45Z",
    "link": "http://arxiv.org/pdf/2505.23518v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Hangoo Kang",
      "Jehyeok Yeon",
      "Gagandeep Singh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.17516v2",
    "title": "Functional Classification of Spiking Signal Data Using Artificial Intelligence Techniques: A Review",
    "summary": "Human brain neuron activities are incredibly significant nowadays. Neuronal behavior is assessed by analyzing signal data such as electroencephalography (EEG), which can offer scientists valuable information about diseases and human-computer interaction. One of the difficulties researchers confront while evaluating these signals is the existence of large volumes of spike data. Spikes are some considerable parts of signal data that can happen as a consequence of vital biomarkers or physical issues such as electrode movements. Hence, distinguishing types of spikes is important. From this spot, the spike classification concept commences. Previously, researchers classified spikes manually. The manual classification was not precise enough as it involves extensive analysis. Consequently, Artificial Intelligence (AI) was introduced into neuroscience to assist clinicians in classifying spikes correctly. This review discusses the importance and use of AI in spike classification, focusing on the recognition of neural activity noises. The task is divided into three main components: preprocessing, classification, and evaluation. Existing methods are introduced and their importance is determined. The review also highlights the need for more efficient algorithms. The primary goal is to provide a perspective on spike classification for future research and provide a comprehensive understanding of the methodologies and issues involved. The review organizes materials in the spike classification field for future studies. In this work, numerous studies were extracted from different databases. The PRISMA-related research guidelines were then used to choose papers. Then, research studies based on spike classification using machine learning and deep learning approaches with effective preprocessing were selected.",
    "published": "2024-09-26T03:50:55Z",
    "updated": "2025-11-23T23:59:06Z",
    "link": "http://arxiv.org/pdf/2409.17516v2.pdf",
    "category": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "authors": [
      "Danial Sharifrazi",
      "Nouman Javed",
      "Javad Hassannataj Joloudari",
      "Roohallah Alizadehsani",
      "Prasad N. Paradkar",
      "Ru-San Tan",
      "U. Rajendra Acharya",
      "Asim Bhatti"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18653v1",
    "title": "FHE-Agent: Automating CKKS Configuration for Practical Encrypted Inference via an LLM-Guided Agentic Framework",
    "summary": "Fully Homomorphic Encryption (FHE), particularly the CKKS scheme, is a promising enabler for privacy-preserving MLaaS, but its practical deployment faces a prohibitive barrier: it heavily relies on domain expertise. Configuring CKKS involves a tightly coupled space of ring dimensions, modulus chains, and packing layouts. Without deep cryptographic knowledge to navigate these interactions, practitioners are restricted to compilers that rely on fixed heuristics. These \"one-shot\" tools often emit rigid configurations that are either severely over-provisioned in latency or fail to find a feasible solution entirely for deeper networks.\n  We present FHE-Agent, an agentic framework that automates this expert reasoning process. By coupling a Large Language Model (LLM) controller with a deterministic tool suite, FHE-Agent decomposes the search into global parameter selection and layer-wise bottleneck repair. The agents operate within a multi-fidelity workflow, pruning invalid regimes using cheap static analysis and reserving expensive encrypted evaluations for the most promising candidates.\n  We instantiate FHE-Agent on the Orion compiler and evaluate it on standard benchmarks (MLP, LeNet, LoLa) and deeper architectures (AlexNet). FHE-Agent consistently achieves better precision and lower latency than naïve search strategies. Crucially, it automatically discovers feasible, 128-bit secure configurations for complex models where baseline heuristics and one-shot prompts fail to produce a valid setup.",
    "published": "2025-11-23T23:26:21Z",
    "updated": "2025-11-23T23:26:21Z",
    "link": "http://arxiv.org/pdf/2511.18653v1.pdf",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Nuo Xu",
      "Zhaoting Gong",
      "Ran Ran",
      "Jinwei Tang",
      "Wujie Wen",
      "Caiwen Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18651v1",
    "title": "Lean 5.0: A Predictive, Human-AI, and Ethically Grounded Paradigm for Construction Management",
    "summary": "This paper introduces Lean 5.0, a human-centric evolution of Lean-Digital integration that connects predictive analytics, AI collaboration, and continuous learning within Industry 5.0 and Construction 5.0 contexts. A systematic literature review (2019-2024) and a 12-week empirical validation study demonstrate measurable performance gains, including a 13% increase in Plan Percent Complete (PPC), 22% reduction in rework, and 42% improvement in forecast accuracy. The study adopts a mixed-method Design Science Research (DSR) approach aligned with PRISMA 2020 guidelines. The paper also examines integration with digital twin and blockchain technologies to improve traceability, auditability, and lifecycle transparency. Despite limitations related to sample size, single-case design, and study duration, the findings show that Lean 5.0 provides a transformative paradigm connecting human cognition with predictive control in construction management.",
    "published": "2025-11-23T23:11:55Z",
    "updated": "2025-11-23T23:11:55Z",
    "link": "http://arxiv.org/pdf/2511.18651v1.pdf",
    "category": [
      "cs.CE",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Atena Khoshkonesh",
      "Mohsen Mohammadagha",
      "Navid Ebrahimi",
      "Narges Sadeghigolshan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18643v1",
    "title": "Kitty: Accurate and Efficient 2-bit KV Cache Quantization with Dynamic Channel-wise Precision Boost",
    "summary": "The KV cache is a dominant memory bottleneck for LLM inference. While 4-bit KV quantization preserves accuracy, 2-bit often degrades it, especially on long-context reasoning. We close this gap via an algorithm-system co-design for mixed-precision KV caching: Kitty. On the algorithm side, extensive experiments show that Dynamic Channel-wise Precision Boost -- which ranks Key-cache channels by sensitivity and keeps only a small fraction at higher precision -- maintains near-zero loss in accuracy drop while approaching 2-bit memory. The main challenge is handling dynamic 4-bit channel boosts while keeping the page layout coalesced and the dequantization uniform, with no scattered reads or hard-coded masks. Kitty addresses these issues by decompose each mixed-precision Key page into two tensors with unified 2-bit precision. Based on this, Kitty provides a page-centric KV layout, Triton-compatible page dequantization kernels, and a lightweight runtime pipeline that preserves coalescing and avoids divergence. Across seven tasks and two model families (Qwen3, LLaMA3), Kitty cuts KV memory by nearly 8x with negligible accuracy loss, enabling up to 8x larger batches and 2.1x-4.1x higher throughput under the same memory budget. We release the full implementation of Kitty at https://github.com/Summer-Summer/Kitty.",
    "published": "2025-11-23T22:54:48Z",
    "updated": "2025-11-23T22:54:48Z",
    "link": "http://arxiv.org/pdf/2511.18643v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Haojun Xia",
      "Xiaoxia Wu",
      "Jisen Li",
      "Robert Wu",
      "Junxiong Wang",
      "Jue Wang",
      "Chenxi Li",
      "Aman Singhal",
      "Alay Dilipbhai Shah",
      "Alpay Ariyak",
      "Donglin Zhuang",
      "Zhongzhu Zhou",
      "Ben Athiwaratkun",
      "Zhen Zheng",
      "Shuaiwen Leon Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2312.15524v3",
    "title": "The Challenge of Using LLMs to Simulate Human Behavior: A Causal Inference Perspective",
    "summary": "Large Language Models (LLMs) have shown impressive potential to simulate human behavior. We identify a fundamental challenge in using them to simulate experiments: when LLM-simulated subjects are blind to the experimental design (as is standard practice with human subjects), variations in treatment systematically affect unspecified variables that should remain constant, violating the unconfoundedness assumption. Using demand estimation as a context and an actual experiment with 40 different products as a benchmark, we show this can lead to implausible results. While confounding may in principle be addressed by controlling for covariates, this can compromise ecological validity in the context of LLM simulations: controlled covariates become artificially salient in the simulated decision process. We show formally that confoundness stems from ambiguous prompting strategies. Therefore, it can be addressed by developing unambiguous prompting strategies through unblinding, i.e., revealing the experiment design in LLM simulations. Our empirical results show that this strategy consistently enhances model performance across all tested models, including both out-of-box reasoning and non-reasoning models. We also show that it is a technique that complements fine-tuning: while fine-tuning can improve simulation performance, an unambiguous prompting strategy makes the predictions robust to the inclusion of irrelevant data in the fine-tuning process.",
    "published": "2023-12-24T16:32:35Z",
    "updated": "2025-11-23T22:53:45Z",
    "link": "http://arxiv.org/pdf/2312.15524v3.pdf",
    "category": [
      "cs.AI",
      "cs.IR",
      "econ.EM",
      "stat.AP"
    ],
    "authors": [
      "George Gui",
      "Olivier Toubia"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18640v1",
    "title": "Health system learning achieves generalist neuroimaging models",
    "summary": "Frontier artificial intelligence (AI) models, such as OpenAI's GPT-5 and Meta's DINOv3, have advanced rapidly through training on internet-scale public data, yet such systems lack access to private clinical data. Neuroimaging, in particular, is underrepresented in the public domain due to identifiable facial features within MRI and CT scans, fundamentally restricting model performance in clinical medicine. Here, we show that frontier models underperform on neuroimaging tasks and that learning directly from uncurated data generated during routine clinical care at health systems, a paradigm we call health system learning, yields high-performance, generalist neuroimaging models. We introduce NeuroVFM, a visual foundation model trained on 5.24 million clinical MRI and CT volumes using a scalable volumetric joint-embedding predictive architecture. NeuroVFM learns comprehensive representations of brain anatomy and pathology, achieving state-of-the-art performance across multiple clinical tasks, including radiologic diagnosis and report generation. The model exhibits emergent neuroanatomic understanding and interpretable visual grounding of diagnostic findings. When paired with open-source language models through lightweight visual instruction tuning, NeuroVFM generates radiology reports that surpass frontier models in accuracy, clinical triage, and expert preference. Through clinically grounded visual understanding, NeuroVFM reduces hallucinated findings and critical errors, offering safer clinical decision support. These results establish health system learning as a paradigm for building generalist medical AI and provide a scalable framework for clinical foundation models.",
    "published": "2025-11-23T22:34:50Z",
    "updated": "2025-11-23T22:34:50Z",
    "link": "http://arxiv.org/pdf/2511.18640v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Akhil Kondepudi",
      "Akshay Rao",
      "Chenhui Zhao",
      "Yiwei Lyu",
      "Samir Harake",
      "Soumyanil Banerjee",
      "Rushikesh Joshi",
      "Anna-Katharina Meissner",
      "Renly Hou",
      "Cheng Jiang",
      "Asadur Chowdury",
      "Ashok Srinivasan",
      "Brian Athey",
      "Vikas Gulani",
      "Aditya Pandey",
      "Honglak Lee",
      "Todd Hollon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18635v1",
    "title": "No Free Lunch in Language Model Bias Mitigation? Targeted Bias Reduction Can Exacerbate Unmitigated LLM Biases",
    "summary": "Large Language Models (LLMs) inherit societal biases from their training data, potentially leading to harmful or unfair outputs. While various techniques aim to mitigate these biases, their effects are often evaluated only along the dimension of the bias being targeted. This work investigates the cross-category consequences of targeted bias mitigation. We study four bias mitigation techniques applied across ten models from seven model families, and we explore racial, religious, profession- and gender-related biases. We measure the impact of debiasing on model coherence and stereotypical preference using the StereoSet benchmark. Our results consistently show that while targeted mitigation can sometimes reduce bias in the intended dimension, it frequently leads to unintended and often negative consequences in others, such as increasing model bias and decreasing general coherence. These findings underscore the critical need for robust, multi-dimensional evaluation tools when examining and developing bias mitigation strategies to avoid inadvertently shifting or worsening bias along untargeted axes.",
    "published": "2025-11-23T22:21:18Z",
    "updated": "2025-11-23T22:21:18Z",
    "link": "http://arxiv.org/pdf/2511.18635v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Shireen Chand",
      "Faith Baca",
      "Emilio Ferrara"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18633v1",
    "title": "Bridging Philosophy and Machine Learning: A Structuralist Framework for Classifying Neural Network Representations",
    "summary": "Machine learning models increasingly function as representational systems, yet the philosoph- ical assumptions underlying their internal structures remain largely unexamined. This paper develops a structuralist decision framework for classifying the implicit ontological commitments made in machine learning research on neural network representations. Using a modified PRISMA protocol, a systematic review of the last two decades of literature on representation learning and interpretability is conducted. Five influential papers are analysed through three hierarchical criteria derived from structuralist philosophy of science: entity elimination, source of structure, and mode of existence. The results reveal a pronounced tendency toward structural idealism, where learned representations are treated as model-dependent constructions shaped by architec- ture, data priors, and training dynamics. Eliminative and non-eliminative structuralist stances appear selectively, while structural realism is notably absent. The proposed framework clarifies conceptual tensions in debates on interpretability, emergence, and epistemic trust in machine learning, and offers a rigorous foundation for future interdisciplinary work between philosophy of science and machine learning.",
    "published": "2025-11-23T22:19:43Z",
    "updated": "2025-11-23T22:19:43Z",
    "link": "http://arxiv.org/pdf/2511.18633v1.pdf",
    "category": [
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yildiz Culcu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.02712v2",
    "title": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks",
    "summary": "Large Language Models (LLMs) have revolutionized conversational AI, yet their robustness in extended multi-turn dialogues remains poorly understood. Existing evaluation frameworks focus on static benchmarks and single-turn assessments, failing to capture the temporal dynamics of conversational degradation that characterize real-world interactions. In this work, we present a large-scale survival analysis of conversational robustness, modeling failure as a time-to-event process over 36,951 turns from 9 state-of-the-art LLMs on the MT-Consistency benchmark. Our framework combines Cox proportional hazards, Accelerated Failure Time (AFT), and Random Survival Forest models with simple semantic drift features. We find that abrupt prompt-to-prompt semantic drift sharply increases the hazard of inconsistency, whereas cumulative drift is counterintuitively \\emph{protective}, suggesting adaptation in conversations that survive multiple shifts. AFT models with model-drift interactions achieve the best combination of discrimination and calibration, and proportional hazards checks reveal systematic violations for key drift covariates, explaining the limitations of Cox-style modeling in this setting. Finally, we show that a lightweight AFT model can be turned into a turn-level risk monitor that flags most failing conversations several turns before the first inconsistent answer while keeping false alerts modest. These results establish survival analysis as a powerful paradigm for evaluating multi-turn robustness and for designing practical safeguards for conversational AI systems.",
    "published": "2025-10-03T04:26:10Z",
    "updated": "2025-11-23T22:18:51Z",
    "link": "http://arxiv.org/pdf/2510.02712v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "authors": [
      "Yubo Li",
      "Ramayya Krishnan",
      "Rema Padman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18630v1",
    "title": "Majority of the Bests: Improving Best-of-N via Bootstrapping",
    "summary": "Sampling multiple outputs from a Large Language Model (LLM) and selecting the most frequent (Self-consistency) or highest-scoring (Best-of-N) candidate is a popular approach to achieve higher accuracy in tasks with discrete final answers. Best-of-N (BoN) selects the output with the highest reward, and with perfect rewards, it often achieves near-perfect accuracy. With imperfect rewards from reward models, however, BoN fails to reliably find the correct answer and its performance degrades drastically. We consider the distribution of BoN's outputs and highlight that, although the correct answer does not usually have a probability close to one under imperfect rewards, it is often the most likely outcome. This suggests that the mode of this distribution can be more reliably correct than a sample from it. Based on this idea, we propose Majority-of-the-Bests (MoB), a novel selection mechanism that estimates the output distribution of BoN via bootstrapping and selects its mode. Experimental results across five benchmarks, three different base LLMs, and two reward models demonstrate consistent improvements over BoN in 25 out of 30 setups. We also provide theoretical results for the consistency of the bootstrapping. MoB serves as a simple, yet strong alternative to BoN and self-consistency, and more broadly, motivates further research in more nuanced selection mechanisms.",
    "published": "2025-11-23T22:05:08Z",
    "updated": "2025-11-23T22:05:08Z",
    "link": "http://arxiv.org/pdf/2511.18630v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ME",
      "stat.ML"
    ],
    "authors": [
      "Amin Rakhsha",
      "Kanika Madan",
      "Tianyu Zhang",
      "Amir-massoud Farahmand",
      "Amir Khasahmadi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18622v1",
    "title": "OpenGloss: A Synthetic Encyclopedic Dictionary and Semantic Knowledge Graph",
    "summary": "We present OpenGloss, a synthetic encyclopedic dictionary and semantic knowledge graph for English that integrates lexicographic definitions, encyclopedic context, etymological histories, and semantic relationships in a unified resource. OpenGloss contains 537K senses across 150K lexemes, on par with WordNet 3.1 and Open English WordNet, while providing more than four times as many sense definitions. These lexemes include 9.1M semantic edges, 1M usage examples, 3M collocations, and 60M words of encyclopedic content.\n  Generated through a multi-agent procedural generation pipeline with schema-validated LLM outputs and automated quality assurance, the entire resource was produced in under one week for under $1,000. This demonstrates that structured generation can create comprehensive lexical resources at cost and time scales impractical for manual curation, enabling rapid iteration as foundation models improve. The resource addresses gaps in pedagogical applications by providing integrated content -- definitions, examples, collocations, encyclopedias, etymology -- that supports both vocabulary learning and natural language processing tasks.\n  As a synthetically generated resource, OpenGloss reflects both the capabilities and limitations of current foundation models. The dataset is publicly available on Hugging Face under CC-BY 4.0, enabling researchers and educators to build upon and adapt this resource.",
    "published": "2025-11-23T21:33:53Z",
    "updated": "2025-11-23T21:33:53Z",
    "link": "http://arxiv.org/pdf/2511.18622v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Michael J. Bommarito"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18618v1",
    "title": "A Unified BERT-CNN-BiLSTM Framework for Simultaneous Headline Classification and Sentiment Analysis of Bangla News",
    "summary": "In our daily lives, newspapers are an essential information source that impacts how the public talks about present-day issues. However, effectively navigating the vast amount of news content from different newspapers and online news portals can be challenging. Newspaper headlines with sentiment analysis tell us what the news is about (e.g., politics, sports) and how the news makes us feel (positive, negative, neutral). This helps us quickly understand the emotional tone of the news. This research presents a state-of-the-art approach to Bangla news headline classification combined with sentiment analysis applying Natural Language Processing (NLP) techniques, particularly the hybrid transfer learning model BERT-CNN-BiLSTM. We have explored a dataset called BAN-ABSA of 9014 news headlines, which is the first time that has been experimented with simultaneously in the headline and sentiment categorization in Bengali newspapers. Over this imbalanced dataset, we applied two experimental strategies: technique-1, where undersampling and oversampling are applied before splitting, and technique-2, where undersampling and oversampling are applied after splitting on the In technique-1 oversampling provided the strongest performance, both headline and sentiment, that is 78.57\\% and 73.43\\% respectively, while technique-2 delivered the highest result when trained directly on the original imbalanced dataset, both headline and sentiment, that is 81.37\\% and 64.46\\% respectively. The proposed model BERT-CNN-BiLSTM significantly outperforms all baseline models in classification tasks, and achieves new state-of-the-art results for Bangla news headline classification and sentiment analysis. These results demonstrate the importance of leveraging both the headline and sentiment datasets, and provide a strong baseline for Bangla text classification in low-resource.",
    "published": "2025-11-23T21:22:56Z",
    "updated": "2025-11-23T21:22:56Z",
    "link": "http://arxiv.org/pdf/2511.18618v1.pdf",
    "category": [
      "cs.CL",
      "cs.AI"
    ],
    "authors": [
      "Mirza Raquib",
      "Munazer Montasir Akash",
      "Tawhid Ahmed",
      "Saydul Akbar Murad",
      "Farida Siddiqi Prity",
      "Mohammad Amzad Hossain",
      "Asif Pervez Polok",
      "Nick Rahimi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18613v1",
    "title": "KAN vs LSTM Performance in Time Series Forecasting",
    "summary": "This paper compares Kolmogorov-Arnold Networks (KAN) and Long Short-Term Memory networks (LSTM) for forecasting non-deterministic stock price data, evaluating predictive accuracy versus interpretability trade-offs using Root Mean Square Error (RMSE).LSTM demonstrates substantial superiority across all tested prediction horizons, confirming their established effectiveness for sequential data modelling. Standard KAN, while offering theoretical interpretability through the Kolmogorov-Arnold representation theorem, exhibits significantly higher error rates and limited practical applicability for time series forecasting. The results confirm LSTM dominance in accuracy-critical time series applications while identifying computational efficiency as KANs' primary advantage in resource-constrained scenarios where accuracy requirements are less stringent. The findings support LSTM adoption for practical financial forecasting while suggesting that continued research into specialised KAN architectures may yield future improvements.",
    "published": "2025-11-23T21:09:58Z",
    "updated": "2025-11-23T21:09:58Z",
    "link": "http://arxiv.org/pdf/2511.18613v1.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "Tabish Ali Rather",
      "S M Mahmudul Hasan Joy",
      "Nadezda Sukhorukova",
      "Federico Frascoli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14730v2",
    "title": "Heterogeneous Multi-Agent Proximal Policy Optimization for Power Distribution System Restoration",
    "summary": "Restoring power distribution systems (PDS) after large-scale outages requires sequential switching operations that reconfigure feeder topology and coordinate distributed energy resources (DERs) under nonlinear constraints such as power balance, voltage limits, and thermal ratings. These challenges make conventional optimization and value-based RL approaches computationally inefficient and difficult to scale. This paper applies a Heterogeneous-Agent Reinforcement Learning (HARL) framework, instantiated through Heterogeneous-Agent Proximal Policy Optimization (HAPPO), to enable coordinated restoration across interconnected microgrids. Each agent controls a distinct microgrid with different loads, DER capacities, and switch counts, introducing practical structural heterogeneity. Decentralized actor policies are trained with a centralized critic to compute advantage values for stable on-policy updates. A physics-informed OpenDSS environment provides full power flow feedback and enforces operational limits via differentiable penalty signals rather than invalid action masking. The total DER generation is capped at 2400 kW, and each microgrid must satisfy local supply-demand feasibility. Experiments on the IEEE 123-bus and IEEE 8500-node systems show that HAPPO achieves faster convergence, higher restored power, and smoother multi-seed training than DQN, PPO, MAES, MAGDPG, MADQN, Mean-Field RL, and QMIX. Results demonstrate that incorporating microgrid-level heterogeneity within the HARL framework yields a scalable, stable, and constraint-aware solution for complex PDS restoration.",
    "published": "2025-11-18T18:23:35Z",
    "updated": "2025-11-23T20:39:15Z",
    "link": "http://arxiv.org/pdf/2511.14730v2.pdf",
    "category": [
      "cs.AI"
    ],
    "authors": [
      "Parya Dolatyabi",
      "Mahdi Khodayar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18609v1",
    "title": "Universality in Collective Intelligence on the Rubik's Cube",
    "summary": "Progress in understanding expert performance is limited by the scarcity of quantitative data on long-term knowledge acquisition and deployment. Here we use the Rubik's Cube as a cognitive model system existing at the intersection of puzzle solving, skill learning, expert knowledge, cultural transmission, and group theory. By studying competitive cube communities, we find evidence for universality in the collective learning of the Rubik's Cube in both sighted and blindfolded conditions: expert performance follows exponential progress curves whose parameters reflect the delayed acquisition of algorithms that shorten solution paths. Blindfold solves form a distinct problem class from sighted solves and are constrained not only by expert knowledge but also by the skill improvements required to overcome short-term memory bottlenecks, a constraint shared with blindfold chess. Cognitive artifacts such as the Rubik's Cube help solvers navigate an otherwise enormous mathematical state space. In doing so, they sustain collective intelligence by integrating communal knowledge stores with individual expertise and skill, illustrating how expertise can, in practice, continue to deepen over the course of a single lifetime.",
    "published": "2025-11-23T20:30:38Z",
    "updated": "2025-11-23T20:30:38Z",
    "link": "http://arxiv.org/pdf/2511.18609v1.pdf",
    "category": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "authors": [
      "David Krakauer",
      "Gülce Kardeş",
      "Joshua Grochow"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18604v1",
    "title": "An Analysis of Constraint-Based Multi-Agent Pathfinding Algorithms",
    "summary": "This study informs the design of future multi-agent pathfinding (MAPF) and multi-robot motion planning (MRMP) algorithms by guiding choices based on constraint classification for constraint-based search algorithms. We categorize constraints as conservative or aggressive and provide insights into their search behavior, focusing specifically on vanilla Conflict-Based Search (CBS) and Conflict-Based Search with Priorities (CBSw/P). Under a hybrid grid-roadmap representation with varying resolution, we observe that aggressive (priority constraint) formulations tend to solve more instances as agent count or resolution increases, whereas conservative (motion constraint) formulations yield stronger solution quality when both succeed. Findings are synthesized in a decision flowchart, aiding users in selecting suitable constraints. Recommendations extend to Multi-Robot Motion Planning (MRMP), emphasizing the importance of considering topological features alongside problem, solution, and representation features. A comprehensive exploration of the study, including raw data and map performance, is available in our public GitHub Repository: https://GitHub.com/hannahjmlee/constraint-mapf-analysis",
    "published": "2025-11-23T20:11:47Z",
    "updated": "2025-11-23T20:11:47Z",
    "link": "http://arxiv.org/pdf/2511.18604v1.pdf",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "authors": [
      "Hannah Lee",
      "James D. Motes",
      "Marco Morales",
      "Nancy M. Amato"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18595v1",
    "title": "Stage-Specific Benchmarking of Deep Learning Models for Glioblastoma Follow-Up MRI",
    "summary": "Differentiating true tumor progression (TP) from treatment-related pseudoprogression (PsP) in glioblastoma remains challenging, especially at early follow-up. We present the first stage-specific, cross-sectional benchmarking of deep learning models for follow-up MRI using the Burdenko GBM Progression cohort (n = 180). We analyze different post-RT scans independently to test whether architecture performance depends on time-point. Eleven representative DL families (CNNs, LSTMs, hybrids, transformers, and selective state-space models) were trained under a unified, QC-driven pipeline with patient-level cross-validation. Across both stages, accuracies were comparable (~0.70-0.74), but discrimination improved at the second follow-up, with F1 and AUC increasing for several models, indicating richer separability later in the care pathway. A Mamba+CNN hybrid consistently offered the best accuracy-efficiency trade-off, while transformer variants delivered competitive AUCs at substantially higher computational cost and lightweight CNNs were efficient but less reliable. Performance also showed sensitivity to batch size, underscoring the need for standardized training protocols. Notably, absolute discrimination remained modest overall, reflecting the intrinsic difficulty of TP vs. PsP and the dataset's size imbalance. These results establish a stage-aware benchmark and motivate future work incorporating longitudinal modeling, multi-sequence MRI, and larger multi-center cohorts.",
    "published": "2025-11-23T19:38:03Z",
    "updated": "2025-11-23T19:38:03Z",
    "link": "http://arxiv.org/pdf/2511.18595v1.pdf",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "authors": [
      "Wenhao Guo",
      "Golrokh Mirzaei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.08663v2",
    "title": "A Novel Framework for Augmenting Rating Scale Tests with LLM-Scored Text Data",
    "summary": "Psychological assessments are dominated by rating scales, which cannot capture the nuance in natural language. Efforts to supplement them with qualitative text have relied on labelled datasets or expert rubrics, limiting scalability. We introduce a framework that avoids this reliance: large language models (LLMs) score free-text responses with simple prompts to produce candidate LLM items, from which we retain those that yield the most test information when co-calibrated with a baseline scale. Using depression as a case study, we developed and tested the method in upper-secondary students (n=693) and a matched synthetic dataset (n=3,000). Results on held-out test sets showed that augmenting a 19-item scale with LLM items improved its precision, accuracy, and convergent validity. Further, the test information gain matched that of adding as many as 16 rating-scale items. This framework leverages the increasing availability of transcribed language to enhance psychometric measures, with applications in clinical health and beyond.",
    "published": "2025-10-09T15:37:24Z",
    "updated": "2025-11-23T19:31:46Z",
    "link": "http://arxiv.org/pdf/2510.08663v2.pdf",
    "category": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "authors": [
      "Joe Watson",
      "Ivan O'Connor",
      "Chia-Wen Chen",
      "Luning Sun",
      "Fang Luo",
      "David Stillwell"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.15938v2",
    "title": "Straight to Zero: Why Linearly Decaying the Learning Rate to Zero Works Best for LLMs",
    "summary": "LLMs are commonly trained with a learning rate (LR) warmup, followed by cosine decay to 10% of the maximum (10x decay). In a large-scale empirical study, we show that under an optimal peak LR, a simple linear decay-to-zero (D2Z) schedule consistently outperforms other schedules when training at compute-optimal dataset sizes. D2Z is superior across a range of model sizes, batch sizes, datasets, and vocabularies. Benefits increase as dataset size increases. Leveraging a novel interpretation of AdamW as an exponential moving average of weight updates, we show how linear D2Z optimally balances the demands of early training (moving away from initial conditions) and late training (averaging over more updates in order to mitigate gradient noise). In experiments, a 610M-parameter model trained for 80 tokens-per-parameter (TPP) using D2Z achieves lower loss than when trained for 200 TPP using 10x decay, corresponding to an astonishing 60% compute savings. Models such as Llama2-7B, trained for 286 TPP with 10x decay, could likely have saved a majority of compute by training with D2Z.",
    "published": "2025-02-21T21:08:24Z",
    "updated": "2025-11-23T19:25:46Z",
    "link": "http://arxiv.org/pdf/2502.15938v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NE"
    ],
    "authors": [
      "Shane Bergsma",
      "Nolan Dey",
      "Gurpreet Gosal",
      "Gavia Gray",
      "Daria Soboleva",
      "Joel Hestness"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.08255v2",
    "title": "Investigating Representation Universality: Case Study on Genealogical Representations",
    "summary": "Motivated by interpretability and reliability, we investigate whether large language models (LLMs) deploy universal geometric structures to encode discrete, graph-structured knowledge. To this end, we present two complementary experimental evidence that might support universality of graph representations. First, on an in-context genealogy Q&A task, we train a cone probe to isolate a tree-like subspace in residual stream activations and use activation patching to verify its causal effect in answering related questions. We validate our findings across five different models. Second, we conduct model stitching experiments across models of diverse architectures and parameter counts (OPT, Pythia, Mistral, and LLaMA, 410 million to 8 billion parameters), quantifying representational alignment via relative degradation in the next-token prediction loss. Generally, we conclude that the lack of ground truth representations of graphs makes it challenging to study how LLMs represent them. Ultimately, improving our understanding of LLM representations could facilitate the development of more interpretable, robust, and controllable AI systems.",
    "published": "2024-10-10T16:23:42Z",
    "updated": "2025-11-23T19:24:43Z",
    "link": "http://arxiv.org/pdf/2410.08255v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "authors": [
      "David D. Baek",
      "Yuxiao Li",
      "Max Tegmark"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.01053v3",
    "title": "Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis",
    "summary": "Large-scale clinical databases offer opportunities for medical research, but their complexity creates barriers to effective use. The Medical Information Mart for Intensive Care (MIMIC-IV), one of the world's largest open-source electronic health record databases, traditionally requires both SQL proficiency and clinical domain expertise. We introduce M3, a system that enables natural language querying of MIMIC-IV data through the Model Context Protocol. With a single command, M3 retrieves MIMIC-IV from PhysioNet, launches a local SQLite instance or connects to hosted BigQuery, and allows researchers to pose clinical questions in plain English. We evaluated M3 using one hundred questions from the EHRSQL 2024 benchmark with two language models: the proprietary Claude Sonnet 4 achieved 94% accuracy, while the open-source gpt-oss-20B (deployable locally on consumer hardware) achieved 93% accuracy. Both models translate natural language into SQL, execute queries against MIMIC-IV, and return structured results alongside the underlying query for verification. Error analysis revealed that most failures stemmed from complex temporal reasoning or ambiguous question phrasing rather than fundamental architectural limitations. The comparable performance of a smaller open-source model demonstrates that privacy-preserving local deployment is viable for sensitive clinical data analysis. M3 lowers technical barriers to critical care data analysis while maintaining security through OAuth2 authentication, query validation, and comprehensive audit logging.",
    "published": "2025-06-27T16:24:17Z",
    "updated": "2025-11-23T19:16:31Z",
    "link": "http://arxiv.org/pdf/2507.01053v3.pdf",
    "category": [
      "cs.IR",
      "cs.AI",
      "cs.DB"
    ],
    "authors": [
      "Rafi Al Attrach",
      "Pedro Moreira",
      "Rajna Fani",
      "Renato Umeton",
      "Amelia Fiske",
      "Leo Anthony Celi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13738v2",
    "title": "Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training",
    "summary": "Efficient LLM pre-training requires well-tuned hyperparameters (HPs), including learning rate $η$ and weight decay $λ$. We study scaling laws for HPs: formulas for how to scale HPs as we scale model size N, dataset size D, and batch size B. Recent work suggests the AdamW timescale, $τ= B/(ηλD)$, should remain constant across training settings, and we verify the implication that optimal $λ$ scales linearly with B, for a fixed N and D. However, as N and D scale, we show optimal $τ$ obeys a precise power law in the tokens-per-parameter ratio, D/N. This law thus provides a method to accurately predict $λ$opt in advance of large-scale training. We also study scaling laws for optimal batch size Bopt (the B enabling lowest loss at a given N,D) and critical batch size Bcrit (the B beyond which further data parallelism becomes ineffective). In contrast to prior work, we find both Bopt and Bcrit scale as power laws in D, independent of model size, N. Finally, we analyze how these findings inform the real-world selection of Pareto-optimal N and D under dual training time and compute objectives. All experiments were run on Cerebras CS-3 systems.",
    "published": "2025-05-19T21:27:33Z",
    "updated": "2025-11-23T19:09:41Z",
    "link": "http://arxiv.org/pdf/2505.13738v2.pdf",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "authors": [
      "Shane Bergsma",
      "Nolan Dey",
      "Gurpreet Gosal",
      "Gavia Gray",
      "Daria Soboleva",
      "Joel Hestness"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18589v1",
    "title": "Strategic Decision Framework for Enterprise LLM Adoption",
    "summary": "Organizations are rapidly adopting Large Language Models (LLMs) to transform their operations, yet they lack clear guidance on key decisions for adoption and implementation. While LLMs offer powerful capabilities in content generation, assisted coding, and process automation, businesses face critical challenges in data security, LLM solution development approach, infrastructure requirements, and deployment strategies. Healthcare providers must protect patient data while leveraging LLMs for medical analysis, financial institutions need to balance automated customer service with regulatory compliance, and software companies seek to enhance development productivity while maintaining code security.\n  This article presents a systematic six-step decision framework for LLM adoption, helping organizations navigate from initial application selection to final deployment. Based on extensive interviews and analysis of successful and failed implementations, our framework provides practical guidance for business leaders to align technological capabilities with business objectives. Through key decision points and real-world examples from both B2B and B2C contexts, organizations can make informed decisions about LLM adoption while ensuring secure and efficient integration across various use cases, from customer service automation to content creation and advanced analytics.",
    "published": "2025-11-23T19:05:52Z",
    "updated": "2025-11-23T19:05:52Z",
    "link": "http://arxiv.org/pdf/2511.18589v1.pdf",
    "category": [
      "cs.SE",
      "cs.AI"
    ],
    "authors": [
      "Michael Trusov",
      "Minha Hwang",
      "Zainab Jamal",
      "Swarup Chandra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.04763v2",
    "title": "MiniF2F in Rocq: Automatic Translation Between Proof Assistants -- A Case Study",
    "summary": "In this work, we conduct an experiment using state-of-the-art LLMs to translate MiniF2F into Rocq. The translation task focuses on generating a Rocq theorem based on three sources: a natural language description, the Lean formalization, and the Isabelle formalization. We conducted our experiment in 3 stages of increasing complexity, from basic one-shot prompting to multi-turn conversations that incorporate feedback from unsuccessful attempts. At each stage, we perform multiple rounds of translation using increasingly advanced models: GPT-4o mini, Claude 3.5 Sonnet, o1 mini, and o1. We successfully translated 478 out of 488 theorems. The dataset is opensource: https://github.com/LLM4Rocq/miniF2F-rocq.",
    "published": "2025-02-11T09:32:55Z",
    "updated": "2025-11-24T18:41:20Z",
    "link": "http://arxiv.org/pdf/2503.04763v2.pdf",
    "category": [
      "cs.LO",
      "cs.CL",
      "cs.LG",
      "cs.PL"
    ],
    "authors": [
      "Jules Viennot",
      "Guillaume Baudart",
      "Emilio Jesùs Gallego Arias",
      "Marc Lelarge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.10659v2",
    "title": "Information Extraction From Fiscal Documents Using LLMs",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in text comprehension, but their ability to process complex, hierarchical tabular data remains underexplored. We present a novel approach to extracting structured data from multi-page government fiscal documents using LLM-based techniques. Applied to annual fiscal documents from the State of Karnataka in India (200+ pages), our method achieves high accuracy through a multi-stage pipeline that leverages domain knowledge, sequential context, and algorithmic validation. A large challenge with traditional OCR methods is the inability to verify the accurate extraction of numbers. When applied to fiscal data, the inherent structure of fiscal tables, with totals at each level of the hierarchy, allows for robust internal validation of the extracted data. We use these hierarchical relationships to create multi-level validation checks. We demonstrate that LLMs can read tables and also process document-specific structural hierarchies, offering a scalable process for converting PDF-based fiscal disclosures into research-ready databases. Our implementation shows promise for broader applications across developing country contexts.",
    "published": "2025-11-03T19:17:49Z",
    "updated": "2025-11-24T18:25:34Z",
    "link": "http://arxiv.org/pdf/2511.10659v2.pdf",
    "category": [
      "cs.CL",
      "cs.IR"
    ],
    "authors": [
      "Vikram Aggarwal",
      "Jay Kulkarni",
      "Aditi Mascarenhas",
      "Aakriti Narang",
      "Siddarth Raman",
      "Ajay Shah",
      "Susan Thomas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.01870v3",
    "title": "PEANuT: Parameter-Efficient Adaptation with Weight-aware Neural Tweakers",
    "summary": "Fine-tuning large pre-trained foundation models often yields excellent downstream performance but is prohibitively expensive when updating all parameters. Parameter-efficient fine-tuning (PEFT) methods such as LoRA alleviate this by introducing lightweight update modules, yet they commonly rely on weight-agnostic linear approximations, limiting their expressiveness. In this work, we propose PEANuT, a novel PEFT framework that introduces weight-aware neural tweakers, compact neural modules that generate task-adaptive updates conditioned on frozen pre-trained weights. PEANuT provides a flexible yet efficient way to capture complex update patterns without full model tuning. We theoretically show that PEANuT achieves equivalent or greater expressivity than existing linear PEFT methods with comparable or fewer parameters. Extensive experiments across four benchmarks with over twenty datasets demonstrate that PEANuT consistently outperforms strong baselines in both NLP and vision tasks, while maintaining low computational overhead.",
    "published": "2024-10-02T17:29:23Z",
    "updated": "2025-11-24T18:17:37Z",
    "link": "http://arxiv.org/pdf/2410.01870v3.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Yibo Zhong",
      "Haoxiang Jiang",
      "Lincan Li",
      "Ryumei Nakada",
      "Tianci Liu",
      "Linjun Zhang",
      "Huaxiu Yao",
      "Haoyu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19350v1",
    "title": "Scalable Parameter-Light Spectral Method for Clustering Short Text Embeddings with a Cohesion-Based Evaluation Metric",
    "summary": "Clustering short text embeddings is a foundational task in natural language processing, yet remains challenging due to the need to specify the number of clusters in advance. We introduce a scalable spectral method that estimates the number of clusters directly from the structure of the Laplacian eigenspectrum, constructed using cosine similarities and guided by an adaptive sampling strategy. This sampling approach enables our estimator to efficiently scale to large datasets without sacrificing reliability. To support intrinsic evaluation of cluster quality without ground-truth labels, we propose the Cohesion Ratio, a simple and interpretable evaluation metric that quantifies how much intra-cluster similarity exceeds the global similarity background. It has an information-theoretic motivation inspired by mutual information, and in our experiments it correlates closely with extrinsic measures such as normalized mutual information and homogeneity. Extensive experiments on six short-text datasets and four modern embedding models show that standard algorithms like K-Means and HAC, when guided by our estimator, significantly outperform popular parameter-light methods such as HDBSCAN, OPTICS, and Leiden. These results demonstrate the practical value of our spectral estimator and Cohesion Ratio for unsupervised organization and evaluation of short text data. Implementation of our estimator of k and Cohesion Ratio, along with code for reproducing the experiments, is available at https://anonymous.4open.science/r/towards_clustering-0C2E.",
    "published": "2025-11-24T17:52:58Z",
    "updated": "2025-11-24T17:52:58Z",
    "link": "http://arxiv.org/pdf/2511.19350v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Nikita Neveditsin",
      "Pawan Lingras",
      "Vijay Mago"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.14734v4",
    "title": "Sentence Smith: Controllable Edits for Evaluating Text Embeddings",
    "summary": "Controllable and transparent text generation has been a long-standing goal in NLP. Almost as long-standing is a general idea for addressing this challenge: Parsing text to a symbolic representation, and generating from it. However, earlier approaches were hindered by parsing and generation insufficiencies. Using modern parsers and a safety supervision mechanism, we show how close current methods come to this goal. Concretely, we propose the Sentence Smith framework for English, which has three steps: 1. Parsing a sentence into a semantic graph. 2. Applying human-designed semantic manipulation rules. 3. Generating text from the manipulated graph. A final entailment check (4.) verifies the validity of the applied transformation. To demonstrate our framework's utility, we use it to induce hard negative text pairs that challenge text embedding models. Since the controllable generation makes it possible to clearly isolate different types of semantic shifts, we can evaluate text embedding models in a fine-grained way, also addressing an issue in current benchmarking where linguistic phenomena remain opaque. Human validation confirms that our transparent generation process produces texts of good quality. Notably, our way of generation is very resource-efficient, since it relies only on smaller neural networks.",
    "published": "2025-02-20T17:00:19Z",
    "updated": "2025-11-24T17:36:08Z",
    "link": "http://arxiv.org/pdf/2502.14734v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hongji Li",
      "Andrianos Michail",
      "Reto Gubelmann",
      "Simon Clematide",
      "Juri Opitz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19333v1",
    "title": "Learning to Reason: Training LLMs with GPT-OSS or DeepSeek R1 Reasoning Traces",
    "summary": "Test-time scaling, which leverages additional computation during inference to improve model accuracy, has enabled a new class of Large Language Models (LLMs) that are able to reason through complex problems by understanding the goal, turning this goal into a plan, working through intermediate steps, and checking their own work before answering . Frontier large language models with reasoning capabilities, such as DeepSeek-R1 and OpenAI's gpt-oss, follow the same procedure when solving complex problems by generating intermediate reasoning traces before giving the final answer. Today, these models are being increasingly used to generate reasoning traces that serve as high-quality supervised data for post-training of small and medium-sized language models to teach reasoning capabilities without requiring expensive human curation. In this work, we compare the performance of medium-sized LLMs on Math problems after post-training on two kinds of reasoning traces. We compare the impact of reasoning traces generated by DeepSeek-R1 and gpt-oss LLMs in terms of accuracy and inference efficiency.",
    "published": "2025-11-24T17:26:58Z",
    "updated": "2025-11-24T17:26:58Z",
    "link": "http://arxiv.org/pdf/2511.19333v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Shaltiel Shmidman",
      "Asher Fredman",
      "Oleg Sudakov",
      "Meriem Bendris"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.22006v2",
    "title": "Enhancing Domain-Specific Encoder Models with LLM-Generated Data: How to Leverage Ontologies, and How to Do Without Them",
    "summary": "We investigate the use of LLM-generated data for continual pretraining of encoder models in specialized domains with limited training data, using the scientific domain of invasion biology as a case study. To this end, we leverage domain-specific ontologies by enriching them with LLM-generated data and pretraining the encoder model as an ontology-informed embedding model for concept definitions. To evaluate the effectiveness of this method, we compile a benchmark specifically designed for assessing model performance in invasion biology. After demonstrating substantial improvements over standard LLM pretraining, we investigate the feasibility of applying the proposed approach to domains without comprehensive ontologies by substituting ontological concepts with concepts automatically extracted from a small corpus of scientific abstracts and establishing relationships between concepts through distributional statistics. Our results demonstrate that this automated approach achieves comparable performance using only a small set of scientific abstracts, resulting in a fully automated pipeline for enhancing domain-specific understanding of small encoder models that is especially suited for application in low-resource settings and achieves performance comparable to masked language modeling pretraining on much larger datasets.",
    "published": "2025-03-27T21:51:24Z",
    "updated": "2025-11-24T17:17:31Z",
    "link": "http://arxiv.org/pdf/2503.22006v2.pdf",
    "category": [
      "cs.CL",
      "cs.LG"
    ],
    "authors": [
      "Marc Brinner",
      "Tarek Al Mustafa",
      "Sina Zarrieß"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19317v1",
    "title": "MultiBanAbs: A Comprehensive Multi-Domain Bangla Abstractive Text Summarization Dataset",
    "summary": "This study developed a new Bangla abstractive summarization dataset to generate concise summaries of Bangla articles from diverse sources. Most existing studies in this field have concentrated on news articles, where journalists usually follow a fixed writing style. While such approaches are effective in limited contexts, they often fail to adapt to the varied nature of real-world Bangla texts. In today's digital era, a massive amount of Bangla content is continuously produced across blogs, newspapers, and social media. This creates a pressing need for summarization systems that can reduce information overload and help readers understand content more quickly. To address this challenge, we developed a dataset of over 54,000 Bangla articles and summaries collected from multiple sources, including blogs such as Cinegolpo and newspapers such as Samakal and The Business Standard. Unlike single-domain resources, our dataset spans multiple domains and writing styles. It offers greater adaptability and practical relevance. To establish strong baselines, we trained and evaluated this dataset using several deep learning and transfer learning models, including LSTM, BanglaT5-small, and MTS-small. The results highlight its potential as a benchmark for future research in Bangla natural language processing. This dataset provides a solid foundation for building robust summarization systems and helps expand NLP resources for low-resource languages.",
    "published": "2025-11-24T17:11:49Z",
    "updated": "2025-11-24T17:11:49Z",
    "link": "http://arxiv.org/pdf/2511.19317v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Md. Tanzim Ferdous",
      "Naeem Ahsan Chowdhury",
      "Prithwiraj Bhattacharjee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.02106v3",
    "title": "ContrastScore: Towards Higher Quality, Less Biased, More Efficient Evaluation Metrics with Contrastive Evaluation",
    "summary": "Evaluating the quality of generated text automatically remains a significant challenge. Conventional reference-based metrics have been shown to exhibit relatively weak correlation with human evaluations. Recent research advocates the use of large language models (LLMs) as source-based metrics for natural language generation (NLG) assessment. While promising, LLM-based metrics, particularly those using smaller models, still fall short in aligning with human judgments. In this work, we introduce ContrastScore, a contrastive evaluation metric designed to enable higher-quality, less biased, and more efficient assessment of generated text. We evaluate ContrastScore on two NLG tasks: machine translation and summarization. Experimental results show that ContrastScore consistently achieves stronger correlation with human judgments than both single-model and ensemble-based baselines. Notably, ContrastScore based on Qwen 3B and 0.5B even outperforms Qwen 7B, despite having only half as many parameters, demonstrating its efficiency. Furthermore, it effectively mitigates common evaluation biases such as length and likelihood preferences, resulting in more robust automatic evaluation.",
    "published": "2025-04-02T20:11:45Z",
    "updated": "2025-11-24T17:00:44Z",
    "link": "http://arxiv.org/pdf/2504.02106v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Xiao Wang",
      "Daniil Larionov",
      "Siwei Wu",
      "Yiqi Liu",
      "Steffen Eger",
      "Nafise Sadat Moosavi",
      "Chenghua Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14709v2",
    "title": "Strategic Innovation Management in the Age of Large Language Models Market Intelligence, Adaptive R&D, and Ethical Governance",
    "summary": "This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market for breakthrough ideas.",
    "published": "2025-11-18T17:50:39Z",
    "updated": "2025-11-24T16:42:33Z",
    "link": "http://arxiv.org/pdf/2511.14709v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Raha Aghaei",
      "Ali A. Kiaei",
      "Mahnaz Boush",
      "Mahan Rofoosheh",
      "Mohammad Zavvar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19279v1",
    "title": "MapFormer: Self-Supervised Learning of Cognitive Maps with Input-Dependent Positional Embeddings",
    "summary": "A cognitive map is an internal model which encodes the abstract relationships among entities in the world, giving humans and animals the flexibility to adapt to new situations, with a strong out-of-distribution (OOD) generalization that current AI systems still do not possess. To bridge this gap, we introduce MapFormers, new architectures based on Transformer models, which can learn cognitive maps from observational data and perform path integration in parallel, in a self-supervised manner. Cognitive maps are learned in the model by disentangling structural relationships in the inputs from their specific content, a property that can be achieved naturally by updating the positional encoding in Transformers with input-dependent matrices. We developed two variants of MapFormers that unify absolute and relative positional encoding to model episodic (EM) and working memory (WM), respectively. We tested MapFormers on several tasks, including a classic 2D navigation task, showing that our models can learn a cognitive map of the underlying space and generalize OOD (e.g., to longer sequences) with near-perfect performance, unlike current architectures. Together, these results demonstrate the superiority of models designed to learn a cognitive map, and the importance of introducing a structural bias for structure-content disentanglement, which can be achieved in Transformers with input-dependent positional encoding. MapFormers have broad applications in both neuroscience and AI, by explaining the neural mechanisms giving rise to cognitive maps, while allowing these relation models to be learned at scale.",
    "published": "2025-11-24T16:29:02Z",
    "updated": "2025-11-24T16:29:02Z",
    "link": "http://arxiv.org/pdf/2511.19279v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Victor Rambaud",
      "Salvador Mascarenhas",
      "Yair Lakretz"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19269v1",
    "title": "CDLM: Consistency Diffusion Language Models For Faster Sampling",
    "summary": "Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.",
    "published": "2025-11-24T16:21:25Z",
    "updated": "2025-11-24T16:21:25Z",
    "link": "http://arxiv.org/pdf/2511.19269v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Minseo Kim",
      "Chenfeng Xu",
      "Coleman Hooper",
      "Harman Singh",
      "Ben Athiwaratkun",
      "Ce Zhang",
      "Kurt Keutzer",
      "Amir Gholami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2310.18089v2",
    "title": "Lost in translation: using global fact-checks to measure multilingual misinformation prevalence, spread, and evolution",
    "summary": "Misinformation and disinformation are growing threats in the digital age, affecting people across languages and borders. However, no research has investigated the prevalence of multilingual misinformation and quantified the extent to which misinformation diffuses across languages. This paper investigates the prevalence and dynamics of multilingual misinformation through an analysis of 264,487 fact-checks spanning 95 languages. To study the evolution of claims over time and mutations across languages, we represent fact-checks with multilingual sentence embeddings and build a graph where semantically similar claims are linked. We provide quantitative evidence of repeated fact-checking efforts and establish that claims diffuse across languages. Specifically, we find that while the majority of misinformation claims are only fact-checked once, 10.26%, corresponding to more than 27,000 claims, are checked multiple times. Using fact-checks as a proxy for the spread of misinformation, we find 32.26% of repeated claims cross linguistic boundaries, suggesting that some misinformation permeates language barriers. However, spreading patterns exhibit strong assortativity, with misinformation more likely to spread within the same language or language family. Next we show that fact-checkers take more time to fact-check claims that have crossed language barriers and model the temporal and cross-lingual evolution of claims. We analyze connected components and shortest paths connecting different versions of a claim finding that claims gradually drift over time and undergo greater alteration when traversing languages. Misinformation changes over time, reducing the effectiveness of static claim matching algorithms. The findings advocate for expanded information sharing between fact-checkers globally while underscoring the importance of localized verification.",
    "published": "2023-10-27T12:21:55Z",
    "updated": "2025-11-24T15:21:07Z",
    "link": "http://arxiv.org/pdf/2310.18089v2.pdf",
    "category": [
      "cs.CL",
      "cs.CY",
      "cs.SI"
    ],
    "authors": [
      "Dorian Quelle",
      "Calvin Cheng",
      "Alexandre Bovet",
      "Scott A. Hale"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19168v1",
    "title": "RAVEN++: Pinpointing Fine-Grained Violations in Advertisement Videos with Active Reinforcement Reasoning",
    "summary": "Advertising (Ad) is a cornerstone of the digital economy, yet the moderation of video advertisements remains a significant challenge due to their complexity and the need for precise violation localization. While recent advancements, such as the RAVEN model, have improved coarse-grained violation detection, critical gaps persist in fine-grained understanding, explainability, and generalization. To address these limitations, we propose RAVEN++, a novel framework that introduces three key innovations: 1) Active Reinforcement Learning (RL), which dynamically adapts training to samples of varying difficulty; 2) Fine-Grained Violation Understanding, achieved through hierarchical reward functions and reasoning distillation; and 3) Progressive Multi-Stage Training, which systematically combines knowledge injection, curriculum-based passive RL, and active RL. Extensive experiments on both public and proprietary datasets, on both offline scenarios and online deployed A/B Testing, demonstrate that RAVEN++ outperforms general-purpose LLMs and specialized models like RAVEN in terms of fine-grained violation understanding, reasoning capabilities, and generalization ability.",
    "published": "2025-11-24T14:32:13Z",
    "updated": "2025-11-24T14:32:13Z",
    "link": "http://arxiv.org/pdf/2511.19168v1.pdf",
    "category": [
      "cs.LG",
      "cs.CL"
    ],
    "authors": [
      "Deyi Ji",
      "Yuekui Yang",
      "Liqun Liu",
      "Peng Shu",
      "Haiyang Wu",
      "Shaogang Tang",
      "Xudong Chen",
      "Shaoping Ma",
      "Tianrun Chen",
      "Lanyun Zhu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19166v1",
    "title": "Representational Stability of Truth in Large Language Models",
    "summary": "Large language models (LLMs) are widely used for factual tasks such as \"What treats asthma?\" or \"What is the capital of Latvia?\". However, it remains unclear how stably LLMs encode distinctions between true, false, and neither-true-nor-false content in their internal probabilistic representations. We introduce representational stability as the robustness of an LLM's veracity representations to perturbations in the operational definition of truth. We assess representational stability by (i) training a linear probe on an LLM's activations to separate true from not-true statements and (ii) measuring how its learned decision boundary shifts under controlled label changes. Using activations from sixteen open-source models and three factual domains, we compare two types of neither statements. The first are fact-like assertions about entities we believe to be absent from any training data. We call these unfamiliar neither statements. The second are nonfactual claims drawn from well-known fictional contexts. We call these familiar neither statements. The unfamiliar statements induce the largest boundary shifts, producing up to $40\\%$ flipped truth judgements in fragile domains (such as word definitions), while familiar fictional statements remain more coherently clustered and yield smaller changes ($\\leq 8.2\\%$). These results suggest that representational stability stems more from epistemic familiarity than from linguistic form. More broadly, our approach provides a diagnostic for auditing and training LLMs to preserve coherent truth assignments under semantic uncertainty, rather than optimizing for output accuracy alone.",
    "published": "2025-11-24T14:28:50Z",
    "updated": "2025-11-24T14:28:50Z",
    "link": "http://arxiv.org/pdf/2511.19166v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Samantha Dies",
      "Courtney Maynard",
      "Germans Savcisens",
      "Tina Eliassi-Rad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.16570v2",
    "title": "URLs Help, Topics Guide: Understanding Metadata Utility in LLM Training",
    "summary": "Large Language Models (LLMs) are commonly pretrained on vast corpora of text without utilizing contextual metadata such as source, quality, or topic, leading to a context-free learning paradigm. While recent studies suggest that adding metadata like URL information as context (i.e., auxiliary inputs not used in the loss calculation) can improve training efficiency and downstream performance, they offer limited understanding of which types of metadata are truly effective and under what conditions. In this work, we conduct a systematic evaluation and find that not all metadata types contribute equally. Only URL context speeds up training, whereas quality scores and topic/format domain information offer no clear benefit. Furthermore, the improved downstream performances of URL conditioning emerge only when longer prompts are used at inference time. In addition, we demonstrate that context-aware pretraining enables more controllable generation than context-free pretraining, in a classifier-free guidance fashion. Although topic and format metadata do not accelerate training, they are effective for steering outputs, offering human-interpretable control over generation.",
    "published": "2025-05-22T12:01:20Z",
    "updated": "2025-11-24T14:20:11Z",
    "link": "http://arxiv.org/pdf/2505.16570v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Dongyang Fan",
      "Vinko Sabolčec",
      "Martin Jaggi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19131v1",
    "title": "Eliciting Chain-of-Thought in Base LLMs via Gradient-Based Representation Optimization",
    "summary": "Chain-of-Thought (CoT) reasoning is a critical capability for large language models (LLMs), enabling them to tackle com- plex multi-step tasks. While base LLMs, pre-trained on general text corpora, often struggle with reasoning due to a lack of specialized training, recent studies reveal their latent reason- ing potential tied to hidden states. However, existing hidden state manipulation methods, such as linear activation steering, suffer from limitations due to their rigid and unconstrained nature, often leading to distribution shifts and degraded text quality. In this work, we propose a novel approach for elic- iting CoT reasoning from base LLMs through hidden state manipulation grounded in probabilistic conditional generation. By reformulating the challenge as an optimization problem with a balanced likelihood and prior regularization framework, our method guides hidden states toward reasoning-oriented trajectories while preserving linguistic coherence. Extensive evaluations across mathematical, commonsense, and logical reasoning benchmarks demonstrate that our approach con- sistently outperforms existing steering methods, offering a theoretically principled and effective solution for enhancing reasoning capabilities in base LLMs.",
    "published": "2025-11-24T13:55:57Z",
    "updated": "2025-11-24T13:55:57Z",
    "link": "http://arxiv.org/pdf/2511.19131v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Zijian Wang",
      "Yanxiang Ma",
      "Chang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19122v1",
    "title": "Emotion-Enhanced Multi-Task Learning with LLMs for Aspect Category Sentiment Analysis",
    "summary": "Aspect category sentiment analysis (ACSA) has achieved remarkable progress with large language models (LLMs), yet existing approaches primarily emphasize sentiment polarity while overlooking the underlying emotional dimensions that shape sentiment expressions. This limitation hinders the model's ability to capture fine-grained affective signals toward specific aspect categories. To address this limitation, we introduce a novel emotion-enhanced multi-task ACSA framework that jointly learns sentiment polarity and category-specific emotions grounded in Ekman's six basic emotions. Leveraging the generative capabilities of LLMs, our approach enables the model to produce emotional descriptions for each aspect category, thereby enriching sentiment representations with affective expressions. Furthermore, to ensure the accuracy and consistency of the generated emotions, we introduce an emotion refinement mechanism based on the Valence-Arousal-Dominance (VAD) dimensional framework. Specifically, emotions predicted by the LLM are projected onto a VAD space, and those inconsistent with their corresponding VAD coordinates are re-annotated using a structured LLM-based refinement strategy. Experimental results demonstrate that our approach significantly outperforms strong baselines on all benchmark datasets. This underlines the effectiveness of integrating affective dimensions into ACSA.",
    "published": "2025-11-24T13:52:42Z",
    "updated": "2025-11-24T13:52:42Z",
    "link": "http://arxiv.org/pdf/2511.19122v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yaping Chai",
      "Haoran Xie",
      "Joe S. Qin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19118v1",
    "title": "A symbolic Perl algorithm for the unification of Nahuatl word spellings",
    "summary": "In this paper, we describe a symbolic model for the automatic orthographic unification of Nawatl text documents. Our model is based on algorithms that we have previously used to analyze sentences in Nawatl, and on the corpus called $π$-yalli, consisting of texts in several Nawatl orthographies. Our automatic unification algorithm implements linguistic rules in symbolic regular expressions. We also present a manual evaluation protocol that we have proposed and implemented to assess the quality of the unified sentences generated by our algorithm, by testing in a sentence semantic task. We have obtained encouraging results from the evaluators for most of the desired features of our artificially unified sentences",
    "published": "2025-11-24T13:49:13Z",
    "updated": "2025-11-24T13:49:13Z",
    "link": "http://arxiv.org/pdf/2511.19118v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Juan-José Guzmán-Landa",
      "Jesús Vázquez-Osorio",
      "Juan-Manuel Torres-Moreno",
      "Ligia Quintana Torres",
      "Miguel Figueroa-Saavedra",
      "Martha-Lorena Avendaño-Garrido",
      "Graham Ranger",
      "Patricia Velázquez-Morales",
      "Gerardo Eugenio Sierra Martínez"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19083v1",
    "title": "A Multi-Agent LLM Framework for Multi-Domain Low-Resource In-Context NER via Knowledge Retrieval, Disambiguation and Reflective Analysis",
    "summary": "In-context learning (ICL) with large language models (LLMs) has emerged as a promising paradigm for named entity recognition (NER) in low-resource scenarios. However, existing ICL-based NER methods suffer from three key limitations: (1) reliance on dynamic retrieval of annotated examples, which is problematic when annotated data is scarce; (2) limited generalization to unseen domains due to the LLM's insufficient internal domain knowledge; and (3) failure to incorporate external knowledge or resolve entity ambiguities. To address these challenges, we propose KDR-Agent, a novel multi-agent framework for multi-domain low-resource in-context NER that integrates Knowledge retrieval, Disambiguation, and Reflective analysis. KDR-Agent leverages natural-language type definitions and a static set of entity-level contrastive demonstrations to reduce dependency on large annotated corpora. A central planner coordinates specialized agents to (i) retrieve factual knowledge from Wikipedia for domain-specific mentions, (ii) resolve ambiguous entities via contextualized reasoning, and (iii) reflect on and correct model predictions through structured self-assessment. Experiments across ten datasets from five domains demonstrate that KDR-Agent significantly outperforms existing zero-shot and few-shot ICL baselines across multiple LLM backbones. The code and data can be found at https://github.com/MWXGOD/KDR-Agent.",
    "published": "2025-11-24T13:23:34Z",
    "updated": "2025-11-24T13:23:34Z",
    "link": "http://arxiv.org/pdf/2511.19083v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Wenxuan Mu",
      "Jinzhong Ning",
      "Di Zhao",
      "Yijia Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19063v1",
    "title": "Logic of Montage",
    "summary": "In expressing emotions, as an expression form separate from natural language, we propose an alternative form that complements natural language, acting as a proxy or window for emotional states. First, we set up an expression form \"Effect of Contradictory Structure.\" \"Effect of Contradictory Structure\" is not static but dynamic. Effect in \"Effect of Contradictory Structure\" is unpleasant or pleasant, and the orientation to avoid that unpleasantness is considered pseudo-expression of will. Second, \"Effect of Contradictory Structure\" can be overlapped with each other. This overlapping operation is called \"montage.\" A broader \"Structure\" that includes related \"Effect of Contradictory Structure\" and \"Effect of Structure\" are set up. Montage produces \"Effect of Structure\". In montage, it is necessary to set something like \"strength,\" so we adopted Deleuze and Deleuze/Guattari's word \"intensity\" and set it as an element of our model. We set up a general theoretical framework - Word Import Between Systems (Models) and justified the import of \"intensity\" through Austin's use of the word \"force.\" \"Effect of Structure\" process is demonstrated using the example of proceeding to the next level of education.",
    "published": "2025-11-24T12:55:20Z",
    "updated": "2025-11-24T12:55:20Z",
    "link": "http://arxiv.org/pdf/2511.19063v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hayami Takahashi",
      "Kensuke Takahashi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.05060v2",
    "title": "ModernBERT is More Efficient than Conventional BERT for Chest CT Findings Classification in Japanese Radiology Reports",
    "summary": "Japanese language models for medical text classification face challenges with complex vocabulary and linguistic structures in radiology reports. This study compared three Japanese models--BERT Base, JMedRoBERTa, and ModernBERT--for multi-label classification of 18 chest CT findings. Using the CT-RATE-JPN dataset, all models were fine-tuned under identical conditions. ModernBERT showed clear efficiency advantages, producing substantially fewer tokens and achieving faster training and inference than the other models while maintaining comparable performance on the internal test dataset (exact match accuracy: 74.7% vs. 72.7% for BERT Base). To assess generalizability, we additionally constructed RR-Findings, an external dataset of 243 naturally written Japanese radiology reports annotated using the same schema. Under this domain-shifted setting, performance differences became pronounced: BERT Base outperformed both JMedRoBERTa and ModernBERT, whereas ModernBERT showed the largest decline in exact match accuracy. Average precision differences were smaller, indicating that ModernBERT retained reasonable ranking ability despite reduced calibration. Overall, ModernBERT offers substantial computational efficiency and strong in-domain performance but remains sensitive to real-world linguistic variability. These results highlight the need for more diverse natural-language training data and domain-specific calibration strategies to improve robustness when deploying modern transformer models in heterogeneous clinical environments.",
    "published": "2025-03-07T00:28:08Z",
    "updated": "2025-11-24T12:54:31Z",
    "link": "http://arxiv.org/pdf/2503.05060v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yosuke Yamagishi",
      "Tomohiro Kikuchi",
      "Shouhei Hanaoka",
      "Takeharu Yoshikawa",
      "Osamu Abe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19009v1",
    "title": "Understanding and Mitigating Over-refusal for Large Language Models via Safety Representation",
    "summary": "Large language models demonstrate powerful capabilities across various natural language processing tasks, yet they also harbor safety vulnerabilities. To enhance LLM safety, various jailbreak defense methods have been proposed to guard against harmful outputs. However, improvements in model safety often come at the cost of severe over-refusal, failing to strike a good balance between safety and usability. In this paper, we first analyze the causes of over-refusal from a representation perspective, revealing that over-refusal samples reside at the boundary between benign and malicious samples. Based on this, we propose MOSR, designed to mitigate over-refusal by intervening the safety representation of LLMs. MOSR incorporates two novel components: (1) Overlap-Aware Loss Weighting, which determines the erasure weight for malicious samples by quantifying their similarity to pseudo-malicious samples in the representation space, and (2) Context-Aware Augmentation, which supplements the necessary context for rejection decisions by adding harmful prefixes before rejection responses. Experiments demonstrate that our method outperforms existing approaches in mitigating over-refusal while largely maintaining safety. Overall, we advocate that future defense methods should strike a better balance between safety and over-refusal.",
    "published": "2025-11-24T11:38:53Z",
    "updated": "2025-11-24T11:38:53Z",
    "link": "http://arxiv.org/pdf/2511.19009v1.pdf",
    "category": [
      "cs.CR",
      "cs.CL"
    ],
    "authors": [
      "Junbo Zhang",
      "Ran Chen",
      "Qianli Zhou",
      "Xinyang Deng",
      "Wen Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14258v2",
    "title": "Entropy-Guided Reasoning Compression",
    "summary": "Large reasoning models have demonstrated remarkable performance on complex reasoning tasks, yet the excessive length of their chain-of-thought outputs remains a major practical bottleneck due to high computation cost and poor deployability. Existing compression methods have achieved partial success but overlook a crucial phenomenon in the training process -- the entropy conflict. During compression training, entropy decreases, leading to shorter reasoning but limited exploration, while accuracy-oriented objectives increase entropy, lengthening reasoning chains. This can cause the model to get stuck in a local dilemma. Our analysis further reveals the origin of the entropy conflict: many high-entropy tokens are logical connectors that receive larger gradients and are encouraged under the performance objective, while the compression objective simultaneously penalizes these potentially redundant connectors. This opposing pressure creates a direct source of entropy conflict. To address these issues, we adopt an entropy-guided training framework. As entropy descends, the model is guided toward efficient reasoning by encouraging concise thought steps; as entropy rises, exploration is reinforced under the compact reasoning mode to improve robustness. Experiments on six mathematical benchmarks show that our method compresses reasoning length to 20% of the original while maintaining or even surpassing baseline accuracy. Code and models will be released publicly.",
    "published": "2025-11-18T08:48:58Z",
    "updated": "2025-11-24T10:36:50Z",
    "link": "http://arxiv.org/pdf/2511.14258v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Hourun Zhu",
      "Yang Gao",
      "Wenlong Fei",
      "Jiawei Li",
      "Huashan Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.07682v5",
    "title": "TRIM: Token Reduction and Inference Modeling for Cost-Effective Language Generation",
    "summary": "The high inference cost of Large Language Models (LLMs) poses challenges, especially for tasks requiring lengthy outputs. However, natural language often contains redundancy, which presents an opportunity for optimization. We have observed that LLMs can generate distilled language (i.e., concise outputs that retain essential meaning) when prompted appropriately. We propose TRIM, a pipeline for saving computational cost in which the LLM omits a predefined set of semantically irrelevant and easily inferable words based on the context during inference. Then, a specifically trained smaller language model with lower inference cost reconstructs the distilled answer into the ideal answer. Our experiments show promising results, particularly on the proposed NaLDA evaluation dataset focused on the reconstruction task, with 19.4% saved tokens on average for GPT-4o and only a tiny decrease in evaluation metrics. This suggests that the approach can effectively balance efficiency and accuracy in language processing tasks.",
    "published": "2024-12-10T17:13:35Z",
    "updated": "2025-11-24T09:56:59Z",
    "link": "http://arxiv.org/pdf/2412.07682v5.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Alfredo Garrachón Ruiz",
      "Tomás de la Rosa",
      "Daniel Borrajo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18937v1",
    "title": "Knowledge-based Graphical Method for Safety Signal Detection in Clinical Trials",
    "summary": "We present a graphical, knowledge-based method for reviewing treatment-emergent adverse events (AEs) in clinical trials. The approach enhances MedDRA by adding a hidden medical knowledge layer (Safeterm) that captures semantic relationships between terms in a 2-D map. Using this layer, AE Preferred Terms can be regrouped automatically into similarity clusters, and their association to the trial disease may be quantified. The Safeterm map is available online and connected to aggregated AE incidence tables from ClinicalTrials.gov. For signal detection, we compute treatment-specific disproportionality metrics using shrinkage incidence ratios. Cluster-level EBGM values are then derived through precision-weighted aggregation. Two visual outputs support interpretation: a semantic map showing AE incidence and an expectedness-versus-disproportionality plot for rapid signal detection. Applied to three legacy trials, the automated method clearly recovers all expected safety signals. Overall, augmenting MedDRA with a medical knowledge layer improves clarity, efficiency, and accuracy in AE interpretation for clinical trials.",
    "published": "2025-11-24T09:42:58Z",
    "updated": "2025-11-24T09:42:58Z",
    "link": "http://arxiv.org/pdf/2511.18937v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Francois Vandenhende",
      "Anna Georgiou",
      "Michalis Georgiou",
      "Theodoros Psaras",
      "Ellie Karekla",
      "Elena Hadjicosta"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.22061v3",
    "title": "Safeguarding Privacy of Retrieval Data against Membership Inference Attacks: Is This Query Too Close to Home?",
    "summary": "Retrieval-augmented generation (RAG) mitigates the hallucination problem in large language models (LLMs) and has proven effective for personalized usages. However, delivering private retrieved documents directly to LLMs introduces vulnerability to membership inference attacks (MIAs), which try to determine whether the target data point exists in the private external database or not. Based on the insight that MIA queries typically exhibit high similarity to only one target document, we introduce a novel similarity-based MIA detection framework designed for the RAG system. With the proposed method, we show that a simple detect-and-hide strategy can successfully obfuscate attackers, maintain data utility, and remain system-agnostic against MIA. We experimentally prove its detection and defense against various state-of-the-art MIA methods and its adaptability to existing RAG systems.",
    "published": "2025-05-28T07:35:07Z",
    "updated": "2025-11-24T09:27:33Z",
    "link": "http://arxiv.org/pdf/2505.22061v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yujin Choi",
      "Youngjoo Park",
      "Junyoung Byun",
      "Jaewook Lee",
      "Jinseong Park"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.18486v4",
    "title": "Evaluation of OpenAI o1: Opportunities and Challenges of AGI",
    "summary": "This comprehensive study evaluates the performance of OpenAI's o1-preview large language model across a diverse array of complex reasoning tasks, spanning multiple domains, including computer science, mathematics, natural sciences, medicine, linguistics, and social sciences. Through rigorous testing, o1-preview demonstrated remarkable capabilities, often achieving human-level or superior performance in areas ranging from coding challenges to scientific reasoning and from language processing to creative problem-solving. Key findings include:\n  -83.3% success rate in solving complex competitive programming problems, surpassing many human experts.\n  -Superior ability in generating coherent and accurate radiology reports, outperforming other evaluated models.\n  -100% accuracy in high school-level mathematical reasoning tasks, providing detailed step-by-step solutions.\n  -Advanced natural language inference capabilities across general and specialized domains like medicine.\n  -Impressive performance in chip design tasks, outperforming specialized models in areas such as EDA script generation and bug analysis.\n  -Remarkable proficiency in anthropology and geology, demonstrating deep understanding and reasoning in these specialized fields.\n  -Strong capabilities in quantitative investing. O1 has comprehensive financial knowledge and statistical modeling skills.\n  -Effective performance in social media analysis, including sentiment analysis and emotion recognition.\n  The model excelled particularly in tasks requiring intricate reasoning and knowledge integration across various fields. While some limitations were observed, including occasional errors on simpler problems and challenges with certain highly specialized concepts, the overall results indicate significant progress towards artificial general intelligence.",
    "published": "2024-09-27T06:57:00Z",
    "updated": "2025-11-24T09:15:19Z",
    "link": "http://arxiv.org/pdf/2409.18486v4.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Tianyang Zhong",
      "Zhengliang Liu",
      "Yi Pan",
      "Yutong Zhang",
      "Zeyu Zhang",
      "Yifan Zhou",
      "Shizhe Liang",
      "Zihao Wu",
      "Yanjun Lyu",
      "Peng Shu",
      "Xiaowei Yu",
      "Chao Cao",
      "Hanqi Jiang",
      "Hanxu Chen",
      "Yiwei Li",
      "Junhao Chen",
      "Huawen Hu",
      "Yiheng Liu",
      "Huaqin Zhao",
      "Shaochen Xu",
      "Haixing Dai",
      "Lin Zhao",
      "Ruidong Zhang",
      "Wei Zhao",
      "Zhenyuan Yang",
      "Jingyuan Chen",
      "Peilong Wang",
      "Wei Ruan",
      "Hui Wang",
      "Huan Zhao",
      "Jing Zhang",
      "Yiming Ren",
      "Shihuan Qin",
      "Tong Chen",
      "Jiaxi Li",
      "Arif Hassan Zidan",
      "Afrar Jahin",
      "Minheng Chen",
      "Sichen Xia",
      "Jason Holmes",
      "Yan Zhuang",
      "Jiaqi Wang",
      "Bochen Xu",
      "Weiran Xia",
      "Jichao Yu",
      "Kaibo Tang",
      "Yaxuan Yang",
      "Bolun Sun",
      "Tao Yang",
      "Guoyu Lu",
      "Xianqiao Wang",
      "Lilong Chai",
      "He Li",
      "Jin Lu",
      "Xin Zhang",
      "Bao Ge",
      "Xintao Hu",
      "Lian Zhang",
      "Hua Zhou",
      "Lu Zhang",
      "Shu Zhang",
      "Zhen Xiang",
      "Yudan Ren",
      "Jun Liu",
      "Xi Jiang",
      "Yu Bao",
      "Wei Zhang",
      "Xiang Li",
      "Gang Li",
      "Wei Liu",
      "Dinggang Shen",
      "Andrea Sikora",
      "Xiaoming Zhai",
      "Dajiang Zhu",
      "Tuo Zhang",
      "Tianming Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18891v1",
    "title": "Reproducibility Study of Large Language Model Bayesian Optimization",
    "summary": "In this reproducibility study, we revisit the LLAMBO framework of Daxberger et al. (2024), a prompting-based Bayesian optimization (BO) method that uses large language models as discriminative surrogates and acquisition optimizers via text-only interactions. We replicate the core Bayesmark and HPOBench experiments under the original evaluation protocol, but replace GPT-3.5 with the open-weight Llama 3.1 70B model used for all text encoding components.\n  Our results broadly confirm the main claims of LLAMBO. Contextual warm starting via textual problem and hyperparameter descriptions substantially improves early regret behaviour and reduces variance across runs. LLAMBO's discriminative surrogate is weaker than GP or SMAC as a pure single task regressor, yet benefits from cross task semantic priors induced by the language model. Ablations that remove textual context markedly degrade predictive accuracy and calibration, while the LLAMBO candidate sampler consistently generates higher quality and more diverse proposals than TPE or random sampling. Experiments with smaller backbones (Gemma 27B, Llama 3.1 8B) yield unstable or invalid predictions, suggesting insufficient capacity for reliable surrogate behaviour.\n  Overall, our study shows that the LLAMBO architecture is robust to changing the language model backbone and remains effective when instantiated with Llama 3.1 70B.",
    "published": "2025-11-24T08:48:38Z",
    "updated": "2025-11-24T08:48:38Z",
    "link": "http://arxiv.org/pdf/2511.18891v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Adam Rychert",
      "Gasper Spagnolo",
      "Evgenii Posashkov"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19766v2",
    "title": "SGM: A Framework for Building Specification-Guided Moderation Filters",
    "summary": "Aligning large language models (LLMs) with deployment-specific requirements is critical but inherently imperfect. Despite extensive training, models remain susceptible to misalignment and adversarial inputs such as jailbreaks. Content moderation filters are commonly used as external safeguards, though they typically focus narrowly on safety. We introduce SGM (Specification-Guided Moderation), a flexible framework for training moderation filters grounded in user-defined specifications that go beyond standard safety concerns. SGM automates training data generation without relying on human-written examples, enabling scalable support for diverse, application-specific alignment goals. SGM-trained filters perform on par with state-of-the-art safety filters built on curated datasets, while supporting fine-grained and user-defined alignment control.",
    "published": "2025-05-26T09:49:43Z",
    "updated": "2025-11-24T08:41:00Z",
    "link": "http://arxiv.org/pdf/2505.19766v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Masoomali Fatehkia",
      "Enes Altinisik",
      "Mohamed Osman",
      "Husrev Taha Sencar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.23715v2",
    "title": "Don't Take the Premise for Granted: Evaluating the Premise Critique Ability of Large Language Models",
    "summary": "Large language models (LLMs) have witnessed rapid advancements, demonstrating remarkable capabilities. However, a notable vulnerability persists: LLMs often uncritically accept flawed or contradictory premises, leading to inefficient reasoning and unreliable outputs. This emphasizes the significance of possessing the \\textbf{Premise Critique Ability} for LLMs, defined as the capacity to proactively identify and articulate errors in input premises. Most existing studies assess LLMs' reasoning ability in ideal settings, largely ignoring their vulnerabilities when faced with flawed premises. Thus, we introduce the \\textbf{Premise Critique Bench (PCBench)}, designed by incorporating four error types across three difficulty levels, paired with multi-faceted evaluation metrics. We conducted systematic evaluations of 15 representative LLMs. Our findings reveal: (1) Most models rely heavily on explicit prompts to detect errors, with limited autonomous critique; (2) Premise critique ability depends on question difficulty and error type, with direct contradictions being easier to detect than complex or procedural errors; (3) Reasoning ability does not consistently correlate with the premise critique ability; (4) Flawed premises trigger overthinking in reasoning models, markedly lengthening responses due to repeated attempts at resolving conflicts. These insights underscore the urgent need to enhance LLMs' proactive evaluation of input validity, positioning premise critique as a foundational capability for developing reliable, human-centric systems. The code is available at https://github.com/MLGroupJLU/Premise_Critique.",
    "published": "2025-05-29T17:49:44Z",
    "updated": "2025-11-24T08:35:39Z",
    "link": "http://arxiv.org/pdf/2505.23715v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jinzhe Li",
      "Gengxu Li",
      "Yi Chang",
      "Yuan Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18864v1",
    "title": "Think Before You Prune: Selective Self-Generated Calibration for Pruning Large Reasoning Models",
    "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning benchmarks. However, their long chain-of-thought reasoning processes incur significant inference overhead. Pruning has emerged as a promising approach to reducing computational costs. However, existing efforts have primarily focused on large language models (LLMs), while pruning LRMs remains unexplored. In this work, we conduct the first empirical study on pruning LRMs and show that directly applying existing pruning techniques fails to yield satisfactory results. Our findings indicate that using self-generated reasoning data for calibration can substantially improve pruning performance. We further investigate how the difficulty and length of reasoning data affect pruning outcomes. Our analysis reveals that challenging and moderately long self-generated reasoning data serve as ideal calibration data. Based on these insights, we propose a Selective Self-Generated Reasoning (SSGR) data construction strategy to provide effective calibration data for pruning LRMs. Experimental results on the DeepSeek-R1-Distill model series validate that our strategy improves the reasoning ability of pruned LRMs by 10%-13% compared to general pruning methods.",
    "published": "2025-11-24T08:08:19Z",
    "updated": "2025-11-24T08:08:19Z",
    "link": "http://arxiv.org/pdf/2511.18864v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yang Xiang",
      "Yixin Ji",
      "Juntao Li",
      "Min Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18852v1",
    "title": "FanarGuard: A Culturally-Aware Moderation Filter for Arabic Language Models",
    "summary": "Content moderation filters are a critical safeguard against alignment failures in language models. Yet most existing filters focus narrowly on general safety and overlook cultural context. In this work, we introduce FanarGuard, a bilingual moderation filter that evaluates both safety and cultural alignment in Arabic and English. We construct a dataset of over 468K prompt and response pairs, drawn from synthetic and public datasets, scored by a panel of LLM judges on harmlessness and cultural awareness, and use it to train two filter variants. To rigorously evaluate cultural alignment, we further develop the first benchmark targeting Arabic cultural contexts, comprising over 1k norm-sensitive prompts with LLM-generated responses annotated by human raters. Results show that FanarGuard achieves stronger agreement with human annotations than inter-annotator reliability, while matching the performance of state-of-the-art filters on safety benchmarks. These findings highlight the importance of integrating cultural awareness into moderation and establish FanarGuard as a practical step toward more context-sensitive safeguards.",
    "published": "2025-11-24T07:48:35Z",
    "updated": "2025-11-24T07:48:35Z",
    "link": "http://arxiv.org/pdf/2511.18852v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Masoomali Fatehkia",
      "Enes Altinisik",
      "Husrev Taha Sencar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18850v1",
    "title": "Cognitive Alpha Mining via LLM-Driven Code-Based Evolution",
    "summary": "Discovering effective predictive signals, or ``alphas,'' from financial data with high dimensionality and extremely low signal-to-noise ratio remains a difficult open problem. Despite progress in deep learning, genetic programming, and, more recently, large language model (LLM)--based factor generation, existing approaches still explore only a narrow region of the vast alpha search space. Neural models tend to produce opaque and fragile patterns, while symbolic or formula-based methods often yield redundant or economically ungrounded expressions that generalize poorly. Although different in form, these paradigms share a key limitation: none can conduct broad, structured, and human-like exploration that balances logical consistency with creative leaps. To address this gap, we introduce the Cognitive Alpha Mining Framework (CogAlpha), which combines code-level alpha representation with LLM-driven reasoning and evolutionary search. Treating LLMs as adaptive cognitive agents, our framework iteratively refines, mutates, and recombines alpha candidates through multi-stage prompts and financial feedback. This synergistic design enables deeper thinking, richer structural diversity, and economically interpretable alpha discovery, while greatly expanding the effective search space. Experiments on A-share equities demonstrate that CogAlpha consistently discovers alphas with superior predictive accuracy, robustness, and generalization over existing methods. Our results highlight the promise of aligning evolutionary optimization with LLM-based reasoning for automated and explainable alpha discovery. All source code will be released.",
    "published": "2025-11-24T07:45:59Z",
    "updated": "2025-11-24T07:45:59Z",
    "link": "http://arxiv.org/pdf/2511.18850v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Fengyuan Liu",
      "Huang Yi",
      "Sichun Luo",
      "Yuqi Wang",
      "Yazheng Yang",
      "Xinye Li",
      "Zefa Hu",
      "Junlan Feng",
      "Qi Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18848v1",
    "title": "Large Language Models for the Summarization of Czech Documents: From History to the Present",
    "summary": "Text summarization is the task of automatically condensing longer texts into shorter, coherent summaries while preserving the original meaning and key information. Although this task has been extensively studied in English and other high-resource languages, Czech summarization, particularly in the context of historical documents, remains underexplored. This is largely due to the inherent linguistic complexity of Czech and the lack of high-quality annotated datasets.\n  In this work, we address this gap by leveraging the capabilities of Large Language Models (LLMs), specifically Mistral and mT5, which have demonstrated strong performance across a wide range of natural language processing tasks and multilingual settings. In addition, we also propose a translation-based approach that first translates Czech texts into English, summarizes them using an English-language model, and then translates the summaries back into Czech. Our study makes the following main contributions: We demonstrate that LLMs achieve new state-of-the-art results on the SumeCzech dataset, a benchmark for modern Czech text summarization, showing the effectiveness of multilingual LLMs even for morphologically rich, medium-resource languages like Czech. We introduce a new dataset, Posel od Čerchova, designed for the summarization of historical Czech texts. This dataset is derived from digitized 19th-century publications and annotated for abstractive summarization. We provide initial baselines using modern LLMs to facilitate further research in this underrepresented area.\n  By combining cutting-edge models with both modern and historical Czech datasets, our work lays the foundation for further progress in Czech summarization and contributes valuable resources for future research in Czech historical document processing and low-resource summarization more broadly.",
    "published": "2025-11-24T07:40:31Z",
    "updated": "2025-11-24T07:40:31Z",
    "link": "http://arxiv.org/pdf/2511.18848v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Václav Tran",
      "Jakub Šmíd",
      "Ladislav Lenc",
      "Jean-Pierre Salmon",
      "Pavel Král"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.17265v4",
    "title": "Systematic Reward Gap Optimization for Mitigating VLM Hallucinations",
    "summary": "The success of Direct Preference Optimization (DPO) in mitigating hallucinations in Vision Language Models (VLMs) critically hinges on the true reward gaps within preference pairs. However, current methods, typically relying on ranking or rewriting strategies, often struggle to optimize these reward gaps in a systematic way during data curation. A core difficulty lies in precisely characterizing and strategically manipulating the overall reward gap configuration, that is, the deliberate design of how to shape these reward gaps within each preference pair across the data. To address this, we introduce Topic-level Preference Rewriting(TPR), a novel framework designed for the systematic optimization of reward gap configuration. Through selectively replacing semantic topics within VLM responses with model's own resampled candidates for targeted rewriting, TPR can provide topic-level control over fine-grained semantic details. This precise control enables advanced data curation strategies, such as progressively adjusting the difficulty of rejected responses, thereby sculpting an effective reward gap configuration that guides the model to overcome challenging hallucinations. Comprehensive experiments demonstrate TPR achieves state-of-the-art performance on multiple hallucination benchmarks, outperforming previous methods by an average of 20%. Notably, it significantly reduces hallucinations by up to 93% on ObjectHal-Bench, and also exhibits superior data efficiency towards robust and cost-effective VLM alignment. Code and datasets are available at https://tpr-dpo.github.io .",
    "published": "2024-11-26T09:42:07Z",
    "updated": "2025-11-24T07:35:03Z",
    "link": "http://arxiv.org/pdf/2411.17265v4.pdf",
    "category": [
      "cs.CL",
      "cs.CV"
    ],
    "authors": [
      "Lehan He",
      "Zeren Chen",
      "Zhelun Shi",
      "Tianyu Yu",
      "Jing Shao",
      "Lu Sheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18843v1",
    "title": "A Reproducible Framework for Neural Topic Modeling in Focus Group Analysis",
    "summary": "Focus group discussions generate rich qualitative data but their analysis traditionally relies on labor-intensive manual coding that limits scalability and reproducibility. We present a rigorous, reproducible computational framework for applying neural topic modeling to focus group transcripts, addressing fundamental methodological challenges: hyperparameter sensitivity, model stability, and validation of interpretability. Using BERTopic applied to ten focus groups exploring HPV vaccine perceptions in Tunisia (1,076 utterances), we conducted systematic evaluation across 27 hyperparameter configurations, assessed stability through bootstrap resampling with 30 replicates per configuration, and validated interpretability through formal human evaluation by three domain experts. Our analysis demonstrates substantial sensitivity to hyperparameter choices and reveals that metric selection for stability assessment must align with analytical goals. A hierarchical merging strategy (extracting fine-grained topics for stability then consolidating for interpretability) effectively navigates the stability-coherence tradeoff, achieving coherence of 0.558 compared to 0.539 for direct extraction. Human validation confirmed topic quality with very good inter-rater reliability (ICC = 0.79, weighted Cohen's kappa = 0.578). Our framework provides practical guidelines that researchers can adapt to their own qualitative research contexts. All code, data processing scripts, and evaluation protocols are publicly available to support reproduction and extension of this work.",
    "published": "2025-11-24T07:30:15Z",
    "updated": "2025-11-24T07:30:15Z",
    "link": "http://arxiv.org/pdf/2511.18843v1.pdf",
    "category": [
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "authors": [
      "Heger Arfaoui",
      "Mohammed Iheb Hergli",
      "Beya Benzina",
      "Slimane BenMiled"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.09456v3",
    "title": "IAG: Input-aware Backdoor Attack on VLM-based Visual Grounding",
    "summary": "Recent advances in vision-language models (VLMs) have significantly enhanced the visual grounding task, which involves locating objects in an image based on natural language queries. Despite these advancements, the security of VLM-based grounding systems has not been thoroughly investigated. This paper reveals a novel and realistic vulnerability: the first multi-target backdoor attack on VLM-based visual grounding. Unlike prior attacks that rely on static triggers or fixed targets, we propose IAG, a method that dynamically generates input-aware, text-guided triggers conditioned on any specified target object description to execute the attack. This is achieved through a text-conditioned UNet that embeds imperceptible target semantic cues into visual inputs while preserving normal grounding performance on benign samples. We further develop a joint training objective that balances language capability with perceptual reconstruction to ensure imperceptibility, effectiveness, and stealth. Extensive experiments on multiple VLMs (e.g., LLaVA, InternVL, Ferret) and benchmarks (RefCOCO, RefCOCO+, RefCOCOg, Flickr30k Entities, and ShowUI) demonstrate that IAG achieves the best ASRs compared with other baselines on almost all settings without compromising clean accuracy, maintaining robustness against existing defenses, and exhibiting transferability across datasets and models. These findings underscore critical security risks in grounding-capable VLMs and highlight the need for further research on trustworthy multimodal understanding.",
    "published": "2025-08-13T03:22:19Z",
    "updated": "2025-11-24T07:19:43Z",
    "link": "http://arxiv.org/pdf/2508.09456v3.pdf",
    "category": [
      "cs.CV",
      "cs.CL",
      "cs.CR"
    ],
    "authors": [
      "Junxian Li",
      "Beining Xu",
      "Simin Chen",
      "Jiatong Li",
      "Jingdi Lei",
      "Haodong Zhao",
      "Di Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18832v1",
    "title": "Concept than Document: Context Compression via AMR-based Conceptual Entropy",
    "summary": "Large Language Models (LLMs) face information overload when handling long contexts, particularly in Retrieval-Augmented Generation (RAG) where extensive supporting documents often introduce redundant content. This issue not only weakens reasoning accuracy but also increases computational overhead. We propose an unsupervised context compression framework that exploits Abstract Meaning Representation (AMR) graphs to preserve semantically essential information while filtering out irrelevant text. By quantifying node-level entropy within AMR graphs, our method estimates the conceptual importance of each node, enabling the retention of core semantics. Specifically, we construct AMR graphs from raw contexts, compute the conceptual entropy of each node, and screen significant informative nodes to form a condensed and semantically focused context than raw documents. Experiments on the PopQA and EntityQuestions datasets show that our method outperforms vanilla and other baselines, achieving higher accuracy while substantially reducing context length. To the best of our knowledge, this is the first work introducing AMR-based conceptual entropy for context compression, demonstrating the potential of stable linguistic features in context engineering.",
    "published": "2025-11-24T07:08:02Z",
    "updated": "2025-11-24T07:08:02Z",
    "link": "http://arxiv.org/pdf/2511.18832v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Kaize Shi",
      "Xueyao Sun",
      "Xiaohui Tao",
      "Lin Li",
      "Qika Lin",
      "Guandong Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18824v1",
    "title": "Assessing the alignment between infants' visual and linguistic experience using multimodal language models",
    "summary": "Figuring out which objects or concepts words refer to is a central language learning challenge for young children. Most models of this process posit that children learn early object labels from co-occurrences of words and their referents that occur when someone around them talks about an object in the immediate physical environment. But how aligned in time are children's visual and linguistic experiences during everyday learning? To date, answers to this question have been limited by the need for labor-intensive manual annotations of vision-language co-occurrences. Here, we evaluate the use of contrastive language-image pretraining (CLIP) models to automatically characterize vision-language alignment in egocentric videos taken from the infant perspective in home environments. After validating CLIP alignment scores using human alignment judgments, we apply this metric to a large corpus of infant-perspective videos. We show that idealized aligned moments for learning (e.g., \"look at the ball\" with a ball present in the child's view) are relatively rare in children's everyday experiences compared to modern machine learning datasets, and highlight variability in alignment both within and across children. These findings suggest that infrequent alignment is a constraint for models describing early word learning and offer a new method for investigating children's multimodal environment.",
    "published": "2025-11-24T06:58:16Z",
    "updated": "2025-11-24T06:58:16Z",
    "link": "http://arxiv.org/pdf/2511.18824v1.pdf",
    "category": [
      "cs.CV",
      "cs.CL"
    ],
    "authors": [
      "Alvin Wei Ming Tan",
      "Jane Yang",
      "Tarun Sepuri",
      "Khai Loong Aw",
      "Robert Z. Sparks",
      "Zi Yin",
      "Virginia A. Marchman",
      "Michael C. Frank",
      "Bria Long"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.18436v5",
    "title": "Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching",
    "summary": "Recent large language models (LLMs) demonstrate multilingual abilities, yet they are English-centric due to dominance of English in training corpora. The limited resource for low-resource languages remains a crucial challenge. Code-switching (CS), a phenomenon where multilingual speakers alternate between languages in a discourse, can convey subtle cultural and linguistic nuances that can be otherwise lost in translation and elicits language-specific knowledge in human communications. In light of this, we investigate whether code-switching can activate, or identify and leverage knowledge for reasoning when LLMs solve low-resource language tasks. To facilitate the research, we first present EnKoQA, a synthetic English-Korean CS question-answering dataset. We provide comprehensive analysis on a variety of multilingual LLMs by subdividing activation process into knowledge identification and knowledge leveraging. Our results demonstrate that compared to English text, CS can faithfully activate knowledge inside LLMs especially on language-specific domains, suggesting the potential of code-switching on low-resource language tasks.",
    "published": "2024-10-24T05:14:03Z",
    "updated": "2025-11-24T06:51:53Z",
    "link": "http://arxiv.org/pdf/2410.18436v5.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Seoyeon Kim",
      "Huiseo Kim",
      "Chanjun Park",
      "Jinyoung Yeo",
      "Dongha Lee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.06447v2",
    "title": "SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning",
    "summary": "Long-context inference for Large Language Models (LLMs) is heavily limited by high computational demands. While several existing methods optimize attention computation, they still process the full set of hidden states at each layer, limiting overall efficiency. In this work, we propose SlimInfer, an innovative framework that aims to accelerate inference by directly pruning less critical prompt tokens during the forward pass. Our key insight is an information diffusion phenomenon: As information from critical tokens propagates through layers, it becomes distributed across the entire sequence. This diffusion process suggests that LLMs can maintain their semantic integrity when excessive tokens, even including these critical ones, are pruned in hidden states. Motivated by this, SlimInfer introduces a dynamic fine-grained pruning mechanism that accurately removes redundant tokens of hidden state at intermediate layers. This layer-wise pruning naturally enables an asynchronous KV cache manager that prefetches required token blocks without complex predictors, reducing both memory usage and I/O costs. Extensive experiments show that SlimInfer can achieve up to $\\mathbf{2.53\\times}$ time-to-first-token (TTFT) speedup and $\\mathbf{1.88\\times}$ end-to-end latency reduction for LLaMA3.1-8B-Instruct on a single RTX 4090, without sacrificing performance on LongBench. Our code is available at https://github.com/Longxmas/SlimInfer.",
    "published": "2025-08-08T16:42:38Z",
    "updated": "2025-11-24T06:26:25Z",
    "link": "http://arxiv.org/pdf/2508.06447v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Lingkun Long",
      "Rubing Yang",
      "Yushi Huang",
      "Desheng Hui",
      "Ao Zhou",
      "Jianlei Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18774v1",
    "title": "Context-Aware Whisper for Arabic ASR Under Linguistic Varieties",
    "summary": "Low-resource ASR remains a challenging problem, especially for languages like Arabic that exhibit wide dialectal variation and limited labeled data. We propose context-aware prompting strategies to adapt OpenAI's Whisper for Arabic speech recognition without retraining. Our methods include decoder prompting with first-pass transcriptions or retrieved utterances, and encoder prefixing using speech synthesized in the target speaker's voice. We introduce techniques such as prompt reordering, speaker-aware prefix synthesis, and modality-specific retrieval (lexical, semantic, acoustic) to improve transcription in real-world, zero-shot settings. Evaluated on nine Arabic linguistic conditions, our approach reduces WER by up to 22.3% on Modern Standard Arabic and 9.2% on dialectal speech, significantly mitigating hallucinations and speaker mismatch.",
    "published": "2025-11-24T05:16:04Z",
    "updated": "2025-11-24T05:16:04Z",
    "link": "http://arxiv.org/pdf/2511.18774v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Bashar Talafha",
      "Amin Abu Alhassan",
      "Muhammad Abdul-Mageed"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18751v1",
    "title": "Robust Multimodal Sentiment Analysis with Distribution-Based Feature Recovery and Fusion",
    "summary": "As posts on social media increase rapidly, analyzing the sentiments embedded in image-text pairs has become a popular research topic in recent years. Although existing works achieve impressive accomplishments in simultaneously harnessing image and text information, they lack the considerations of possible low-quality and missing modalities. In real-world applications, these issues might frequently occur, leading to urgent needs for models capable of predicting sentiment robustly. Therefore, we propose a Distribution-based feature Recovery and Fusion (DRF) method for robust multimodal sentiment analysis of image-text pairs. Specifically, we maintain a feature queue for each modality to approximate their feature distributions, through which we can simultaneously handle low-quality and missing modalities in a unified framework. For low-quality modalities, we reduce their contributions to the fusion by quantitatively estimating modality qualities based on the distributions. For missing modalities, we build inter-modal mapping relationships supervised by samples and distributions, thereby recovering the missing modalities from available ones. In experiments, two disruption strategies that corrupt and discard some modalities in samples are adopted to mimic the low-quality and missing modalities in various real-world scenarios. Through comprehensive experiments on three publicly available image-text datasets, we demonstrate the universal improvements of DRF compared to SOTA methods under both two strategies, validating its effectiveness in robust multimodal sentiment analysis.",
    "published": "2025-11-24T04:24:33Z",
    "updated": "2025-11-24T04:24:33Z",
    "link": "http://arxiv.org/pdf/2511.18751v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Daiqing Wu",
      "Dongbao Yang",
      "Can Ma",
      "Yu Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18749v1",
    "title": "Large Language Models Require Curated Context for Reliable Political Fact-Checking -- Even with Reasoning and Web Search",
    "summary": "Large language models (LLMs) have raised hopes for automated end-to-end fact-checking, but prior studies report mixed results. As mainstream chatbots increasingly ship with reasoning capabilities and web search tools -- and millions of users already rely on them for verification -- rigorous evaluation is urgent. We evaluate 15 recent LLMs from OpenAI, Google, Meta, and DeepSeek on more than 6,000 claims fact-checked by PolitiFact, comparing standard models with reasoning- and web-search variants. Standard models perform poorly, reasoning offers minimal benefits, and web search provides only moderate gains, despite fact-checks being available on the web. In contrast, a curated RAG system using PolitiFact summaries improved macro F1 by 233% on average across model variants. These findings suggest that giving models access to curated high-quality context is a promising path for automated fact-checking.",
    "published": "2025-11-24T04:22:32Z",
    "updated": "2025-11-24T04:22:32Z",
    "link": "http://arxiv.org/pdf/2511.18749v1.pdf",
    "category": [
      "cs.CL",
      "cs.CY",
      "cs.IR"
    ],
    "authors": [
      "Matthew R. DeVerna",
      "Kai-Cheng Yang",
      "Harry Yaojun Yan",
      "Filippo Menczer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17086v3",
    "title": "Advancing Multi-Agent RAG Systems with Minimalist Reinforcement Learning",
    "summary": "Large Language Models (LLMs) equipped with modern Retrieval-Augmented Generation (RAG) systems often employ multi-turn interaction pipelines to interface with search engines for complex reasoning tasks. However, such multi-turn interactions inevitably produce long intermediate contexts, as context length grows exponentially with exploration depth. This leads to a well-known limitation of LLMs: their difficulty in effectively leveraging information from long contexts. This problem is further amplified in RAG systems that depend on in-context learning, where few-shot demonstrations must also be included in the prompt, compounding the context-length bottleneck. To address these challenges, we propose Mujica-MyGo, a unified framework for efficient multi-turn reasoning in RAG. Inspired by the divide-and-conquer principle, we introduce Mujica (Multi-hop Joint Intelligence for Complex Question Answering), a multi-agent RAG workflow that decomposes multi-turn interactions into cooperative sub-interactions, thereby mitigating long-context issues. To eliminate the dependency on in-context learning, we further develop MyGO (Minimalist Policy Gradient Optimization), a lightweight and efficient reinforcement learning algorithm that enables effective post-training of LLMs within complex RAG pipelines. We provide theoretical guarantees for MyGO's convergence to the optimal policy. Empirical evaluations across diverse question-answering benchmarks, covering both text corpora and knowledge graphs, show that Mujica-MyGO achieves superior performance.",
    "published": "2025-05-20T18:33:03Z",
    "updated": "2025-11-24T00:33:29Z",
    "link": "http://arxiv.org/pdf/2505.17086v3.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yihong Wu",
      "Liheng Ma",
      "Muzhi Li",
      "Jiaming Zhou",
      "Lei Ding",
      "Jianye Hao",
      "Ho-fung Leung",
      "Irwin King",
      "Yingxue Zhang",
      "Jian-Yun Nie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18659v1",
    "title": "CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning",
    "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but still suffers from long contexts and disjoint retrieval-generation optimization. In this work, we propose CLaRa (Continuous Latent Reasoning), a unified framework that performs embedding-based compression and joint optimization in a shared continuous space. To obtain semantically rich and retrievable compressed vectors, we introduce SCP, a key-preserving data synthesis framework using QA and paraphrase supervision. CLaRa then trains the reranker and generator end-to-end via a single language modeling loss, with gradients flowing through both modules using a differentiable top-k estimator. Theoretically, this unified optimization aligns retrieval relevance with answer quality. Experiments across multiple QA benchmarks show that CLaRa achieves state-of-the-art compression and reranking performance, often surpassing text-based fine-tuned baselines.",
    "published": "2025-11-24T00:11:14Z",
    "updated": "2025-11-24T00:11:14Z",
    "link": "http://arxiv.org/pdf/2511.18659v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Jie He",
      "Richard He Bai",
      "Sinead Williamson",
      "Jeff Z. Pan",
      "Navdeep Jaitly",
      "Yizhe Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18649v1",
    "title": "Evaluating Large Language Models on the 2026 Korean CSAT Mathematics Exam: Measuring Mathematical Ability in a Zero-Data-Leakage Setting",
    "summary": "This study systematically evaluated the mathematical reasoning capabilities of Large Language Models (LLMs) using the 2026 Korean College Scholastic Ability Test (CSAT) Mathematics section, ensuring a completely contamination-free evaluation environment. To address data leakage issues in existing benchmarks, we digitized all 46 questions (22 common and 24 elective) within two hours of the exam's public release, eliminating any possibility of inclusion in model training data. We conducted comprehensive evaluations of 24 state-of-the-art LLMs across varying input modalities (text, image, text+figure) and prompt languages (Korean, English).\n  GPT-5 Codex achieved the only perfect score (100 points) with text input and Korean prompts, while Grok 4, GPT-5, and Deepseek R1 scored above 95 points. Notably, gpt-oss-20B achieved 95.7 points despite its relatively small size, demonstrating high cost-effectiveness. Problem-specific analysis revealed geometry as the weakest domain (77.7% average) with significant performance degradation on 4-point high-difficulty problems. Text input consistently outperformed image input, while prompt language effects varied by model scale.\n  In reasoning enhancement experiments with GPT-5 series, increased reasoning intensity improved performance (from 82.6 to 100 points) but quadrupled token usage and drastically reduced efficiency, suggesting that models with minimal reasoning may be more practical. This research contributes: (1) implementation of a completely unexposed evaluation environment, (2) a real-exam-based LLM assessment framework, and (3) a practical evaluation perspective integrating performance, cost, and time considerations. Detailed results and model comparisons are available at the 2026 Korean CSAT LLM Evaluation Leaderboard (https://isoft.cnu.ac.kr/csat2026/).",
    "published": "2025-11-23T23:09:33Z",
    "updated": "2025-11-23T23:09:33Z",
    "link": "http://arxiv.org/pdf/2511.18649v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Goun Pyeon",
      "Inbum Heo",
      "Jeesu Jung",
      "Taewook Hwang",
      "Hyuk Namgoong",
      "Hyein Seo",
      "Yerim Han",
      "Eunbin Kim",
      "Hyeonseok Kang",
      "Sangkeun Jung"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.19580v5",
    "title": "LLMs4All: A Review of Large Language Models Across Academic Disciplines",
    "summary": "Cutting-edge Artificial Intelligence (AI) techniques keep reshaping our view of the world. For example, Large Language Models (LLMs) based applications such as ChatGPT have shown the capability of generating human-like conversation on extensive topics. Due to the impressive performance on a variety of language-related tasks (e.g., open-domain question answering, translation, and document summarization), one can envision the far-reaching impacts that can be brought by the LLMs with broader real-world applications (e.g., customer service, education and accessibility, and scientific discovery). Inspired by their success, this paper will offer an overview of state-of-the-art LLMs and their integration into a wide range of academic disciplines, including: (1) arts, letters, and law (e.g., history, philosophy, political science, arts and architecture, law), (2) economics and business (e.g., finance, economics, accounting, marketing), and (3) science and engineering (e.g., mathematics, physics and mechanical engineering, chemistry and chemical engineering, life sciences and bioengineering, earth sciences and civil engineering, computer science and electrical engineering). Integrating humanity and technology, in this paper, we will explore how LLMs are shaping research and practice in these fields, while also discussing key limitations, open challenges, and future directions in the era of generative AI. The review of how LLMs are engaged across disciplines-along with key observations and insights-can help researchers and practitioners interested in exploiting LLMs to advance their works in diverse real-world applications.",
    "published": "2025-09-23T21:09:24Z",
    "updated": "2025-11-23T22:45:29Z",
    "link": "http://arxiv.org/pdf/2509.19580v5.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Yanfang Ye",
      "Zheyuan Zhang",
      "Tianyi Ma",
      "Zehong Wang",
      "Yiyang Li",
      "Shifu Hou",
      "Weixiang Sun",
      "Kaiwen Shi",
      "Yijun Ma",
      "Wei Song",
      "Ahmed Abbasi",
      "Ying Cheng",
      "Jane Cleland-Huang",
      "Steven Corcelli",
      "Robert Goulding",
      "Ming Hu",
      "Ting Hua",
      "John Lalor",
      "Fang Liu",
      "Tengfei Luo",
      "Edward Maginn",
      "Nuno Moniz",
      "Jason Rohr",
      "Brett Savoie",
      "Daniel Slate",
      "Matthew Webber",
      "Olaf Wiest",
      "Johnny Zhang",
      "Nitesh V. Chawla"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13467v2",
    "title": "Non-Linear Scoring Model for Translation Quality Evaluation",
    "summary": "Analytic Translation Quality Evaluation (TQE), based on Multidimensional Quality Metrics (MQM), traditionally uses a linear error-to-penalty scale calibrated to a reference sample of 1000-2000 words. However, linear extrapolation biases judgment on samples of different sizes, over-penalizing short samples and under-penalizing long ones, producing misalignment with expert intuition.\n  Building on the Multi-Range framework, this paper presents a calibrated, non-linear scoring model that better reflects how human content consumers perceive translation quality across samples of varying length. Empirical data from three large-scale enterprise environments shows that acceptable error counts grow logarithmically, not linearly, with sample size.\n  Psychophysical and cognitive evidence, including the Weber-Fechner law and Cognitive Load Theory, supports this premise by explaining why the perceptual impact of additional errors diminishes while the cognitive burden grows with scale. We propose a two-parameter model\n  E(x) = a * ln(1 + b * x), a, b > 0,\n  anchored to a reference tolerance and calibrated from two tolerance points using a one-dimensional root-finding step. The model yields an explicit interval within which the linear approximation stays within +/-20 percent relative error and integrates into existing evaluation workflows with only a dynamic tolerance function added.\n  The approach improves interpretability, fairness, and inter-rater reliability across both human and AI-generated translations. By operationalizing a perceptually valid scoring paradigm, it advances translation quality evaluation toward more accurate and scalable assessment. The model also provides a stronger basis for AI-based document-level evaluation aligned with human judgment. Implementation considerations for CAT/LQA systems and implications for human and AI-generated text evaluation are discussed.",
    "published": "2025-11-17T15:09:22Z",
    "updated": "2025-11-23T22:43:55Z",
    "link": "http://arxiv.org/pdf/2511.13467v2.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Serge Gladkoff",
      "Lifeng Han",
      "Katerina Gasova"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18619v1",
    "title": "Prompt Optimization as a State-Space Search Problem",
    "summary": "Language Models are extremely susceptible to performance collapse with even small changes to input prompt strings. Libraries such as DSpy (from Stanford NLP) avoid this problem through demonstration-based prompt optimisation. Inspired by this, I propose an alternative approach that treats prompt optimisation as a classical state-space search problem. I model the prompt space as a graph where nodes represent prompt states and edges correspond to deliberate transformations such as shortening, adding examples, or re- ordering content. Using beam search and random walk algorithms, I systematically explore this space, evaluating candidates on development sets and pruning unpromising branches. Across five NLP tasks (sentiment classification, question answering, summarisation, reason- ing, and natural language inference), I find that even shallow search configurations (beam width=2, depth=2) improve upon seed prompts on development sets. For instance, beam search achieves development accuracy gains from 0.40 to 0.80 on reasoning tasks, though test set improvements are more modest (0.20 to 0.50), indicating overfitting to the develop- ment heuristic. Analysis of successful optimisation paths reveals that transformations that make prompts concise appear most frequently, while verbosity operators are never selected. My results validate prompt optimization as a search problem and suggest that with greater computational resources and improved evaluation metrics, deeper exploration could yield more robust prompts that generalize beyond development sets. Code and implementation are available at [https://github.com/MaanasTaneja/PromptOptimiser].",
    "published": "2025-11-23T21:24:13Z",
    "updated": "2025-11-23T21:24:13Z",
    "link": "http://arxiv.org/pdf/2511.18619v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Maanas Taneja"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18616v1",
    "title": "A Benchmark for Zero-Shot Belief Inference in Large Language Models",
    "summary": "Beliefs are central to how humans reason, communicate, and form social connections, yet most computational approaches to studying them remain confined to narrow sociopolitical contexts and rely on fine-tuning for optimal performance. Despite the growing use of large language models (LLMs) across disciplines, how well these systems generalize across diverse belief domains remains unclear. We introduce a systematic, reproducible benchmark that evaluates the ability of LLMs to predict individuals' stances on a wide range of topics in a zero-shot setting using data from an online debate platform. The benchmark includes multiple informational conditions that isolate the contribution of demographic context and known prior beliefs to predictive success. Across several small- to medium-sized models, we find that providing more background information about an individual improves predictive accuracy, but performance varies substantially across belief domains. These findings reveal both the capacity and limitations of current LLMs to emulate human reasoning, advancing the study of machine behavior and offering a scalable framework for modeling belief systems beyond the sociopolitical sphere.",
    "published": "2025-11-23T21:13:20Z",
    "updated": "2025-11-23T21:13:20Z",
    "link": "http://arxiv.org/pdf/2511.18616v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "Joseph Malone",
      "Rachith Aiyappa",
      "Byunghwee Lee",
      "Haewoon Kwak",
      "Jisun An",
      "Yong-Yeol Ahn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18597v1",
    "title": "Toward Trustworthy Difficulty Assessments: Large Language Models as Judges in Programming and Synthetic Tasks",
    "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in natural language and code generation, and are increasingly deployed as automatic judges of model outputs and learning activities. Yet, their behavior on structured tasks such as predicting the difficulty of competitive programming problems remains under-explored. We conduct a systematic comparison of GPT-4o, used purely as a natural-language difficulty assessor, against an interpretable Light-GBM ensemble trained on explicit numeric and textual features. On a dataset of 1,825 LeetCode problems labeled Easy, Medium, or Hard, LightGBM attains 86% accuracy, whereas GPT-4o reaches only 37.75%. Detailed analyses, including confusion matrices and SHAP-based interpretability, show that numeric constraints -- such as input size limits and acceptance rates -- play a crucial role in separating Hard problems from easier ones. By contrast, GPT-4o often overlooks these cues and exhibits a strong bias toward simpler categories. We further probe GPT-4o through a synthetic Hard-problem generation protocol. Surprisingly, GPT-4o labels almost all of its own synthetic Hard problems as Medium, contradicting its tendency to downgrade real Hard problems to Easy. Our findings connect to recent work on LLMs-as-judges and automatic difficulty estimation in programming and education, and highlight concrete failure modes that must be addressed before LLM-based judges can be considered trustworthy in competitive programming, educational platforms, or reinforcement-learning pipelines.",
    "published": "2025-11-23T19:39:44Z",
    "updated": "2025-11-23T19:39:44Z",
    "link": "http://arxiv.org/pdf/2511.18597v1.pdf",
    "category": [
      "cs.CL"
    ],
    "authors": [
      "H. M. Shadman Tabib",
      "Jaber Ahmed Deedar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19437v1",
    "title": "LumiTex: Towards High-Fidelity PBR Texture Generation with Illumination Context",
    "summary": "Physically-based rendering (PBR) provides a principled standard for realistic material-lighting interactions in computer graphics. Despite recent advances in generating PBR textures, existing methods fail to address two fundamental challenges: 1) materials decomposition from image prompts under limited illumination cues, and 2) seamless and view-consistent texture completion. To this end, we propose LumiTex, an end-to-end framework that comprises three key components: (1) a multi-branch generation scheme that disentangles albedo and metallic-roughness under shared illumination priors for robust material understanding, (2) a lighting-aware material attention mechanism that injects illumination context into the decoding process for physically grounded generation of albedo, metallic, and roughness maps, and (3) a geometry-guided inpainting module based on a large view synthesis model that enriches texture coverage and ensures seamless, view-consistent UV completion. Extensive experiments demonstrate that LumiTex achieves state-of-the-art performance in texture quality, surpassing both existing open-source and commercial methods.",
    "published": "2025-11-24T18:59:58Z",
    "updated": "2025-11-24T18:59:58Z",
    "link": "http://arxiv.org/pdf/2511.19437v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jingzhi Bao",
      "Hongze Chen",
      "Lingting Zhu",
      "Chenyu Liu",
      "Runze Zhang",
      "Keyang Luo",
      "Zeyu Hu",
      "Weikai Chen",
      "Yingda Yin",
      "Xin Wang",
      "Zehong Lin",
      "Jun Zhang",
      "Xiaoguang Han"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19435v1",
    "title": "Are Image-to-Video Models Good Zero-Shot Image Editors?",
    "summary": "Large-scale video diffusion models show strong world simulation and temporal reasoning abilities, but their use as zero-shot image editors remains underexplored. We introduce IF-Edit, a tuning-free framework that repurposes pretrained image-to-video diffusion models for instruction-driven image editing. IF-Edit addresses three key challenges: prompt misalignment, redundant temporal latents, and blurry late-stage frames. It includes (1) a chain-of-thought prompt enhancement module that transforms static editing instructions into temporally grounded reasoning prompts; (2) a temporal latent dropout strategy that compresses frame latents after the expert-switch point, accelerating denoising while preserving semantic and temporal coherence; and (3) a self-consistent post-refinement step that sharpens late-stage frames using a short still-video trajectory. Experiments on four public benchmarks, covering non-rigid editing, physical and temporal reasoning, and general instruction edits, show that IF-Edit performs strongly on reasoning-centric tasks while remaining competitive on general-purpose edits. Our study provides a systematic view of video diffusion models as image editors and highlights a simple recipe for unified video-image generative reasoning.",
    "published": "2025-11-24T18:59:54Z",
    "updated": "2025-11-24T18:59:54Z",
    "link": "http://arxiv.org/pdf/2511.19435v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zechuan Zhang",
      "Zhenyuan Chen",
      "Zongxin Yang",
      "Yi Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19434v1",
    "title": "Breaking the Likelihood-Quality Trade-off in Diffusion Models by Merging Pretrained Experts",
    "summary": "Diffusion models for image generation often exhibit a trade-off between perceptual sample quality and data likelihood: training objectives emphasizing high-noise denoising steps yield realistic images but poor likelihoods, whereas likelihood-oriented training overweights low-noise steps and harms visual fidelity. We introduce a simple plug-and-play sampling method that combines two pretrained diffusion experts by switching between them along the denoising trajectory. Specifically, we apply an image-quality expert at high noise levels to shape global structure, then switch to a likelihood expert at low noise levels to refine pixel statistics. The approach requires no retraining or fine-tuning -- only the choice of an intermediate switching step. On CIFAR-10 and ImageNet32, the merged model consistently matches or outperforms its base components, improving or preserving both likelihood and sample quality relative to each expert alone. These results demonstrate that expert switching across noise levels is an effective way to break the likelihood-quality trade-off in image diffusion models.",
    "published": "2025-11-24T18:59:53Z",
    "updated": "2025-11-24T18:59:53Z",
    "link": "http://arxiv.org/pdf/2511.19434v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Yasin Esfandiari",
      "Stefan Bauer",
      "Sebastian U. Stich",
      "Andrea Dittadi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19431v1",
    "title": "Cloud4D",
    "summary": "There has been great progress in improving numerical weather prediction and climate models using machine learning. However, most global models act at a kilometer-scale, making it challenging to model individual clouds and factors such as extreme precipitation, wind gusts, turbulence, and surface irradiance. Therefore, there is a need to move towards higher-resolution models, which in turn require high-resolution real-world observations that current instruments struggle to obtain. We present Cloud4D, the first learning-based framework that reconstructs a physically consistent, four-dimensional cloud state using only synchronized ground-based cameras. Leveraging a homography-guided 2D-to-3D transformer, Cloud4D infers the full 3D distribution of liquid water content at 25 m spatial and 5 s temporal resolution. By tracking the 3D liquid water content retrievals over time, Cloud4D additionally estimates horizontal wind vectors. Across a two-month deployment comprising six skyward cameras, our system delivers an order-of-magnitude improvement in space-time resolution relative to state-of-the-art satellite measurements, while retaining single-digit relative error ($<10\\%$) against collocated radar measurements. Code and data are available on our project page https://cloud4d.jacob-lin.com/.",
    "published": "2025-11-24T18:59:37Z",
    "updated": "2025-11-24T18:59:37Z",
    "link": "http://arxiv.org/pdf/2511.19431v1.pdf",
    "category": [
      "cs.CV",
      "physics.ao-ph"
    ],
    "authors": [
      "Jacob Lin",
      "Edward Gryspeerdt",
      "Ronald Clark"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19430v1",
    "title": "Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution",
    "summary": "Task scheduling is critical for embodied AI, enabling agents to follow natural language instructions and execute actions efficiently in 3D physical worlds. However, existing datasets often simplify task planning by ignoring operations research (OR) knowledge and 3D spatial grounding. In this work, we propose Operations Research knowledge-based 3D Grounded Task Scheduling (ORS3D), a new task that requires the synergy of language understanding, 3D grounding, and efficiency optimization. Unlike prior settings, ORS3D demands that agents minimize total completion time by leveraging parallelizable subtasks, e.g., cleaning the sink while the microwave operates. To facilitate research on ORS3D, we construct ORS3D-60K, a large-scale dataset comprising 60K composite tasks across 4K real-world scenes. Furthermore, we propose GRANT, an embodied multi-modal large language model equipped with a simple yet effective scheduling token mechanism to generate efficient task schedules and grounded actions. Extensive experiments on ORS3D-60K validate the effectiveness of GRANT across language understanding, 3D grounding, and scheduling efficiency. The code is available at https://github.com/H-EmbodVis/GRANT",
    "published": "2025-11-24T18:59:17Z",
    "updated": "2025-11-24T18:59:17Z",
    "link": "http://arxiv.org/pdf/2511.19430v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dingkang Liang",
      "Cheng Zhang",
      "Xiaopeng Xu",
      "Jianzhong Ju",
      "Zhenbo Luo",
      "Xiang Bai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19428v1",
    "title": "Flow Map Distillation Without Data",
    "summary": "State-of-the-art flow models achieve remarkable quality but require slow, iterative sampling. To accelerate this, flow maps can be distilled from pre-trained teachers, a procedure that conventionally requires sampling from an external dataset. We argue that this data-dependency introduces a fundamental risk of Teacher-Data Mismatch, as a static dataset may provide an incomplete or even misaligned representation of the teacher's full generative capabilities. This leads us to question whether this reliance on data is truly necessary for successful flow map distillation. In this work, we explore a data-free alternative that samples only from the prior distribution, a distribution the teacher is guaranteed to follow by construction, thereby circumventing the mismatch risk entirely. To demonstrate the practical viability of this philosophy, we introduce a principled framework that learns to predict the teacher's sampling path while actively correcting for its own compounding errors to ensure high fidelity. Our approach surpasses all data-based counterparts and establishes a new state-of-the-art by a significant margin. Specifically, distilling from SiT-XL/2+REPA, our method reaches an impressive FID of 1.45 on ImageNet 256x256, and 1.49 on ImageNet 512x512, both with only 1 sampling step. We hope our work establishes a more robust paradigm for accelerating generative models and motivates the broader adoption of flow map distillation without data.",
    "published": "2025-11-24T18:58:55Z",
    "updated": "2025-11-24T18:58:55Z",
    "link": "http://arxiv.org/pdf/2511.19428v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Shangyuan Tong",
      "Nanye Ma",
      "Saining Xie",
      "Tommi Jaakkola"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19426v1",
    "title": "Ref-SAM3D: Bridging SAM3D with Text for Reference 3D Reconstruction",
    "summary": "SAM3D has garnered widespread attention for its strong 3D object reconstruction capabilities. However, a key limitation remains: SAM3D cannot reconstruct specific objects referred to by textual descriptions, a capability that is essential for practical applications such as 3D editing, game development, and virtual environments. To address this gap, we introduce Ref-SAM3D, a simple yet effective extension to SAM3D that incorporates textual descriptions as a high-level prior, enabling text-guided 3D reconstruction from a single RGB image. Through extensive qualitative experiments, we show that Ref-SAM3D, guided only by natural language and a single 2D view, delivers competitive and high-fidelity zero-shot reconstruction performance. Our results demonstrate that Ref-SAM3D effectively bridges the gap between 2D visual cues and 3D geometric understanding, offering a more flexible and accessible paradigm for reference-guided 3D reconstruction. Code is available at: https://github.com/FudanCVL/Ref-SAM3D.",
    "published": "2025-11-24T18:58:22Z",
    "updated": "2025-11-24T18:58:22Z",
    "link": "http://arxiv.org/pdf/2511.19426v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yun Zhou",
      "Yaoting Wang",
      "Guangquan Jie",
      "Jinyu Liu",
      "Henghui Ding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19425v1",
    "title": "SAM3-Adapter: Efficient Adaptation of Segment Anything 3 for Camouflage Object Segmentation, Shadow Detection, and Medical Image Segmentation",
    "summary": "The rapid rise of large-scale foundation models has reshaped the landscape of image segmentation, with models such as Segment Anything achieving unprecedented versatility across diverse vision tasks. However, previous generations-including SAM and its successor-still struggle with fine-grained, low-level segmentation challenges such as camouflaged object detection, medical image segmentation, cell image segmentation, and shadow detection. To address these limitations, we originally proposed SAM-Adapter in 2023, demonstrating substantial gains on these difficult scenarios. With the emergence of Segment Anything 3 (SAM3)-a more efficient and higher-performing evolution with a redesigned architecture and improved training pipeline-we revisit these long-standing challenges. In this work, we present SAM3-Adapter, the first adapter framework tailored for SAM3 that unlocks its full segmentation capability. SAM3-Adapter not only reduces computational overhead but also consistently surpasses both SAM and SAM2-based solutions, establishing new state-of-the-art results across multiple downstream tasks, including medical imaging, camouflaged (concealed) object segmentation, and shadow detection. Built upon the modular and composable design philosophy of the original SAM-Adapter, SAM3-Adapter provides stronger generalizability, richer task adaptability, and significantly improved segmentation precision. Extensive experiments confirm that integrating SAM3 with our adapter yields superior accuracy, robustness, and efficiency compared to all prior SAM-based adaptations. We hope SAM3-Adapter can serve as a foundation for future research and practical segmentation applications. Code, pre-trained models, and data processing pipelines are available.",
    "published": "2025-11-24T18:57:54Z",
    "updated": "2025-11-24T18:57:54Z",
    "link": "http://arxiv.org/pdf/2511.19425v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tianrun Chen",
      "Runlong Cao",
      "Xinda Yu",
      "Lanyun Zhu",
      "Chaotao Ding",
      "Deyi Ji",
      "Cheng Chen",
      "Qi Zhu",
      "Chunyan Xu",
      "Papa Mao",
      "Ying Zang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19394v1",
    "title": "BackSplit: The Importance of Sub-dividing the Background in Biomedical Lesion Segmentation",
    "summary": "Segmenting small lesions in medical images remains notoriously difficult. Most prior work tackles this challenge by either designing better architectures, loss functions, or data augmentation schemes; and collecting more labeled data. We take a different view, arguing that part of the problem lies in how the background is modeled. Common lesion segmentation collapses all non-lesion pixels into a single \"background\" class, ignoring the rich anatomical context in which lesions appear. In reality, the background is highly heterogeneous-composed of tissues, organs, and other structures that can now be labeled manually or inferred automatically using existing segmentation models.\n  In this paper, we argue that training with fine-grained labels that sub-divide the background class, which we call BackSplit, is a simple yet powerful paradigm that can offer a significant performance boost without increasing inference costs. From an information theoretic standpoint, we prove that BackSplit increases the expected Fisher Information relative to conventional binary training, leading to tighter asymptotic bounds and more stable optimization. With extensive experiments across multiple datasets and architectures, we empirically show that BackSplit consistently boosts small-lesion segmentation performance, even when auxiliary labels are generated automatically using pretrained segmentation models. Additionally, we demonstrate that auxiliary labels derived from interactive segmentation frameworks exhibit the same beneficial effect, demonstrating its robustness, simplicity, and broad applicability.",
    "published": "2025-11-24T18:31:51Z",
    "updated": "2025-11-24T18:31:51Z",
    "link": "http://arxiv.org/pdf/2511.19394v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Rachit Saluja",
      "Asli Cihangir",
      "Ruining Deng",
      "Johannes C. Paetzold",
      "Fengbei Liu",
      "Mert R. Sabuncu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19380v1",
    "title": "UISearch: Graph-Based Embeddings for Multimodal Enterprise UI Screenshots Retrieval",
    "summary": "Enterprise software companies maintain thousands of user interface screens across products and versions, creating critical challenges for design consistency, pattern discovery, and compliance check. Existing approaches rely on visual similarity or text semantics, lacking explicit modeling of structural properties fundamental to user interface (UI) composition. We present a novel graph-based representation that converts UI screenshots into attributed graphs encoding hierarchical relationships and spatial arrangements, potentially generalizable to document layouts, architectural diagrams, and other structured visual domains. A contrastive graph autoencoder learns embeddings preserving multi-level similarity across visual, structural, and semantic properties. The comprehensive analysis demonstrates that our structural embeddings achieve better discriminative power than state-of-the-art Vision Encoders, representing a fundamental advance in the expressiveness of the UI representation. We implement this representation in UISearch, a multi-modal search framework that combines structural embeddings with semantic search through a composable query language. On 20,396 financial software UIs, UISearch achieves 0.92 Top-5 accuracy with 47.5ms median latency (P95: 124ms), scaling to 20,000+ screens. The hybrid indexing architecture enables complex queries and supports fine-grained UI distinction impossible with vision-only approaches.",
    "published": "2025-11-24T18:20:08Z",
    "updated": "2025-11-24T18:20:08Z",
    "link": "http://arxiv.org/pdf/2511.19380v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Maroun Ayli",
      "Youssef Bakouny",
      "Tushar Sharma",
      "Nader Jalloul",
      "Hani Seifeddine",
      "Rima Kilany"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.18716v2",
    "title": "SketchDeco: Training-Free Latent Composition for Precise Sketch Colourisation",
    "summary": "We introduce SketchDeco, a training-free approach to sketch colourisation that bridges the gap between professional design needs and intuitive, region-based control. Our method empowers artists to use simple masks and colour palettes for precise spatial and chromatic specification, avoiding both the tediousness of manual assignment and the ambiguity of text-based prompts. We reformulate this task as a novel, training-free composition problem. Our core technical contribution is a guided latent-space blending process: we first leverage diffusion inversion to precisely ``paint'' user-defined colours into specified regions, and then use a custom self-attention mechanism to harmoniously blend these local edits with a globally consistent base image. This ensures both local colour fidelity and global harmony without requiring any model fine-tuning. Our system produces high-quality results in 15--20 inference steps on consumer GPUs, making professional-quality, controllable colourisation accessible.",
    "published": "2024-05-29T02:53:59Z",
    "updated": "2025-11-24T18:15:06Z",
    "link": "http://arxiv.org/pdf/2405.18716v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chaitat Utintu",
      "Pinaki Nath Chowdhury",
      "Aneeshan Sain",
      "Subhadeep Koley",
      "Ayan Kumar Bhunia",
      "Yi-Zhe Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19356v1",
    "title": "Growing with the Generator: Self-paced GRPO for Video Generation",
    "summary": "Group Relative Policy Optimization (GRPO) has emerged as a powerful reinforcement learning paradigm for post-training video generation models. However, existing GRPO pipelines rely on static, fixed-capacity reward models whose evaluation behavior is frozen during training. Such rigid rewards introduce distributional bias, saturate quickly as the generator improves, and ultimately limit the stability and effectiveness of reinforcement-based alignment. We propose Self-Paced GRPO, a competence-aware GRPO framework in which reward feedback co-evolves with the generator. Our method introduces a progressive reward mechanism that automatically shifts its emphasis from coarse visual fidelity to temporal coherence and fine-grained text-video semantic alignment as generation quality increases. This self-paced curriculum alleviates reward-policy mismatch, mitigates reward exploitation, and yields more stable optimization. Experiments on VBench across multiple video generation backbones demonstrate consistent improvements in both visual quality and semantic alignment over GRPO baselines with static rewards, validating the effectiveness and generality of Self-Paced GRPO.",
    "published": "2025-11-24T17:56:03Z",
    "updated": "2025-11-24T17:56:03Z",
    "link": "http://arxiv.org/pdf/2511.19356v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Rui Li",
      "Yuanzhi Liang",
      "Ziqi Ni",
      "Haibing Huang",
      "Chi Zhang",
      "Xuelong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19351v1",
    "title": "CellFMCount: A Fluorescence Microscopy Dataset, Benchmark, and Methods for Cell Counting",
    "summary": "Accurate cell counting is essential in various biomedical research and clinical applications, including cancer diagnosis, stem cell research, and immunology. Manual counting is labor-intensive and error-prone, motivating automation through deep learning techniques. However, training reliable deep learning models requires large amounts of high-quality annotated data, which is difficult and time-consuming to produce manually. Consequently, existing cell-counting datasets are often limited, frequently containing fewer than $500$ images. In this work, we introduce a large-scale annotated dataset comprising $3{,}023$ images from immunocytochemistry experiments related to cellular differentiation, containing over $430{,}000$ manually annotated cell locations. The dataset presents significant challenges: high cell density, overlapping and morphologically diverse cells, a long-tailed distribution of cell count per image, and variation in staining protocols. We benchmark three categories of existing methods: regression-based, crowd-counting, and cell-counting techniques on a test set with cell counts ranging from $10$ to $2{,}126$ cells per image. We also evaluate how the Segment Anything Model (SAM) can be adapted for microscopy cell counting using only dot-annotated datasets. As a case study, we implement a density-map-based adaptation of SAM (SAM-Counter) and report a mean absolute error (MAE) of $22.12$, which outperforms existing approaches (second-best MAE of $27.46$). Our results underscore the value of the dataset and the benchmarking framework for driving progress in automated cell counting and provide a robust foundation for future research and development.",
    "published": "2025-11-24T17:53:59Z",
    "updated": "2025-11-24T17:53:59Z",
    "link": "http://arxiv.org/pdf/2511.19351v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Abdurahman Ali Mohammed",
      "Catherine Fonder",
      "Ying Wei",
      "Wallapak Tavanapong",
      "Donald S Sakaguchi",
      "Qi Li",
      "Surya K. Mallapragada"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19343v1",
    "title": "Syn-GRPO: Self-Evolving Data Synthesis for MLLM Perception Reasoning",
    "summary": "RL (reinforcement learning) methods (e.g., GRPO) for MLLM (Multimodal LLM) perception ability has attracted wide research interest owing to its remarkable generalization ability. Nevertheless, existing reinforcement learning methods still face the problem of low data quality, where data samples cannot elicit diverse responses from MLLMs, thus restricting the exploration scope for MLLM reinforcement learning. Some methods attempt to mitigate this problem by imposing constraints on entropy, but none address it at its root. Therefore, to tackle this problem, this work proposes Syn-GRPO (Synthesis-GRPO), which employs an online data generator to synthesize high-quality training data with diverse responses in GRPO training. Specifically, Syn-GRPO consists of two components: (1) data server; (2) GRPO workflow. The data server synthesizes new samples from existing ones using an image generation model, featuring a decoupled and asynchronous scheme to achieve high generation efficiency. The GRPO workflow provides the data server with the new image descriptions, and it leverages a diversity reward to supervise the MLLM to predict image descriptions for synthesizing samples with diverse responses. Experiment results across three visual perception tasks demonstrate that Syn-GRPO improves the data quality by a large margin, achieving significant superior performance to existing MLLM perception methods, and Syn-GRPO presents promising potential for scaling long-term self-evolving RL. Our code is available at https://github.com/hqhQAQ/Syn-GRPO.",
    "published": "2025-11-24T17:42:29Z",
    "updated": "2025-11-24T17:42:29Z",
    "link": "http://arxiv.org/pdf/2511.19343v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qihan Huang",
      "Haofei Zhang",
      "Rong Wei",
      "Yi Wang",
      "Rui Tang",
      "Mingli Song",
      "Jie Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19339v1",
    "title": "POUR: A Provably Optimal Method for Unlearning Representations via Neural Collapse",
    "summary": "In computer vision, machine unlearning aims to remove the influence of specific visual concepts or training images without retraining from scratch. Studies show that existing approaches often modify the classifier while leaving internal representations intact, resulting in incomplete forgetting. In this work, we extend the notion of unlearning to the representation level, deriving a three-term interplay between forgetting efficacy, retention fidelity, and class separation. Building on Neural Collapse theory, we show that the orthogonal projection of a simplex Equiangular Tight Frame (ETF) remains an ETF in a lower dimensional space, yielding a provably optimal forgetting operator. We further introduce the Representation Unlearning Score (RUS) to quantify representation-level forgetting and retention fidelity. Building on this, we introduce POUR (Provably Optimal Unlearning of Representations), a geometric projection method with closed-form (POUR-P) and a feature-level unlearning variant under a distillation scheme (POUR-D). Experiments on CIFAR-10/100 and PathMNIST demonstrate that POUR achieves effective unlearning while preserving retained knowledge, outperforming state-of-the-art unlearning methods on both classification-level and representation-level metrics.",
    "published": "2025-11-24T17:38:53Z",
    "updated": "2025-11-24T17:38:53Z",
    "link": "http://arxiv.org/pdf/2511.19339v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Anjie Le",
      "Can Peng",
      "Yuyuan Liu",
      "J. Alison Noble"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19326v1",
    "title": "MonoMSK: Monocular 3D Musculoskeletal Dynamics Estimation",
    "summary": "Reconstructing biomechanically realistic 3D human motion - recovering both kinematics (motion) and kinetics (forces) - is a critical challenge. While marker-based systems are lab-bound and slow, popular monocular methods use oversimplified, anatomically inaccurate models (e.g., SMPL) and ignore physics, fundamentally limiting their biomechanical fidelity. In this work, we introduce MonoMSK, a hybrid framework that bridges data-driven learning and physics-based simulation for biomechanically realistic 3D human motion estimation from monocular video. MonoMSK jointly recovers both kinematics (motions) and kinetics (forces and torques) through an anatomically accurate musculoskeletal model. By integrating transformer-based inverse dynamics with differentiable forward kinematics and dynamics layers governed by ODE-based simulation, MonoMSK establishes a physics-regulated inverse-forward loop that enforces biomechanical causality and physical plausibility. A novel forward-inverse consistency loss further aligns motion reconstruction with the underlying kinetic reasoning. Experiments on BML-MoVi, BEDLAM, and OpenCap show that MonoMSK significantly outperforms state-of-the-art methods in kinematic accuracy, while for the first time enabling precise monocular kinetics estimation.",
    "published": "2025-11-24T17:20:17Z",
    "updated": "2025-11-24T17:20:17Z",
    "link": "http://arxiv.org/pdf/2511.19326v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Farnoosh Koleini",
      "Hongfei Xue",
      "Ahmed Helmy",
      "Pu Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19320v1",
    "title": "SteadyDancer: Harmonized and Coherent Human Image Animation with First-Frame Preservation",
    "summary": "Preserving first-frame identity while ensuring precise motion control is a fundamental challenge in human image animation. The Image-to-Motion Binding process of the dominant Reference-to-Video (R2V) paradigm overlooks critical spatio-temporal misalignments common in real-world applications, leading to failures such as identity drift and visual artifacts. We introduce SteadyDancer, an Image-to-Video (I2V) paradigm-based framework that achieves harmonized and coherent animation and is the first to ensure first-frame preservation robustly. Firstly, we propose a Condition-Reconciliation Mechanism to harmonize the two conflicting conditions, enabling precise control without sacrificing fidelity. Secondly, we design Synergistic Pose Modulation Modules to generate an adaptive and coherent pose representation that is highly compatible with the reference image. Finally, we employ a Staged Decoupled-Objective Training Pipeline that hierarchically optimizes the model for motion fidelity, visual quality, and temporal coherence. Experiments demonstrate that SteadyDancer achieves state-of-the-art performance in both appearance fidelity and motion control, while requiring significantly fewer training resources than comparable methods.",
    "published": "2025-11-24T17:15:55Z",
    "updated": "2025-11-24T17:15:55Z",
    "link": "http://arxiv.org/pdf/2511.19320v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiaming Zhang",
      "Shengming Cao",
      "Rui Li",
      "Xiaotong Zhao",
      "Yutao Cui",
      "Xinglin Hou",
      "Gangshan Wu",
      "Haolan Chen",
      "Yu Xu",
      "Limin Wang",
      "Kai Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19319v1",
    "title": "SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and Motion for Hand-Object Interaction Synthesis",
    "summary": "Hand-Object Interaction (HOI) generation plays a critical role in advancing applications across animation and robotics. Current video-based methods are predominantly single-view, which impedes comprehensive 3D geometry perception and often results in geometric distortions or unrealistic motion patterns. While 3D HOI approaches can generate dynamically plausible motions, their dependence on high-quality 3D data captured in controlled laboratory settings severely limits their generalization to real-world scenarios. To overcome these limitations, we introduce SyncMV4D, the first model that jointly generates synchronized multi-view HOI videos and 4D motions by unifying visual prior, motion dynamics, and multi-view geometry. Our framework features two core innovations: (1) a Multi-view Joint Diffusion (MJD) model that co-generates HOI videos and intermediate motions, and (2) a Diffusion Points Aligner (DPA) that refines the coarse intermediate motion into globally aligned 4D metric point tracks. To tightly couple 2D appearance with 4D dynamics, we establish a closed-loop, mutually enhancing cycle. During the diffusion denoising process, the generated video conditions the refinement of the 4D motion, while the aligned 4D point tracks are reprojected to guide next-step joint generation. Experimentally, our method demonstrates superior performance to state-of-the-art alternatives in visual realism, motion plausibility, and multi-view consistency.",
    "published": "2025-11-24T17:14:19Z",
    "updated": "2025-11-24T17:14:19Z",
    "link": "http://arxiv.org/pdf/2511.19319v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Lingwei Dang",
      "Zonghan Li",
      "Juntong Li",
      "Hongwen Zhang",
      "Liang An",
      "Yebin Liu",
      "Qingyao Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.16621v2",
    "title": "A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System",
    "summary": "Extrinsic Calibration represents the cornerstone of autonomous driving. Its accuracy plays a crucial role in the perception pipeline, as any errors can have implications for the safety of the vehicle. Modern sensor systems collect different types of data from the environment, making it harder to align the data. To this end, we propose a target-based extrinsic calibration system tailored for a multi-LiDAR and multi-camera sensor suite. This system enables cross-calibration between LiDARs and cameras with limited prior knowledge using a custom ChArUco board and a tailored nonlinear optimization method. We test the system with real-world data gathered in a warehouse. Results demonstrated the effectiveness of the proposed method, highlighting the feasibility of a unique pipeline tailored for various types of sensors.",
    "published": "2025-07-22T14:15:28Z",
    "updated": "2025-11-24T17:08:56Z",
    "link": "http://arxiv.org/pdf/2507.16621v2.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Lorenzo Gentilini",
      "Pierpaolo Serio",
      "Valentina Donzella",
      "Lorenzo Pollini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19306v1",
    "title": "Dual-Granularity Semantic Prompting for Language Guidance Infrared Small Target Detection",
    "summary": "Infrared small target detection remains challenging due to limited feature representation and severe background interference, resulting in sub-optimal performance. While recent CLIP-inspired methods attempt to leverage textual guidance for detection, they are hindered by inaccurate text descriptions and reliance on manual annotations. To overcome these limitations, we propose DGSPNet, an end-to-end language prompt-driven framework. Our approach integrates dual-granularity semantic prompts: coarse-grained textual priors (e.g., 'infrared image', 'small target') and fine-grained personalized semantic descriptions derived through visual-to-textual mapping within the image space. This design not only facilitates learning fine-grained semantic information but also can inherently leverage language prompts during inference without relying on any annotation requirements. By fully leveraging the precision and conciseness of text descriptions, we further introduce a text-guide channel attention (TGCA) mechanism and text-guide spatial attention (TGSA) mechanism that enhances the model's sensitivity to potential targets across both low- and high-level feature spaces. Extensive experiments demonstrate that our method significantly improves detection accuracy and achieves state-of-the-art performance on three benchmark datasets.",
    "published": "2025-11-24T16:58:23Z",
    "updated": "2025-11-24T16:58:23Z",
    "link": "http://arxiv.org/pdf/2511.19306v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zixuan Wang",
      "Haoran Sun",
      "Jiaming Lu",
      "Wenxuan Wang",
      "Zhongling Huang",
      "Dingwen Zhang",
      "Xuelin Qian",
      "Junwei Han"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19301v1",
    "title": "IDEAL-M3D: Instance Diversity-Enriched Active Learning for Monocular 3D Detection",
    "summary": "Monocular 3D detection relies on just a single camera and is therefore easy to deploy. Yet, achieving reliable 3D understanding from monocular images requires substantial annotation, and 3D labels are especially costly. To maximize performance under constrained labeling budgets, it is essential to prioritize annotating samples expected to deliver the largest performance gains. This prioritization is the focus of active learning. Curiously, we observed two significant limitations in active learning algorithms for 3D monocular object detection. First, previous approaches select entire images, which is inefficient, as non-informative instances contained in the same image also need to be labeled. Secondly, existing methods rely on uncertainty-based selection, which in monocular 3D object detection creates a bias toward depth ambiguity. Consequently, distant objects are selected, while nearby objects are overlooked.\n  To address these limitations, we propose IDEAL-M3D, the first instance-level pipeline for monocular 3D detection. For the first time, we demonstrate that an explicitly diverse, fast-to-train ensemble improves diversity-driven active learning for monocular 3D. We induce diversity with heterogeneous backbones and task-agnostic features, loss weight perturbation, and time-dependent bagging. IDEAL-M3D shows superior performance and significant resource savings: with just 60% of the annotations, we achieve similar or better AP3D on KITTI validation and test set results compared to training the same detector on the whole dataset.",
    "published": "2025-11-24T16:49:20Z",
    "updated": "2025-11-24T16:49:20Z",
    "link": "http://arxiv.org/pdf/2511.19301v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Johannes Meier",
      "Florian Günther",
      "Riccardo Marin",
      "Oussema Dhaouadi",
      "Jacques Kaiser",
      "Daniel Cremers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19294v1",
    "title": "DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting",
    "summary": "This paper addresses the limitations of existing 3D Gaussian Splatting (3DGS) methods, particularly their reliance on adaptive density control, which can lead to floating artifacts and inefficient resource usage. We propose a novel densify beforehand approach that enhances the initialization of 3D scenes by combining sparse LiDAR data with monocular depth estimation from corresponding RGB images. Our ROI-aware sampling scheme prioritizes semantically and geometrically important regions, yielding a dense point cloud that improves visual fidelity and computational efficiency. This densify beforehand approach bypasses the adaptive density control that may introduce redundant Gaussians in the original pipeline, allowing the optimization to focus on the other attributes of 3D Gaussian primitives, reducing overlap while enhancing visual quality. Our method achieves comparable results to state-of-the-art techniques while significantly lowering resource consumption and training time. We validate our approach through extensive comparisons and ablation studies on four newly collected datasets, showcasing its effectiveness in preserving regions of interest in complex scenes.",
    "published": "2025-11-24T16:39:13Z",
    "updated": "2025-11-24T16:39:13Z",
    "link": "http://arxiv.org/pdf/2511.19294v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Phurtivilai Patt",
      "Leyang Huang",
      "Yinqiang Zhang",
      "Yang Lei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19278v1",
    "title": "ReMatch: Boosting Representation through Matching for Multimodal Retrieval",
    "summary": "We present ReMatch, a framework that leverages the generative strength of MLLMs for multimodal retrieval. Previous approaches treated an MLLM as a simple encoder, ignoring its generative nature, and under-utilising its compositional reasoning and world knowledge. We instead train the embedding MLLM end-to-end with a chat-style generative matching stage. The matching stage uses the same MLLM to autoregressively decide relevance from multi-view inputs, including both raw data and its own projected embeddings for each query and document. It provides instance-wise discrimination supervision that complements a standard contrastive loss, offering stronger gradients on hard negatives and preserving the compositional strengths of the original MLLM. To obtain semantically richer multimodal embeddings, we use multiple learnable tokens to augment each input, generating fine-grained contextual, mutually orthogonal embeddings with low inference cost. Leveraging our established high-performance baseline,we assemble the ideas mentioned above into a powerful training recipe and achieve a new state-of-the-art on the Massive Multimodal Embedding Benchmark (MMEB). Our experiments show particularly strong zero-shot generalization results on five datasets, highlighting the robustness and transferability of ReMatch.",
    "published": "2025-11-24T16:28:49Z",
    "updated": "2025-11-24T16:28:49Z",
    "link": "http://arxiv.org/pdf/2511.19278v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qianying Liu",
      "Xiao Liang",
      "Zhiqiang Zhang",
      "Yibo Chen",
      "Xu Tang",
      "Zhongfei Qing",
      "Fengfan Zhou",
      "Yao Hu",
      "Paul Henderson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.01421v3",
    "title": "InfoScale: Unleashing Training-free Variable-scaled Image Generation via Effective Utilization of Information",
    "summary": "Diffusion models (DMs) have become dominant in visual generation but suffer performance drop when tested on resolutions that differ from the training scale, whether lower or higher. In fact, the key challenge in generating variable-scale images lies in the differing amounts of information across resolutions, which requires information conversion procedures to be varied for generating variable-scaled images. In this paper, we investigate the issues of three critical aspects in DMs for a unified analysis in variable-scaled generation: dilated convolution, attention mechanisms, and initial noise. Specifically, 1) dilated convolution in DMs for the higher-resolution generation loses high-frequency information. 2) Attention for variable-scaled image generation struggles to adjust the information aggregation adaptively. 3) The spatial distribution of information in the initial noise is misaligned with variable-scaled image. To solve the above problems, we propose \\textbf{InfoScale}, an information-centric framework for variable-scaled image generation by effectively utilizing information from three aspects correspondingly. For information loss in 1), we introduce Progressive Frequency Compensation module to compensate for high-frequency information lost by dilated convolution in higher-resolution generation. For information aggregation inflexibility in 2), we introduce Adaptive Information Aggregation module to adaptively aggregate information in lower-resolution generation and achieve an effective balance between local and global information in higher-resolution generation. For information distribution misalignment in 3), we design Noise Adaptation module to re-distribute information in initial noise for variable-scaled generation. Our method is plug-and-play for DMs and extensive experiments demonstrate the effectiveness in variable-scaled image generation.",
    "published": "2025-09-01T12:27:04Z",
    "updated": "2025-11-24T16:26:00Z",
    "link": "http://arxiv.org/pdf/2509.01421v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Guohui Zhang",
      "Jiangtong Tan",
      "Linjiang Huang",
      "Zhonghang Yuan",
      "Mingde Yao",
      "Jie Huang",
      "Feng Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19274v1",
    "title": "Diffusion Reconstruction-based Data Likelihood Estimation for Core-Set Selection",
    "summary": "Existing core-set selection methods predominantly rely on heuristic scoring signals such as training dynamics or model uncertainty, lacking explicit modeling of data likelihood. This omission may hinder the constructed subset from capturing subtle yet critical distributional structures that underpin effective model training. In this work, we propose a novel, theoretically grounded approach that leverages diffusion models to estimate data likelihood via reconstruction deviation induced by partial reverse denoising. Specifically, we establish a formal connection between reconstruction error and data likelihood, grounded in the Evidence Lower Bound (ELBO) of Markovian diffusion processes, thereby enabling a principled, distribution-aware scoring criterion for data selection. Complementarily, we introduce an efficient information-theoretic method to identify the optimal reconstruction timestep, ensuring that the deviation provides a reliable signal indicative of underlying data likelihood. Extensive experiments on ImageNet demonstrate that reconstruction deviation offers an effective scoring criterion, consistently outperforming existing baselines across selection ratios, and closely matching full-data training using only 50% of the data. Further analysis shows that the likelihood-informed nature of our score reveals informative insights in data selection, shedding light on the interplay between data distributional characteristics and model learning preferences.",
    "published": "2025-11-24T16:25:34Z",
    "updated": "2025-11-24T16:25:34Z",
    "link": "http://arxiv.org/pdf/2511.19274v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mingyang Chen",
      "Jiawei Du",
      "Bo Huang",
      "Yi Wang",
      "Xiaobo Zhang",
      "Wei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19268v1",
    "title": "BideDPO: Conditional Image Generation with Simultaneous Text and Condition Alignment",
    "summary": "Conditional image generation enhances text-to-image synthesis with structural, spatial, or stylistic priors, but current methods face challenges in handling conflicts between sources. These include 1) input-level conflicts, where the conditioning image contradicts the text prompt, and 2) model-bias conflicts, where generative biases disrupt alignment even when conditions match the text. Addressing these conflicts requires nuanced solutions, which standard supervised fine-tuning struggles to provide. Preference-based optimization techniques like Direct Preference Optimization (DPO) show promise but are limited by gradient entanglement between text and condition signals and lack disentangled training data for multi-constraint tasks. To overcome this, we propose a bidirectionally decoupled DPO framework (BideDPO). Our method creates two disentangled preference pairs-one for the condition and one for the text-to reduce gradient entanglement. The influence of pairs is managed using an Adaptive Loss Balancing strategy for balanced optimization. We introduce an automated data pipeline to sample model outputs and generate conflict-aware data. This process is embedded in an iterative optimization strategy that refines both the model and the data. We construct a DualAlign benchmark to evaluate conflict resolution between text and condition. Experiments show BideDPO significantly improves text success rates (e.g., +35%) and condition adherence. We also validate our approach using the COCO dataset. Project Pages: https://limuloo.github.io/BideDPO/.",
    "published": "2025-11-24T16:20:11Z",
    "updated": "2025-11-24T16:20:11Z",
    "link": "http://arxiv.org/pdf/2511.19268v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dewei Zhou",
      "Mingwei Li",
      "Zongxin Yang",
      "Yu Lu",
      "Yunqiu Xu",
      "Zhizhong Wang",
      "Zeyi Huang",
      "Yi Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19261v1",
    "title": "LAST: LeArning to Think in Space and Time for Generalist Vision-Language Models",
    "summary": "Humans can perceive and understand 3D space and long videos from sequential visual observations. But do vision-language models (VLMs) can? Recent work demonstrates that even state-of-the-art VLMs still struggle to understand 3D space and long videos, although they are powerful in typical vision-language tasks. Current methods often rely on specialized architectural designs to improve performance for 3D tasks and video understanding tasks separately. In contrast, we propose LAST, short for LeArn to Think in Space and Time, to jointly improve 3D spatial and long video understanding for general VLMs with only a set of 2D images as inputs. LAST makes VLMs think in space and time rather than only with text before giving the final answer, building visual thinking trajectories in 3D space and temporal dimension. We demonstrate the effectiveness of LAST in two scenarios: 1) zero-shot, where we directly prompt proprietary models; and 2) fine-tuning general VLMs with data that include thinking trajectories in 3D space and time. We show that LAST brings substantial gains in various benchmarks, including 3 spatial understanding, 4 video understanding, and 3 image understanding tasks. Notably, 15.8% gains on EgoSchema with GPT-4o in a zero-shot manner and 8.3 gains on VSI-Bench compared with Qwen2.5-VL-7B.",
    "published": "2025-11-24T16:13:26Z",
    "updated": "2025-11-24T16:13:26Z",
    "link": "http://arxiv.org/pdf/2511.19261v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shuai Wang",
      "Daoan Zhang",
      "Tianyi Bai",
      "Shitong Shao",
      "Jiebo Luo",
      "Jiaheng Wei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.05813v2",
    "title": "Optimization-Free Style Transfer for 3D Gaussian Splats",
    "summary": "The task of style transfer for 3D Gaussian splats has been explored in many previous works, but these require reconstructing or fine-tuning the splat while incorporating style information or optimizing a feature extraction network on the splat representation. We propose a reconstruction- and optimization-free approach to stylizing 3D Gaussian splats, allowing for direct stylization on a .ply or .splat file without requiring the original camera views. This is done by generating a graph structure across the implicit surface of the splat representation. A feed-forward, surface-based stylization method is then used and interpolated back to the individual splats in the scene. This also allows for fast stylization of splats with no additional training, achieving speeds under 2 minutes even on CPU-based consumer hardware. We demonstrate the quality results this approach achieves and compare to other 3D Gaussian splat style transfer methods. Code is publicly available at https://github.com/davidmhart/FastSplatStyler.",
    "published": "2025-08-07T19:35:01Z",
    "updated": "2025-11-24T16:09:54Z",
    "link": "http://arxiv.org/pdf/2508.05813v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Raphael Du Sablon",
      "David Hart"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19248v1",
    "title": "FedPoisonTTP: A Threat Model and Poisoning Attack for Federated Test-Time Personalization",
    "summary": "Test-time personalization in federated learning enables models at clients to adjust online to local domain shifts, enhancing robustness and personalization in deployment. Yet, existing federated learning work largely overlooks the security risks that arise when local adaptation occurs at test time. Heterogeneous domain arrivals, diverse adaptation algorithms, and limited cross-client visibility create vulnerabilities where compromised participants can craft poisoned inputs and submit adversarial updates that undermine both global and per-client performance. To address this threat, we introduce FedPoisonTTP, a realistic grey-box attack framework that explores test-time data poisoning in the federated adaptation setting. FedPoisonTTP distills a surrogate model from adversarial queries, synthesizes in-distribution poisons using feature-consistency, and optimizes attack objectives to generate high-entropy or class-confident poisons that evade common adaptation filters. These poisons are injected during local adaptation and spread through collaborative updates, leading to broad degradation. Extensive experiments on corrupted vision benchmarks show that compromised participants can substantially diminish overall test-time performance.",
    "published": "2025-11-24T16:02:01Z",
    "updated": "2025-11-24T16:02:01Z",
    "link": "http://arxiv.org/pdf/2511.19248v1.pdf",
    "category": [
      "cs.CR",
      "cs.CV"
    ],
    "authors": [
      "Md Akil Raihan Iftee",
      "Syed Md. Ahnaf Hasan",
      "Amin Ahsan Ali",
      "AKM Mahbubur Rahman",
      "Sajib Mistry",
      "Aneesh Krishna"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.15349v2",
    "title": "Zero-Shot Coreset Selection via Iterative Subspace Sampling",
    "summary": "Deep learning increasingly relies on massive data with substantial storage, annotation, and training costs. To reduce costs, coreset selection finds a representative subset of data to train models while ideally performing on par with the full data training. To maximize performance, current state-of-the-art coreset methods select data using dataset-specific ground truth labels and training. However, these methodological requirements prevent selection at scale on real-world, unlabeled data. To that end, this paper addresses the selection of coresets that achieve state-of-the-art performance but without using any labels or training on candidate data. Instead, our solution, Zero-Shot Coreset Selection via Iterative Subspace Sampling (ZCore), uses previously-trained foundation models to generate zero-shot, high-dimensional embedding spaces to interpret unlabeled data. ZCore then iteratively quantifies the relative value of all candidate data based on coverage and redundancy in numerous subspace distributions. Finally, ZCore selects a coreset sized for any data budget to train downstream models. We evaluate ZCore on four datasets and outperform several state-of-the-art label-based methods, especially at low data rates that provide the most substantial cost reduction. On ImageNet, ZCore selections for 10% training data achieve a downstream validation accuracy of 53.99%, which outperforms prior label-based methods and removes annotation and training costs for 1.15 million images. Our paper's code is publicly available at https://github.com/voxel51/zcore.",
    "published": "2024-11-22T21:17:49Z",
    "updated": "2025-11-24T16:01:24Z",
    "link": "http://arxiv.org/pdf/2411.15349v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Brent A. Griffin",
      "Jacob Marks",
      "Jason J. Corso"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.15986v2",
    "title": "Fairness in Multi-modal Medical Diagnosis with Demonstration Selection",
    "summary": "Multimodal large language models (MLLMs) have shown strong potential for medical image reasoning, yet fairness across demographic groups remains a major concern. Existing debiasing methods often rely on large labeled datasets or fine-tuning, which are impractical for foundation-scale models. We explore In-Context Learning (ICL) as a lightweight, tuning-free alternative for improving fairness. Through systematic analysis, we find that conventional demonstration selection (DS) strategies fail to ensure fairness due to demographic imbalance in selected exemplars. To address this, we propose Fairness-Aware Demonstration Selection (FADS), which builds demographically balanced and semantically relevant demonstrations via clustering-based sampling. Experiments on multiple medical imaging benchmarks show that FADS consistently reduces gender-, race-, and ethnicity-related disparities while maintaining strong accuracy, offering an efficient and scalable path toward fair medical image reasoning. These results highlight the potential of fairness-aware in-context learning as a scalable and data-efficient solution for equitable medical image reasoning.",
    "published": "2025-11-20T02:38:00Z",
    "updated": "2025-11-24T15:59:06Z",
    "link": "http://arxiv.org/pdf/2511.15986v2.pdf",
    "category": [
      "cs.CV",
      "cs.CY",
      "cs.LG"
    ],
    "authors": [
      "Dawei Li",
      "Zijian Gu",
      "Peng Wang",
      "Chuhan Song",
      "Zhen Tan",
      "Mohan Zhang",
      "Tianlong Chen",
      "Yu Tian",
      "Song Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13533v2",
    "title": "Minimax Multi-Target Conformal Prediction with Applications to Imaging Inverse Problems",
    "summary": "In ill-posed imaging inverse problems, uncertainty quantification remains a fundamental challenge, especially in safety-critical applications. Recently, conformal prediction has been used to quantify the uncertainty that the inverse problem contributes to downstream tasks like image classification, image quality assessment, fat mass quantification, etc. While existing works handle only a scalar estimation target, practical applications often involve multiple targets. In response, we propose an asymptotically minimax approach to multi-target conformal prediction that provides tight prediction intervals while ensuring joint marginal coverage. We then outline how our minimax approach can be applied to multi-metric blind image quality assessment, multi-task uncertainty quantification, and multi-round measurement acquisition. Finally, we numerically demonstrate the benefits of our minimax method, relative to existing multi-target conformal prediction methods, using both synthetic and magnetic resonance imaging (MRI) data. Code is available at https://github.com/jwen307/multi_target_minimax.",
    "published": "2025-11-17T16:06:37Z",
    "updated": "2025-11-24T15:58:49Z",
    "link": "http://arxiv.org/pdf/2511.13533v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jeffrey Wen",
      "Rizwan Ahmad",
      "Philip Schniter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2201.00708v2",
    "title": "Multiview point cloud registration with anisotropic and space-varying localization noise",
    "summary": "In this paper, we address the problem of registering multiple point clouds corrupted with high anisotropic localization noise. Our approach follows the widely used framework of Gaussian mixture model (GMM) reconstruction with an expectation-maximization (EM) algorithm. Existing methods are based on an implicit assumption of space-invariant isotropic Gaussian noise. However, this assumption is violated in practice in applications such as single molecule localization microscopy (SMLM). To address this issue, we propose to introduce an explicit localization noise model that decouples shape modeling with the GMM from noise handling. We design a stochastic EM algorithm that considers noise-free data as a latent variable, with closed-form solutions at each EM step. The first advantage of our approach is to handle space-variant and anisotropic Gaussian noise with arbitrary covariances. The second advantage is to leverage the explicit noise model to impose prior knowledge about the noise that may be available from physical sensors. We show on various simulated data that our noise handling strategy improves significantly the robustness to high levels of anisotropic noise. We also demonstrate the performance of our method on real SMLM data.",
    "published": "2022-01-03T15:21:24Z",
    "updated": "2025-11-24T15:58:39Z",
    "link": "http://arxiv.org/pdf/2201.00708v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Denis Fortun",
      "Etienne Baudrier",
      "Fabian Zwettler",
      "Markus Sauer",
      "Sylvain Faisan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19235v1",
    "title": "IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes",
    "summary": "Reconstructing dynamic driving scenes is essential for developing autonomous systems through sensor-realistic simulation. Although recent methods achieve high-fidelity reconstructions, they either rely on costly human annotations for object trajectories or use time-varying representations without explicit object-level decomposition, leading to intertwined static and dynamic elements that hinder scene separation. We present IDSplat, a self-supervised 3D Gaussian Splatting framework that reconstructs dynamic scenes with explicit instance decomposition and learnable motion trajectories, without requiring human annotations. Our key insight is to model dynamic objects as coherent instances undergoing rigid transformations, rather than unstructured time-varying primitives. For instance decomposition, we employ zero-shot, language-grounded video tracking anchored to 3D using lidar, and estimate consistent poses via feature correspondences. We introduce a coordinated-turn smoothing scheme to obtain temporally and physically consistent motion trajectories, mitigating pose misalignments and tracking failures, followed by joint optimization of object poses and Gaussian parameters. Experiments on the Waymo Open Dataset demonstrate that our method achieves competitive reconstruction quality while maintaining instance-level decomposition and generalizes across diverse sequences and view densities without retraining, making it practical for large-scale autonomous driving applications. Code will be released.",
    "published": "2025-11-24T15:48:08Z",
    "updated": "2025-11-24T15:48:08Z",
    "link": "http://arxiv.org/pdf/2511.19235v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Carl Lindström",
      "Mahan Rafidashti",
      "Maryam Fatemi",
      "Lars Hammarstrand",
      "Martin R. Oswald",
      "Lennart Svensson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19221v1",
    "title": "Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving",
    "summary": "Autonomous driving heavily relies on accurate and robust spatial perception. Many failures arise from inaccuracies and instability, especially in long-tail scenarios and complex interactions. However, current vision-language models are weak at spatial grounding and understanding, and VLA systems built on them therefore show limited perception and localization ability. To address these challenges, we introduce Percept-WAM, a perception-enhanced World-Awareness-Action Model that is the first to implicitly integrate 2D/3D scene understanding abilities within a single vision-language model (VLM). Instead of relying on QA-style spatial reasoning, Percept-WAM unifies 2D/3D perception tasks into World-PV and World-BEV tokens, which encode both spatial coordinates and confidence. We propose a grid-conditioned prediction mechanism for dense object perception, incorporating IoU-aware scoring and parallel autoregressive decoding, improving stability in long-tail, far-range, and small-object scenarios. Additionally, Percept-WAM leverages pretrained VLM parameters to retain general intelligence (e.g., logical reasoning) and can output perception results and trajectory control outputs directly. Experiments show that Percept-WAM matches or surpasses classical detectors and segmenters on downstream perception benchmarks, achieving 51.7/58.9 mAP on COCO 2D detection and nuScenes BEV 3D detection. When integrated with trajectory decoders, it further improves planning performance on nuScenes and NAVSIM, e.g., surpassing DiffusionDrive by 2.1 in PMDS on NAVSIM. Qualitative results further highlight its strong open-vocabulary and long-tail generalization.",
    "published": "2025-11-24T15:28:25Z",
    "updated": "2025-11-24T15:28:25Z",
    "link": "http://arxiv.org/pdf/2511.19221v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jianhua Han",
      "Meng Tian",
      "Jiangtong Zhu",
      "Fan He",
      "Huixin Zhang",
      "Sitong Guo",
      "Dechang Zhu",
      "Hao Tang",
      "Pei Xu",
      "Yuze Guo",
      "Minzhe Niu",
      "Haojie Zhu",
      "Qichao Dong",
      "Xuechao Yan",
      "Siyuan Dong",
      "Lu Hou",
      "Qingqiu Huang",
      "Xiaosong Jia",
      "Hang Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19217v1",
    "title": "ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided Alignment",
    "summary": "Text-to-motion generation, which synthesizes 3D human motions from text inputs, holds immense potential for applications in gaming, film, and robotics. Recently, diffusion-based methods have been shown to generate more diversity and realistic motion. However, there exists a misalignment between text and motion distributions in diffusion models, which leads to semantically inconsistent or low-quality motions. To address this limitation, we propose Reward-guided sampling Alignment (ReAlign), comprising a step-aware reward model to assess alignment quality during the denoising sampling and a reward-guided strategy that directs the diffusion process toward an optimally aligned distribution. This reward model integrates step-aware tokens and combines a text-aligned module for semantic consistency and a motion-aligned module for realism, refining noisy motions at each timestep to balance probability density and alignment. Extensive experiments of both motion generation and retrieval tasks demonstrate that our approach significantly improves text-motion alignment and motion quality compared to existing state-of-the-art methods.",
    "published": "2025-11-24T15:23:36Z",
    "updated": "2025-11-24T15:23:36Z",
    "link": "http://arxiv.org/pdf/2511.19217v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wanjiang Weng",
      "Xiaofeng Tan",
      "Junbo Wang",
      "Guo-Sen Xie",
      "Pan Zhou",
      "Hongsong Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.21698v2",
    "title": "MedBridge: Bridging Foundation Vision-Language Models to Medical Image Diagnosis in Chest X-Ray",
    "summary": "Recent vision-language foundation models deliver state-of-the-art results in natural image classification, but falter in medical images due to pronounced domain shifts. Training a medical foundation model also requires substantial resources, including extensive annotated data and high computational capacity. To bridge this gap with minimal overhead, we introduce MedBridge, a lightweight multimodal adaptation framework that flexibly re-purposes arbitrary pre-trained foundation VLMs for medical image diagnosis. MedBridge comprises three novel core components. First, a Focal Sampling module that subsamples and extracts high-resolution local regions to capture subtle pathological features, compensating for the limited input resolution of foundation VLMs. Second, a Query-Encoder model with a small set of learnable queries to align the feature maps of frozen VLMs with medical semantics, without requiring retraining of the backbone layers. Third, a Mixture of Experts mechanism, driven by learnable queries, harnesses the complementary strength of various VLMs to maximize diagnostic performance. We evaluate MedBridge on five chest radiograph benchmarks in three key adaptation tasks, demonstrating its superior performance in both cross-domain and in-domain adaptation settings under varying levels of training data availability. MedBridge achieved an improvement of 6-15% in AUC compared to state-of-the-art VLM adaptation methods in multi-label thoracic disease diagnosis, underscoring its effectiveness in leveraging diverse foundation models for accurate and data-efficient medical diagnosis. Our project and code are available at https://github.com/ai-med/MedBridge.",
    "published": "2025-05-27T19:37:51Z",
    "updated": "2025-11-24T15:19:38Z",
    "link": "http://arxiv.org/pdf/2505.21698v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yitong Li",
      "Morteza Ghahremani",
      "Christian Wachinger"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19202v1",
    "title": "NVGS: Neural Visibility for Occlusion Culling in 3D Gaussian Splatting",
    "summary": "3D Gaussian Splatting can exploit frustum culling and level-of-detail strategies to accelerate rendering of scenes containing a large number of primitives. However, the semi-transparent nature of Gaussians prevents the application of another highly effective technique: occlusion culling. We address this limitation by proposing a novel method to learn the viewpoint-dependent visibility function of all Gaussians in a trained model using a small, shared MLP across instances of an asset in a scene. By querying it for Gaussians within the viewing frustum prior to rasterization, our method can discard occluded primitives during rendering. Leveraging Tensor Cores for efficient computation, we integrate these neural queries directly into a novel instanced software rasterizer. Our approach outperforms the current state of the art for composed scenes in terms of VRAM usage and image quality, utilizing a combination of our instanced rasterizer and occlusion culling MLP, and exhibits complementary properties to existing LoD techniques.",
    "published": "2025-11-24T15:11:12Z",
    "updated": "2025-11-24T15:11:12Z",
    "link": "http://arxiv.org/pdf/2511.19202v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Brent Zoomers",
      "Florian Hahlbohm",
      "Joni Vanherck",
      "Lode Jorissen",
      "Marcus Magnor",
      "Nick Michiels"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19200v1",
    "title": "Can Modern Vision Models Understand the Difference Between an Object and a Look-alike?",
    "summary": "Recent advances in computer vision have yielded models with strong performance on recognition benchmarks; however, significant gaps remain in comparison to human perception. One subtle ability is to judge whether an image looks like a given object without being an instance of that object. We study whether vision-language models such as CLIP capture this distinction. We curated a dataset named RoLA (Real or Lookalike) of real and lookalike exemplars (e.g., toys, statues, drawings, pareidolia) across multiple categories, and first evaluate a prompt-based baseline with paired \"real\"/\"lookalike\" prompts. We then estimate a direction in CLIP's embedding space that moves representations between real and lookalike. Applying this direction to image and text embeddings improves discrimination in cross-modal retrieval on Conceptual12M, and also enhances captions produced by a CLIP prefix captioner.",
    "published": "2025-11-24T15:09:32Z",
    "updated": "2025-11-24T15:09:32Z",
    "link": "http://arxiv.org/pdf/2511.19200v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Itay Cohen",
      "Ethan Fetaya",
      "Amir Rosenfeld"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.20776v2",
    "title": "CUPID: Generative 3D Reconstruction via Joint Object and Pose Modeling",
    "summary": "We introduce Cupid, a generative 3D reconstruction framework that jointly models the full distribution over both canonical objects and camera poses. Our two-stage flow-based model first generates a coarse 3D structure and 2D-3D correspondences to estimate the camera pose robustly. Conditioned on this pose, a refinement stage injects pixel-aligned image features directly into the generative process, marrying the rich prior of a generative model with the geometric fidelity of reconstruction. This strategy achieves exceptional faithfulness, outperforming state-of-the-art reconstruction methods by over 3 dB PSNR and 10% in Chamfer Distance. As a unified generative model that decouples the object and camera pose, Cupid naturally extends to multi-view and scene-level reconstruction tasks without requiring post-hoc optimization or fine-tuning.",
    "published": "2025-10-23T17:47:38Z",
    "updated": "2025-11-24T15:08:33Z",
    "link": "http://arxiv.org/pdf/2510.20776v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Binbin Huang",
      "Haobin Duan",
      "Yiqun Zhao",
      "Zibo Zhao",
      "Yi Ma",
      "Shenghua Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19198v1",
    "title": "Three-Dimensional Anatomical Data Generation Based on Artificial Neural Networks",
    "summary": "Surgical planning and training based on machine learning requires a large amount of 3D anatomical models reconstructed from medical imaging, which is currently one of the major bottlenecks. Obtaining these data from real patients and during surgery is very demanding, if even possible, due to legal, ethical, and technical challenges. It is especially difficult for soft tissue organs with poor imaging contrast, such as the prostate. To overcome these challenges, we present a novel workflow for automated 3D anatomical data generation using data obtained from physical organ models. We additionally use a 3D Generative Adversarial Network (GAN) to obtain a manifold of 3D models useful for other downstream machine learning tasks that rely on 3D data. We demonstrate our workflow using an artificial prostate model made of biomimetic hydrogels with imaging contrast in multiple zones. This is used to physically simulate endoscopic surgery. For evaluation and 3D data generation, we place it into a customized ultrasound scanner that records the prostate before and after the procedure. A neural network is trained to segment the recorded ultrasound images, which outperforms conventional, non-learning-based computer vision techniques in terms of intersection over union (IoU). Based on the segmentations, a 3D mesh model is reconstructed, and performance feedback is provided.",
    "published": "2025-11-24T15:07:45Z",
    "updated": "2025-11-24T15:07:45Z",
    "link": "http://arxiv.org/pdf/2511.19198v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Ann-Sophia Müller",
      "Moonkwang Jeong",
      "Meng Zhang",
      "Jiyuan Tian",
      "Arkadiusz Miernik",
      "Stefanie Speidel",
      "Tian Qiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.05224v2",
    "title": "Don't Reach for the Stars: Rethinking Topology for Resilient Federated Learning",
    "summary": "Federated learning (FL) enables collaborative model training across distributed clients while preserving data privacy by keeping data local. Traditional FL approaches rely on a centralized, star-shaped topology, where a central server aggregates model updates from clients. However, this architecture introduces several limitations, including a single point of failure, limited personalization, and poor robustness to distribution shifts or vulnerability to malfunctioning clients. Moreover, update selection in centralized FL often relies on low-level parameter differences, which can be unreliable when client data is not independent and identically distributed, and offer clients little control. In this work, we propose a decentralized, peer-to-peer (P2P) FL framework. It leverages the flexibility of the P2P topology to enable each client to identify and aggregate a personalized set of trustworthy and beneficial updates.This framework is the Local Inference Guided Aggregation for Heterogeneous Training Environments to Yield Enhancement Through Agreement and Regularization (LIGHTYEAR). Central to our method is an agreement score, computed on a local validation set, which quantifies the semantic alignment of incoming updates in the function space with respect to the clients reference model. Each client uses this score to select a tailored subset of updates and performs aggregation with a regularization term that further stabilizes the training. Our empirical evaluation across five datasets shows that the proposed approach consistently outperforms both, centralized baselines and existing P2P methods in terms of client-level performance, particularly under adversarial and heterogeneous conditions.",
    "published": "2025-08-07T10:10:37Z",
    "updated": "2025-11-24T14:59:34Z",
    "link": "http://arxiv.org/pdf/2508.05224v2.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Mirko Konstantin",
      "Anirban Mukhopadhyay"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19187v1",
    "title": "SpectraNet: FFT-assisted Deep Learning Classifier for Deepfake Face Detection",
    "summary": "Detecting deepfake images is crucial in combating misinformation. We present a lightweight, generalizable binary classification model based on EfficientNet-B6, fine-tuned with transformation techniques to address severe class imbalances. By leveraging robust preprocessing, oversampling, and optimization strategies, our model achieves high accuracy, stability, and generalization. While incorporating Fourier transform-based phase and amplitude features showed minimal impact, our proposed framework helps non-experts to effectively identify deepfake images, making significant strides toward accessible and reliable deepfake detection.",
    "published": "2025-11-24T14:54:00Z",
    "updated": "2025-11-24T14:54:00Z",
    "link": "http://arxiv.org/pdf/2511.19187v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Nithira Jayarathne",
      "Naveen Basnayake",
      "Keshawa Jayasundara",
      "Pasindu Dodampegama",
      "Praveen Wijesinghe",
      "Hirushika Pelagewatta",
      "Kavishka Abeywardana",
      "Sandushan Ranaweera",
      "Chamira Edussooriya"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19183v1",
    "title": "nnActive: A Framework for Evaluation of Active Learning in 3D Biomedical Segmentation",
    "summary": "Semantic segmentation is crucial for various biomedical applications, yet its reliance on large annotated datasets presents a bottleneck due to the high cost and specialized expertise required for manual labeling. Active Learning (AL) aims to mitigate this challenge by querying only the most informative samples, thereby reducing annotation effort. However, in the domain of 3D biomedical imaging, there is no consensus on whether AL consistently outperforms Random sampling. Four evaluation pitfalls hinder the current methodological assessment. These are (1) restriction to too few datasets and annotation budgets, (2) using 2D models on 3D images without partial annotations, (3) Random baseline not being adapted to the task, and (4) measuring annotation cost only in voxels. In this work, we introduce nnActive, an open-source AL framework that overcomes these pitfalls by (1) means of a large scale study spanning four biomedical imaging datasets and three label regimes, (2) extending nnU-Net by using partial annotations for training with 3D patch-based query selection, (3) proposing Foreground Aware Random sampling strategies tackling the foreground-background class imbalance of medical images and (4) propose the foreground efficiency metric, which captures the low annotation cost of background-regions. We reveal the following findings: (A) while all AL methods outperform standard Random sampling, none reliably surpasses an improved Foreground Aware Random sampling; (B) benefits of AL depend on task specific parameters; (C) Predictive Entropy is overall the best performing AL method, but likely requires the most annotation effort; (D) AL performance can be improved with more compute intensive design choices. As a holistic, open-source framework, nnActive can serve as a catalyst for research and application of AL in 3D biomedical imaging. Code is at: https://github.com/MIC-DKFZ/nnActive",
    "published": "2025-11-24T14:50:36Z",
    "updated": "2025-11-24T14:50:36Z",
    "link": "http://arxiv.org/pdf/2511.19183v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Carsten T. Lüth",
      "Jeremias Traub",
      "Kim-Celine Kahl",
      "Till J. Bungert",
      "Lukas Klein",
      "Lars Krämer",
      "Paul F. Jaeger",
      "Fabian Isensee",
      "Klaus Maier-Hein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19180v1",
    "title": "Evaluating Deep Learning and Traditional Approaches Used in Source Camera Identification",
    "summary": "One of the most important tasks in computer vision is identifying the device using which the image was taken, useful for facilitating further comprehensive analysis of the image. This paper presents comparative analysis of three techniques used in source camera identification (SCI): Photo Response Non-Uniformity (PRNU), JPEG compression artifact analysis, and convolutional neural networks (CNNs). It evaluates each method in terms of device classification accuracy. Furthermore, the research discusses the possible scientific development needed for the implementation of the methods in real-life scenarios.",
    "published": "2025-11-24T14:42:44Z",
    "updated": "2025-11-24T14:42:44Z",
    "link": "http://arxiv.org/pdf/2511.19180v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mansur Ozaman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19172v1",
    "title": "MetroGS: Efficient and Stable Reconstruction of Geometrically Accurate High-Fidelity Large-Scale Scenes",
    "summary": "Recently, 3D Gaussian Splatting and its derivatives have achieved significant breakthroughs in large-scale scene reconstruction. However, how to efficiently and stably achieve high-quality geometric fidelity remains a core challenge. To address this issue, we introduce MetroGS, a novel Gaussian Splatting framework for efficient and robust reconstruction in complex urban environments. Our method is built upon a distributed 2D Gaussian Splatting representation as the core foundation, serving as a unified backbone for subsequent modules. To handle potential sparse regions in complex scenes, we propose a structured dense enhancement scheme that utilizes SfM priors and a pointmap model to achieve a denser initialization, while incorporating a sparsity compensation mechanism to improve reconstruction completeness. Furthermore, we design a progressive hybrid geometric optimization strategy that organically integrates monocular and multi-view optimization to achieve efficient and accurate geometric refinement. Finally, to address the appearance inconsistency commonly observed in large-scale scenes, we introduce a depth-guided appearance modeling approach that learns spatial features with 3D consistency, facilitating effective decoupling between geometry and appearance and further enhancing reconstruction stability. Experiments on large-scale urban datasets demonstrate that MetroGS achieves superior geometric accuracy, rendering quality, offering a unified solution for high-fidelity large-scale scene reconstruction.",
    "published": "2025-11-24T14:34:19Z",
    "updated": "2025-11-24T14:34:19Z",
    "link": "http://arxiv.org/pdf/2511.19172v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kehua Chen",
      "Tianlu Mao",
      "Zhuxin Ma",
      "Hao Jiang",
      "Zehao Li",
      "Zihan Liu",
      "Shuqi Gao",
      "Honglong Zhao",
      "Feng Dai",
      "Yucheng Zhang",
      "Zhaoqi Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19169v1",
    "title": "Test-Time Preference Optimization for Image Restoration",
    "summary": "Image restoration (IR) models are typically trained to recover high-quality images using L1 or LPIPS loss. To handle diverse unknown degradations, zero-shot IR methods have also been introduced. However, existing pre-trained and zero-shot IR approaches often fail to align with human preferences, resulting in restored images that may not be favored. This highlights the critical need to enhance restoration quality and adapt flexibly to various image restoration tasks or backbones without requiring model retraining and ideally without labor-intensive preference data collection. In this paper, we propose the first Test-Time Preference Optimization (TTPO) paradigm for image restoration, which enhances perceptual quality, generates preference data on-the-fly, and is compatible with any IR model backbone. Specifically, we design a training-free, three-stage pipeline: (i) generate candidate preference images online using diffusion inversion and denoising based on the initially restored image; (ii) select preferred and dispreferred images using automated preference-aligned metrics or human feedback; and (iii) use the selected preference images as reward signals to guide the diffusion denoising process, optimizing the restored image to better align with human preferences. Extensive experiments across various image restoration tasks and models demonstrate the effectiveness and flexibility of the proposed pipeline.",
    "published": "2025-11-24T14:32:27Z",
    "updated": "2025-11-24T14:32:27Z",
    "link": "http://arxiv.org/pdf/2511.19169v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bingchen Li",
      "Xin Li",
      "Jiaqi Xu",
      "Jiaming Guo",
      "Wenbo Li",
      "Renjing Pei",
      "Zhibo Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19147v1",
    "title": "Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation",
    "summary": "Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data. Recent advances in Foundation Models (FMs) have introduced new opportunities for leveraging external semantic knowledge to guide SFDA. However, relying on a single FM is often insufficient, as it tends to bias adaptation toward a restricted semantic coverage, failing to capture diverse contextual cues under domain shift. To overcome this limitation, we propose a Collaborative Multi-foundation Adaptation (CoMA) framework that jointly leverages two different FMs (e.g., CLIP and BLIP) with complementary properties to capture both global semantics and local contextual cues. Specifically, we employ a bidirectional adaptation mechanism that (1) aligns different FMs with the target model for task adaptation while maintaining their semantic distinctiveness, and (2) transfers complementary knowledge from the FMs to the target model. To ensure stable adaptation under mini-batch training, we introduce Decomposed Mutual Information (DMI) that selectively enhances true dependencies while suppressing false dependencies arising from incomplete class coverage. Extensive experiments demonstrate that our method consistently outperforms existing state-of-the-art SFDA methods across four benchmarks, including Office-31, Office-Home, DomainNet-126, and VisDA, under the closed-set setting, while also achieving best results on partial-set and open-set variants.",
    "published": "2025-11-24T14:12:22Z",
    "updated": "2025-11-24T14:12:22Z",
    "link": "http://arxiv.org/pdf/2511.19147v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Huisoo Lee",
      "Jisu Han",
      "Hyunsouk Cho",
      "Wonjun Hwang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19145v1",
    "title": "ABM-LoRA: Activation Boundary Matching for Fast Convergence in Low-Rank Adaptation",
    "summary": "We propose Activation Boundary Matching for Low-Rank Adaptation (ABM-LoRA), a principled initialization strategy that substantially accelerates the convergence of low-rank adapters. While LoRA offers high parameter efficiency, its random initialization restricts gradient updates to a mismatched tangent space, causing significant information loss and hindering early convergence. Our ABM-LoRA addresses this by aligning the adapter's activation boundaries with those of the pretrained model before downstream training, thereby maximizing the projection of full-parameter gradients into the adapter subspace. This alignment sharply reduces information loss at initialization, yields a lower starting loss, and accelerates convergence. We demonstrate ABM-LoRA's effectiveness across diverse architectures and tasks: language understanding (T5-Base on GLUE), dialogue generation (LLaMA2-7B on WizardLM), and vision recognition (ViT-B/16 on VTAB-1K). On VTAB-1K, it achieves the highest accuracy among all methods, with strong gains on structured reasoning tasks requiring geometric understanding.",
    "published": "2025-11-24T14:09:42Z",
    "updated": "2025-11-24T14:09:42Z",
    "link": "http://arxiv.org/pdf/2511.19145v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Dongha Lee",
      "Jinhee Park",
      "Minjun Kim",
      "Junseok Kwon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.18414v2",
    "title": "U-REPA: Aligning Diffusion U-Nets to ViTs",
    "summary": "Representation Alignment (REPA) that aligns Diffusion Transformer (DiT) hidden-states with ViT visual encoders has proven highly effective in DiT training, demonstrating superior convergence properties, but it has not been validated on the canonical diffusion U-Net architecture that shows faster convergence compared to DiTs. However, adapting REPA to U-Net architectures presents unique challenges: (1) different block functionalities necessitate revised alignment strategies; (2) spatial-dimension inconsistencies emerge from U-Net's spatial downsampling operations; (3) space gaps between U-Net and ViT hinder the effectiveness of tokenwise alignment. To encounter these challenges, we propose \\textbf{U-REPA}, a representation alignment paradigm that bridges U-Net hidden states and ViT features as follows: Firstly, we propose via observation that due to skip connection, the middle stage of U-Net is the best alignment option. Secondly, we propose upsampling of U-Net features after passing them through MLPs. Thirdly, we observe difficulty when performing tokenwise similarity alignment, and further introduces a manifold loss that regularizes the relative similarity between samples. Experiments indicate that the resulting U-REPA could achieve excellent generation quality and greatly accelerates the convergence speed. With CFG guidance interval, U-REPA could reach $FID<1.5$ in 200 epochs or 1M iterations on ImageNet 256 $\\times$ 256, and needs only half the total epochs to perform better than REPA under sd-vae-ft-ema. Codes: https://github.com/YuchuanTian/U-REPA",
    "published": "2025-03-24T07:46:00Z",
    "updated": "2025-11-24T14:03:50Z",
    "link": "http://arxiv.org/pdf/2503.18414v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuchuan Tian",
      "Hanting Chen",
      "Mengyu Zheng",
      "Yuchen Liang",
      "Chao Xu",
      "Yunhe Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14208v2",
    "title": "InstantViR: Real-Time Video Inverse Problem Solver with Distilled Diffusion Prior",
    "summary": "Video inverse problems are fundamental to streaming, telepresence, and AR/VR, where high perceptual quality must coexist with tight latency constraints. Diffusion-based priors currently deliver state-of-the-art reconstructions, but existing approaches either adapt image diffusion models with ad hoc temporal regularizers - leading to temporal artifacts - or rely on native video diffusion models whose iterative posterior sampling is far too slow for real-time use. We introduce InstantViR, an amortized inference framework for ultra-fast video reconstruction powered by a pre-trained video diffusion prior. We distill a powerful bidirectional video diffusion model (teacher) into a causal autoregressive student that maps a degraded video directly to its restored version in a single forward pass, inheriting the teacher's strong temporal modeling while completely removing iterative test-time optimization. The distillation is prior-driven: it only requires the teacher diffusion model and known degradation operators, and does not rely on externally paired clean/noisy video data. To further boost throughput, we replace the video-diffusion backbone VAE with a high-efficiency LeanVAE via an innovative teacher-space regularized distillation scheme, enabling low-latency latent-space processing. Across streaming random inpainting, Gaussian deblurring and super-resolution, InstantViR matches or surpasses the reconstruction quality of diffusion-based baselines while running at over 35 FPS on NVIDIA A100 GPUs, achieving up to 100 times speedups over iterative video diffusion solvers. These results show that diffusion-based video reconstruction is compatible with real-time, interactive, editable, streaming scenarios, turning high-quality video restoration into a practical component of modern vision systems.",
    "published": "2025-11-18T07:40:38Z",
    "updated": "2025-11-24T14:03:29Z",
    "link": "http://arxiv.org/pdf/2511.14208v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Weimin Bai",
      "Suzhe Xu",
      "Yiwei Ren",
      "Jinhua Hao",
      "Ming Sun",
      "Wenzheng Chen",
      "He Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19137v1",
    "title": "FilmSceneDesigner: Chaining Set Design for Procedural Film Scene Generation",
    "summary": "Film set design plays a pivotal role in cinematic storytelling and shaping the visual atmosphere. However, the traditional process depends on expert-driven manual modeling, which is labor-intensive and time-consuming. To address this issue, we introduce FilmSceneDesigner, an automated scene generation system that emulates professional film set design workflow. Given a natural language description, including scene type, historical period, and style, we design an agent-based chaining framework to generate structured parameters aligned with film set design workflow, guided by prompt strategies that ensure parameter accuracy and coherence. On the other hand, we propose a procedural generation pipeline which executes a series of dedicated functions with the structured parameters for floorplan and structure generation, material assignment, door and window placement, and object retrieval and layout, ultimately constructing a complete film scene from scratch. Moreover, to enhance cinematic realism and asset diversity, we construct SetDepot-Pro, a curated dataset of 6,862 film-specific 3D assets and 733 materials. Experimental results and human evaluations demonstrate that our system produces structurally sound scenes with strong cinematic fidelity, supporting downstream tasks such as virtual previs, construction drawing and mood board creation.",
    "published": "2025-11-24T14:00:40Z",
    "updated": "2025-11-24T14:00:40Z",
    "link": "http://arxiv.org/pdf/2511.19137v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhifeng Xie",
      "Keyi Zhang",
      "Yiye Yan",
      "Yuling Guo",
      "Fan Yang",
      "Jiting Zhou",
      "Mengtian Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19134v1",
    "title": "MambaRefine-YOLO: A Dual-Modality Small Object Detector for UAV Imagery",
    "summary": "Small object detection in Unmanned Aerial Vehicle (UAV) imagery is a persistent challenge, hindered by low resolution and background clutter. While fusing RGB and infrared (IR) data offers a promising solution, existing methods often struggle with the trade-off between effective cross-modal interaction and computational efficiency. In this letter, we introduce MambaRefine-YOLO. Its core contributions are a Dual-Gated Complementary Mamba fusion module (DGC-MFM) that adaptively balances RGB and IR modalities through illumination-aware and difference-aware gating mechanisms, and a Hierarchical Feature Aggregation Neck (HFAN) that uses a ``refine-then-fuse'' strategy to enhance multi-scale features. Our comprehensive experiments validate this dual-pronged approach. On the dual-modality DroneVehicle dataset, the full model achieves a state-of-the-art mAP of 83.2%, an improvement of 7.9% over the baseline. On the single-modality VisDrone dataset, a variant using only the HFAN also shows significant gains, demonstrating its general applicability. Our work presents a superior balance between accuracy and speed, making it highly suitable for real-world UAV applications.",
    "published": "2025-11-24T13:59:01Z",
    "updated": "2025-11-24T13:59:01Z",
    "link": "http://arxiv.org/pdf/2511.19134v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shuyu Cao",
      "Minxin Chen",
      "Yucheng Song",
      "Zhaozhong Chen",
      "Xinyou Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19126v1",
    "title": "When Semantics Regulate: Rethinking Patch Shuffle and Internal Bias for Generated Image Detection with CLIP",
    "summary": "The rapid progress of GANs and Diffusion Models poses new challenges for detecting AI-generated images. Although CLIP-based detectors exhibit promising generalization, they often rely on semantic cues rather than generator artifacts, leading to brittle performance under distribution shifts. In this work, we revisit the nature of semantic bias and uncover that Patch Shuffle provides an unusually strong benefit for CLIP, that disrupts global semantic continuity while preserving local artifact cues, which reduces semantic entropy and homogenizes feature distributions between natural and synthetic images. Through a detailed layer-wise analysis, we further show that CLIP's deep semantic structure functions as a regulator that stabilizes cross-domain representations once semantic bias is suppressed. Guided by these findings, we propose SemAnti, a semantic-antagonistic fine-tuning paradigm that freezes the semantic subspace and adapts only artifact-sensitive layers under shuffled semantics. Despite its simplicity, SemAnti achieves state-of-the-art cross-domain generalization on AIGCDetectBenchmark and GenImage, demonstrating that regulating semantics is key to unlocking CLIP's full potential for robust AI-generated image detection.",
    "published": "2025-11-24T13:54:00Z",
    "updated": "2025-11-24T13:54:00Z",
    "link": "http://arxiv.org/pdf/2511.19126v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Beilin Chu",
      "Weike You",
      "Mengtao Li",
      "Tingting Zheng",
      "Kehan Zhao",
      "Xuan Xu",
      "Zhigao Lu",
      "Jia Song",
      "Moxuan Xu",
      "Linna Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19119v1",
    "title": "MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images",
    "summary": "Spatial reasoning (SR), the ability to infer 3D spatial information from 2D inputs, is essential for real-world applications such as embodied AI and autonomous driving. However, existing research primarily focuses on indoor environments and typically relies on multi-view observations, which limits their generalizability to outdoor scenarios and constrains their applicability to monocular images, the most common real-world setting. In this work, we propose MonoSR, a large-scale monocular spatial reasoning dataset that spans diverse scenarios including indoor, outdoor, and object-centric settings, and supports multiple question types. MonoSR provides a path toward open-world monocular spatial reasoning. Beyond introducing the dataset, we evaluate advanced vision-language models to reveal their limitations on this challenging task. We further analyze whether auxiliary information is crucial for monocular spatial reasoning and offer practical guidance for designing future models. These contributions collectively establish a foundation for advancing monocular spatial reasoning in real-world, open-world environments.",
    "published": "2025-11-24T13:49:17Z",
    "updated": "2025-11-24T13:49:17Z",
    "link": "http://arxiv.org/pdf/2511.19119v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qirui Wang",
      "Jingyi He",
      "Yining Pan",
      "Si Yong Yeo",
      "Xulei Yang",
      "Shijie Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19117v1",
    "title": "3M-TI: High-Quality Mobile Thermal Imaging via Calibration-free Multi-Camera Cross-Modal Diffusion",
    "summary": "The miniaturization of thermal sensors for mobile platforms inherently limits their spatial resolution and textural fidelity, leading to blurry and less informative images. Existing thermal super-resolution (SR) methods can be grouped into single-image and RGB-guided approaches: the former struggles to recover fine structures from limited information, while the latter relies on accurate and laborious cross-camera calibration, which hinders practical deployment and robustness. Here, we propose 3M-TI, a calibration-free Multi-camera cross-Modality diffusion framework for Mobile Thermal Imaging. At its core, 3M-TI integrates a cross-modal self-attention module (CSM) into the diffusion UNet, replacing the original self-attention layers to adaptively align thermal and RGB features throughout the denoising process, without requiring explicit camera calibration. This design enables the diffusion network to leverage its generative prior to enhance spatial resolution, structural fidelity, and texture detail in the super-resolved thermal images. Extensive evaluations on real-world mobile thermal cameras and public benchmarks validate our superior performance, achieving state-of-the-art results in both visual quality and quantitative metrics. More importantly, the thermal images enhanced by 3M-TI lead to substantial gains in critical downstream tasks like object detection and segmentation, underscoring its practical value for robust mobile thermal perception systems. More materials: https://github.com/work-submit/3MTI.",
    "published": "2025-11-24T13:48:47Z",
    "updated": "2025-11-24T13:48:47Z",
    "link": "http://arxiv.org/pdf/2511.19117v1.pdf",
    "category": [
      "cs.CV",
      "physics.optics"
    ],
    "authors": [
      "Minchong Chen",
      "Xiaoyun Yuan",
      "Junzhe Wan",
      "Jianing Zhang",
      "Jun Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19111v1",
    "title": "DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC Detection",
    "summary": "Diffusion-based editing enables realistic modification of local image regions, making AI-generated content harder to detect. Existing AIGC detection benchmarks focus on classifying entire images, overlooking the localization of diffusion-based edits. We introduce DiffSeg30k, a publicly available dataset of 30k diffusion-edited images with pixel-level annotations, designed to support fine-grained detection. DiffSeg30k features: 1) In-the-wild images--we collect images or image prompts from COCO to reflect real-world content diversity; 2) Diverse diffusion models--local edits using eight SOTA diffusion models; 3) Multi-turn editing--each image undergoes up to three sequential edits to mimic real-world sequential editing; and 4) Realistic editing scenarios--a vision-language model (VLM)-based pipeline automatically identifies meaningful regions and generates context-aware prompts covering additions, removals, and attribute changes. DiffSeg30k shifts AIGC detection from binary classification to semantic segmentation, enabling simultaneous localization of edits and identification of the editing models. We benchmark three baseline segmentation approaches, revealing significant challenges in semantic segmentation tasks, particularly concerning robustness to image distortions. Experiments also reveal that segmentation models, despite being trained for pixel-level localization, emerge as highly reliable whole-image classifiers of diffusion edits, outperforming established forgery classifiers while showing great potential in cross-generator generalization. We believe DiffSeg30k will advance research in fine-grained localization of AI-generated content by demonstrating the promise and limitations of segmentation-based methods. DiffSeg30k is released at: https://huggingface.co/datasets/Chaos2629/Diffseg30k",
    "published": "2025-11-24T13:43:54Z",
    "updated": "2025-11-24T13:43:54Z",
    "link": "http://arxiv.org/pdf/2511.19111v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hai Ci",
      "Ziheng Peng",
      "Pei Yang",
      "Yingxin Xuan",
      "Mike Zheng Shou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19109v1",
    "title": "HABIT: Human Action Benchmark for Interactive Traffic in CARLA",
    "summary": "Current autonomous driving (AD) simulations are critically limited by their inadequate representation of realistic and diverse human behavior, which is essential for ensuring safety and reliability. Existing benchmarks often simplify pedestrian interactions, failing to capture complex, dynamic intentions and varied responses critical for robust system deployment. To overcome this, we introduce HABIT (Human Action Benchmark for Interactive Traffic), a high-fidelity simulation benchmark. HABIT integrates real-world human motion, sourced from mocap and videos, into CARLA (Car Learning to Act, a full autonomous driving simulator) via a modular, extensible, and physically consistent motion retargeting pipeline. From an initial pool of approximately 30,000 retargeted motions, we curate 4,730 traffic-compatible pedestrian motions, standardized in SMPL format for physically consistent trajectories. HABIT seamlessly integrates with CARLA's Leaderboard, enabling automated scenario generation and rigorous agent evaluation. Our safety metrics, including Abbreviated Injury Scale (AIS) and False Positive Braking Rate (FPBR), reveal critical failure modes in state-of-the-art AD agents missed by prior evaluations. Evaluating three state-of-the-art autonomous driving agents, InterFuser, TransFuser, and BEVDriver, demonstrates how HABIT exposes planner weaknesses that remain hidden in scripted simulations. Despite achieving close or equal to zero collisions per kilometer on the CARLA Leaderboard, the autonomous agents perform notably worse on HABIT, with up to 7.43 collisions/km and a 12.94% AIS 3+ injury risk, and they brake unnecessarily in up to 33% of cases. All components are publicly released to support reproducible, pedestrian-aware AI research.",
    "published": "2025-11-24T13:43:39Z",
    "updated": "2025-11-24T13:43:39Z",
    "link": "http://arxiv.org/pdf/2511.19109v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mohan Ramesh",
      "Mark Azer",
      "Fabian B. Flohr"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19105v1",
    "title": "Graph-based 3D Human Pose Estimation using WiFi Signals",
    "summary": "WiFi-based human pose estimation (HPE) has attracted increasing attention due to its resilience to occlusion and privacy-preserving compared to camera-based methods. However, existing WiFi-based HPE approaches often employ regression networks that directly map WiFi channel state information (CSI) to 3D joint coordinates, ignoring the inherent topological relationships among human joints. In this paper, we present GraphPose-Fi, a graph-based framework that explicitly models skeletal topology for WiFi-based 3D HPE. Our framework comprises a CNN encoder shared across antennas for subcarrier-time feature extraction, a lightweight attention module that adaptively reweights features over time and across antennas, and a graph-based regression head that combines GCN layers with self-attention to capture local topology and global dependencies. Our proposed method significantly outperforms existing methods on the MM-Fi dataset in various settings. The source code is available at: https://github.com/Cirrick/GraphPose-Fi.",
    "published": "2025-11-24T13:40:26Z",
    "updated": "2025-11-24T13:40:26Z",
    "link": "http://arxiv.org/pdf/2511.19105v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jichao Chen",
      "YangYang Qu",
      "Ruibo Tang",
      "Dirk Slock"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.03121v2",
    "title": "Splats in Splats: Robust and Effective 3D Steganography towards Gaussian Splatting",
    "summary": "3D Gaussian splatting (3DGS) has demonstrated impressive 3D reconstruction performance with explicit scene representations. Given the widespread application of 3DGS in 3D reconstruction and generation tasks, there is an urgent need to protect the copyright of 3DGS assets. However, existing copyright protection techniques for 3DGS overlook the usability of 3D assets, posing challenges for practical deployment. Here we describe splats in splats, the first 3DGS steganography framework that embeds 3D content in 3DGS itself without modifying any attributes. To achieve this, we take a deep insight into spherical harmonics (SH) and devise an importance-graded SH coefficient encryption strategy to embed the hidden SH coefficients. Furthermore, we employ a convolutional autoencoder to establish a mapping between the original Gaussian primitives' opacity and the hidden Gaussian primitives' opacity. Extensive experiments indicate that our method significantly outperforms existing 3D steganography techniques, with 5.31% higher scene fidelity and 3x faster rendering speed, while ensuring security, robustness, and user experience.",
    "published": "2024-12-04T08:40:11Z",
    "updated": "2025-11-24T13:39:34Z",
    "link": "http://arxiv.org/pdf/2412.03121v2.pdf",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Yijia Guo",
      "Wenkai Huang",
      "Yang Li",
      "Gaolei Li",
      "Hang Zhang",
      "Liwen Hu",
      "Jianhua Li",
      "Tiejun Huang",
      "Lei Ma"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.12547v2",
    "title": "HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with Diffusion Models",
    "summary": "Generative diffusion models show promise for data augmentation. However, applying them to fine-grained tasks presents a significant challenge: ensuring synthetic images accurately capture the subtle, category-defining features critical for high fidelity. Standard approaches, such as text-based Classifier-Free Guidance (CFG), often lack the required specificity, potentially generating misleading examples that degrade fine-grained classifier performance. To address this, we propose Hierarchically Guided Fine-grained Augmentation (HiGFA). HiGFA leverages the temporal dynamics of the diffusion sampling process. It employs strong text and transformed contour guidance with fixed strengths in the early-to-mid sampling stages to establish overall scene, style, and structure. In the final sampling stages, HiGFA activates a specialized fine-grained classifier guidance and dynamically modulates the strength of all guidance signals based on prediction confidence. This hierarchical, confidence-driven orchestration enables HiGFA to generate diverse yet faithful synthetic images by intelligently balancing global structure formation with precise detail refinement. Experiments on several FGVC datasets demonstrate the effectiveness of HiGFA.",
    "published": "2025-11-16T10:46:16Z",
    "updated": "2025-11-24T13:31:40Z",
    "link": "http://arxiv.org/pdf/2511.12547v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhiguang Lu",
      "Qianqian Xu",
      "Peisong Wen",
      "Siran Dai",
      "Qingming Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19080v1",
    "title": "Towards Generalizable Deepfake Detection via Forgery-aware Audio-Visual Adaptation: A Variational Bayesian Approach",
    "summary": "The widespread application of AIGC contents has brought not only unprecedented opportunities, but also potential security concerns, e.g., audio-visual deepfakes. Therefore, it is of great importance to develop an effective and generalizable method for multi-modal deepfake detection. Typically, the audio-visual correlation learning could expose subtle cross-modal inconsistencies, e.g., audio-visual misalignment, which serve as crucial clues in deepfake detection. In this paper, we reformulate the correlation learning with variational Bayesian estimation, where audio-visual correlation is approximated as a Gaussian distributed latent variable, and thus develop a novel framework for deepfake detection, i.e., Forgery-aware Audio-Visual Adaptation with Variational Bayes (FoVB). Specifically, given the prior knowledge of pre-trained backbones, we adopt two core designs to estimate audio-visual correlations effectively. First, we exploit various difference convolutions and a high-pass filter to discern local and global forgery traces from both modalities. Second, with the extracted forgery-aware features, we estimate the latent Gaussian variable of audio-visual correlation via variational Bayes. Then, we factorize the variable into modality-specific and correlation-specific ones with orthogonality constraint, allowing them to better learn intra-modal and cross-modal forgery traces with less entanglement. Extensive experiments demonstrate that our FoVB outperforms other state-of-the-art methods in various benchmarks.",
    "published": "2025-11-24T13:20:03Z",
    "updated": "2025-11-24T13:20:03Z",
    "link": "http://arxiv.org/pdf/2511.19080v1.pdf",
    "category": [
      "cs.MM",
      "cs.CV"
    ],
    "authors": [
      "Fan Nie",
      "Jiangqun Ni",
      "Jian Zhang",
      "Bin Zhang",
      "Weizhe Zhang",
      "Bin Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19071v1",
    "title": "DEAP-3DSAM: Decoder Enhanced and Auto Prompt SAM for 3D Medical Image Segmentation",
    "summary": "The Segment Anything Model (SAM) has recently demonstrated significant potential in medical image segmentation. Although SAM is primarily trained on 2D images, attempts have been made to apply it to 3D medical image segmentation. However, the pseudo 3D processing used to adapt SAM results in spatial feature loss, limiting its performance. Additionally, most SAM-based methods still rely on manual prompts, which are challenging to implement in real-world scenarios and require extensive external expert knowledge. To address these limitations, we introduce the Decoder Enhanced and Auto Prompt SAM (DEAP-3DSAM) to tackle these limitations. Specifically, we propose a Feature Enhanced Decoder that fuses the original image features with rich and detailed spatial information to enhance spatial features. We also design a Dual Attention Prompter to automatically obtain prompt information through Spatial Attention and Channel Attention. We conduct comprehensive experiments on four public abdominal tumor segmentation datasets. The results indicate that our DEAP-3DSAM achieves state-of-the-art performance in 3D image segmentation, outperforming or matching existing manual prompt methods. Furthermore, both quantitative and qualitative ablation studies confirm the effectiveness of our proposed modules.",
    "published": "2025-11-24T13:07:22Z",
    "updated": "2025-11-24T13:07:22Z",
    "link": "http://arxiv.org/pdf/2511.19071v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Fangda Chen",
      "Jintao Tang",
      "Pancheng Wang",
      "Ting Wang",
      "Shasha Li",
      "Ting Deng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21171v3",
    "title": "TokenCLIP: Token-wise Prompt Learning for Zero-shot Anomaly Detection",
    "summary": "Adapting CLIP for anomaly detection on unseen objects has shown strong potential in a zero-shot manner. However, existing methods typically rely on a single textual space to align with visual semantics across diverse objects and domains. The indiscriminate alignment hinders the model from accurately capturing varied anomaly semantics. We propose TokenCLIP, a token-wise adaptation framework that enables dynamic alignment between visual and learnable textual spaces for fine-grained anomaly learning. Rather than mapping all visual tokens to a single, token-agnostic textual space, TokenCLIP aligns each token with a customized textual subspace that represents its visual characteristics. Explicitly assigning a unique learnable textual space to each token is computationally intractable and prone to insufficient optimization. We instead expand the token-agnostic textual space into a set of orthogonal subspaces, and then dynamically assign each token to a subspace combination guided by semantic affinity, which jointly supports customized and efficient token-wise adaptation. To this end, we formulate dynamic alignment as an optimal transport problem, where all visual tokens in an image are transported to textual subspaces based on semantic similarity. The transport constraints of OT ensure sufficient optimization across subspaces and encourage them to focus on different semantics. Solving the problem yields a transport plan that adaptively assigns each token to semantically relevant subspaces. A top-k masking is then applied to sparsify the plan and specialize subspaces for distinct visual regions. Extensive experiments demonstrate the superiority of TokenCLIP.",
    "published": "2025-10-24T05:51:31Z",
    "updated": "2025-11-24T13:00:02Z",
    "link": "http://arxiv.org/pdf/2510.21171v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qihang Zhou",
      "Binbin Gao",
      "Guansong Pang",
      "Xin Wang",
      "Jiming Chen",
      "Shibo He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19062v1",
    "title": "Granular Computing-driven SAM: From Coarse-to-Fine Guidance for Prompt-Free Segmentation",
    "summary": "Prompt-free image segmentation aims to generate accurate masks without manual guidance. Typical pre-trained models, notably Segmentation Anything Model (SAM), generate prompts directly at a single granularity level. However, this approach has two limitations: (1) Localizability, lacking mechanisms for autonomous region localization; (2) Scalability, limited fine-grained modeling at high resolution. To address these challenges, we introduce Granular Computing-driven SAM (Grc-SAM), a coarse-to-fine framework motivated by Granular Computing (GrC). First, the coarse stage adaptively extracts high-response regions from features to achieve precise foreground localization and reduce reliance on external prompts. Second, the fine stage applies finer patch partitioning with sparse local swin-style attention to enhance detail modeling and enable high-resolution segmentation. Third, refined masks are encoded as latent prompt embeddings for the SAM decoder, replacing handcrafted prompts with an automated reasoning process. By integrating multi-granularity attention, Grc-SAM bridges granular computing with vision transformers. Extensive experimental results demonstrate Grc-SAM outperforms baseline methods in both accuracy and scalability. It offers a unique granular computational perspective for prompt-free segmentation.",
    "published": "2025-11-24T12:55:02Z",
    "updated": "2025-11-24T12:55:02Z",
    "link": "http://arxiv.org/pdf/2511.19062v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qiyang Yu",
      "Yu Fang",
      "Tianrui Li",
      "Xuemei Cao",
      "Yan Chen",
      "Jianghao Li",
      "Fan Min",
      "Yi Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19057v1",
    "title": "LAA3D: A Benchmark of Detecting and Tracking Low-Altitude Aircraft in 3D Space",
    "summary": "Perception of Low-Altitude Aircraft (LAA) in 3D space enables precise 3D object localization and behavior understanding. However, datasets tailored for 3D LAA perception remain scarce. To address this gap, we present LAA3D, a large-scale dataset designed to advance 3D detection and tracking of low-altitude aerial vehicles. LAA3D contains 15,000 real images and 600,000 synthetic frames, captured across diverse scenarios, including urban and suburban environments. It covers multiple aerial object categories, including electric Vertical Take-Off and Landing (eVTOL) aircraft, Micro Aerial Vehicles (MAVs), and Helicopters. Each instance is annotated with 3D bounding box, class label, and instance identity, supporting tasks such as 3D object detection, 3D multi-object tracking (MOT), and 6-DoF pose estimation. Besides, we establish the LAA3D Benchmark, integrating multiple tasks and methods with unified evaluation protocols for comparison. Furthermore, we propose MonoLAA, a monocular 3D detection baseline, achieving robust 3D localization from zoom cameras with varying focal lengths. Models pretrained on synthetic images transfer effectively to real-world data with fine-tuning, demonstrating strong sim-to-real generalization. Our LAA3D provides a comprehensive foundation for future research in low-altitude 3D object perception.",
    "published": "2025-11-24T12:50:34Z",
    "updated": "2025-11-24T12:50:34Z",
    "link": "http://arxiv.org/pdf/2511.19057v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hai Wu",
      "Shuai Tang",
      "Jiale Wang",
      "Longkun Zou",
      "Mingyue Guo",
      "Rongqin Liang",
      "Ke Chen",
      "Yaowei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19049v1",
    "title": "Beyond Reward Margin: Rethinking and Resolving Likelihood Displacement in Diffusion Models via Video Generation",
    "summary": "Direct Preference Optimization (DPO) has shown promising results in aligning generative outputs with human preferences by distinguishing between chosen and rejected samples. However, a critical limitation of DPO is likelihood displacement, where the probabilities of chosen samples paradoxically decrease during training, undermining the quality of generation. Although this issue has been investigated in autoregressive models, its impact within diffusion-based models remains largely unexplored. This gap leads to suboptimal performance in tasks involving video generation. To address this, we conduct a formal analysis of DPO loss through updating policy within the diffusion framework, which describes how the updating of specific training samples influences the model's predictions on other samples. Using this tool, we identify two main failure modes: (1) Optimization Conflict, which arises from small reward margins between chosen and rejected samples, and (2) Suboptimal Maximization, caused by large reward margins. Informed by these insights, we introduce a novel solution named Policy-Guided DPO (PG-DPO), combining Adaptive Rejection Scaling (ARS) and Implicit Preference Regularization (IPR) to effectively mitigate likelihood displacement. Experiments show that PG-DPO outperforms existing methods in both quantitative metrics and qualitative evaluations, offering a robust solution for improving preference alignment in video generation tasks.",
    "published": "2025-11-24T12:37:49Z",
    "updated": "2025-11-24T12:37:49Z",
    "link": "http://arxiv.org/pdf/2511.19049v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ruojun Xu",
      "Yu Kai",
      "Xuhua Ren",
      "Jiaxiang Cheng",
      "Bing Ma",
      "Tianxiang Zheng",
      "Qinhlin Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19033v1",
    "title": "ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay",
    "summary": "Embodied exploration is a target-driven process that requires embodied agents to possess fine-grained perception and knowledge-enhanced decision making. While recent attempts leverage MLLMs for exploration due to their strong perceptual and reasoning abilities, we find that MLLM-based embodied agents remain suboptimal in exploring new environments: (i) they rely on profound but stale pre-trained knowledge, (ii) training-based approaches such as imitation learning or reinforcement learning are expensive for long-horizon tasks with sparse outcome rewards, and (iii) frontier-based exploration yields a large, visually nuanced action space that is difficult for MLLMs to make reliable decisions. We address these challenges with ReEXplore, a training-free framework that performs retrospective experience replay to inject distilled, abstract experience at inference time, and hierarchical frontier selection to decompose frontier ranking into coarse-to-fine decisions. Our approach enables robust, traceable, and efficient exploration. Across multiple embodied exploration benchmarks, ReEXplore yields great improvements over strong MLLM baselines, up to 3x higher performance in both success rate and in navigation efficiency under open-source backbones.",
    "published": "2025-11-24T12:13:05Z",
    "updated": "2025-11-24T12:13:05Z",
    "link": "http://arxiv.org/pdf/2511.19033v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Gengyuan Zhang",
      "Mingcong Ding",
      "Jingpei Wu",
      "Ruotong Liao",
      "Volker Tresp"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19032v1",
    "title": "Benchmarking Corruption Robustness of LVLMs: A Discriminative Benchmark and Robustness Alignment Metric",
    "summary": "Despite the remarkable reasoning abilities of large vision-language models (LVLMs), their robustness under visual corruptions remains insufficiently studied. Existing evaluation paradigms exhibit two major limitations: 1) the dominance of low-discriminative samples in current datasets masks the real robustness gap between models; and 2) conventional accuracy-based metric fail to capture the degradation of the underlying prediction structure. To bridge these gaps, we introduce Bench-C, a comprehensive benchmark emphasizing discriminative samples for assessing corruption robustness, where a selection strategy is proposed to jointly consider the prediction inconsistency under corruption and the semantic diversity. Furthermore, we propose the Robustness Alignment Score (RAS), a unified metric that measures degradation in logit-level prediction structure by considering the shifts in prediction uncertainty and calibration alignment. Comprehensive experiments and analysis reveal several interesting findings: 1) model behaviors exhibit distinguish patterns under corruptions, such as erroneous confidence and hesitation; 2) despite subtle corruption may lead to a slight accuracy gain, the overall prediction structure still degrades; 3) by decomposing corruption robustness into destructive and corrective components, the distinct failure and recovery patterns across models can be revealed.",
    "published": "2025-11-24T12:07:56Z",
    "updated": "2025-11-24T12:07:56Z",
    "link": "http://arxiv.org/pdf/2511.19032v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiangjie Sui",
      "Songyang Li",
      "Hanwei Zhu",
      "Baoliang Chen",
      "Yuming Fang",
      "Xin Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19021v1",
    "title": "Dynamic Granularity Matters: Rethinking Vision Transformers Beyond Fixed Patch Splitting",
    "summary": "Vision Transformers (ViTs) have demonstrated strong capabilities in capturing global dependencies but often struggle to efficiently represent fine-grained local details. Existing multi-scale approaches alleviate this issue by integrating hierarchical or hybrid features; however, they rely on fixed patch sizes and introduce redundant computation. To address these limitations, we propose Granularity-driven Vision Transformer (Grc-ViT), a dynamic coarse-to-fine framework that adaptively adjusts visual granularity based on image complexity. It comprises two key stages: (1) Coarse Granularity Evaluation module, which assesses visual complexity using edge density, entropy, and frequency-domain cues to estimate suitable patch and window sizes; (2) Fine-grained Refinement module, which refines attention computation according to the selected granularity, enabling efficient and precise feature learning. Two learnable parameters, α and \\b{eta}, are optimized end-to-end to balance global reasoning and local perception. Comprehensive evaluations demonstrate that Grc-ViT enhances fine-grained discrimination while achieving a superior trade-off between accuracy and computational efficiency.",
    "published": "2025-11-24T11:55:22Z",
    "updated": "2025-11-24T11:55:22Z",
    "link": "http://arxiv.org/pdf/2511.19021v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qiyang Yu",
      "Yu Fang",
      "Tianrui Li",
      "Xuemei Cao",
      "Yan Chen",
      "Jianghao Li",
      "Fan Min"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.16301v2",
    "title": "Upsample Anything: A Simple and Hard to Beat Baseline for Feature Upsampling",
    "summary": "We present \\textbf{Upsample Anything}, a lightweight test-time optimization (TTO) framework that restores low-resolution features to high-resolution, pixel-wise outputs without any training. Although Vision Foundation Models demonstrate strong generalization across diverse downstream tasks, their representations are typically downsampled by 14x/16x (e.g., ViT), which limits their direct use in pixel-level applications. Existing feature upsampling approaches depend on dataset-specific retraining or heavy implicit optimization, restricting scalability and generalization. Upsample Anything addresses these issues through a simple per-image optimization that learns an anisotropic Gaussian kernel combining spatial and range cues, effectively bridging Gaussian Splatting and Joint Bilateral Upsampling. The learned kernel acts as a universal, edge-aware operator that transfers seamlessly across architectures and modalities, enabling precise high-resolution reconstruction of features, depth, or probability maps. It runs in only $\\approx0.419 \\text{s}$ per 224x224 image and achieves state-of-the-art performance on semantic segmentation, depth estimation, and both depth and probability map upsampling. \\textbf{Project page:} \\href{https://seominseok0429.github.io/Upsample-Anything/}{https://seominseok0429.github.io/Upsample-Anything/}",
    "published": "2025-11-20T12:27:53Z",
    "updated": "2025-11-24T11:32:47Z",
    "link": "http://arxiv.org/pdf/2511.16301v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Minseok Seo",
      "Mark Hamilton",
      "Changick Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19004v1",
    "title": "A Self-Conditioned Representation Guided Diffusion Model for Realistic Text-to-LiDAR Scene Generation",
    "summary": "Text-to-LiDAR generation can customize 3D data with rich structures and diverse scenes for downstream tasks. However, the scarcity of Text-LiDAR pairs often causes insufficient training priors, generating overly smooth 3D scenes. Moreover, low-quality text descriptions may degrade generation quality and controllability. In this paper, we propose a Text-to-LiDAR Diffusion Model for scene generation, named T2LDM, with a Self-Conditioned Representation Guidance (SCRG). Specifically, SCRG, by aligning to the real representations, provides the soft supervision with reconstruction details for the Denoising Network (DN) in training, while decoupled in inference. In this way, T2LDM can perceive rich geometric structures from data distribution, generating detailed objects in scenes. Meanwhile, we construct a content-composable Text-LiDAR benchmark, T2nuScenes, along with a controllability metric. Based on this, we analyze the effects of different text prompts for LiDAR generation quality and controllability, providing practical prompt paradigms and insights. Furthermore, a directional position prior is designed to mitigate street distortion, further improving scene fidelity. Additionally, by learning a conditional encoder via frozen DN, T2LDM can support multiple conditional tasks, including Sparse-to-Dense, Dense-to-Sparse, and Semantic-to-LiDAR generation. Extensive experiments in unconditional and conditional generation demonstrate that T2LDM outperforms existing methods, achieving state-of-the-art scene generation.",
    "published": "2025-11-24T11:32:15Z",
    "updated": "2025-11-24T11:32:15Z",
    "link": "http://arxiv.org/pdf/2511.19004v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wentao Qu",
      "Guofeng Mei",
      "Yang Wu",
      "Yongshun Gong",
      "Xiaoshui Huang",
      "Liang Xiao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18993v1",
    "title": "AuViRe: Audio-visual Speech Representation Reconstruction for Deepfake Temporal Localization",
    "summary": "With the rapid advancement of sophisticated synthetic audio-visual content, e.g., for subtle malicious manipulations, ensuring the integrity of digital media has become paramount. This work presents a novel approach to temporal localization of deepfakes by leveraging Audio-Visual Speech Representation Reconstruction (AuViRe). Specifically, our approach reconstructs speech representations from one modality (e.g., lip movements) based on the other (e.g., audio waveform). Cross-modal reconstruction is significantly more challenging in manipulated video segments, leading to amplified discrepancies, thereby providing robust discriminative cues for precise temporal forgery localization. AuViRe outperforms the state of the art by +8.9 AP@0.95 on LAV-DF, +9.6 AP@0.5 on AV-Deepfake1M, and +5.1 AUC on an in-the-wild experiment. Code available at https://github.com/mever-team/auvire.",
    "published": "2025-11-24T11:19:21Z",
    "updated": "2025-11-24T11:19:21Z",
    "link": "http://arxiv.org/pdf/2511.18993v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Christos Koutlis",
      "Symeon Papadopoulos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18991v1",
    "title": "View-Consistent Diffusion Representations for 3D-Consistent Video Generation",
    "summary": "Video generation models have made significant progress in generating realistic content, enabling applications in simulation, gaming, and film making. However, current generated videos still contain visual artifacts arising from 3D inconsistencies, e.g., objects and structures deforming under changes in camera pose, which can undermine user experience and simulation fidelity. Motivated by recent findings on representation alignment for diffusion models, we hypothesize that improving the multi-view consistency of video diffusion representations will yield more 3D-consistent video generation. Through detailed analysis on multiple recent camera-controlled video diffusion models we reveal strong correlations between 3D-consistent representations and videos. We also propose ViCoDR, a new approach for improving the 3D consistency of video models by learning multi-view consistent diffusion representations. We evaluate ViCoDR on camera controlled image-to-video, text-to-video, and multi-view generation models, demonstrating significant improvements in the 3D consistency of the generated videos. Project page: https://danier97.github.io/ViCoDR.",
    "published": "2025-11-24T11:16:55Z",
    "updated": "2025-11-24T11:16:55Z",
    "link": "http://arxiv.org/pdf/2511.18991v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Duolikun Danier",
      "Ge Gao",
      "Steven McDonagh",
      "Changjian Li",
      "Hakan Bilen",
      "Oisin Mac Aodha"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.00416v3",
    "title": "Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding",
    "summary": "Vision-Language-Action (VLA) models have emerged as a promising framework for enabling generalist robots capable of perceiving, reasoning, and acting in the real world. These models usually build upon pretrained Vision-Language Models (VLMs), which excel at semantic understanding due to large-scale image and text pretraining. However, existing VLMs typically lack precise spatial understanding capabilities, as they are primarily tuned on 2D image-text pairs without 3D supervision. To address this limitation, recent approaches have incorporated explicit 3D inputs such as point clouds or depth maps, but this necessitates additional depth sensors or pre-trained depth estimation models, which may yield defective results. In contrast, our work introduces a plug-and-play module that implicitly incorporates 3D geometry features into VLA models by leveraging an off-the-shelf visual geometry foundation model. This integration provides the model with depth-aware visual representations, improving its ability to understand the geometric structure of the scene and the spatial relationships among objects from RGB images alone. We evaluate our method on a set of spatially challenging tasks in both simulation and the real world. Extensive evaluations show that our method significantly improves the performance of state-of-the-art VLA models across diverse scenarios.",
    "published": "2025-07-01T04:05:47Z",
    "updated": "2025-11-24T11:10:14Z",
    "link": "http://arxiv.org/pdf/2507.00416v3.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Tao Lin",
      "Gen Li",
      "Yilei Zhong",
      "Yanwen Zou",
      "Yuxin Du",
      "Jiting Liu",
      "Encheng Gu",
      "Bo Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.03213v2",
    "title": "ConMamba: Contrastive Vision Mamba for Plant Disease Detection",
    "summary": "Plant Disease Detection (PDD) is a key aspect of precision agriculture. However, existing deep learning methods often rely on extensively annotated datasets, which are time-consuming and costly to generate. Self-supervised Learning (SSL) offers a promising alternative by exploiting the abundance of unlabeled data. However, most existing SSL approaches suffer from high computational costs due to convolutional neural networks or transformer-based architectures. Additionally, they struggle to capture long-range dependencies in visual representation and rely on static loss functions that fail to align local and global features effectively. To address these challenges, we propose ConMamba, a novel SSL framework specially designed for PDD. ConMamba integrates the Vision Mamba Encoder (VME), which employs a bidirectional State Space Model (SSM) to capture long-range dependencies efficiently. Furthermore, we introduce a dual-level contrastive loss with dynamic weight adjustment to optimize local-global feature alignment. Experimental results on three benchmark datasets demonstrate that ConMamba significantly outperforms state-of-the-art methods across multiple evaluation metrics. This provides an efficient and robust solution for PDD.",
    "published": "2025-06-03T03:01:38Z",
    "updated": "2025-11-24T11:08:46Z",
    "link": "http://arxiv.org/pdf/2506.03213v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Abdullah Al Mamun",
      "Miaohua Zhang",
      "David Ahmedt-Aristizabal",
      "Zeeshan Hayder",
      "Mohammad Awrangjeb"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18983v1",
    "title": "UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection",
    "summary": "In deepfake detection, the varying degrees of compression employed by social media platforms pose significant challenges for model generalization and reliability. Although existing methods have progressed from single-modal to multimodal approaches, they face critical limitations: single-modal methods struggle with feature degradation under data compression in social media streaming, while multimodal approaches require expensive data collection and labeling and suffer from inconsistent modal quality or accessibility in real-world scenarios. To address these challenges, we propose a novel Unimodal-generated Multimodal Contrastive Learning (UMCL) framework for robust cross-compression-rate (CCR) deepfake detection. In the training stage, our approach transforms a single visual modality into three complementary features: compression-robust rPPG signals, temporal landmark dynamics, and semantic embeddings from pre-trained vision-language models. These features are explicitly aligned through an affinity-driven semantic alignment (ASA) strategy, which models inter-modal relationships through affinity matrices and optimizes their consistency through contrastive learning. Subsequently, our cross-quality similarity learning (CQSL) strategy enhances feature robustness across compression rates. Extensive experiments demonstrate that our method achieves superior performance across various compression rates and manipulation types, establishing a new benchmark for robust deepfake detection. Notably, our approach maintains high detection accuracy even when individual features degrade, while providing interpretable insights into feature relationships through explicit alignment.",
    "published": "2025-11-24T10:56:22Z",
    "updated": "2025-11-24T10:56:22Z",
    "link": "http://arxiv.org/pdf/2511.18983v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ching-Yi Lai",
      "Chih-Yu Jian",
      "Pei-Cheng Chuang",
      "Chia-Ming Lee",
      "Chih-Chung Hsu",
      "Chiou-Ting Hsu",
      "Chia-Wen Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2411.03511v3",
    "title": "Beyond Complete Shapes: A Benchmark for Quantitative Evaluation of 3D Shape Surface Matching Algorithms",
    "summary": "Finding correspondences between 3D deformable shapes is an important and long-standing problem in geometry processing, computer vision, graphics, and beyond. While various shape matching datasets exist, they are mostly static or limited in size, restricting their adaptation to different problem settings, including both full and partial shape matching. In particular the existing partial shape matching datasets are small (fewer than 100 shapes) and thus unsuitable for data-hungry machine learning approaches. Moreover, the type of partiality present in existing datasets is often artificial and far from realistic. To address these limitations, we introduce a generic and flexible framework for the procedural generation of challenging full and partial shape matching datasets. Our framework allows the propagation of custom annotations across shapes, making it useful for various applications. By utilising our framework and manually creating cross-dataset correspondences between seven existing (complete geometry) shape matching datasets, we propose a new large benchmark BeCoS with a total of 2543 shapes. Based on this, we offer several challenging benchmark settings, covering both full and partial matching, for which we evaluate respective state-of-the-art methods as baselines.",
    "published": "2024-11-05T21:08:19Z",
    "updated": "2025-11-24T10:52:17Z",
    "link": "http://arxiv.org/pdf/2411.03511v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Viktoria Ehm",
      "Nafie El Amrani",
      "Yizheng Xie",
      "Lennart Bastian",
      "Maolin Gao",
      "Weikang Wang",
      "Lu Sang",
      "Dongliang Cao",
      "Tobias Weißberg",
      "Zorah Lähner",
      "Daniel Cremers",
      "Florian Bernard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18978v1",
    "title": "Zero-shot segmentation of skin tumors in whole-slide images with vision-language foundation models",
    "summary": "Accurate annotation of cutaneous neoplasm biopsies represents a major challenge due to their wide morphological variability, overlapping histological patterns, and the subtle distinctions between benign and malignant lesions. Vision-language foundation models (VLMs), pre-trained on paired image-text corpora, learn joint representations that bridge visual features and diagnostic terminology, enabling zero-shot localization and classification of tissue regions without pixel-level labels. However, most existing VLM applications in histopathology remain limited to slide-level tasks or rely on coarse interactive prompts, and they struggle to produce fine-grained segmentations across gigapixel whole-slide images (WSIs). In this work, we introduce a zero-shot visual-language segmentation pipeline for whole-slide images (ZEUS), a fully automated, zero-shot segmentation framework that leverages class-specific textual prompt ensembles and frozen VLM encoders to generate high-resolution tumor masks in WSIs. By partitioning each WSI into overlapping patches, extracting visual embeddings, and computing cosine similarities against text prompts, we generate a final segmentation mask. We demonstrate competitive performance on two in-house datasets, primary spindle cell neoplasms and cutaneous metastases, highlighting the influence of prompt design, domain shifts, and institutional variability in VLMs for histopathology. ZEUS markedly reduces annotation burden while offering scalable, explainable tumor delineation for downstream diagnostic workflows.",
    "published": "2025-11-24T10:50:30Z",
    "updated": "2025-11-24T10:50:30Z",
    "link": "http://arxiv.org/pdf/2511.18978v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Santiago Moreno",
      "Pablo Meseguer",
      "Rocío del Amor",
      "Valery Naranjo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18976v1",
    "title": "Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs",
    "summary": "We address two fundamental challenges in adapting general deep CNNs for FHE-based inference: approximating non-linear activations such as ReLU with low-degree polynomials while minimizing accuracy degradation, and overcoming the ciphertext capacity barrier that constrains high-resolution image processing on FHE inference. Our contributions are twofold: (1) a single-stage fine-tuning (SFT) strategy that directly converts pre-trained CNNs into FHE-friendly forms using low-degree polynomials, achieving competitive accuracy with minimal training overhead; and (2) a generalized interleaved packing (GIP) scheme that is compatible with feature maps of virtually arbitrary spatial resolutions, accompanied by a suite of carefully designed homomorphic operators that preserve the GIP-form encryption throughout computation. These advances enable efficient, end-to-end FHE inference across diverse CNN architectures. Experiments on CIFAR-10, ImageNet, and MS COCO demonstrate that the FHE-friendly CNNs obtained via our SFT strategy achieve accuracy comparable to baselines using ReLU or SiLU activations. Moreover, this work presents the first demonstration of FHE-based inference for YOLO architectures in object detection leveraging low-degree polynomial activations.",
    "published": "2025-11-24T10:47:39Z",
    "updated": "2025-11-24T10:47:39Z",
    "link": "http://arxiv.org/pdf/2511.18976v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Huaming Ling",
      "Ying Wang",
      "Si Chen",
      "Junfeng Fan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.01347v3",
    "title": "From Spots to Pixels: Dense Spatial Gene Expression Prediction from Histology Images",
    "summary": "Spatial transcriptomics (ST) measures gene expression at fine-grained spatial resolution, offering insights into tissue molecular landscapes. Previous methods for spatial gene expression prediction typically crop spots of interest from histopathology slide images, and train models to map each spot to a corresponding gene expression profile. However, these methods inherently lose the spatial resolution in gene expression: 1) each spot often contains multiple cells with distinct gene expression profiles; 2) spots are typically defined at fixed spatial resolutions, limiting the ability to predict gene expression at varying scales. To address these limitations, this paper presents PixNet, a dense prediction network capable of predicting spatially resolved gene expression across spots of varying sizes and scales directly from histopathology slide images. Different from previous methods that map individual spots to gene expression values, we generate a spatially dense continuous gene expression map from the histopathology slide image, and aggregate values within spots of interest to predict the gene expression. Our PixNet outperforms state-of-the-art methods on four common ST datasets in multiple spatial scales. The source code will be publicly available.",
    "published": "2025-03-03T09:38:01Z",
    "updated": "2025-11-24T10:34:13Z",
    "link": "http://arxiv.org/pdf/2503.01347v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ruikun Zhang",
      "Yan Yang",
      "Liyuan Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18968v1",
    "title": "CataractCompDetect: Intraoperative Complication Detection in Cataract Surgery",
    "summary": "Cataract surgery is one of the most commonly performed surgeries worldwide, yet intraoperative complications such as iris prolapse, posterior capsule rupture (PCR), and vitreous loss remain major causes of adverse outcomes. Automated detection of such events could enable early warning systems and objective training feedback. In this work, we propose CataractCompDetect, a complication detection framework that combines phase-aware localization, SAM 2-based tracking, complication-specific risk scoring, and vision-language reasoning for final classification. To validate CataractCompDetect, we curate CataComp, the first cataract surgery video dataset annotated for intraoperative complications, comprising 53 surgeries, including 23 with clinical complications. On CataComp, CataractCompDetect achieves an average F1 score of 70.63%, with per-complication performance of 81.8% (Iris Prolapse), 60.87% (PCR), and 69.23% (Vitreous Loss). These results highlight the value of combining structured surgical priors with vision-language reasoning for recognizing rare but high-impact intraoperative events. Our dataset and code will be publicly released upon acceptance.",
    "published": "2025-11-24T10:34:12Z",
    "updated": "2025-11-24T10:34:12Z",
    "link": "http://arxiv.org/pdf/2511.18968v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bhuvan Sachdeva",
      "Sneha Kumari",
      "Rudransh Agarwal",
      "Shalaka Kumaraswamy",
      "Niharika Singri Prasad",
      "Simon Mueller",
      "Raphael Lechtenboehmer",
      "Maximilian W. M. Wintergerst",
      "Thomas Schultz",
      "Kaushik Murali",
      "Mohit Jain"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.00450v2",
    "title": "Unsupervised and Source-Free Ranking of Biomedical Segmentation Models",
    "summary": "Model transfer presents a solution to the challenges of segmentation in the biomedical community, where the immense cost of data annotation is a major bottleneck in the use of deep learning. At the same time, hundreds of models get trained on biomedical data, submitted to challenges, and posted in model zoos and repositories. A major hurdle to wider adoption of pre-trained models lies in the lack of methods for best model selection. While such methods have been proposed for classification models, semantic and instance segmentation model ranking remain largely unaddressed, especially in a practically important setting where no labels are available on the target dataset. Similarly, if unsupervised domain adaptation is used, practitioners are faced with the task of selecting the best adapted model without target domain labels. Building on previous work linking model generalisation and consistency under perturbation, we propose the first unsupervised and source-free transferability estimator for semantic and instance segmentation tasks. We evaluate on multiple segmentation problems across biomedical imaging, finding a strong correlation between the rankings based on our estimator and rankings based on target dataset performance.",
    "published": "2025-03-01T11:11:06Z",
    "updated": "2025-11-24T10:28:28Z",
    "link": "http://arxiv.org/pdf/2503.00450v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Joshua Talks",
      "Kevin Marchesini",
      "Luca Lumetti",
      "Federico Bolelli",
      "Anna Kreshuk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18960v1",
    "title": "AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention",
    "summary": "Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.",
    "published": "2025-11-24T10:22:28Z",
    "updated": "2025-11-24T10:22:28Z",
    "link": "http://arxiv.org/pdf/2511.18960v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Lei Xiao",
      "Jifeng Li",
      "Juntao Gao",
      "Feiyang Ye",
      "Yan Jin",
      "Jingjing Qian",
      "Jing Zhang",
      "Yong Wu",
      "Xiaoyuan Yu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18957v1",
    "title": "Eevee: Towards Close-up High-resolution Video-based Virtual Try-on",
    "summary": "Video virtual try-on technology provides a cost-effective solution for creating marketing videos in fashion e-commerce. However, its practical adoption is hindered by two critical limitations. First, the reliance on a single garment image as input in current virtual try-on datasets limits the accurate capture of realistic texture details. Second, most existing methods focus solely on generating full-shot virtual try-on videos, neglecting the business's demand for videos that also provide detailed close-ups. To address these challenges, we introduce a high-resolution dataset for video-based virtual try-on. This dataset offers two key features. First, it provides more detailed information on the garments, which includes high-fidelity images with detailed close-ups and textual descriptions; Second, it uniquely includes full-shot and close-up try-on videos of real human models. Furthermore, accurately assessing consistency becomes significantly more critical for the close-up videos, which demand high-fidelity preservation of garment details. To facilitate such fine-grained evaluation, we propose a new garment consistency metric VGID (Video Garment Inception Distance) that quantifies the preservation of both texture and structure. Our experiments validate these contributions. We demonstrate that by utilizing the detailed images from our dataset, existing video generation models can extract and incorporate texture features, significantly enhancing the realism and detail fidelity of virtual try-on results. Furthermore, we conduct a comprehensive benchmark of recent models. The benchmark effectively identifies the texture and structural preservation problems among current methods.",
    "published": "2025-11-24T10:19:56Z",
    "updated": "2025-11-24T10:19:56Z",
    "link": "http://arxiv.org/pdf/2511.18957v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jianhao Zeng",
      "Yancheng Bai",
      "Ruidong Chen",
      "Xuanpu Zhang",
      "Lei Sun",
      "Dongyang Jin",
      "Ryan Xu",
      "Nannan Zhang",
      "Dan Song",
      "Xiangxiang Chu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18950v1",
    "title": "Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation",
    "summary": "Vision-Language-Action (VLA) models have emerged as a powerful paradigm in Embodied AI. However, the significant computational overhead of processing redundant visual tokens remains a critical bottleneck for real-time robotic deployment. While standard token pruning techniques can alleviate this, these task-agnostic methods struggle to preserve task-critical visual information. To address this challenge, simultaneously preserving both the holistic context and fine-grained details for precise action, we propose Compressor-VLA, a novel hybrid instruction-conditioned token compression framework designed for efficient, task-oriented compression of visual information in VLA models. The proposed Compressor-VLA framework consists of two token compression modules: a Semantic Task Compressor (STC) that distills holistic, task-relevant context, and a Spatial Refinement Compressor (SRC) that preserves fine-grained spatial details. This compression is dynamically modulated by the natural language instruction, allowing for the adaptive condensation of task-relevant visual information. Experimentally, extensive evaluations demonstrate that Compressor-VLA achieves a competitive success rate on the LIBERO benchmark while reducing FLOPs by 59% and the visual token count by over 3x compared to its baseline. The real-robot deployments on a dual-arm robot platform validate the model's sim-to-real transferability and practical applicability. Moreover, qualitative analyses reveal that our instruction guidance dynamically steers the model's perceptual focus toward task-relevant objects, thereby validating the effectiveness of our approach.",
    "published": "2025-11-24T10:06:41Z",
    "updated": "2025-11-24T10:06:41Z",
    "link": "http://arxiv.org/pdf/2511.18950v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Juntao Gao",
      "Feiyang Ye",
      "Jing Zhang",
      "Wenjing Qian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18946v1",
    "title": "Leveraging Adversarial Learning for Pathological Fidelity in Virtual Staining",
    "summary": "In addition to evaluating tumor morphology using H&E staining, immunohistochemistry is used to assess the presence of specific proteins within the tissue. However, this is a costly and labor-intensive technique, for which virtual staining, as an image-to-image translation task, offers a promising alternative. Although recent, this is an emerging field of research with 64% of published studies just in 2024. Most studies use publicly available datasets of H&E-IHC pairs from consecutive tissue sections. Recognizing the training challenges, many authors develop complex virtual staining models based on conditional Generative Adversarial Networks, but ignore the impact of adversarial loss on the quality of virtual staining. Furthermore, overlooking the issues of model evaluation, they claim improved performance based on metrics such as SSIM and PSNR, which are not sufficiently robust to evaluate the quality of virtually stained images. In this paper, we developed CSSP2P GAN, which we demonstrate to achieve heightened pathological fidelity through a blind pathological expert evaluation. Furthermore, while iteratively developing our model, we study the impact of the adversarial loss and demonstrate its crucial role in the quality of virtually stained images. Finally, while comparing our model with reference works in the field, we underscore the limitations of the currently used evaluation metrics and demonstrate the superior performance of CSSP2P GAN.",
    "published": "2025-11-24T09:56:35Z",
    "updated": "2025-11-24T09:56:35Z",
    "link": "http://arxiv.org/pdf/2511.18946v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "José Teixeira",
      "Pascal Klöckner",
      "Diana Montezuma",
      "Melis Erdal Cesur",
      "João Fraga",
      "Hugo M. Horlings",
      "Jaime S. Cardoso",
      "Sara P. Oliveira"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18942v1",
    "title": "VeCoR - Velocity Contrastive Regularization for Flow Matching",
    "summary": "Flow Matching (FM) has recently emerged as a principled and efficient alternative to diffusion models. Standard FM encourages the learned velocity field to follow a target direction; however, it may accumulate errors along the trajectory and drive samples off the data manifold, leading to perceptual degradation, especially in lightweight or low-step configurations.\n  To enhance stability and generalization, we extend FM into a balanced attract-repel scheme that provides explicit guidance on both \"where to go\" and \"where not to go.\" To be formal, we propose \\textbf{Velocity Contrastive Regularization (VeCoR)}, a complementary training scheme for flow-based generative modeling that augments the standard FM objective with contrastive, two-sided supervision. VeCoR not only aligns the predicted velocity with a stable reference direction (positive supervision) but also pushes it away from inconsistent, off-manifold directions (negative supervision). This contrastive formulation transforms FM from a purely attractive, one-sided objective into a two-sided training signal, regularizing trajectory evolution and improving perceptual fidelity across datasets and backbones.\n  On ImageNet-1K 256$\\times$256, VeCoR yields 22\\% and 35\\% relative FID reductions on SiT-XL/2 and REPA-SiT-XL/2 backbones, respectively, and achieves further FID gains (32\\% relative) on MS-COCO text-to-image generation, demonstrating consistent improvements in stability, convergence, and image quality, particularly in low-step and lightweight settings. Project page: https://p458732.github.io/VeCoR_Project_Page/",
    "published": "2025-11-24T09:48:38Z",
    "updated": "2025-11-24T09:48:38Z",
    "link": "http://arxiv.org/pdf/2511.18942v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zong-Wei Hong",
      "Jing-lun Li",
      "Lin-Ze Li",
      "Shen Zhang",
      "Yao Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.21590v2",
    "title": "Restore Text First, Enhance Image Later: Two-Stage Scene Text Image Super-Resolution with Glyph Structure Guidance",
    "summary": "Current image super-resolution methods show strong performance on natural images but distort text, creating a fundamental trade-off between image quality and textual readability. To address this, we introduce TIGER (Text-Image Guided supEr-Resolution), a novel two-stage framework that breaks this trade-off through a \"text-first, image-later\" paradigm. TIGER explicitly decouples glyph restoration from image enhancement: it first reconstructs precise text structures and uses them to guide full-image super-resolution. This ensures high fidelity and readability. To support comprehensive training and evaluation, we present the UZ-ST (UltraZoom-Scene Text) dataset, the first Chinese scene text dataset with extreme zoom. Extensive experiments show TIGER achieves state-of-the-art performance, enhancing readability and image quality.",
    "published": "2025-10-24T15:59:04Z",
    "updated": "2025-11-24T09:37:15Z",
    "link": "http://arxiv.org/pdf/2510.21590v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Minxing Luo",
      "Linlong Fan",
      "Wang Qiushi",
      "Ge Wu",
      "Yiyan Luo",
      "Yuhang Yu",
      "Jinwei Chen",
      "Yaxing Wang",
      "Qingnan Fan",
      "Jian Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10353v4",
    "title": "Motion-R1: Enhancing Motion Generation with Decomposed Chain-of-Thought and RL Binding",
    "summary": "Text-to-Motion generation has become a fundamental task in human-machine interaction, enabling the synthesis of realistic human motions from natural language descriptions. Although recent advances in large language models and reinforcement learning have contributed to high-quality motion generation, two major challenges remain. Existing approaches often fail to capture the temporal and causal complexities inherent in natural language, leading to oversimplified or incoherent motions. Additionally, RL-based methods are frequently overly complex, hindering their scalability and adaptability across various motion generation tasks. To address these challenges, we propose Motion-R1, a novel framework that combines decomposed Chain-of-Thought reasoning with reinforcement learning to enhance both the quality and interpretability of generated motions. Specifically, we introduce the Decomposed CoT Data Engine, which leverages an automated pipeline to synthesize high-quality reasoning data, allowing the model to better capture the temporal dependencies and causal relationships of human motion. We also propose RL Binding, a reinforcement learning strategy that incorporates multi-modal text-motion alignment into the RL reward function, guiding the model to produce motions that are both semantically accurate and motionally realistic. Extensive experiments across benchmark datasets demonstrate that Motion-R1 achieves state-of-the-art performance, with a 3.5% improvement in MM-Dist on HumanML3D and improvements in R-Precision and FID on KIT-ML and BABEL, surpassing existing methods across key metrics and highlighting its superior capability in handling complex motion generation tasks. Project page: https://motion-r1.github.io/.",
    "published": "2025-06-12T05:21:43Z",
    "updated": "2025-11-24T09:35:11Z",
    "link": "http://arxiv.org/pdf/2506.10353v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Runqi Ouyang",
      "Haoyun Li",
      "Zhenyuan Zhang",
      "Xiaofeng Wang",
      "Zeyu Zhang",
      "Zheng Zhu",
      "Guan Huang",
      "Sirui Han",
      "Xingang Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18929v1",
    "title": "Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and Scalable Tree-Based Search",
    "summary": "Recent progress in robotics and embodied AI is largely driven by Large Multimodal Models (LMMs). However, a key challenge remains underexplored: how can we advance LMMs to discover tasks that directly assist humans in open-future scenarios, where human intentions are highly concurrent and dynamic. In this work, we formalize the problem of Human-centric Open-future Task Discovery (HOTD), focusing particularly on identifying tasks that reduce human effort across multiple plausible futures. To facilitate this study, we propose an HOTD-Bench, which features over 2K real-world videos, a semi-automated annotation pipeline, and a simulation-based protocol tailored for open-set future evaluation. Additionally, we propose the Collaborative Multi-Agent Search Tree (CMAST) framework, which decomposes the complex reasoning through a multi-agent system and structures the reasoning process through a scalable search tree module. In our experiments, CMAST achieves the best performance on the HOTD-Bench, significantly surpassing existing LMMs. It also integrates well with existing LMMs, consistently improving performance.",
    "published": "2025-11-24T09:33:59Z",
    "updated": "2025-11-24T09:33:59Z",
    "link": "http://arxiv.org/pdf/2511.18929v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zijian Song",
      "Xiaoxin Lin",
      "Tao Pu",
      "Zhenlong Yuan",
      "Guangrun Wang",
      "Liang Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18927v1",
    "title": "FineXtrol: Controllable Motion Generation via Fine-Grained Text",
    "summary": "Recent works have sought to enhance the controllability and precision of text-driven motion generation. Some approaches leverage large language models (LLMs) to produce more detailed texts, while others incorporate global 3D coordinate sequences as additional control signals. However, the former often introduces misaligned details and lacks explicit temporal cues, and the latter incurs significant computational cost when converting coordinates to standard motion representations. To address these issues, we propose FineXtrol, a novel control framework for efficient motion generation guided by temporally-aware, precise, user-friendly, and fine-grained textual control signals that describe specific body part movements over time. In support of this framework, we design a hierarchical contrastive learning module that encourages the text encoder to produce more discriminative embeddings for our novel control signals, thereby improving motion controllability. Quantitative results show that FineXtrol achieves strong performance in controllable motion generation, while qualitative analysis demonstrates its flexibility in directing specific body part movements.",
    "published": "2025-11-24T09:32:26Z",
    "updated": "2025-11-24T09:32:26Z",
    "link": "http://arxiv.org/pdf/2511.18927v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Keming Shen",
      "Bizhu Wu",
      "Junliang Chen",
      "Xiaoqin Wang",
      "Linlin Shen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18925v1",
    "title": "AttenDence: Maximizing Attention Confidence for Test Time Adaptation",
    "summary": "Test-time adaptation (TTA) enables models to adapt to distribution shifts at inference time. While entropy minimization over the output distribution has proven effective for TTA, transformers offer an additional unsupervised learning signal through their attention mechanisms. We propose minimizing the entropy of attention distributions from the CLS token to image patches as a novel TTA objective.This approach encourages the model to attend more confidently to relevant image regions under distribution shift and is effective even when only a single test image is available. We demonstrate that attention entropy minimization improves robustness across diverse corruption types while not hurting performance on clean data on a single sample stream of images at test time.",
    "published": "2025-11-24T09:32:01Z",
    "updated": "2025-11-24T09:32:01Z",
    "link": "http://arxiv.org/pdf/2511.18925v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yash Mali"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.08840v4",
    "title": "Directed-CP: Directed Collaborative Perception for Connected and Autonomous Vehicles via Proactive Attention",
    "summary": "Collaborative perception (CP) leverages visual data from connected and autonomous vehicles (CAV) to enhance an ego vehicle's field of view (FoV). Despite recent progress, current CP methods expand the ego vehicle's 360-degree perceptual range almost equally, which faces two key challenges. Firstly, in areas with uneven traffic distribution, focusing on directions with little traffic offers limited benefits. Secondly, under limited communication budgets, allocating excessive bandwidth to less critical directions lowers the perception accuracy in more vital areas. To address these issues, we propose Direct-CP, a proactive and direction-aware CP system aiming at improving CP in specific directions. Our key idea is to enable an ego vehicle to proactively signal its interested directions and readjust its attention to enhance local directional CP performance. To achieve this, we first propose an RSU-aided direction masking mechanism that assists an ego vehicle in identifying vital directions. Additionally, we design a direction-aware selective attention module to wisely aggregate pertinent features based on ego vehicle's directional priorities, communication budget, and the positional data of CAVs. Moreover, we introduce a direction-weighted detection loss (DWLoss) to capture the divergence between directional CP outcomes and the ground truth, facilitating effective model training. Extensive experiments on the V2X-Sim 2.0 dataset demonstrate that our approach achieves 19.8\\% higher local perception accuracy in interested directions and 2.5\\% higher overall perception accuracy than the state-of-the-art methods in collaborative 3D object detection tasks. Codes are available at https://github.com/yihangtao/Directed-CP.git.",
    "published": "2024-09-13T13:53:52Z",
    "updated": "2025-11-24T09:31:39Z",
    "link": "http://arxiv.org/pdf/2409.08840v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yihang Tao",
      "Senkang Hu",
      "Zhengru Fang",
      "Yuguang Fang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18922v1",
    "title": "One4D: Unified 4D Generation and Reconstruction via Decoupled LoRA Control",
    "summary": "We present One4D, a unified framework for 4D generation and reconstruction that produces dynamic 4D content as synchronized RGB frames and pointmaps. By consistently handling varying sparsities of conditioning frames through a Unified Masked Conditioning (UMC) mechanism, One4D can seamlessly transition between 4D generation from a single image, 4D reconstruction from a full video, and mixed generation and reconstruction from sparse frames. Our framework adapts a powerful video generation model for joint RGB and pointmap generation, with carefully designed network architectures. The commonly used diffusion finetuning strategies for depthmap or pointmap reconstruction often fail on joint RGB and pointmap generation, quickly degrading the base video model. To address this challenge, we introduce Decoupled LoRA Control (DLC), which employs two modality-specific LoRA adapters to form decoupled computation branches for RGB frames and pointmaps, connected by lightweight, zero-initialized control links that gradually learn mutual pixel-level consistency. Trained on a mixture of synthetic and real 4D datasets under modest computational budgets, One4D produces high-quality RGB frames and accurate pointmaps across both generation and reconstruction tasks. This work represents a step toward general, high-quality geometry-based 4D world modeling using video diffusion models. Project page: https://mizhenxing.github.io/One4D",
    "published": "2025-11-24T09:31:23Z",
    "updated": "2025-11-24T09:31:23Z",
    "link": "http://arxiv.org/pdf/2511.18922v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhenxing Mi",
      "Yuxin Wang",
      "Dan Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2310.17218v2",
    "title": "Prototypical Contrastive Learning-based CLIP Fine-tuning for Object Re-identification",
    "summary": "This work aims to adapt large-scale pre-trained vision-language models, such as contrastive language-image pretraining (CLIP), to enhance the performance of object reidentification (Re-ID) across various supervision settings. Although prompt learning has enabled a recent work named CLIP-ReID to achieve promising performance, the underlying mechanisms and the necessity of prompt learning remain unclear due to the absence of semantic labels in ReID tasks. In this work, we first analyze the role prompt learning in CLIP-ReID and identify its limitations. Based on our investigations, we propose a simple yet effective approach to adapt CLIP for supervised object Re-ID. Our approach directly fine-tunes the image encoder of CLIP using a prototypical contrastive learning (PCL) loss, eliminating the need for prompt learning. Experimental results on both person and vehicle Re-ID datasets demonstrate the competitiveness of our method compared to CLIP-ReID. Furthermore, we extend our PCL-based CLIP fine-tuning approach to unsupervised scenarios, where we achieve state-of-the art performance.",
    "published": "2023-10-26T08:12:53Z",
    "updated": "2025-11-24T09:30:49Z",
    "link": "http://arxiv.org/pdf/2310.17218v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiachen Li",
      "Xiaojin Gong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18921v1",
    "title": "BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models",
    "summary": "Backdoor attacks undermine the reliability and trustworthiness of machine learning systems by injecting hidden behaviors that can be maliciously activated at inference time. While such threats have been extensively studied in unimodal settings, their impact on multimodal foundation models, particularly vision-language models (VLMs), remains largely underexplored. In this work, we introduce \\textbf{BackdoorVLM}, the first comprehensive benchmark for systematically evaluating backdoor attacks on VLMs across a broad range of settings. It adopts a unified perspective that injects and analyzes backdoors across core vision-language tasks, including image captioning and visual question answering. BackdoorVLM organizes multimodal backdoor threats into 5 representative categories: targeted refusal, malicious injection, jailbreak, concept substitution, and perceptual hijack. Each category captures a distinct pathway through which an adversary can manipulate a model's behavior. We evaluate these threats using 12 representative attack methods spanning text, image, and bimodal triggers, tested on 2 open-source VLMs and 3 multimodal datasets. Our analysis reveals that VLMs exhibit strong sensitivity to textual instructions, and in bimodal backdoors the text trigger typically overwhelms the image trigger when forming the backdoor mapping. Notably, backdoors involving the textual modality remain highly potent, with poisoning rates as low as 1\\% yielding over 90\\% success across most tasks. These findings highlight significant, previously underexplored vulnerabilities in current VLMs. We hope that BackdoorVLM can serve as a useful benchmark for analyzing and mitigating multimodal backdoor threats. Code is available at: https://github.com/bin015/BackdoorVLM .",
    "published": "2025-11-24T09:30:38Z",
    "updated": "2025-11-24T09:30:38Z",
    "link": "http://arxiv.org/pdf/2511.18921v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Juncheng Li",
      "Yige Li",
      "Hanxun Huang",
      "Yunhao Chen",
      "Xin Wang",
      "Yixu Wang",
      "Xingjun Ma",
      "Yu-Gang Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18920v1",
    "title": "EventSTU: Event-Guided Efficient Spatio-Temporal Understanding for Video Large Language Models",
    "summary": "Video large language models have demonstrated strong video understanding capabilities but suffer from high inference costs due to the massive number of tokens in long videos. Inspired by event-based vision, we propose an event-guided, training-free framework for efficient spatio-temporal understanding, named EventSTU. In the temporal domain, we design a coarse-to-fine keyframe sampling algorithm that exploits the change-triggered property of event cameras to eliminate redundant frames. In the spatial domain, we design an adaptive token pruning algorithm that leverages the visual saliency of events as a zero-cost prior to guide spatial reduction. From a holistic spatio-temporal perspective, we further integrate question relevance from keyframe sampling to adaptively allocate token pruning budgets. To facilitate evaluation, we construct EventBench, the first event-inclusive, human-annotated multimodal benchmark that covers diverse real-world scenarios. Beyond physical event cameras, EventSTU also supports general video understanding using simulated events. Comprehensive experiments show that EventSTU achieves 3.01x FLOPs reduction and 3.10x prefilling speedup over the strongest baseline while still improving performance.",
    "published": "2025-11-24T09:30:02Z",
    "updated": "2025-11-24T09:30:02Z",
    "link": "http://arxiv.org/pdf/2511.18920v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wenhao Xu",
      "Xin Dong",
      "Yue Li",
      "Haoyuan Shi",
      "Zhiwei Xiong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2103.02211v2",
    "title": "K-FACE: A Large-Scale KIST Face Database in Consideration with Unconstrained Environments",
    "summary": "In this paper, we introduce a new large-scale face database from KIST, denoted as K-FACE, and describe a novel capturing device specifically designed to obtain the data. The K-FACE database contains more than 1 million high-quality images of 1,000 subjects selected by considering the ratio of gender and age groups. It includes a variety of attributes, including 27 poses, 35 lighting conditions, three expressions, and occlusions by the combination of five types of accessories. As the K-FACE database is systematically constructed through a hemispherical capturing system with elaborate lighting control and multiple cameras, it is possible to accurately analyze the effects of factors that cause performance degradation, such as poses, lighting changes, and accessories. We consider not only the balance of external environmental factors, such as pose and lighting, but also the balance of personal characteristics such as gender and age group. The gender ratio is the same, while the age groups of subjects are uniformly distributed from the 20s to 50s for both genders. The K-FACE database can be extensively utilized in various vision tasks, such as face recognition, face frontalization, illumination normalization, face age estimation, and three-dimensional face model generation. We expect systematic diversity and uniformity of the K-FACE database to promote these research fields.",
    "published": "2021-03-03T06:50:33Z",
    "updated": "2025-11-24T09:20:42Z",
    "link": "http://arxiv.org/pdf/2103.02211v2.pdf",
    "category": [
      "cs.CV",
      "cs.DB"
    ],
    "authors": [
      "Yeji Choi",
      "Hyunjung Park",
      "Gi Pyo Nam",
      "Haksub Kim",
      "Heeseung Choi",
      "Junghyun Cho",
      "Ig-Jae Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2404.01064v4",
    "title": "Roadside Monocular 3D Detection Prompted by 2D Detection",
    "summary": "Roadside monocular 3D detection requires detecting objects of predefined classes in an RGB frame and predicting their 3D attributes, such as bird's-eye-view (BEV) locations. It has broad applications in traffic control, vehicle-vehicle communication, and vehicle-infrastructure cooperative perception. To address this task, we introduce Promptable 3D Detector (Pro3D), a novel detector design that leverages 2D detections as prompts. We build our Pro3D upon two key insights. First, compared to a typical 3D detector, a 2D detector is ``easier'' to train due to fewer loss terms and performs significantly better at localizing objects w.r.t 2D metrics. Second, once 2D detections precisely locate objects in the image, a 3D detector can focus on lifting these detections into 3D BEV, especially when fixed camera pose or scene geometry provide an informative prior. To encode and incorporate 2D detections, we explore three methods: (a) concatenating features from both 2D and 3D detectors, (b) attentively fusing 2D and 3D detector features, and (c) encoding properties of predicted 2D bounding boxes \\{$x$, $y$, width, height, label\\} and attentively fusing them with the 3D detector feature. Interestingly, the third method significantly outperforms the others, underscoring the effectiveness of 2D detections as prompts that offer precise object targets and allow the 3D detector to focus on lifting them into 3D. Pro3D is adaptable for use with a wide range of 2D and 3D detectors with minimal modifications. Comprehensive experiments demonstrate that our Pro3D significantly enhances existing methods, achieving state-of-the-art results on two contemporary benchmarks.",
    "published": "2024-04-01T11:57:34Z",
    "updated": "2025-11-24T09:12:46Z",
    "link": "http://arxiv.org/pdf/2404.01064v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yechi Ma",
      "Yanan Li",
      "Wei Hua",
      "Shu Kong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18900v1",
    "title": "MatMart: Material Reconstruction of 3D Objects via Diffusion",
    "summary": "Applying diffusion models to physically-based material estimation and generation has recently gained prominence. In this paper, we propose \\ttt, a novel material reconstruction framework for 3D objects, offering the following advantages. First, \\ttt\\ adopts a two-stage reconstruction, starting with accurate material prediction from inputs and followed by prior-guided material generation for unobserved views, yielding high-fidelity results. Second, by utilizing progressive inference alongside the proposed view-material cross-attention (VMCA), \\ttt\\ enables reconstruction from an arbitrary number of input images, demonstrating strong scalability and flexibility. Finally, \\ttt\\ achieves both material prediction and generation capabilities through end-to-end optimization of a single diffusion model, without relying on additional pre-trained models, thereby exhibiting enhanced stability across various types of objects. Extensive experiments demonstrate that \\ttt\\ achieves superior performance in material reconstruction compared to existing methods.",
    "published": "2025-11-24T08:58:14Z",
    "updated": "2025-11-24T08:58:14Z",
    "link": "http://arxiv.org/pdf/2511.18900v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Xiuchao Wu",
      "Pengfei Zhu",
      "Jiangjing Lyu",
      "Xinguo Liu",
      "Jie Guo",
      "Yanwen Guo",
      "Weiwei Xu",
      "Chengfei Lyu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.02916v2",
    "title": "Monocular Person Localization under Camera Ego-motion",
    "summary": "Localizing a person from a moving monocular camera is critical for Human-Robot Interaction (HRI). To estimate the 3D human position from a 2D image, existing methods either depend on the geometric assumption of a fixed camera or use a position regression model trained on datasets containing little camera ego-motion. These methods are vulnerable to severe camera ego-motion, resulting in inaccurate person localization. We consider person localization as a part of a pose estimation problem. By representing a human with a four-point model, our method jointly estimates the 2D camera attitude and the person's 3D location through optimization. Evaluations on both public datasets and real robot experiments demonstrate our method outperforms baselines in person localization accuracy. Our method is further implemented into a person-following system and deployed on an agile quadruped robot.",
    "published": "2025-03-04T11:07:27Z",
    "updated": "2025-11-24T08:57:24Z",
    "link": "http://arxiv.org/pdf/2503.02916v2.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Yu Zhan",
      "Hanjing Ye",
      "Hong Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18888v1",
    "title": "MFmamba: A Multi-function Network for Panchromatic Image Resolution Restoration Based on State-Space Model",
    "summary": "Remote sensing images are becoming increasingly widespread in military, earth resource exploration. Because of the limitation of a single sensor, we can obtain high spatial resolution grayscale panchromatic (PAN) images and low spatial resolution color multispectral (MS) images. Therefore, an important issue is to obtain a color image with high spatial resolution when there is only a PAN image at the input. The existing methods improve spatial resolution using super-resolution (SR) technology and spectral recovery using colorization technology. However, the SR technique cannot improve the spectral resolution, and the colorization technique cannot improve the spatial resolution. Moreover, the pansharpening method needs two registered inputs and can not achieve SR. As a result, an integrated approach is expected. To solve the above problems, we designed a novel multi-function model (MFmamba) to realize the tasks of SR, spectral recovery, joint SR and spectral recovery through three different inputs. Firstly, MFmamba utilizes UNet++ as the backbone, and a Mamba Upsample Block (MUB) is combined with UNet++. Secondly, a Dual Pool Attention (DPA) is designed to replace the skip connection in UNet++. Finally, a Multi-scale Hybrid Cross Block (MHCB) is proposed for initial feature extraction. Many experiments show that MFmamba is competitive in evaluation metrics and visual results and performs well in the three tasks when only the input PAN image is used.",
    "published": "2025-11-24T08:44:04Z",
    "updated": "2025-11-24T08:44:04Z",
    "link": "http://arxiv.org/pdf/2511.18888v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qian Jiang",
      "Qianqian Wang",
      "Xin Jin",
      "Michal Wozniak",
      "Shaowen Yao",
      "Wei Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18886v1",
    "title": "MagicWorld: Interactive Geometry-driven Video World Exploration",
    "summary": "Recent interactive video world model methods generate scene evolution conditioned on user instructions. Although they achieve impressive results, two key limitations remain. First, they fail to fully exploit the correspondence between instruction-driven scene motion and the underlying 3D geometry, which results in structural instability under viewpoint changes. Second, they easily forget historical information during multi-step interaction, resulting in error accumulation and progressive drift in scene semantics and structure. To address these issues, we propose MagicWorld, an interactive video world model that integrates 3D geometric priors and historical retrieval. MagicWorld starts from a single scene image, employs user actions to drive dynamic scene evolution, and autoregressively synthesizes continuous scenes. We introduce the Action-Guided 3D Geometry Module (AG3D), which constructs a point cloud from the first frame of each interaction and the corresponding action, providing explicit geometric constraints for viewpoint transitions and thereby improving structural consistency. We further propose History Cache Retrieval (HCR) mechanism, which retrieves relevant historical frames during generation and injects them as conditioning signals, helping the model utilize past scene information and mitigate error accumulation. Experimental results demonstrate that MagicWorld achieves notable improvements in scene stability and continuity across interaction iterations.",
    "published": "2025-11-24T08:41:28Z",
    "updated": "2025-11-24T08:41:28Z",
    "link": "http://arxiv.org/pdf/2511.18886v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Guangyuan Li",
      "Siming Zheng",
      "Shuolin Xu",
      "Jinwei Chen",
      "Bo Li",
      "Xiaobin Hu",
      "Lei Zhao",
      "Peng-Tao Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18882v1",
    "title": "Facade Segmentation for Solar Photovoltaic Suitability",
    "summary": "Building integrated photovoltaic (BIPV) facades represent a promising pathway towards urban decarbonization, especially where roof areas are insufficient and ground-mounted arrays are infeasible. Although machine learning-based approaches to support photovoltaic (PV) planning on rooftops are well researched, automated approaches for facades still remain scarce and oversimplified. This paper therefore presents a pipeline that integrates detailed information on the architectural composition of the facade to automatically identify suitable surfaces for PV application and estimate the solar energy potential. The pipeline fine-tunes SegFormer-B5 on the CMP Facades dataset and converts semantic predictions into facade-level PV suitability masks and PV panel layouts considering module sizes and clearances. Applied to a dataset of 373 facades with known dimensions from ten cities, the results show that installable BIPV potential is significantly lower than theoretical potential, thus providing valuable insights for reliable urban energy planning. With the growing availability of facade imagery, the proposed pipeline can be scaled to support BIPV planning in cities worldwide.",
    "published": "2025-11-24T08:37:35Z",
    "updated": "2025-11-24T08:37:35Z",
    "link": "http://arxiv.org/pdf/2511.18882v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ayca Duran",
      "Christoph Waibel",
      "Bernd Bickel",
      "Iro Armeni",
      "Arno Schlueter"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18875v1",
    "title": "Parallel Vision Token Scheduling for Fast and Accurate Multimodal LMMs Inference",
    "summary": "Multimodal large language models (MLLMs) deliver impressive vision-language reasoning but suffer steep inference latency because self-attention scales quadratically with sequence length and thousands of visual tokens contributed by high-resolution images. Naively pruning less-informative visual tokens reduces this burden, yet indiscriminate removal can strip away contextual cues essential for background or fine-grained questions, undermining accuracy. In this paper, we present ParVTS (Parallel Vision Token Scheduling), a training-free scheduling framework that partitions visual tokens into subject and non-subject groups, processes them in parallel to transfer their semantics into question tokens, and discards the non-subject path mid-inference to reduce computation. This scheduling reduces computational complexity, requires no heuristics or additional modules, and is compatible with diverse existing MLLM architectures. Experiments across multiple MLLM backbones show that ParVTS prunes up to 88.9% of visual tokens with minimal performance drop, achieving 1.77x speedup and 70% FLOPs reduction.",
    "published": "2025-11-24T08:29:36Z",
    "updated": "2025-11-24T08:29:36Z",
    "link": "http://arxiv.org/pdf/2511.18875v1.pdf",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Wengyi Zhan",
      "Mingbao Lin",
      "Zhihang Lin",
      "Rongrong Ji"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18873v1",
    "title": "Neural Texture Splatting: Expressive 3D Gaussian Splatting for View Synthesis, Geometry, and Dynamic Reconstruction",
    "summary": "3D Gaussian Splatting (3DGS) has emerged as a leading approach for high-quality novel view synthesis, with numerous variants extending its applicability to a broad spectrum of 3D and 4D scene reconstruction tasks. Despite its success, the representational capacity of 3DGS remains limited by the use of 3D Gaussian kernels to model local variations. Recent works have proposed to augment 3DGS with additional per-primitive capacity, such as per-splat textures, to enhance its expressiveness. However, these per-splat texture approaches primarily target dense novel view synthesis with a reduced number of Gaussian primitives, and their effectiveness tends to diminish when applied to more general reconstruction scenarios. In this paper, we aim to achieve concrete performance improvement over state-of-the-art 3DGS variants across a wide range of reconstruction tasks, including novel view synthesis, geometry and dynamic reconstruction, under both sparse and dense input settings. To this end, we introduce Neural Texture Splatting (NTS). At the core of our approach is a global neural field (represented as a hybrid of a tri-plane and a neural decoder) that predicts local appearance and geometric fields for each primitive. By leveraging this shared global representation that models local texture fields across primitives, we significantly reduce model size and facilitate efficient global information exchange, demonstrating strong generalization across tasks. Furthermore, our neural modeling of local texture fields introduces expressive view- and time-dependent effects, a critical aspect that existing methods fail to account for. Extensive experiments show that Neural Texture Splatting consistently improves models and achieves state-of-the-art results across multiple benchmarks.",
    "published": "2025-11-24T08:26:32Z",
    "updated": "2025-11-24T08:26:32Z",
    "link": "http://arxiv.org/pdf/2511.18873v1.pdf",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "authors": [
      "Yiming Wang",
      "Shaofei Wang",
      "Marko Mihajlovic",
      "Siyu Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.23867v2",
    "title": "Sim-DETR: Unlock DETR for Temporal Sentence Grounding",
    "summary": "Temporal sentence grounding aims to identify exact moments in a video that correspond to a given textual query, typically addressed with detection transformer (DETR) solutions. However, we find that typical strategies designed to enhance DETR do not improve, and may even degrade, its performance in this task. We systematically analyze and identify the root causes of this abnormal behavior: (1) conflicts between queries from similar target moments and (2) internal query conflicts due to the tension between global semantics and local localization. Building on these insights, we propose a simple yet powerful baseline, Sim-DETR, which extends the standard DETR with two minor modifications in the decoder layers: (1) constraining self-attention between queries based on their semantic and positional overlap and (2) adding query-to-frame alignment to bridge the global and local contexts. Experiments demonstrate that Sim-DETR unlocks the full potential of DETR for temporal sentence grounding, offering a strong baseline for future research.",
    "published": "2025-09-28T13:21:10Z",
    "updated": "2025-11-24T08:22:15Z",
    "link": "http://arxiv.org/pdf/2509.23867v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiajin Tang",
      "Zhengxuan Wei",
      "Yuchen Zhu",
      "Cheng Shi",
      "Guanbin Li",
      "Liang Lin",
      "Sibei Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18870v1",
    "title": "HunyuanVideo 1.5 Technical Report",
    "summary": "We present HunyuanVideo 1.5, a lightweight yet powerful open-source video generation model that achieves state-of-the-art visual quality and motion coherence with only 8.3 billion parameters, enabling efficient inference on consumer-grade GPUs. This achievement is built upon several key components, including meticulous data curation, an advanced DiT architecture featuring selective and sliding tile attention (SSTA), enhanced bilingual understanding through glyph-aware text encoding, progressive pre-training and post-training, and an efficient video super-resolution network. Leveraging these designs, we developed a unified framework capable of high-quality text-to-video and image-to-video generation across multiple durations and resolutions.Extensive experiments demonstrate that this compact and proficient model establishes a new state-of-the-art among open-source video generation models. By releasing the code and model weights, we provide the community with a high-performance foundation that lowers the barrier to video creation and research, making advanced video generation accessible to a broader audience. All open-source assets are publicly available at https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5.",
    "published": "2025-11-24T08:22:07Z",
    "updated": "2025-11-24T08:22:07Z",
    "link": "http://arxiv.org/pdf/2511.18870v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Bing Wu",
      "Chang Zou",
      "Changlin Li",
      "Duojun Huang",
      "Fang Yang",
      "Hao Tan",
      "Jack Peng",
      "Jianbing Wu",
      "Jiangfeng Xiong",
      "Jie Jiang",
      " Linus",
      " Patrol",
      "Peizhen Zhang",
      "Peng Chen",
      "Penghao Zhao",
      "Qi Tian",
      "Songtao Liu",
      "Weijie Kong",
      "Weiyan Wang",
      "Xiao He",
      "Xin Li",
      "Xinchi Deng",
      "Xuefei Zhe",
      "Yang Li",
      "Yanxin Long",
      "Yuanbo Peng",
      "Yue Wu",
      "Yuhong Liu",
      "Zhenyu Wang",
      "Zuozhuo Dai",
      "Bo Peng",
      "Coopers Li",
      "Gu Gong",
      "Guojian Xiao",
      "Jiahe Tian",
      "Jiaxin Lin",
      "Jie Liu",
      "Jihong Zhang",
      "Jiesong Lian",
      "Kaihang Pan",
      "Lei Wang",
      "Lin Niu",
      "Mingtao Chen",
      "Mingyang Chen",
      "Mingzhe Zheng",
      "Miles Yang",
      "Qiangqiang Hu",
      "Qi Yang",
      "Qiuyong Xiao",
      "Runzhou Wu",
      "Ryan Xu",
      "Rui Yuan",
      "Shanshan Sang",
      "Shisheng Huang",
      "Siruis Gong",
      "Shuo Huang",
      "Weiting Guo",
      "Xiang Yuan",
      "Xiaojia Chen",
      "Xiawei Hu",
      "Wenzhi Sun",
      "Xiele Wu",
      "Xianshun Ren",
      "Xiaoyan Yuan",
      "Xiaoyue Mi",
      "Yepeng Zhang",
      "Yifu Sun",
      "Yiting Lu",
      "Yitong Li",
      "You Huang",
      "Yu Tang",
      "Yixuan Li",
      "Yuhang Deng",
      "Yuan Zhou",
      "Zhichao Hu",
      "Zhiguang Liu",
      "Zhihe Yang",
      "Zilin Yang",
      "Zhenzhi Lu",
      "Zixiang Zhou",
      "Zhao Zhong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.19161v2",
    "title": "Benchmarking Endoscopic Surgical Image Restoration and Beyond",
    "summary": "In endoscopic surgery, a clear and high-quality visual field is critical for surgeons to make accurate intraoperative decisions. However, persistent visual degradation, including smoke generated by energy devices, lens fogging from thermal gradients, and lens contamination due to blood or tissue fluid splashes during surgical procedures, severely impairs visual clarity. These degenerations can seriously hinder surgical workflow and pose risks to patient safety. To systematically investigate and address various forms of surgical scene degradation, we introduce a real- world open-source surgical image restoration dataset covering endoscopic environments, called SurgClean, which involves multi-type image restoration tasks from two medical sites, i.e., desmoking, defogging, and desplashing. SurgClean comprises 3,113 images with diverse degradation types and corresponding paired reference labels. Based on SurgClean, we establish a standardized evaluation benchmark and provide performance for 22 representative generic task-specific image restoration approaches, including 12 generic and 10 task-specific image restoration approaches. Experimental results reveal substantial performance gaps relative to clinical requirements, highlighting a critical opportunity for algorithm advancements in intelligent surgical restoration. Furthermore, we explore the degradation discrepancies between surgical and natural scenes from structural perception and semantic under- standing perspectives, providing fundamental insights for domain-specific image restoration research. Our work aims to empower restoration algorithms and improve the efficiency of clinical procedures.",
    "published": "2025-05-25T14:17:56Z",
    "updated": "2025-11-24T08:12:05Z",
    "link": "http://arxiv.org/pdf/2505.19161v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jialun Pei",
      "Diandian Guo",
      "Donghui Yang",
      "Zhixi Li",
      "Yuxin Feng",
      "Long Ma",
      "Bo Du",
      "Pheng-Ann Heng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18865v1",
    "title": "DualGazeNet: A Biologically Inspired Dual-Gaze Query Network for Salient Object Detection",
    "summary": "Recent salient object detection (SOD) methods aim to improve performance in four key directions: semantic enhancement, boundary refinement, auxiliary task supervision, and multi-modal fusion. In pursuit of continuous gains, these approaches have evolved toward increasingly sophisticated architectures with multi-stage pipelines, specialized fusion modules, edge-guided learning, and elaborate attention mechanisms. However, this complexity paradoxically introduces feature redundancy and cross-component interference that obscure salient cues, ultimately reaching performance bottlenecks. In contrast, human vision achieves efficient salient object identification without such architectural complexity. This contrast raises a fundamental question: can we design a biologically grounded yet architecturally simple SOD framework that dispenses with most of this engineering complexity, while achieving state-of-the-art accuracy, computational efficiency, and interpretability? In this work, we answer this question affirmatively by introducing DualGazeNet, a biologically inspired pure Transformer framework that models the dual biological principles of robust representation learning and magnocellular-parvocellular dual-pathway processing with cortical attention modulation in the human visual system. Extensive experiments on five RGB SOD benchmarks show that DualGazeNet consistently surpasses 25 state-of-the-art CNN- and Transformer-based methods. On average, DualGazeNet achieves about 60\\% higher inference speed and 53.4\\% fewer FLOPs than four Transformer-based baselines of similar capacity (VST++, MDSAM, Sam2unet, and BiRefNet). Moreover, DualGazeNet exhibits strong cross-domain generalization, achieving leading or highly competitive performance on camouflaged and underwater SOD benchmarks without relying on additional modalities.",
    "published": "2025-11-24T08:08:22Z",
    "updated": "2025-11-24T08:08:22Z",
    "link": "http://arxiv.org/pdf/2511.18865v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yu Zhang",
      "Haoan Ping",
      "Yuchen Li",
      "Zhenshan Bing",
      "Fuchun Sun",
      "Alois Knoll"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.21783v4",
    "title": "Prompt-guided Disentangled Representation for Action Recognition",
    "summary": "Action recognition is a fundamental task in video understanding. Existing methods typically extract unified features to process all actions in one video, which makes it challenging to model the interactions between different objects in multi-action scenarios. To alleviate this issue, we explore disentangling any specified actions from complex scenes as an effective solution. In this paper, we propose Prompt-guided Disentangled Representation for Action Recognition (ProDA), a novel framework that disentangles any specified actions from a multi-action scene. ProDA leverages Spatio-temporal Scene Graphs (SSGs) and introduces Dynamic Prompt Module (DPM) to guide a Graph Parsing Neural Network (GPNN) in generating action-specific representations. Furthermore, we design a video-adapted GPNN that aggregates information using dynamic weights. Experiments in video action recognition demonstrate the effectiveness of our approach when compared with the state-of-the-art methods. Our code can be found in https://github.com/iamsnaping/ProDA.git",
    "published": "2025-09-26T02:39:40Z",
    "updated": "2025-11-24T07:59:44Z",
    "link": "http://arxiv.org/pdf/2509.21783v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tianci Wu",
      "Guangming Zhu",
      "Jiang Lu",
      "Siyuan Wang",
      "Ning Wang",
      "Nuoye Xiong",
      "Zhang Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.17852v3",
    "title": "Sketch-1-to-3: One Single Sketch to 3D Detailed Face Reconstruction",
    "summary": "3D face reconstruction from a single sketch is a critical yet underexplored task with significant practical applications. The primary challenges stem from the substantial modality gap between 2D sketches and 3D facial structures, including: (1) accurately extracting facial keypoints from 2D sketches; (2) preserving diverse facial expressions and fine-grained texture details; and (3) training a high-performing model with limited data. In this paper, we propose Sketch-1-to-3, a novel framework for realistic 3D face reconstruction from a single sketch, to address these challenges. Specifically, we first introduce the Geometric Contour and Texture Detail (GCTD) module, which enhances the extraction of geometric contours and texture details from facial sketches. Additionally, we design a deep learning architecture with a domain adaptation module and a tailored loss function to align sketches with the 3D facial space, enabling high-fidelity expression and texture reconstruction. To facilitate evaluation and further research, we construct SketchFaces, a real hand-drawn facial sketch dataset, and Syn-SketchFaces, a synthetic facial sketch dataset. Extensive experiments demonstrate that Sketch-1-to-3 achieves state-of-the-art performance in sketch-based 3D face reconstruction.",
    "published": "2025-02-25T04:58:17Z",
    "updated": "2025-11-24T07:57:57Z",
    "link": "http://arxiv.org/pdf/2502.17852v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Liting Wen",
      "Zimo Yang",
      "Xianlin Zhang",
      "Chi Ding",
      "Mingdao Wang",
      "Xueming Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18859v1",
    "title": "Robust and Generalizable GNN Fine-Tuning via Uncertainty-aware Adapter Learning",
    "summary": "Recently, fine-tuning large-scale pre-trained GNNs has yielded remarkable attention in adapting pre-trained GNN models for downstream graph learning tasks. One representative fine-tuning method is to exploit adapter (termed AdapterGNN) which aims to 'augment' the pre-trained model by inserting a lightweight module to make the 'augmented' model better adapt to the downstream tasks. However, graph data may contain various types of noise in downstream tasks, such as noisy edges and ambiguous node attributes. Existing AdapterGNNs are often prone to graph noise and exhibit limited generalizability. How to enhance the robustness and generalization ability of GNNs' fine tuning remains an open problem. In this paper, we show that the above problem can be well addressed by integrating uncertainty learning into the GNN adapter. We propose the Uncertainty-aware Adapter (UAdapterGNN) that fortifies pre-trained GNN models against noisy graph data in the fine-tuning process. Specifically, in contrast to regular AdapterGNN, our UAdapterGNN exploits Gaussian probabilistic adapter to augment the pre-trained GNN model. In this way, when the graph contains various noises,our method can automatically absorb the effects of changes in the variances of the Gaussian distribution, thereby significantly enhancing the model's robustness. Also, UAdapterGNN can further improve the generalization ability of the model on the downstream tasks. Extensive experiments on several benchmarks demonstrate the effectiveness, robustness and high generalization ability of the proposed UAdapterGNN method.",
    "published": "2025-11-24T07:57:37Z",
    "updated": "2025-11-24T07:57:37Z",
    "link": "http://arxiv.org/pdf/2511.18859v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Bo Jiang",
      "Weijun Zhao",
      "Beibei Wang",
      "Xiao Wang",
      "Jin Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18858v1",
    "title": "Rethinking Long-tailed Dataset Distillation: A Uni-Level Framework with Unbiased Recovery and Relabeling",
    "summary": "Dataset distillation creates a small distilled set that enables efficient training by capturing key information from the full dataset. While existing dataset distillation methods perform well on balanced datasets, they struggle under long-tailed distributions, where imbalanced class frequencies induce biased model representations and corrupt statistical estimates such as Batch Normalization (BN) statistics. In this paper, we rethink long-tailed dataset distillation by revisiting the limitations of trajectory-based methods, and instead adopt the statistical alignment perspective to jointly mitigate model bias and restore fair supervision. To this end, we introduce three dedicated components that enable unbiased recovery of distilled images and soft relabeling: (1) enhancing expert models (an observer model for recovery and a teacher model for relabeling) to enable reliable statistics estimation and soft-label generation; (2) recalibrating BN statistics via a full forward pass with dynamically adjusted momentum to reduce representation skew; (3) initializing synthetic images by incrementally selecting high-confidence and diverse augmentations via a multi-round mechanism that promotes coverage and diversity. Extensive experiments on four long-tailed benchmarks show consistent improvements over state-of-the-art methods across varying degrees of class imbalance.Notably, our approach improves top-1 accuracy by 15.6% on CIFAR-100-LT and 11.8% on Tiny-ImageNet-LT under IPC=10 and IF=10.",
    "published": "2025-11-24T07:57:01Z",
    "updated": "2025-11-24T07:57:01Z",
    "link": "http://arxiv.org/pdf/2511.18858v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiao Cui",
      "Yulei Qin",
      "Xinyue Li",
      "Wengang Zhou",
      "Hongsheng Li",
      "Houqiang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.13861v4",
    "title": "PositionIC: Unified Position and Identity Consistency for Image Customization",
    "summary": "Recent subject-driven image customization excels in fidelity, yet fine-grained instance-level spatial control remains an elusive challenge, hindering real-world applications. This limitation stems from two factors: a scarcity of scalable, position-annotated datasets, and the entanglement of identity and layout by global attention mechanisms. To this end, we introduce \\modelname{}, a unified framework for high-fidelity, spatially controllable multi-subject customization. First, we present BMPDS, the first automatic data-synthesis pipeline for position-annotated multi-subject datasets, effectively providing crucial spatial supervision. Second, we design a lightweight, layout-aware diffusion framework that integrates a novel visibility-aware attention mechanism. This mechanism explicitly models spatial relationships via an NeRF-inspired volumetric weight regulation to effectively decouple instance-level spatial embeddings from semantic identity features, enabling precise, occlusion-aware placement of multiple subjects.\n  Extensive experiments demonstrate \\modelname{} achieves state-of-the-art performance on public benchmarks, setting new records for spatial precision and identity consistency. Our work represents a significant step towards truly controllable, high-fidelity image customization in multi-entity scenarios. Code and data will be publicly released.",
    "published": "2025-07-18T12:35:47Z",
    "updated": "2025-11-24T07:52:10Z",
    "link": "http://arxiv.org/pdf/2507.13861v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junjie Hu",
      "Tianyang Han",
      "Kai Ma",
      "Jialin Gao",
      "Song Yang",
      "Xianhua He",
      "Junfeng Luo",
      "Xiaoming Wei",
      "Wenqiang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18851v1",
    "title": "Robust Long-term Test-Time Adaptation for 3D Human Pose Estimation through Motion Discretization",
    "summary": "Online test-time adaptation addresses the train-test domain gap by adapting the model on unlabeled streaming test inputs before making the final prediction. However, online adaptation for 3D human pose estimation suffers from error accumulation when relying on self-supervision with imperfect predictions, leading to degraded performance over time. To mitigate this fundamental challenge, we propose a novel solution that highlights the use of motion discretization. Specifically, we employ unsupervised clustering in the latent motion representation space to derive a set of anchor motions, whose regularity aids in supervising the human pose estimator and enables efficient self-replay. Additionally, we introduce an effective and efficient soft-reset mechanism by reverting the pose estimator to its exponential moving average during continuous adaptation. We examine long-term online adaptation by continuously adapting to out-of-domain streaming test videos of the same individual, which allows for the capture of consistent personal shape and motion traits throughout the streaming observation. By mitigating error accumulation, our solution enables robust exploitation of these personal traits for enhanced accuracy. Experiments demonstrate that our solution outperforms previous online test-time adaptation methods and validate our design choices.",
    "published": "2025-11-24T07:46:58Z",
    "updated": "2025-11-24T07:46:58Z",
    "link": "http://arxiv.org/pdf/2511.18851v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yilin Wen",
      "Kechuan Dong",
      "Yusuke Sugano"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.22174v3",
    "title": "Synergistic Bleeding Region and Point Detection in Laparoscopic Surgical Videos",
    "summary": "Intraoperative bleeding in laparoscopic surgery causes rapid obscuration of the operative field to hinder the surgical process and increases the risk of postoperative complications. Intelligent detection of bleeding areas can quantify the blood loss to assist decision-making, while locating bleeding points helps surgeons quickly identify the source of bleeding and achieve hemostasis in time to improve surgical success rates. To fill the benchmark gap, we first construct a real-world laparoscopic surgical bleeding detection dataset, named SurgBlood, comprising 5,330 frames from 95 surgical video clips with bleeding region and point annotations. Accordingly, we develop a dual-task synergistic online detector called BlooDet, enabling simultaneous detection of bleeding regions and points in laparoscopic surgery. The baseline embraces a dual-branch bidirectional guid- ance design based on Segment Anything Model 2. The mask branch detects bleeding regions through adaptive edge and point prompt embeddings, while the point branch leverages mask memory to induce bleeding point memory modeling and captures point motion direction via inter-frame optical flow. By coupled bidirectional guidance, our framework explores spatial-temporal correlations while exploiting memory modeling to infer current bleeding status. Extensive experiments indicate that our method outperforms 13 counterparts in bleeding detection.",
    "published": "2025-03-28T06:27:55Z",
    "updated": "2025-11-24T07:45:44Z",
    "link": "http://arxiv.org/pdf/2503.22174v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jialun Pei",
      "Zhangjun Zhou",
      "Diandian Guo",
      "Zhixi Li",
      "Jing Qin",
      "Bo Du",
      "Pheng-Ann Heng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.17951v2",
    "title": "SplatCo: Structure-View Collaborative Gaussian Splatting for Detail-Preserving Rendering of Large-Scale Unbounded Scenes",
    "summary": "We present SplatCo, a structure-view collaborative Gaussian splatting framework for high-fidelity rendering of complex outdoor environments. SplatCo builds upon two novel components: (1) a cross-structure collaboration module that combines global tri-plane representations, which capture coarse scene layouts, with local context grid features that represent fine surface details. This fusion is achieved through a novel hierarchical compensation strategy, ensuring both global consistency and local detail preservation; and (2) a cross-view assisted training strategy that enhances multi-view consistency by synchronizing gradient updates across viewpoints, applying visibility-aware densification, and pruning overfitted or inaccurate Gaussians based on structural consistency. Through joint optimization of structural representation and multi-view coherence, SplatCo effectively reconstructs fine-grained geometric structures and complex textures in large-scale scenes. Comprehensive evaluations on 13 diverse large-scale scenes, including Mill19, MatrixCity, Tanks & Temples, WHU, and custom aerial captures, demonstrate that SplatCo consistently achieves higher reconstruction quality than state-of-the-art methods, with PSNR improvements of 1-2 dB and SSIM gains of 0.1 to 0.2. These results establish a new benchmark for high-fidelity rendering of large-scale unbounded scenes. Code and additional information are available at https://github.com/SCUT-BIP-Lab/SplatCo.",
    "published": "2025-05-23T14:27:12Z",
    "updated": "2025-11-24T07:37:20Z",
    "link": "http://arxiv.org/pdf/2505.17951v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Haihong Xiao",
      "Jianan Zou",
      "Yuxin Zhou",
      "Ying He",
      "Wenxiong Kang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20951v4",
    "title": "DSOcc: Leveraging Depth Awareness and Semantic Aid to Boost Camera-Based 3D Semantic Occupancy Prediction",
    "summary": "Camera-based 3D semantic occupancy prediction offers an efficient and cost-effective solution for perceiving surrounding scenes in autonomous driving. However, existing works rely on explicit occupancy state inference, leading to numerous incorrect feature assignments, and insufficient samples restrict the learning of occupancy class inference. To address these challenges, we propose leveraging \\textbf{D}epth awareness and \\textbf{S}emantic aid to boost camera-based 3D semantic \\textbf{Occ}upancy prediction (\\textbf{DSOcc}). We jointly perform occupancy state and occupancy class inference, where soft occupancy confidence is calculated by non-learning method and multiplied with image features to make voxels aware of depth, enabling adaptive implicit occupancy state inference. Instead of enhancing feature learning, we directly utilize well-trained image semantic segmentation and fuse multiple frames with their occupancy probabilities to aid occupancy class inference, thereby enhancing robustness. Experimental results demonstrate that DSOcc achieves state-of-the-art performance on the SemanticKITTI dataset among camera-based methods and achieves competitive performance on the SSCBench-KITTI-360 and Occ3D-nuScenes datasets. Code will be released on github.",
    "published": "2025-05-27T09:45:00Z",
    "updated": "2025-11-24T07:25:10Z",
    "link": "http://arxiv.org/pdf/2505.20951v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Naiyu Fang",
      "Zheyuan Zhou",
      "Kang Wang",
      "Ruibo Li",
      "Lemiao Qiu",
      "Shuyou Zhang",
      "Zhe Wang",
      "Guosheng Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.23951v3",
    "title": "JointTuner: Appearance-Motion Adaptive Joint Training for Customized Video Generation",
    "summary": "Recent advancements in customized video generation have led to significant improvements in the simultaneous adaptation of appearance and motion. Typically, decoupling the appearance and motion training, prior methods often introduce concept interference, resulting in inaccurate rendering of appearance features or motion patterns. In addition, these methods often suffer from appearance contamination, in which background and foreground elements from reference videos distort the customized video. This paper aims to alleviate these issues by proposing JointTuner. The core motivation of our JointTuner is to enable joint optimization of both appearance and motion components, upon which two key innovations are developed, i.e., Gated Low-Rank Adaptation (GLoRA) and Appearance-independent Temporal Loss (AiT Loss). Specifically, GLoRA uses a context-aware activation layer, analogous to a gating regulator, to dynamically steer LoRA modules toward learning either appearance or motion while maintaining spatio-temporal consistency. Moreover, with the finding that channel-temporal shift noise suppresses appearance-related low-frequencies while enhancing motion-related high-frequencies, we designed the AiT Loss. This loss adds the same shift to the diffusion model's predicted noise during fine-tuning, forcing the model to prioritize learning motion patterns. JointTuner's architecture-agnostic design supports both UNet (e.g., ZeroScope) and Diffusion Transformer (e.g., CogVideoX) backbones, ensuring its customization capabilities scale with the evolution of foundational video models. Furthermore, we present a systematic evaluation framework for appearance-motion combined customization, covering 90 combinations evaluated along four critical dimensions: semantic alignment, motion dynamism, temporal consistency, and perceptual quality. Our project homepage is available online.",
    "published": "2025-03-31T11:04:07Z",
    "updated": "2025-11-24T07:22:57Z",
    "link": "http://arxiv.org/pdf/2503.23951v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Fangda Chen",
      "Shanshan Zhao",
      "Chuanfu Xu",
      "Long Lan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18839v1",
    "title": "Enhancing Multi-Label Thoracic Disease Diagnosis with Deep Ensemble-Based Uncertainty Quantification",
    "summary": "The utility of deep learning models, such as CheXNet, in high stakes clinical settings is fundamentally constrained by their purely deterministic nature, failing to provide reliable measures of predictive confidence. This project addresses this critical gap by integrating robust Uncertainty Quantification (UQ) into a high performance diagnostic platform for 14 common thoracic diseases on the NIH ChestX-ray14 dataset. Initial architectural development failed to stabilize performance and calibration using Monte Carlo Dropout (MCD), yielding an unacceptable Expected Calibration Error (ECE) of 0.7588. This technical failure necessitated a rigorous architectural pivot to a high diversity, 9-member Deep Ensemble (DE). This resulting DE successfully stabilized performance and delivered superior reliability, achieving a State-of-the-Art (SOTA) average Area Under the Receiver Operating Characteristic Curve (AUROC) of 0.8559 and an average F1 Score of 0.3857. Crucially, the DE demonstrated superior calibration (Mean ECE of 0.0728 and Negative Log-Likelihood (NLL) of 0.1916) and enabled the reliable decomposition of total uncertainty into its Aleatoric (irreducible data noise) and Epistemic (reducible model knowledge) components, with a mean Epistemic Uncertainty (EU) of 0.0240. These results establish the Deep Ensemble as a trustworthy and explainable platform, transforming the model from a probabilistic tool into a reliable clinical decision support system.",
    "published": "2025-11-24T07:20:40Z",
    "updated": "2025-11-24T07:20:40Z",
    "link": "http://arxiv.org/pdf/2511.18839v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Yasiru Laksara",
      "Uthayasanker Thayasivam"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18838v1",
    "title": "FVAR: Visual Autoregressive Modeling via Next Focus Prediction",
    "summary": "Visual autoregressive models achieve remarkable generation quality through next-scale predictions across multi-scale token pyramids. However, the conventional method uses uniform scale downsampling to build these pyramids, leading to aliasing artifacts that compromise fine details and introduce unwanted jaggies and moiré patterns. To tackle this issue, we present \\textbf{FVAR}, which reframes the paradigm from \\emph{next-scale prediction} to \\emph{next-focus prediction}, mimicking the natural process of camera focusing from blur to clarity. Our approach introduces three key innovations: \\textbf{1) Next-Focus Prediction Paradigm} that transforms multi-scale autoregression by progressively reducing blur rather than simply downsampling; \\textbf{2) Progressive Refocusing Pyramid Construction} that uses physics-consistent defocus kernels to build clean, alias-free multi-scale representations; and \\textbf{3) High-Frequency Residual Learning} that employs a specialized residual teacher network to effectively incorporate alias information during training while maintaining deployment simplicity. Specifically, we construct optical low-pass views using defocus point spread function (PSF) kernels with decreasing radius, creating smooth blur-to-clarity transitions that eliminate aliasing at its source. To further enhance detail generation, we introduce a High-Frequency Residual Teacher that learns from both clean structure and alias residuals, distilling this knowledge to a vanilla VAR deployment network for seamless inference. Extensive experiments on ImageNet demonstrate that FVAR substantially reduces aliasing artifacts, improves fine detail preservation, and enhances text readability, achieving superior performance with perfect compatibility to existing VAR frameworks.",
    "published": "2025-11-24T07:19:04Z",
    "updated": "2025-11-24T07:19:04Z",
    "link": "http://arxiv.org/pdf/2511.18838v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiaofan Li",
      "Chenming Wu",
      "Yanpeng Sun",
      "Jiaming Zhou",
      "Delin Qu",
      "Yansong Qu",
      "Weihao Bo",
      "Haibao Yu",
      "Dingkang Liang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.13009v2",
    "title": "Matrix-game 2.0: An open-source real-time and streaming interactive world model",
    "summary": "Recent advances in interactive video generations have demonstrated diffusion model's potential as world models by capturing complex physical dynamics and interactive behaviors. However, existing interactive world models depend on bidirectional attention and lengthy inference steps, severely limiting real-time performance. Consequently, they are hard to simulate real-world dynamics, where outcomes must update instantaneously based on historical context and current actions. To address this, we present Matrix-Game 2.0, an interactive world model generates long videos on-the-fly via few-step auto-regressive diffusion. Our framework consists of three key components: (1) A scalable data production pipeline for Unreal Engine and GTA5 environments to effectively produce massive amounts (about 1200 hours) of video data with diverse interaction annotations; (2) An action injection module that enables frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step distillation based on the casual architecture for real-time and streaming video generation. Matrix Game 2.0 can generate high-quality minute-level videos across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our model weights and codebase to advance research in interactive world modeling.",
    "published": "2025-08-18T15:28:53Z",
    "updated": "2025-11-24T07:16:26Z",
    "link": "http://arxiv.org/pdf/2508.13009v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xianglong He",
      "Chunli Peng",
      "Zexiang Liu",
      "Boyang Wang",
      "Yifan Zhang",
      "Qi Cui",
      "Fei Kang",
      "Biao Jiang",
      "Mengyin An",
      "Yangyang Ren",
      "Baixin Xu",
      "Hao-Xiang Guo",
      "Kaixiong Gong",
      "Cyrus Wu",
      "Wei Li",
      "Xuchen Song",
      "Yang Liu",
      "Eric Li",
      "Yahui Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14477v2",
    "title": "2D Gaussians Spatial Transport for Point-supervised Density Regression",
    "summary": "This paper introduces Gaussian Spatial Transport (GST), a novel framework that leverages Gaussian splatting to facilitate transport from the probability measure in the image coordinate space to the annotation map. We propose a Gaussian splatting-based method to estimate pixel-annotation correspondence, which is then used to compute a transport plan derived from Bayesian probability. To integrate the resulting transport plan into standard network optimization in typical computer vision tasks, we derive a loss function that measures discrepancy after transport. Extensive experiments on representative computer vision tasks, including crowd counting and landmark detection, validate the effectiveness of our approach. Compared to conventional optimal transport schemes, GST eliminates iterative transport plan computation during training, significantly improving efficiency. Code is available at https://github.com/infinite0522/GST.",
    "published": "2025-11-18T13:16:29Z",
    "updated": "2025-11-24T07:16:18Z",
    "link": "http://arxiv.org/pdf/2511.14477v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Miao Shang",
      "Xiaopeng Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18833v1",
    "title": "PrismAudio: Decomposed Chain-of-Thoughts and Multi-dimensional Rewards for Video-to-Audio Generation",
    "summary": "Video-to-Audio (V2A) generation requires balancing four critical perceptual dimensions: semantic consistency, audio-visual temporal synchrony, aesthetic quality, and spatial accuracy; yet existing methods suffer from objective entanglement that conflates competing goals in single loss functions and lack human preference alignment. We introduce PrismAudio, the first framework to integrate Reinforcement Learning into V2A generation with specialized Chain-of-Thought (CoT) planning. Our approach decomposes monolithic reasoning into four specialized CoT modules (Semantic, Temporal, Aesthetic, and Spatial CoT), each paired with targeted reward functions. This CoT-reward correspondence enables multidimensional RL optimization that guides the model to jointly generate better reasoning across all perspectives, solving the objective entanglement problem while preserving interpretability. To make this optimization computationally practical, we propose Fast-GRPO, which employs hybrid ODE-SDE sampling that dramatically reduces the training overhead compared to existing GRPO implementations. We also introduce AudioCanvas, a rigorous benchmark that is more distributionally balanced and covers more realistically diverse and challenging scenarios than existing datasets, with 300 single-event classes and 501 multi-event samples. Experimental results demonstrate that PrismAudio achieves state-of-the-art performance across all four perceptual dimensions on both the in-domain VGGSound test set and out-of-domain AudioCanvas benchmark. The project page is available at https://PrismAudio-Project.github.io.",
    "published": "2025-11-24T07:11:12Z",
    "updated": "2025-11-24T07:11:12Z",
    "link": "http://arxiv.org/pdf/2511.18833v1.pdf",
    "category": [
      "cs.SD",
      "cs.CV",
      "eess.AS",
      "eess.IV"
    ],
    "authors": [
      "Huadai Liu",
      "Kaicheng Luo",
      "Wen Wang",
      "Qian Chen",
      "Peiwen Sun",
      "Rongjie Huang",
      "Xiangang Li",
      "Jieping Ye",
      "Wei Xue"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18831v1",
    "title": "VideoCompressa: Data-Efficient Video Understanding via Joint Temporal Compression and Spatial Reconstruction",
    "summary": "The scalability of video understanding models is increasingly limited by the prohibitive storage and computational costs of large-scale video datasets. While data synthesis has improved data efficiency in the image domain, its extension to video remains challenging due to pervasive temporal redundancy and complex spatiotemporal dynamics. In this work, we uncover a critical insight: the primary source of inefficiency in video datasets is not inter-sample redundancy, but intra-sample frame-level redundancy. To leverage this insight, we introduce VideoCompressa, a novel framework for video data synthesis that reframes the problem as dynamic latent compression. Specifically, VideoCompressa jointly optimizes a differentiable keyframe selector-implemented as a lightweight ConvNet with Gumbel-Softmax sampling-to identify the most informative frames, and a pretrained, frozen Variational Autoencoder (VAE) to compress these frames into compact, semantically rich latent codes. These latent representations are then fed into a compression network, enabling end-to-end backpropagation. Crucially, the keyframe selector and synthetic latent codes are co-optimized to maximize retention of task-relevant information. Experiments show that our method achieves unprecedented data efficiency: on UCF101 with ConvNets, VideoCompressa surpasses full-data training by 2.34\\% points using only 0.13\\% of the original data, with over 5800x speedup compared to traditional synthesis method. Moreover, when fine-tuning Qwen2.5-7B-VL on HMDB51, VideoCompressa matches full-data performance using just 0.41\\% of the training data-outperforming zero-shot baseline by 10.61\\%.",
    "published": "2025-11-24T07:07:58Z",
    "updated": "2025-11-24T07:07:58Z",
    "link": "http://arxiv.org/pdf/2511.18831v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shaobo Wang",
      "Tianle Niu",
      "Runkang Yang",
      "Deshan Liu",
      "Xu He",
      "Zichen Wen",
      "Conghui He",
      "Xuming Hu",
      "Linfeng Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18827v1",
    "title": "Leveraging Metaheuristic Approaches to Improve Deep Learning Systems for Anxiety Disorder Detection",
    "summary": "Despite being among the most common psychological disorders, anxiety-related conditions are still primarily identified through subjective assessments, such as clinical interviews and self-evaluation questionnaires. These conventional methods often require significant time and may vary depending on the evaluator. However, the emergence of advanced artificial intelligence techniques has created new opportunities for detecting anxiety in a more consistent and automated manner. To address the limitations of traditional approaches, this study introduces a comprehensive model that integrates deep learning architectures with optimization strategies inspired by swarm intelligence. Using multimodal and wearable-sensor datasets, the framework analyzes physiological, emotional, and behavioral signals. Swarm intelligence techniques including genetic algorithms and particle swarm optimization are incorporated to refine the feature space and optimize hyperparameters. Meanwhile, deep learning components are tasked with deriving layered and discriminative representations from sequential, multi-source inputs. Our evaluation shows that the fusion of these two computational paradigms significantly enhances detection performance compared with using deep networks alone. The hybrid model achieves notable improvements in accuracy and demonstrates stronger generalization across various individuals. Overall, the results highlight the potential of combining metaheuristic optimization with deep learning to develop scalable, objective, and clinically meaningful solutions for assessing anxiety disorders",
    "published": "2025-11-24T07:03:15Z",
    "updated": "2025-11-24T07:03:15Z",
    "link": "http://arxiv.org/pdf/2511.18827v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Mohammadreza Amiri",
      "Monireh Hosseini"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18826v1",
    "title": "Uncertainty-Aware Dual-Student Knowledge Distillation for Efficient Image Classification",
    "summary": "Knowledge distillation has emerged as a powerful technique for model compression, enabling the transfer of knowledge from large teacher networks to compact student models. However, traditional knowledge distillation methods treat all teacher predictions equally, regardless of the teacher's confidence in those predictions. This paper proposes an uncertainty-aware dual-student knowledge distillation framework that leverages teacher prediction uncertainty to selectively guide student learning. We introduce a peer-learning mechanism where two heterogeneous student architectures, specifically ResNet-18 and MobileNetV2, learn collaboratively from both the teacher network and each other. Experimental results on ImageNet-100 demonstrate that our approach achieves superior performance compared to baseline knowledge distillation methods, with ResNet-18 achieving 83.84\\% top-1 accuracy and MobileNetV2 achieving 81.46\\% top-1 accuracy, representing improvements of 2.04\\% and 0.92\\% respectively over traditional single-student distillation approaches.",
    "published": "2025-11-24T07:02:22Z",
    "updated": "2025-11-24T07:02:22Z",
    "link": "http://arxiv.org/pdf/2511.18826v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Aakash Gore",
      "Anoushka Dey",
      "Aryan Mishra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18825v1",
    "title": "Q-Save: Towards Scoring and Attribution for Generated Video Evaluation",
    "summary": "We present Q-Save, a new benchmark dataset and model for holistic and explainable evaluation of AI-generated video (AIGV) quality. The dataset contains near 10000 videos, each annotated with a scalar mean opinion score (MOS) and fine-grained attribution labels along three core dimensions: visual quality, dynamic quality, and text-video alignment. These multi-aspect annotations enable both accurate quality assessment and interpretable reasoning behind the scores. To leverage this data, we propose a unified evaluation model that jointly performs quality scoring and attribution-based explanation. The model adopts the SlowFast framework to distinguish between fast frames and slow frames - slow frames are processed with high resolution while fast frames use low resolution, balancing evaluation accuracy and computational efficiency. For training, we use data formatted in Chain-of-Thought (COT) style and employ a multi-stage strategy: we first conduct Supervised Fine-Tuning (SFT), then further enhance the model with Grouped Relative Policy Optimization (GRPO), and finally perform SFT again to improve model stability. Experimental results demonstrate that our model achieves state-of-the-art performance in video quality prediction while also providing human-aligned, interpretable justifications. Our dataset and model establish a strong foundation for explainable evaluation in generative video research, contributing to the development of multimodal generation and trustworthy AI. Code and dataset will be released upon publication.",
    "published": "2025-11-24T07:00:21Z",
    "updated": "2025-11-24T07:00:21Z",
    "link": "http://arxiv.org/pdf/2511.18825v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiele Wu",
      "Zicheng Zhang",
      "Mingtao Chen",
      "Yixian Liu",
      "Yiming Liu",
      "Shushi Wang",
      "Zhichao Hu",
      "Yuhong Liu",
      "Guangtao Zhai",
      "Xiaohong Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18823v1",
    "title": "VideoPerceiver: Enhancing Fine-Grained Temporal Perception in Video Multimodal Large Language Models",
    "summary": "We propose VideoPerceiver, a novel video multimodal large language model (VMLLM) that enhances fine-grained perception in video understanding, addressing VMLLMs' limited ability to reason about brief actions in short clips or rare transient events in long videos. VideoPerceiver adopts a two-stage training framework. During supervised fine-tuning (SFT), we construct \"key-information-missing\" videos by extracting event-action keywords from captions, identifying corresponding key frames, and replacing them with adjacent frames. We jointly encode original and modified video tokens with text tokens, aligning intermediate visual representations with keywords via an auxiliary contrastive loss to enhance sensitivity to fine-grained motion cues. In reinforcement learning (RL), both video variants are fed into the model to generate descriptions, and a novel relative reward ensures responses from complete videos outperform those from degraded inputs, explicitly training the model to recover temporally precise action details. We also curate a dataset of 80,000 videos with fine-grained actions and transient events. Experiments show VideoPerceiver substantially outperforms state-of-the-art VMLLMs on fine-grained action understanding and rare event captioning benchmarks, while maintaining strong performance on standard tasks. By prioritizing task-relevant visual features, our work redefines video-language model training for fine-grained perception.",
    "published": "2025-11-24T06:57:26Z",
    "updated": "2025-11-24T06:57:26Z",
    "link": "http://arxiv.org/pdf/2511.18823v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Fufangchen Zhao",
      "Liao Zhang",
      "Daiqi Shi",
      "Yuanjun Gao",
      "Chen Ye",
      "Yang Cai",
      "Jian Gao",
      "Danfeng Yan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18822v1",
    "title": "DiP: Taming Diffusion Models in Pixel Space",
    "summary": "Diffusion models face a fundamental trade-off between generation quality and computational efficiency. Latent Diffusion Models (LDMs) offer an efficient solution but suffer from potential information loss and non-end-to-end training. In contrast, existing pixel space models bypass VAEs but are computationally prohibitive for high-resolution synthesis. To resolve this dilemma, we propose DiP, an efficient pixel space diffusion framework. DiP decouples generation into a global and a local stage: a Diffusion Transformer (DiT) backbone operates on large patches for efficient global structure construction, while a co-trained lightweight Patch Detailer Head leverages contextual features to restore fine-grained local details. This synergistic design achieves computational efficiency comparable to LDMs without relying on a VAE. DiP is accomplished with up to 10$\\times$ faster inference speeds than previous method while increasing the total number of parameters by only 0.3%, and achieves an 1.90 FID score on ImageNet 256$\\times$256.",
    "published": "2025-11-24T06:55:49Z",
    "updated": "2025-11-24T06:55:49Z",
    "link": "http://arxiv.org/pdf/2511.18822v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhennan Chen",
      "Junwei Zhu",
      "Xu Chen",
      "Jiangning Zhang",
      "Xiaobin Hu",
      "Hanzhen Zhao",
      "Chengjie Wang",
      "Jian Yang",
      "Ying Tai"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18817v1",
    "title": "Disc3D: Automatic Curation of High-Quality 3D Dialog Data via Discriminative Object Referring",
    "summary": "3D Multi-modal Large Language Models (MLLMs) still lag behind their 2D peers, largely because large-scale, high-quality 3D scene-dialogue datasets remain scarce. Prior efforts hinge on expensive human annotation and leave two key ambiguities unresolved: viewpoint ambiguity, where spatial language presumes unknown camera poses, and object referring ambiguity, where non-exclusive descriptions blur the line between targets and distractors. We therefore present a fully automated pipeline that converts raw 3D scans into unambiguous, high-quality dialogue data at a fraction of the previous cost. By synergizing rule-based constraints with 2D MLLMs and LLMs, the pipeline enables controllable, scalable generation without human intervention. The pipeline comprises four stages: (1) meta-annotation collection harvesting object-, frame-, and scene-level captions, (2) scene graph construction with relation correction to capture proximal object relations, (3) discriminative object referring that generates exclusive and compact descriptions, and (4) multi-task data generation synthesizing diverse dialogues. Our pipeline systematically mitigates inherent flaws in source datasets and produces the final Disc3D dataset, over 2 million samples in 25K hybrid 3D scenes, spanning scene, view, and object captioning, visual grounding, and five object-centric QA tasks. Extensive experiments demonstrate that training with Disc3D yields consistent, significant improvements on both public benchmarks and our multifaceted Disc3D-QA tasks. Code, data, and models will be publicly available.",
    "published": "2025-11-24T06:51:34Z",
    "updated": "2025-11-24T06:51:34Z",
    "link": "http://arxiv.org/pdf/2511.18817v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Siyuan Wei",
      "Chunjie Wang",
      "Xiao Liu",
      "Xiaosheng Yan",
      "Zhishan Zhou",
      "Rui Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.03726v2",
    "title": "DICE: Distilling Classifier-Free Guidance into Text Embeddings",
    "summary": "Text-to-image diffusion models are capable of generating high-quality images, but suboptimal pre-trained text representations often result in these images failing to align closely with the given text prompts. Classifier-free guidance (CFG) is a popular and effective technique for improving text-image alignment in the generative process. However, CFG introduces significant computational overhead. In this paper, we present DIstilling CFG by sharpening text Embeddings (DICE) that replaces CFG in the sampling process with half the computational complexity while maintaining similar generation quality. DICE distills a CFG-based text-to-image diffusion model into a CFG-free version by refining text embeddings to replicate CFG-based directions. In this way, we avoid the computational drawbacks of CFG, enabling high-quality, well-aligned image generation at a fast sampling speed. Furthermore, examining the enhancement pattern, we identify the underlying mechanism of DICE that sharpens specific components of text embeddings to preserve semantic information while enhancing fine-grained details. Extensive experiments on multiple Stable Diffusion v1.5 variants, SDXL, and PixArt-$α$ demonstrate the effectiveness of our method. Code is available at https://github.com/zju-pi/dice.",
    "published": "2025-02-06T02:39:45Z",
    "updated": "2025-11-24T06:51:25Z",
    "link": "http://arxiv.org/pdf/2502.03726v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhenyu Zhou",
      "Defang Chen",
      "Can Wang",
      "Chun Chen",
      "Siwei Lyu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18816v1",
    "title": "SupLID: Geometrical Guidance for Out-of-Distribution Detection in Semantic Segmentation",
    "summary": "Out-of-Distribution (OOD) detection in semantic segmentation aims to localize anomalous regions at the pixel level, advancing beyond traditional image-level OOD techniques to better suit real-world applications such as autonomous driving. Recent literature has successfully explored the adaptation of commonly used image-level OOD methods--primarily based on classifier-derived confidence scores (e.g., energy or entropy)--for this pixel-precise task. However, these methods inherit a set of limitations, including vulnerability to overconfidence. In this work, we introduce SupLID, a novel framework that effectively guides classifier-derived OOD scores by exploiting the geometrical structure of the underlying semantic space, particularly using Linear Intrinsic Dimensionality (LID). While LID effectively characterizes the local structure of high-dimensional data by analyzing distance distributions, its direct application at the pixel level remains challenging. To overcome this, SupLID constructs a geometrical coreset that captures the intrinsic structure of the in-distribution (ID) subspace. It then computes OOD scores at the superpixel level, enabling both efficient real-time inference and improved spatial smoothness. We demonstrate that geometrical cues derived from SupLID serve as a complementary signal to traditional classifier confidence, enhancing the model's ability to detect diverse OOD scenarios. Designed as a post-hoc scoring method, SupLID can be seamlessly integrated with any semantic segmentation classifier at deployment time. Our results demonstrate that SupLID significantly enhances existing classifier-based OOD scores, achieving state-of-the-art performance across key evaluation metrics, including AUR, FPR, and AUP. Code is available at https://github.com/hdnugit/SupLID.",
    "published": "2025-11-24T06:49:54Z",
    "updated": "2025-11-24T06:49:54Z",
    "link": "http://arxiv.org/pdf/2511.18816v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Nimeshika Udayangani",
      "Sarah Erfani",
      "Christopher Leckie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18814v1",
    "title": "DetAny4D: Detect Anything 4D Temporally in a Streaming RGB Video",
    "summary": "Reliable 4D object detection, which refers to 3D object detection in streaming video, is crucial for perceiving and understanding the real world. Existing open-set 4D object detection methods typically make predictions on a frame-by-frame basis without modeling temporal consistency, or rely on complex multi-stage pipelines that are prone to error propagation across cascaded stages. Progress in this area has been hindered by the lack of large-scale datasets that capture continuous reliable 3D bounding box (b-box) annotations. To overcome these challenges, we first introduce DA4D, a large-scale 4D detection dataset containing over 280k sequences with high-quality b-box annotations collected under diverse conditions. Building on DA4D, we propose DetAny4D, an open-set end-to-end framework that predicts 3D b-boxes directly from sequential inputs. DetAny4D fuses multi-modal features from pre-trained foundational models and designs a geometry-aware spatiotemporal decoder to effectively capture both spatial and temporal dynamics. Furthermore, it adopts a multi-task learning architecture coupled with a dedicated training strategy to maintain global consistency across sequences of varying lengths. Extensive experiments show that DetAny4D achieves competitive detection accuracy and significantly improves temporal stability, effectively addressing long-standing issues of jitter and inconsistency in 4D object detection. Data and code will be released upon acceptance.",
    "published": "2025-11-24T06:42:17Z",
    "updated": "2025-11-24T06:42:17Z",
    "link": "http://arxiv.org/pdf/2511.18814v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Jiawei Hou",
      "Shenghao Zhang",
      "Can Wang",
      "Zheng Gu",
      "Yonggen Ling",
      "Taiping Zeng",
      "Xiangyang Xue",
      "Jingbo Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18806v1",
    "title": "TPG-INR: Target Prior-Guided Implicit 3D CT Reconstruction for Enhanced Sparse-view Imaging",
    "summary": "X-ray imaging, based on penetration, enables detailed visualization of internal structures. Building on this capability, existing implicit 3D reconstruction methods have adapted the NeRF model and its variants for internal CT reconstruction. However, these approaches often neglect the significance of objects' anatomical priors for implicit learning, limiting both reconstruction precision and learning efficiency, particularly in ultra-sparse view scenarios. To address these challenges, we propose a novel 3D CT reconstruction framework that employs a 'target prior' derived from the object's projection data to enhance implicit learning. Our approach integrates positional and structural encoding to facilitate voxel-wise implicit reconstruction, utilizing the target prior to guide voxel sampling and enrich structural encoding. This dual strategy significantly boosts both learning efficiency and reconstruction quality. Additionally, we introduce a CUDA-based algorithm for rapid estimation of high-quality 3D target priors from sparse-view projections. Experiments utilizing projection data from a complex abdominal dataset demonstrate that the proposed model substantially enhances learning efficiency, outperforming the current leading model, NAF, by a factor of ten. In terms of reconstruction quality, it also exceeds the most accurate model, NeRP, achieving PSNR improvements of 3.57 dB, 5.42 dB, and 5.70 dB with 10, 20, and 30 projections, respectively. The code is available at https://github.com/qlcao171/TPG-INR.",
    "published": "2025-11-24T06:21:52Z",
    "updated": "2025-11-24T06:21:52Z",
    "link": "http://arxiv.org/pdf/2511.18806v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qinglei Cao",
      "Ziyao Tang",
      "Xiaoqin Tang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18801v1",
    "title": "PartDiffuser: Part-wise 3D Mesh Generation via Discrete Diffusion",
    "summary": "Existing autoregressive (AR) methods for generating artist-designed meshes struggle to balance global structural consistency with high-fidelity local details, and are susceptible to error accumulation. To address this, we propose PartDiffuser, a novel semi-autoregressive diffusion framework for point-cloud-to-mesh generation. The method first performs semantic segmentation on the mesh and then operates in a \"part-wise\" manner: it employs autoregression between parts to ensure global topology, while utilizing a parallel discrete diffusion process within each semantic part to precisely reconstruct high-frequency geometric features. PartDiffuser is based on the DiT architecture and introduces a part-aware cross-attention mechanism, using point clouds as hierarchical geometric conditioning to dynamically control the generation process, thereby effectively decoupling the global and local generation tasks. Experiments demonstrate that this method significantly outperforms state-of-the-art (SOTA) models in generating 3D meshes with rich detail, exhibiting exceptional detail representation suitable for real-world applications.",
    "published": "2025-11-24T06:11:21Z",
    "updated": "2025-11-24T06:11:21Z",
    "link": "http://arxiv.org/pdf/2511.18801v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yichen Yang",
      "Hong Li",
      "Haodong Zhu",
      "Linin Yang",
      "Guojun Lei",
      "Sheng Xu",
      "Baochang Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18794v1",
    "title": "ChronoGS: Disentangling Invariants and Changes in Multi-Period Scenes",
    "summary": "Multi-period image collections are common in real-world applications. Cities are re-scanned for mapping, construction sites are revisited for progress tracking, and natural regions are monitored for environmental change. Such data form multi-period scenes, where geometry and appearance evolve. Reconstructing such scenes is an important yet underexplored problem. Existing pipelines rely on incompatible assumptions: static and in-the-wild methods enforce a single geometry, while dynamic ones assume smooth motion, both failing under long-term, discontinuous changes. To solve this problem, we introduce ChronoGS, a temporally modulated Gaussian representation that reconstructs all periods within a unified anchor scaffold. It's also designed to disentangle stable and evolving components, achieving temporally consistent reconstruction of multi-period scenes. To catalyze relevant research, we release ChronoScene dataset, a benchmark of real and synthetic multi-period scenes, capturing geometric and appearance variation. Experiments demonstrate that ChronoGS consistently outperforms baselines in reconstruction quality and temporal consistency. Our code and the ChronoScene dataset are publicly available at https://github.com/ZhongtaoWang/ChronoGS.",
    "published": "2025-11-24T05:55:33Z",
    "updated": "2025-11-24T05:55:33Z",
    "link": "http://arxiv.org/pdf/2511.18794v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Zhongtao Wang",
      "Jiaqi Dai",
      "Qingtian Zhu",
      "Yilong Li",
      "Mai Su",
      "Fei Zhu",
      "Meng Gai",
      "Shaorong Wang",
      "Chengwei Pan",
      "Yisong Chen",
      "Guoping Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18792v1",
    "title": "Scale What Counts, Mask What Matters: Evaluating Foundation Models for Zero-Shot Cross-Domain Wi-Fi Sensing",
    "summary": "While Wi-Fi sensing offers a compelling, privacy-preserving alternative to cameras, its practical utility has been fundamentally undermined by a lack of robustness across domains. Models trained in one setup fail to generalize to new environments, hardware, or users, a critical \"domain shift\" problem exacerbated by modest, fragmented public datasets. We shift from this limited paradigm and apply a foundation model approach, leveraging Masked Autoencoding (MAE) style pretraining on the largest and most heterogeneous Wi-Fi CSI datasets collection assembled to date. Our study pretrains and evaluates models on over 1.3 million samples extracted from 14 datasets, collected using 4 distinct devices across the 2.4/5/6 GHz bands and bandwidths from 20 to 160 MHz. Our large-scale evaluation is the first to systematically disentangle the impacts of data diversity versus model capacity on cross-domain performance. The results establish scaling trends on Wi-Fi CSI sensing. First, our experiments show log-linear improvements in unseen domain performance as the amount of pretraining data increases, suggesting that data scale and diversity are key to domain generalization. Second, based on the current data volume, larger model can only provide marginal gains for cross-domain performance, indicating that data, rather than model capacity, is the current bottleneck for Wi-Fi sensing generalization. Finally, we conduct a series of cross-domain evaluations on human activity recognition, human gesture recognition and user identification tasks. The results show that the large-scale pretraining improves cross-domain accuracy ranging from 2.2% to 15.7%, compared to the supervised learning baseline. Overall, our findings provide insightful direction for designing future Wi-Fi sensing systems that can eventually be robust enough for real-world deployment.",
    "published": "2025-11-24T05:46:29Z",
    "updated": "2025-11-24T05:46:29Z",
    "link": "http://arxiv.org/pdf/2511.18792v1.pdf",
    "category": [
      "cs.CV",
      "cs.IT"
    ],
    "authors": [
      "Cheng Jiang",
      "Yihe Yan",
      "Yanxiang Wang",
      "Chun Tung Chou",
      "Wen Hu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18788v1",
    "title": "StereoDETR: Stereo-based Transformer for 3D Object Detection",
    "summary": "Compared to monocular 3D object detection, stereo-based 3D methods offer significantly higher accuracy but still suffer from high computational overhead and latency. The state-of-the-art stereo 3D detection method achieves twice the accuracy of monocular approaches, yet its inference speed is only half as fast. In this paper, we propose StereoDETR, an efficient stereo 3D object detection framework based on DETR. StereoDETR consists of two branches: a monocular DETR branch and a stereo branch. The DETR branch is built upon 2D DETR with additional channels for predicting object scale, orientation, and sampling points. The stereo branch leverages low-cost multi-scale disparity features to predict object-level depth maps. These two branches are coupled solely through a differentiable depth sampling strategy. To handle occlusion, we introduce a constrained supervision strategy for sampling points without requiring extra annotations. StereoDETR achieves real-time inference and is the first stereo-based method to surpass monocular approaches in speed. It also achieves competitive accuracy on the public KITTI benchmark, setting new state-of-the-art results on pedestrian and cyclist subsets. The code is available at https://github.com/shiyi-mu/StereoDETR-OPEN.",
    "published": "2025-11-24T05:38:31Z",
    "updated": "2025-11-24T05:38:31Z",
    "link": "http://arxiv.org/pdf/2511.18788v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shiyi Mu",
      "Zichong Gu",
      "Zhiqi Ai",
      "Anqi Liu",
      "Yilin Gao",
      "Shugong Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18787v1",
    "title": "Understanding Task Transfer in Vision-Language Models",
    "summary": "Vision-Language Models (VLMs) perform well on multimodal benchmarks but lag behind humans and specialized models on visual perception tasks like depth estimation or object counting. Finetuning on one task can unpredictably affect performance on others, making task-specific finetuning challenging. In this paper, we address this challenge through a systematic study of task transferability. We examine how finetuning a VLM on one perception task affects its zero-shot performance on others. To quantify these effects, we introduce Perfection Gap Factor (PGF), a metric that captures both the breadth and magnitude of transfer. Using three open-weight VLMs evaluated across 13 perception tasks, we construct a task-transfer graph that reveals previously unobserved relationships among perception tasks. Our analysis uncovers patterns of positive and negative transfer, identifies groups of tasks that mutually influence each other, organizes tasks into personas based on their transfer behavior and demonstrates how PGF can guide data selection for more efficient training. These findings highlight both opportunities for positive transfer and risks of negative interference, offering actionable guidance for advancing VLMs.",
    "published": "2025-11-24T05:37:52Z",
    "updated": "2025-11-24T05:37:52Z",
    "link": "http://arxiv.org/pdf/2511.18787v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Bhuvan Sachdeva",
      "Karan Uppal",
      "Abhinav Java",
      "Vineeth N. Balasubramanian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18786v1",
    "title": "STCDiT: Spatio-Temporally Consistent Diffusion Transformer for High-Quality Video Super-Resolution",
    "summary": "We present STCDiT, a video super-resolution framework built upon a pre-trained video diffusion model, aiming to restore structurally faithful and temporally stable videos from degraded inputs, even under complex camera motions. The main challenges lie in maintaining temporal stability during reconstruction and preserving structural fidelity during generation. To address these challenges, we first develop a motion-aware VAE reconstruction method that performs segment-wise reconstruction, with each segment clip exhibiting uniform motion characteristic, thereby effectively handling videos with complex camera motions. Moreover, we observe that the first-frame latent extracted by the VAE encoder in each clip, termed the anchor-frame latent, remains unaffected by temporal compression and retains richer spatial structural information than subsequent frame latents. We further develop an anchor-frame guidance approach that leverages structural information from anchor frames to constrain the generation process and improve structural fidelity of video features. Coupling these two designs enables the video diffusion model to achieve high-quality video super-resolution. Extensive experiments show that STCDiT outperforms state-of-the-art methods in terms of structural fidelity and temporal consistency.",
    "published": "2025-11-24T05:37:23Z",
    "updated": "2025-11-24T05:37:23Z",
    "link": "http://arxiv.org/pdf/2511.18786v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Junyang Chen",
      "Jiangxin Dong",
      "Long Sun",
      "Yixin Yang",
      "Jinshan Pan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18773v1",
    "title": "Sampling Control for Imbalanced Calibration in Semi-Supervised Learning",
    "summary": "Class imbalance remains a critical challenge in semi-supervised learning (SSL), especially when distributional mismatches between labeled and unlabeled data lead to biased classification. Although existing methods address this issue by adjusting logits based on the estimated class distribution of unlabeled data, they often handle model imbalance in a coarse-grained manner, conflating data imbalance with bias arising from varying class-specific learning difficulties. To address this issue, we propose a unified framework, SC-SSL, which suppresses model bias through decoupled sampling control. During training, we identify the key variables for sampling control under ideal conditions. By introducing a classifier with explicit expansion capability and adaptively adjusting sampling probabilities across different data distributions, SC-SSL mitigates feature-level imbalance for minority classes. In the inference phase, we further analyze the weight imbalance of the linear classifier and apply post-hoc sampling control with an optimization bias vector to directly calibrate the logits. Extensive experiments across various benchmark datasets and distribution settings validate the consistency and state-of-the-art performance of SC-SSL.",
    "published": "2025-11-24T05:15:58Z",
    "updated": "2025-11-24T05:15:58Z",
    "link": "http://arxiv.org/pdf/2511.18773v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "authors": [
      "Senmao Tian",
      "Xiang Wei",
      "Shunli Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17092v2",
    "title": "SPAGS: Sparse-View Articulated Object Reconstruction from Single State via Planar Gaussian Splatting",
    "summary": "Articulated objects are ubiquitous in daily environments, and their 3D reconstruction holds great significance across various fields. However, existing articulated object reconstruction methods typically require costly inputs such as multi-stage and multi-view observations. To address the limitations, we propose a category-agnostic articulated object reconstruction framework via planar Gaussian Splatting, which only uses sparse-view RGB images from a single state. Specifically, we first introduce a Gaussian information field to perceive the optimal sparse viewpoints from candidate camera poses. Then we compress 3D Gaussians into planar Gaussians to facilitate accurate estimation of normal and depth. The planar Gaussians are optimized in a coarse-to-fine manner through depth smooth regularization and few-shot diffusion. Moreover, we introduce a part segmentation probability for each Gaussian primitive and update them by back-projecting part segmentation masks of renderings. Extensive experimental results demonstrate that our method achieves higher-fidelity part-level surface reconstruction on both synthetic and real-world data than existing methods. Codes will be made publicly available.",
    "published": "2025-11-21T09:49:53Z",
    "updated": "2025-11-24T05:04:41Z",
    "link": "http://arxiv.org/pdf/2511.17092v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Di Wu",
      "Liu Liu",
      "Xueyu Yuan",
      "Qiaojun Yu",
      "Wenxiao Chen",
      "Ruilong Yan",
      "Yiming Tang",
      "Liangtu Song"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17059v2",
    "title": "REArtGS++: Generalizable Articulation Reconstruction with Temporal Geometry Constraint via Planar Gaussian Splatting",
    "summary": "Articulated objects are pervasive in daily environments, such as drawers and refrigerators. Towards their part-level surface reconstruction and joint parameter estimation, REArtGS introduces a category-agnostic approach using multi-view RGB images at two different states. However, we observe that REArtGS still struggles with screw-joint or multi-part objects and lacks geometric constraints for unseen states. In this paper, we propose REArtGS++, a novel method towards generalizable articulated object reconstruction with temporal geometry constraint and planar Gaussian splatting. We first model a decoupled screw motion for each joint without type prior, and jointly optimize part-aware Gaussians with joint parameters through part motion blending. To introduce time-continuous geometric constraint for articulated modeling, we encourage Gaussians to be planar and propose a temporally consistent regularization between planar normal and depth through Taylor first-order expansion. Extensive experiments on both synthetic and real-world articulated objects demonstrate our superiority in generalizable part-level surface reconstruction and joint parameter estimation, compared to existing approaches. Project Site: https://sites.google.com/view/reartgs2/home.",
    "published": "2025-11-21T09:07:56Z",
    "updated": "2025-11-24T04:58:36Z",
    "link": "http://arxiv.org/pdf/2511.17059v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Di Wu",
      "Liu Liu",
      "Anran Huang",
      "Yuyan Liu",
      "Qiaojun Yu",
      "Shaofan Liu",
      "Liangtu Song",
      "Cewu Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18765v1",
    "title": "NI-Tex: Non-isometric Image-based Garment Texture Generation",
    "summary": "Existing industrial 3D garment meshes already cover most real-world clothing geometries, yet their texture diversity remains limited. To acquire more realistic textures, generative methods are often used to extract Physically-based Rendering (PBR) textures and materials from large collections of wild images and project them back onto garment meshes. However, most image-conditioned texture generation approaches require strict topological consistency between the input image and the input 3D mesh, or rely on accurate mesh deformation to match to the image poses, which significantly constrains the texture generation quality and flexibility. To address the challenging problem of non-isometric image-based garment texture generation, we construct 3D Garment Videos, a physically simulated, garment-centric dataset that provides consistent geometry and material supervision across diverse deformations, enabling robust cross-pose texture learning. We further employ Nano Banana for high-quality non-isometric image editing, achieving reliable cross-topology texture generation between non-isometric image-geometry pairs. Finally, we propose an iterative baking method via uncertainty-guided view selection and reweighting that fuses multi-view predictions into seamless, production-ready PBR textures. Through extensive experiments, we demonstrate that our feedforward dual-branch architecture generates versatile and spatially aligned PBR materials suitable for industry-level 3D garment design.",
    "published": "2025-11-24T04:57:38Z",
    "updated": "2025-11-24T04:57:38Z",
    "link": "http://arxiv.org/pdf/2511.18765v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hui Shan",
      "Ming Li",
      "Haitao Yang",
      "Kai Zheng",
      "Sizhe Zheng",
      "Yanwei Fu",
      "Xiangru Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18763v1",
    "title": "VAOT: Vessel-Aware Optimal Transport for Retinal Fundus Enhancement",
    "summary": "Color fundus photography (CFP) is central to diagnosing and monitoring retinal disease, yet its acquisition variability (e.g., illumination changes) often degrades image quality, which motivates robust enhancement methods. Unpaired enhancement pipelines are typically GAN-based, however, they can distort clinically critical vasculature, altering vessel topology and endpoint integrity. Motivated by these structural alterations, we propose Vessel-Aware Optimal Transport (\\textbf{VAOT}), a framework that combines an optimal-transport objective with two structure-preserving regularizers: (i) a skeleton-based loss to maintain global vascular connectivity and (ii) an endpoint-aware loss to stabilize local termini. These constraints guide learning in the unpaired setting, reducing noise while preserving vessel structure. Experimental results on synthetic degradation benchmark and downstream evaluations in vessel and lesion segmentation demonstrate the superiority of the proposed methods against several state-of-the art baselines. The code is available at https://github.com/Retinal-Research/VAOT",
    "published": "2025-11-24T04:56:08Z",
    "updated": "2025-11-24T04:56:08Z",
    "link": "http://arxiv.org/pdf/2511.18763v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xuanzhao Dong",
      "Wenhui Zhu",
      "Yujian Xiong",
      "Xiwen Chen",
      "Hao Wang",
      "Xin Li",
      "Jiajun Cheng",
      "Zhipeng Wang",
      "Shao Tang",
      "Oana Dumitrascu",
      "Yalin Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.26213v2",
    "title": "OmniDocLayout: Towards Diverse Document Layout Generation via Coarse-to-Fine LLM Learning",
    "summary": "Document AI has advanced rapidly and is attracting increasing attention. Yet, while most efforts have focused on document layout analysis (DLA), its generative counterpart, layout generation, remains underexplored. Distinct from traditional graphic layout design and room layout planning, document layout generation typically involves a larger number of elements per page and exhibits greater structural diversity and complexity. Currently, a major obstacle lies in the scarcity of diverse document layouts: academic papers with Manhattan-style structures dominate existing studies, while open-world genres such as newspapers and magazines remain severely underrepresented. To address this gap, we curate OmniDocLayout-1M, the first million-scale dataset of diverse document layouts, covering six common document types and comprising contemporary layouts collected from multiple sources. Moreover, since existing methods struggle in complex domains and often fail to arrange long sequences coherently, we introduce OmniDocLayout-LLM, a 0.5B model with designed two-stage Coarse-to-Fine learning paradigm:1) learning universal layout principles from our dataset with coarse category definitions, and 2) transferring the knowledge to a specific domain with few fine-grained annotated samples. Extensive experiments demonstrate that our approach achieves strong performance on multiple domains in M$^6$Doc dataset, substantially surpassing both existing layout generation experts and several latest general-purpose LLMs. Our code, dataset, and models will be publicly released.",
    "published": "2025-10-30T07:39:54Z",
    "updated": "2025-11-24T04:55:26Z",
    "link": "http://arxiv.org/pdf/2510.26213v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hengrui Kang",
      "Zhuangcheng Gu",
      "Zhiyuan Zhao",
      "Zichen Wen",
      "Bin Wang",
      "Weijia Li",
      "Conghui He"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.13859v2",
    "title": "QGait: Toward Accurate Quantization for Gait Recognition",
    "summary": "Existing deep learning methods have made significant progress in gait recognition. Quantization can facilitate the application of gait models as a model-agnostic general compression technique. Typically, appearance-based models binarize inputs into silhouette sequences. However, mainstream quantization methods prioritize minimizing task loss over quantization error, which is detrimental to gait recognition with binarized inputs. To address this, we propose a differentiable soft quantizer, which better simulates the gradient of the round function during backpropagation. This enables the network to learn from subtle input perturbations. However, our theoretical analysis and empirical studies reveal that directly applying the soft quantizer can hinder network convergence. We addressed this issue by adopting a two-stage training strategy, introducing a soft quantizer during the fine-tuning phase. However, in the first stage of training, we observed a significant change in the output distribution of different samples in the feature space compared to the full-precision network. It is this change that led to a loss in performance. Based on this, we propose an Inter-class Distance-guided Calibration (IDC) strategy to preserve the relative distance between the embeddings of samples with different labels. Extensive experiments validate the effectiveness of our approach, demonstrating state-of-the-art accuracy across various settings and datasets.",
    "published": "2024-05-22T17:34:18Z",
    "updated": "2025-11-24T04:44:49Z",
    "link": "http://arxiv.org/pdf/2405.13859v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Senmao Tian",
      "Haoyu Gao",
      "Gangyi Hong",
      "Shuyun Wang",
      "JingJie Wang",
      "Xin Yu",
      "Shunli Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18757v1",
    "title": "From Features to Reference Points: Lightweight and Adaptive Fusion for Cooperative Autonomous Driving",
    "summary": "We present RefPtsFusion, a lightweight and interpretable framework for cooperative autonomous driving. Instead of sharing large feature maps or query embeddings, vehicles exchange compact reference points, e.g., objects' positions, velocities, and size information. This approach shifts the focus from \"what is seen\" to \"where to see\", creating a sensor- and model-independent interface that works well across vehicles with heterogeneous perception models while greatly reducing communication bandwidth. To enhance the richness of shared information, we further develop a selective Top-K query fusion that selectively adds high-confidence queries from the sender. It thus achieves a strong balance between accuracy and communication cost. Experiments on the M3CAD dataset show that RefPtsFusion maintains stable perception performance while reducing communication overhead by five orders of magnitude, dropping from hundreds of MB/s to only a few KB/s at 5 FPS (frame per second), compared to traditional feature-level fusion methods. Extensive experiments also demonstrate RefPtsFusion's strong robustness and consistent transmission behavior, highlighting its potential for scalable, real-time cooperative driving systems.",
    "published": "2025-11-24T04:38:57Z",
    "updated": "2025-11-24T04:38:57Z",
    "link": "http://arxiv.org/pdf/2511.18757v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yongqi Zhu",
      "Morui Zhu",
      "Qi Chen",
      "Deyuan Qu",
      "Song Fu",
      "Qing Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.10388v2",
    "title": "Physics-Based Decomposition of Reflectance and Shading using a Single Visible-Thermal Image Pair",
    "summary": "Decomposing an image into its underlying photometric factors--surface reflectance and shading--is a long-standing challenge due to the lack of extensive ground-truth data for real-world scenes. We introduce a novel physics-based approach for intrinsic image decomposition using a pair of visible and thermal images. We leverage the principle that light not reflected from an opaque surface is absorbed and detected as heat by a thermal camera. This allows us to relate the ordinalities (or relative magnitudes) between visible and thermal image intensities to the ordinalities of shading and reflectance, which enables a dense self-supervision of an optimizing neural network to recover shading and reflectance. We perform quantitative evaluations with known reflectance and shading under natural and artificial lighting, and qualitative experiments across diverse scenes. The results demonstrate superior performance over both physics-based and recent learning-based methods, providing a path toward scalable real-world data curation with supervision.",
    "published": "2025-09-12T16:29:02Z",
    "updated": "2025-11-24T04:16:29Z",
    "link": "http://arxiv.org/pdf/2509.10388v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zeqing Leo Yuan",
      "Mani Ramanagopal",
      "Aswin C. Sankaranarayanan",
      "Srinivasa G. Narasimhan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2307.03177v7",
    "title": "PanoDiffusion: 360-degree Panorama Outpainting via Diffusion",
    "summary": "Generating complete 360-degree panoramas from narrow field of view images is ongoing research as omnidirectional RGB data is not readily available. Existing GAN-based approaches face some barriers to achieving higher quality output, and have poor generalization performance over different mask types. In this paper, we present our 360-degree indoor RGB-D panorama outpainting model using latent diffusion models (LDM), called PanoDiffusion. We introduce a new bi-modal latent diffusion structure that utilizes both RGB and depth panoramic data during training, which works surprisingly well to outpaint depth-free RGB images during inference. We further propose a novel technique of introducing progressive camera rotations during each diffusion denoising step, which leads to substantial improvement in achieving panorama wraparound consistency. Results show that our PanoDiffusion not only significantly outperforms state-of-the-art methods on RGB-D panorama outpainting by producing diverse well-structured results for different types of masks, but can also synthesize high-quality depth panoramas to provide realistic 3D indoor models.",
    "published": "2023-07-06T17:57:02Z",
    "updated": "2025-11-24T03:47:03Z",
    "link": "http://arxiv.org/pdf/2307.03177v7.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Tianhao Wu",
      "Chuanxia Zheng",
      "Tat-Jen Cham"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18729v1",
    "title": "GuideFlow: Constraint-Guided Flow Matching for Planning in End-to-End Autonomous Driving",
    "summary": "Driving planning is a critical component of end-to-end (E2E) autonomous driving. However, prevailing Imitative E2E Planners often suffer from multimodal trajectory mode collapse, failing to produce diverse trajectory proposals. Meanwhile, Generative E2E Planners struggle to incorporate crucial safety and physical constraints directly into the generative process, necessitating an additional optimization stage to refine their outputs. In this paper, we propose \\textit{\\textbf{GuideFlow}}, a novel planning framework that leverages Constrained Flow Matching. Concretely, \\textit{\\textbf{GuideFlow}} explicitly models the flow matching process, which inherently mitigates mode collapse and allows for flexible guidance from various conditioning signals. Our core contribution lies in directly enforcing explicit constraints within the flow matching generation process, rather than relying on implicit constraint encoding. Crucially, \\textit{\\textbf{GuideFlow}} unifies the training of the flow matching with the Energy-Based Model (EBM) to enhance the model's autonomous optimization capability to robustly satisfy physical constraints. Secondly, \\textit{\\textbf{GuideFlow}} parameterizes driving aggressiveness as a control signal during generation, enabling precise manipulation of trajectory style. Extensive evaluations on major driving benchmarks (Bench2Drive, NuScenes, NavSim and ADV-NuScenes) validate the effectiveness of \\textit{\\textbf{GuideFlow}}. Notably, on the NavSim test hard split (Navhard), \\textit{\\textbf{GuideFlow}} achieved SOTA with an EPDMS score of 43.0. The code will be released.",
    "published": "2025-11-24T03:45:32Z",
    "updated": "2025-11-24T03:45:32Z",
    "link": "http://arxiv.org/pdf/2511.18729v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Lin Liu",
      "Caiyan Jia",
      "Guanyi Yu",
      "Ziying Song",
      "JunQiao Li",
      "Feiyang Jia",
      "Peiliang Wu",
      "Xiaoshuai Hao",
      "Yandan Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.02792v4",
    "title": "RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation",
    "summary": "Text-to-image (T2I) diffusion models have shown remarkable success in generating high-quality images from text prompts. Recent efforts extend these models to incorporate conditional images (e.g., canny edge) for fine-grained spatial control. Among them, feature injection methods have emerged as a training-free alternative to traditional fine-tuning-based approaches. However, they often suffer from structural misalignment, condition leakage, and visual artifacts, especially when the condition image diverges significantly from natural RGB distributions. Through an empirical analysis of existing methods, we identify a key limitation: the sampling schedule of condition features, previously unexplored, fails to account for the evolving interplay between structure preservation and domain alignment throughout diffusion steps. Inspired by this observation, we propose a flexible training-free framework that decouples the sampling schedule of condition features from the denoising process, and systematically investigate the spectrum of feature injection schedules for a higher-quality structure guidance in the feature space. Specifically, we find that condition features sampled from a single timestep are sufficient, yielding a simple yet efficient schedule that balances structure alignment and appearance quality. We further enhance the sampling process by introducing a restart refinement schedule, and improve the visual quality with an appearance-rich prompting strategy. Together, these designs enable training-free generation that is both structure-rich and appearance-rich. Extensive experiments show that our approach achieves state-of-the-art results across diverse zero-shot conditioning scenarios.",
    "published": "2025-07-03T16:56:15Z",
    "updated": "2025-11-24T03:38:55Z",
    "link": "http://arxiv.org/pdf/2507.02792v4.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Liheng Zhang",
      "Lexi Pang",
      "Hang Ye",
      "Xiaoxuan Ma",
      "Yizhou Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.03100v3",
    "title": "AVATAR: Reinforcement Learning to See, Hear, and Reason Over Video",
    "summary": "Multimodal reasoning over long-horizon video is challenging due to the need for precise spatiotemporal fusion and alignment across modalities. While recent methods such as Group Relative Policy Optimization (GRPO) have shown promise in this domain, they suffer from three key limitations: (1) data inefficiency from their on-policy design, (2) a vanishing advantage problem, where identical or near-identical rewards within a group eliminate the learning signal by producing zero-valued advantages, and (3) uniform credit assignment that fails to emphasize critical reasoning steps. We introduce $\\textbf{AVATAR}$ ($\\textbf{A}$udio-$\\textbf{V}$ideo $\\textbf{A}$gen$\\textbf{t}$ for $\\textbf{A}$lignment and $\\textbf{R}$easoning), a framework that addresses these limitations through two core components: (1) an off-policy training architecture that improves sample efficiency and resolves vanishing advantages by reusing past experiences with greater reward diversity, and (2) Temporal Advantage Shaping (TAS), a novel credit assignment strategy that upweights key reasoning phases during learning. $\\textbf{AVATAR}$ achieves strong performance across various benchmarks, outperforming the Qwen2.5-Omni baseline by $\\mathbf{+5.4}$ on MMVU, $\\mathbf{+4.9}$ on OmniBench, and $\\mathbf{+4.5}$ on Video-Holmes, while demonstrating $\\textbf{$5$$\\times$ sample efficiency}$, requiring $80\\%$ fewer generated completions to reach target performance.",
    "published": "2025-08-05T05:25:17Z",
    "updated": "2025-11-24T03:34:12Z",
    "link": "http://arxiv.org/pdf/2508.03100v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yogesh Kulkarni",
      "Pooyan Fazli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18724v1",
    "title": "Neural B-Frame Coding: Tackling Domain Shift Issues with Lightweight Online Motion Resolution Adaptation",
    "summary": "Learned B-frame codecs with hierarchical temporal prediction often encounter the domain-shift issue due to mismatches between the Group-of-Pictures (GOP) sizes for training and testing, leading to inaccurate motion estimates, particularly for large motion. A common solution is to turn large motion into small motion by downsampling video frames during motion estimation. However, determining the optimal downsampling factor typically requires costly rate-distortion optimization. This work introduces lightweight classifiers to predict downsampling factors. These classifiers leverage simple state signals from current and reference frames to balance rate-distortion performance with computational cost. Three variants are proposed: (1) a binary classifier (Bi-Class) trained with Focal Loss to choose between high and low resolutions, (2) a multi-class classifier (Mu-Class) trained with novel soft labels based on rate-distortion costs, and (3) a co-class approach (Co-Class) that combines the predictive capability of the multi-class classifier with the selective search of the binary classifier. All classifier methods can work seamlessly with existing B-frame codecs without requiring codec retraining. Experimental results show that they achieve coding performance comparable to exhaustive search methods while significantly reducing computational complexity. The code is available at: https://github.com/NYCU-MAPL/Fast-OMRA.git.",
    "published": "2025-11-24T03:29:58Z",
    "updated": "2025-11-24T03:29:58Z",
    "link": "http://arxiv.org/pdf/2511.18724v1.pdf",
    "category": [
      "eess.IV",
      "cs.CV",
      "cs.MM"
    ],
    "authors": [
      "Sang NguyenQuang",
      "Xiem HoangVan",
      "Wen-Hsiao Peng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.05186v4",
    "title": "Learning to See and Act: Task-Aware Virtual View Exploration for Robotic Manipulation",
    "summary": "Recent vision-language-action (VLA) models for multi-task robotic manipulation commonly rely on static viewpoints and shared visual encoders, which limit 3D perception and cause task interference, hindering robustness and generalization. In this work, we propose Task-aware Virtual View Exploration (TVVE), a framework designed to overcome these challenges by integrating virtual view exploration with task-specific representation learning. TVVE employs an efficient exploration policy, accelerated by a novel pseudo-environment, to acquire informative views. Furthermore, we introduce a Task-aware Mixture-of-Experts (TaskMoE) visual encoder to disentangle features across different tasks, boosting both representation fidelity and task generalization. By learning to see the world in a task-aware way, TVVE generates more complete and discriminative visual representations, demonstrating significantly enhanced action prediction across a wide array of manipulation challenges. To further validate the robustness and generalization capability of TVVE under out-of-distribution (OOD) settings, we construct a challenging benchmark, RLBench-OG, covering various visual perturbations and camera pose variations. Extensive experiments on RLBench and RLBench-OG show that our TVVE achieves superior performance over state-of-the-art approaches. In real-robot experiments, TVVE demonstrates exceptional performance and generalizes robustly in multiple OOD settings, including visual disturbances and unseen instructions. Visual results and code are provided at: https://hcplab-sysu.github.io/TAVP.",
    "published": "2025-08-07T09:21:20Z",
    "updated": "2025-11-24T03:28:59Z",
    "link": "http://arxiv.org/pdf/2508.05186v4.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Yongjie Bai",
      "Zhouxia Wang",
      "Yang Liu",
      "Kaijun Luo",
      "Yifan Wen",
      "Mingtong Dai",
      "Weixing Chen",
      "Ziliang Chen",
      "Lingbo Liu",
      "Guanbin Li",
      "Liang Lin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18719v1",
    "title": "Seeing What Matters: Visual Preference Policy Optimization for Visual Generation",
    "summary": "Reinforcement learning (RL) has become a powerful tool for post-training visual generative models, with Group Relative Policy Optimization (GRPO) increasingly used to align generators with human preferences. However, existing GRPO pipelines rely on a single scalar reward per sample, treating each image or video as a holistic entity and ignoring the rich spatial and temporal structure of visual content. This coarse supervision hinders the correction of localized artifacts and the modeling of fine-grained perceptual cues. We introduce Visual Preference Policy Optimization (ViPO), a GRPO variant that lifts scalar feedback into structured, pixel-level advantages. ViPO employs a Perceptual Structuring Module that uses pretrained vision backbones to construct spatially and temporally aware advantage maps, redistributing optimization pressure toward perceptually important regions while preserving the stability of standard GRPO. Across both image and video benchmarks, ViPO consistently outperforms vanilla GRPO, improving in-domain alignment with human-preference rewards and enhancing generalization on out-of-domain evaluations. The method is architecture-agnostic, lightweight, and fully compatible with existing GRPO training pipelines, providing a more expressive and informative learning signal for visual generation.",
    "published": "2025-11-24T03:21:17Z",
    "updated": "2025-11-24T03:21:17Z",
    "link": "http://arxiv.org/pdf/2511.18719v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Ziqi Ni",
      "Yuanzhi Liang",
      "Rui Li",
      "Yi Zhou",
      "Haibing Huang",
      "Chi Zhang",
      "Xuelong Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.07331v2",
    "title": "ERANet: Edge Replacement Augmentation for Semi-Supervised Meniscus Segmentation with Prototype Consistency Alignment and Conditional Self-Training",
    "summary": "Manual segmentation is labor-intensive, and automatic segmentation remains challenging due to the inherent variability in meniscal morphology, partial volume effects, and low contrast between the meniscus and surrounding tissues. To address these challenges, we propose ERANet, an innovative semi-supervised framework for meniscus segmentation that effectively leverages both labeled and unlabeled images through advanced augmentation and learning strategies. ERANet integrates three key components: edge replacement augmentation (ERA), prototype consistency alignment (PCA), and a conditional self-training (CST) strategy within a mean teacher architecture. ERA introduces anatomically relevant perturbations by simulating meniscal variations, ensuring that augmentations align with the structural context. PCA enhances segmentation performance by aligning intra-class features and promoting compact, discriminative feature representations, particularly in scenarios with limited labeled data. CST improves segmentation robustness by iteratively refining pseudo-labels and mitigating the impact of label noise during training. Together, these innovations establish ERANet as a robust and scalable solution for meniscus segmentation, effectively addressing key barriers to practical implementation. We validated ERANet comprehensively on 3D Double Echo Steady State (DESS) and 3D Fast/Turbo Spin Echo (FSE/TSE) MRI sequences. The results demonstrate the superior performance of ERANet compared to state-of-the-art methods. The proposed framework achieves reliable and accurate segmentation of meniscus structures, even when trained on minimal labeled data. Extensive ablation studies further highlight the synergistic contributions of ERA, PCA, and CST, solidifying ERANet as a transformative solution for semi-supervised meniscus segmentation in medical imaging.",
    "published": "2025-02-11T07:49:31Z",
    "updated": "2025-11-24T03:20:33Z",
    "link": "http://arxiv.org/pdf/2502.07331v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Siyue Li",
      "Yongcheng Yao",
      "Junru Zhong",
      "Shutian Zhao",
      "Fan Xiao",
      "Tim-Yun Michael Ong",
      "Ki-Wai Kevin Ho",
      "James F. Griffith",
      "Yudong Zhang",
      "Shuihua Wang",
      "Jin Hong",
      "Weitian Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18716v1",
    "title": "GRIT-LP: Graph Transformer with Long-Range Skip Connection and Partitioned Spatial Graphs for Accurate Ice Layer Thickness Prediction",
    "summary": "Graph transformers have demonstrated remarkable capability on complex spatio-temporal tasks, yet their depth is often limited by oversmoothing and weak long-range dependency modeling. To address these challenges, we introduce GRIT-LP, a graph transformer explicitly designed for polar ice-layer thickness estimation from polar radar imagery. Accurately estimating ice layer thickness is critical for understanding snow accumulation, reconstructing past climate patterns and reducing uncertainties in projections of future ice sheet evolution and sea level rise. GRIT-LP combines an inductive geometric graph learning framework with self-attention mechanism, and introduces two major innovations that jointly address challenges in modeling the spatio-temporal patterns of ice layers: a partitioned spatial graph construction strategy that forms overlapping, fully connected local neighborhoods to preserve spatial coherence and suppress noise from irrelevant long-range links, and a long-range skip connection mechanism within the transformer that improves information flow and mitigates oversmoothing in deeper attention layers. We conducted extensive experiments, demonstrating that GRIT-LP outperforms current state-of-the-art methods with a 24.92\\% improvement in root mean squared error. These results highlight the effectiveness of graph transformers in modeling spatiotemporal patterns by capturing both localized structural features and long-range dependencies across internal ice layers, and demonstrate their potential to advance data-driven understanding of cryospheric processes.",
    "published": "2025-11-24T03:14:55Z",
    "updated": "2025-11-24T03:14:55Z",
    "link": "http://arxiv.org/pdf/2511.18716v1.pdf",
    "category": [
      "cs.LG",
      "cs.CV"
    ],
    "authors": [
      "Zesheng Liu",
      "Maryam Rahnemoonfar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18713v1",
    "title": "DriveFlow: Rectified Flow Adaptation for Robust 3D Object Detection in Autonomous Driving",
    "summary": "In autonomous driving, vision-centric 3D object detection recognizes and localizes 3D objects from RGB images. However, due to high annotation costs and diverse outdoor scenes, training data often fails to cover all possible test scenarios, known as the out-of-distribution (OOD) issue. Training-free image editing offers a promising solution for improving model robustness by training data enhancement without any modifications to pre-trained diffusion models. Nevertheless, inversion-based methods often suffer from limited effectiveness and inherent inaccuracies, while recent rectified-flow-based approaches struggle to preserve objects with accurate 3D geometry. In this paper, we propose DriveFlow, a Rectified Flow Adaptation method for training data enhancement in autonomous driving based on pre-trained Text-to-Image flow models. Based on frequency decomposition, DriveFlow introduces two strategies to adapt noise-free editing paths derived from text-conditioned velocities. 1) High-Frequency Foreground Preservation: DriveFlow incorporates a high-frequency alignment loss for foreground to maintain precise 3D object geometry. 2) Dual-Frequency Background Optimization: DriveFlow also conducts dual-frequency optimization for background, balancing editing flexibility and semantic consistency. Comprehensive experiments validate the effectiveness and efficiency of DriveFlow, demonstrating comprehensive performance improvements on all categories across OOD scenarios. Code is available at https://github.com/Hongbin98/DriveFlow.",
    "published": "2025-11-24T03:12:43Z",
    "updated": "2025-11-24T03:12:43Z",
    "link": "http://arxiv.org/pdf/2511.18713v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hongbin Lin",
      "Yiming Yang",
      "Chaoda Zheng",
      "Yifan Zhang",
      "Shuaicheng Niu",
      "Zilu Guo",
      "Yafeng Li",
      "Gui Gui",
      "Shuguang Cui",
      "Zhen Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.03277v5",
    "title": "PointAD+: Learning Hierarchical Representations for Zero-shot 3D Anomaly Detection",
    "summary": "In this paper, we aim to transfer CLIP's robust 2D generalization capabilities to identify 3D anomalies across unseen objects of highly diverse class semantics. To this end, we propose a unified framework to comprehensively detect and segment 3D anomalies by leveraging both point- and pixel-level information. We first design PointAD, which leverages point-pixel correspondence to represent 3D anomalies through their associated rendering pixel representations. This approach is referred to as implicit 3D representation, as it focuses solely on rendering pixel anomalies but neglects the inherent spatial relationships within point clouds. Then, we propose PointAD+ to further broaden the interpretation of 3D anomalies by introducing explicit 3D representation, emphasizing spatial abnormality to uncover abnormal spatial relationships. Hence, we propose G-aggregation to involve geometry information to enable the aggregated point representations spatially aware. To simultaneously capture rendering and spatial abnormality, PointAD+ proposes hierarchical representation learning, incorporating implicit and explicit anomaly semantics into hierarchical text prompts: rendering prompts for the rendering layer and geometry prompts for the geometry layer. A cross-hierarchy contrastive alignment is further introduced to promote the interaction between the rendering and geometry layers, facilitating mutual anomaly learning. Finally, PointAD+ integrates anomaly semantics from both layers to capture the generalized anomaly semantics. During the test, PointAD+ can integrate RGB information in a plug-and-play manner and further improve its detection performance. Extensive experiments demonstrate the superiority of PointAD+ in ZS 3D anomaly detection across unseen objects with highly diverse class semantics, achieving a holistic understanding of abnormality.",
    "published": "2025-09-03T12:53:40Z",
    "updated": "2025-11-24T03:08:02Z",
    "link": "http://arxiv.org/pdf/2509.03277v5.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Qihang Zhou",
      "Shibo He",
      "Jiangtao Yan",
      "Wenchao Meng",
      "Jiming Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.03596v2",
    "title": "ControlThinker: Unveiling Latent Semantics for Controllable Image Generation through Visual Reasoning",
    "summary": "The field of controllable image generation has seen significant advancements, with various architectures improving generation layout consistency with control signals. However, contemporary methods still face challenges in bridging the semantic gap between input text prompts with sparse semantics and the target images, often over-relying on low-level control signals to infer regional details. To address this challenge, we propose ControlThinker, a novel framework that employs a \"comprehend-then-generate\" paradigm. Firstly, by incentivizing the visual reasoning capability of a MLLM, latent semantics from control images are mined to enrich text prompts. This enriched semantic understanding then seamlessly aids in image generation without the need for additional complex modifications. To further tackle the uncertainty arising from the ambiguity of control images, we encourage broader exploration of reasoning trajectories and select the optimal one using a metric-based output reward model (ORM). Extensive experimental results demonstrate that ControlThinker effectively mitigates the semantic gap between raw text prompts and target images, resulting in improved visual quality and semantic consistency across a wide range of benchmarks. The code and models are available at https://github.com/Maplebb/ControlThinker.",
    "published": "2025-06-04T05:56:19Z",
    "updated": "2025-11-24T03:07:30Z",
    "link": "http://arxiv.org/pdf/2506.03596v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Feng Han",
      "Yang Jiao",
      "Shaoxiang Chen",
      "Junhao Xu",
      "Jingjing Chen",
      "Yu-Gang Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10113v2",
    "title": "ImmerIris: A Large-Scale Dataset and Benchmark for Off-Axis and Unconstrained Iris Recognition in Immersive Applications",
    "summary": "Recently, iris recognition is regaining prominence in immersive applications such as extended reality as a means of seamless user identification. This application scenario introduces unique challenges compared to traditional iris recognition under controlled setups, as the ocular images are primarily captured off-axis and less constrained, causing perspective distortion, intra-subject variation, and quality degradation in iris textures. Datasets capturing these challenges remain limited. This paper fills this gap by presenting a large-scale iris dataset collected via head-mounted displays, termed ImmerIris. It contains 499,791 ocular images from 564 subjects, and is, to our knowledge, the largest public iris dataset to date and among the first dedicated to immersive applications. It is accompanied by a comprehensive set of evaluation protocols that benchmark recognition systems under various challenging conditions. This paper also draws attention to a shared obstacle of current recognition methods, the reliance on a pre-processing, normalization stage, which is fallible in off-axis and unconstrained setups. To this end, this paper further proposes a normalization-free paradigm that directly learns from minimally adjusted ocular images. Despite its simplicity, it outperforms normalization-based prior arts, indicating a promising direction for robust iris recognition.",
    "published": "2025-10-11T08:43:38Z",
    "updated": "2025-11-24T03:07:16Z",
    "link": "http://arxiv.org/pdf/2510.10113v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuxi Mi",
      "Qiuyang Yuan",
      "Zhizhou Zhong",
      "Xuan Zhao",
      "Jiaogen Zhou",
      "Fubao Zhu",
      "Jihong Guan",
      "Shuigeng Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18706v1",
    "title": "CoD: A Diffusion Foundation Model for Image Compression",
    "summary": "Existing diffusion codecs typically build on text-to-image diffusion foundation models like Stable Diffusion. However, text conditioning is suboptimal from a compression perspective, hindering the potential of downstream diffusion codecs, particularly at ultra-low bitrates. To address it, we introduce \\textbf{CoD}, the first \\textbf{Co}mpression-oriented \\textbf{D}iffusion foundation model, trained from scratch to enable end-to-end optimization of both compression and generation. CoD is not a fixed codec but a general foundation model designed for various diffusion-based codecs. It offers several advantages: \\textbf{High compression efficiency}, replacing Stable Diffusion with CoD in downstream codecs like DiffC achieves SOTA results, especially at ultra-low bitrates (e.g., 0.0039 bpp); \\textbf{Low-cost and reproducible training}, 300$\\times$ faster training than Stable Diffusion ($\\sim$ 20 vs. $\\sim$ 6,250 A100 GPU days) on entirely open image-only datasets; \\textbf{Providing new insights}, e.g., We find pixel-space diffusion can achieve VTM-level PSNR with high perceptual quality and can outperform GAN-based codecs using fewer parameters. We hope CoD lays the foundation for future diffusion codec research. Codes will be released.",
    "published": "2025-11-24T03:00:15Z",
    "updated": "2025-11-24T03:00:15Z",
    "link": "http://arxiv.org/pdf/2511.18706v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhaoyang Jia",
      "Zihan Zheng",
      "Naifu Xue",
      "Jiahao Li",
      "Bin Li",
      "Zongyu Guo",
      "Xiaoyi Zhang",
      "Houqiang Li",
      "Yan Lu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18702v1",
    "title": "CNN-Based Camera Pose Estimation and Localisation of Scan Images for Aircraft Visual Inspection",
    "summary": "General Visual Inspection is a manual inspection process regularly used to detect and localise obvious damage on the exterior of commercial aircraft. There has been increasing demand to perform this process at the boarding gate to minimise the downtime of the aircraft and automating this process is desired to reduce the reliance on human labour. Automating this typically requires estimating a camera's pose with respect to the aircraft for initialisation but most existing localisation methods require infrastructure, which is very challenging in uncontrolled outdoor environments and within the limited turnover time (approximately 2 hours) on an airport tarmac. Additionally, many airlines and airports do not allow contact with the aircraft's surface or using UAVs for inspection between flights, and restrict access to commercial aircraft. Hence, this paper proposes an on-site method that is infrastructure-free and easy to deploy for estimating a pan-tilt-zoom camera's pose and localising scan images. This method initialises using the same pan-tilt-zoom camera used for the inspection task by utilising a Deep Convolutional Neural Network fine-tuned on only synthetic images to predict its own pose. We apply domain randomisation to generate the dataset for fine-tuning the network and modify its loss function by leveraging aircraft geometry to improve accuracy. We also propose a workflow for initialisation, scan path planning, and precise localisation of images captured from a pan-tilt-zoom camera. We evaluate and demonstrate our approach through experiments with real aircraft, achieving root-mean-square camera pose estimation errors of less than 0.24 m and 2 degrees for all real scenes.",
    "published": "2025-11-24T02:52:36Z",
    "updated": "2025-11-24T02:52:36Z",
    "link": "http://arxiv.org/pdf/2511.18702v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Xueyan Oh",
      "Leonard Loh",
      "Shaohui Foong",
      "Zhong Bao Andy Koh",
      "Kow Leong Ng",
      "Poh Kang Tan",
      "Pei Lin Pearlin Toh",
      "U-Xuan Tan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.00392v3",
    "title": "RefDrone: A Challenging Benchmark for Referring Expression Comprehension in Drone Scenes",
    "summary": "Drones have become prevalent robotic platforms with diverse applications, showing significant potential in Embodied Artificial Intelligence (Embodied AI). Referring Expression Comprehension (REC) enables drones to locate objects based on natural language expressions, a crucial capability for Embodied AI. Despite advances in REC for ground-level scenes, aerial views introduce unique challenges including varying viewpoints, occlusions and scale variations. To address this gap, we introduce RefDrone, a REC benchmark for drone scenes. RefDrone reveals three key challenges in REC: 1) multi-scale and small-scale target detection; 2) multi-target and no-target samples; 3) complex environment with rich contextual expressions. To efficiently construct this dataset, we develop RDAgent (referring drone annotation framework with multi-agent system), a semi-automated annotation tool for REC tasks. RDAgent ensures high-quality contextual expressions and reduces annotation cost. Furthermore, we propose Number GroundingDINO (NGDINO), a novel method designed to handle multi-target and no-target cases. NGDINO explicitly learns and utilizes the number of objects referred to in the expression. Comprehensive experiments with state-of-the-art REC methods demonstrate that NGDINO achieves superior performance on both the proposed RefDrone and the existing gRefCOCO datasets. The dataset and code are be publicly at https://github.com/sunzc-sunny/refdrone.",
    "published": "2025-02-01T10:44:11Z",
    "updated": "2025-11-24T02:48:47Z",
    "link": "http://arxiv.org/pdf/2502.00392v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Zhichao Sun",
      "Yepeng Liu",
      "Zhiling Su",
      "Huachao Zhu",
      "Yuliang Gu",
      "Yuda Zou",
      "Zelong Liu",
      "Gui-Song Xia",
      "Bo Du",
      "Yongchao Xu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18699v1",
    "title": "Dendritic Convolution for Noise Image Recognition",
    "summary": "In real-world scenarios of image recognition, there exists substantial noise interference. Existing works primarily focus on methods such as adjusting networks or training strategies to address noisy image recognition, and the anti-noise performance has reached a bottleneck. However, little is known about the exploration of anti-interference solutions from a neuronal perspective.This paper proposes an anti-noise neuronal convolution. This convolution mimics the dendritic structure of neurons, integrates the neighborhood interaction computation logic of dendrites into the underlying design of convolutional operations, and simulates the XOR logic preprocessing function of biological dendrites through nonlinear interactions between input features, thereby fundamentally reconstructing the mathematical paradigm of feature extraction. Unlike traditional convolution where noise directly interferes with feature extraction and exerts a significant impact, DDC mitigates the influence of noise by focusing on the interaction of neighborhood information. Experimental results demonstrate that in image classification tasks (using YOLOv11-cls, VGG16, and EfficientNet-B0) and object detection tasks (using YOLOv11, YOLOv8, and YOLOv5), after replacing traditional convolution with the dendritic convolution, the accuracy of the EfficientNet-B0 model on noisy datasets is relatively improved by 11.23%, and the mean Average Precision (mAP) of YOLOv8 is increased by 19.80%. The consistency between the computation method of this convolution and the dendrites of biological neurons enables it to perform significantly better than traditional convolution in complex noisy environments.",
    "published": "2025-11-24T02:43:29Z",
    "updated": "2025-11-24T02:43:29Z",
    "link": "http://arxiv.org/pdf/2511.18699v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Jiarui Xue",
      "Dongjian Yang",
      "Ye Sun",
      "Gang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.10471v2",
    "title": "DAGLFNet: Deep Feature Attention Guided Global and Local Feature Fusion for Pseudo-Image Point Cloud Segmentation",
    "summary": "Environmental perception systems are crucial for high-precision mapping and autonomous navigation, with LiDAR serving as a core sensor providing accurate 3D point cloud data. Efficiently processing unstructured point clouds while extracting structured semantic information remains a significant challenge. In recent years, numerous pseudo-image-based representation methods have emerged to balance efficiency and performance by fusing 3D point clouds with 2D grids. However, the fundamental inconsistency between the pseudo-image representation and the original 3D information critically undermines 2D-3D feature fusion, posing a primary obstacle for coherent information fusion and leading to poor feature discriminability. This work proposes DAGLFNet, a pseudo-image-based semantic segmentation framework designed to extract discriminative features. It incorporates three key components: first, a Global-Local Feature Fusion Encoding (GL-FFE) module to enhance intra-set local feature correlation and capture global contextual information; second, a Multi-Branch Feature Extraction (MB-FE) network to capture richer neighborhood information and improve the discriminability of contour features; and third, a Feature Fusion via Deep Feature-guided Attention (FFDFA) mechanism to refine cross-channel feature fusion precision. Experimental evaluations demonstrate that DAGLFNet achieves mean Intersection-over-Union (mIoU) scores of 69.9% and 78.7% on the validation sets of SemanticKITTI and nuScenes, respectively. The method achieves an excellent balance between accuracy and efficiency.",
    "published": "2025-10-12T06:35:03Z",
    "updated": "2025-11-24T02:38:27Z",
    "link": "http://arxiv.org/pdf/2510.10471v2.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Chuang Chen",
      "Yi Lin",
      "Bo Wang",
      "Jing Hu",
      "Xi Wu",
      "Wenyi Ge"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17126v2",
    "title": "OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation",
    "summary": "Emerging deep-learning-based lens library pre-training (LensLib-PT) pipeline offers a new avenue for blind lens aberration correction by training a universal neural network, demonstrating strong capability in handling diverse unknown optical degradations. This work proposes the OmniLens++ framework, which resolves two challenges that hinder the generalization ability of existing pipelines: the difficulty of scaling data and the absence of prior guidance characterizing optical degradation. To improve data scalability, we expand the design specifications to increase the degradation diversity of the lens source, and we sample a more uniform distribution by quantifying the spatial-variation patterns and severity of optical degradation. In terms of model design, to leverage the Point Spread Functions (PSFs), which intuitively describe optical degradation, as guidance in a blind paradigm, we propose the Latent PSF Representation (LPR). The VQVAE framework is introduced to learn latent features of LensLib's PSFs, which is assisted by modeling the optical degradation process to constrain the learning of degradation priors. Experiments on diverse aberrations of real-world lenses and synthetic LensLib show that OmniLens++ exhibits state-of-the-art generalization capacity in blind aberration correction. Beyond performance, the AODLibpro is verified as a scalable foundation for more effective training across diverse aberrations, and LPR can further tap the potential of large-scale LensLib. The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2.",
    "published": "2025-11-21T10:41:54Z",
    "updated": "2025-11-24T02:34:08Z",
    "link": "http://arxiv.org/pdf/2511.17126v2.pdf",
    "category": [
      "eess.IV",
      "cs.CV",
      "cs.LG",
      "physics.optics"
    ],
    "authors": [
      "Qi Jiang",
      "Xiaolong Qian",
      "Yao Gao",
      "Lei Sun",
      "Kailun Yang",
      "Zhonghua Yi",
      "Wenyong Li",
      "Ming-Hsuan Yang",
      "Luc Van Gool",
      "Kaiwei Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18695v1",
    "title": "Exploring Surround-View Fisheye Camera 3D Object Detection",
    "summary": "In this work, we explore the technical feasibility of implementing end-to-end 3D object detection (3DOD) with surround-view fisheye camera system. Specifically, we first investigate the performance drop incurred when transferring classic pinhole-based 3D object detectors to fisheye imagery. To mitigate this, we then develop two methods that incorporate the unique geometry of fisheye images into mainstream detection frameworks: one based on the bird's-eye-view (BEV) paradigm, named FisheyeBEVDet, and the other on the query-based paradigm, named FisheyePETR. Both methods adopt spherical spatial representations to effectively capture fisheye geometry. In light of the lack of dedicated evaluation benchmarks, we release Fisheye3DOD, a new open dataset synthesized using CARLA and featuring both standard pinhole and fisheye camera arrays. Experiments on Fisheye3DOD show that our fisheye-compatible modeling improves accuracy by up to 6.2% over baseline methods.",
    "published": "2025-11-24T02:28:56Z",
    "updated": "2025-11-24T02:28:56Z",
    "link": "http://arxiv.org/pdf/2511.18695v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Changcai Li",
      "Wenwei Lin",
      "Zuoxun Hou",
      "Gang Chen",
      "Wei Zhang",
      "Huihui Zhou",
      "Weishi Zheng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18691v1",
    "title": "EVCC: Enhanced Vision Transformer-ConvNeXt-CoAtNet Fusion for Classification",
    "summary": "Hybrid vision architectures combining Transformers and CNNs have significantly advanced image classification, but they usually do so at significant computational cost. We introduce EVCC (Enhanced Vision Transformer-ConvNeXt-CoAtNet), a novel multi-branch architecture integrating the Vision Transformer, lightweight ConvNeXt, and CoAtNet through key innovations: (1) adaptive token pruning with information preservation, (2) gated bidirectional cross-attention for enhanced feature refinement, (3) auxiliary classification heads for multi-task learning, and (4) a dynamic router gate employing context-aware confidence-driven weighting. Experiments across the CIFAR-100, Tobacco3482, CelebA, and Brain Cancer datasets demonstrate EVCC's superiority over powerful models like DeiT-Base, MaxViT-Base, and CrossViT-Base by consistently achieving state-of-the-art accuracy with improvements of up to 2 percentage points, while reducing FLOPs by 25 to 35%. Our adaptive architecture adjusts computational demands to deployment needs by dynamically reducing token count, efficiently balancing the accuracy-efficiency trade-off while combining global context, local details, and hierarchical features for real-world applications. The source code of our implementation is available at https://anonymous.4open.science/r/EVCC.",
    "published": "2025-11-24T02:11:19Z",
    "updated": "2025-11-24T02:11:19Z",
    "link": "http://arxiv.org/pdf/2511.18691v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Kazi Reyazul Hasan",
      "Md Nafiu Rahman",
      "Wasif Jalal",
      "Sadif Ahmed",
      "Shahriar Raj",
      "Mubasshira Musarrat",
      "Muhammad Abdullah Adnan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18685v1",
    "title": "Beyond Description: Cognitively Benchmarking Fine-Grained Action for Embodied Agents",
    "summary": "Multimodal Large Language Models (MLLMs) show promising results as decision-making engines for embodied agents operating in complex, physical environments. However, existing benchmarks often prioritize high-level planning or spatial reasoning, leaving the fine-grained action intelligence required for embodied physical interaction underexplored. To address this gap, we introduce CFG-Bench, a new benchmark designed to systematically evaluate this crucial capability. CFG-Bench consists of 1,368 curated videos paired with 19,562 three-modalities question-answer pairs targeting four cognitive abilities: 1) Physical Interaction, 2) Temporal-Causal Relation, 3) Intentional Understanding, and 4) Evaluative Judgment. Together, these dimensions provide a systematic framework for assessing a model's ability to translate visual observations into actionable knowledge, moving beyond mere surface-level recognition. Our comprehensive evaluation on CFG-Bench reveals that leading MLLMs struggle to produce detailed instructions for physical interactions and exhibit profound limitations in the higher-order reasoning of intention and evaluation. Moreover, supervised fine-tuning (SFT) on our data demonstrates that teaching an MLLMs to articulate fine-grained actions directly translates to significant performance gains on established embodied benchmarks. Our analysis highlights these limitations and offers insights for developing more capable and grounded embodied agents.",
    "published": "2025-11-24T02:02:29Z",
    "updated": "2025-11-24T02:02:29Z",
    "link": "http://arxiv.org/pdf/2511.18685v1.pdf",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "authors": [
      "Dayong Liu",
      "Chao Xu",
      "Weihong Chen",
      "Suyu Zhang",
      "Juncheng Wang",
      "Jiankang Deng",
      "Baigui Sun",
      "Yang Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2412.07608v3",
    "title": "Faster and Better 3D Splatting via Group Training",
    "summary": "3D Gaussian Splatting (3DGS) has emerged as a powerful technique for novel view synthesis, demonstrating remarkable capability in high-fidelity scene reconstruction through its Gaussian primitive representations. However, the computational overhead induced by the massive number of primitives poses a significant bottleneck to training efficiency. To overcome this challenge, we propose Group Training, a simple yet effective strategy that organizes Gaussian primitives into manageable groups, optimizing training efficiency and improving rendering quality. This approach shows universal compatibility with existing 3DGS frameworks, including vanilla 3DGS and Mip-Splatting, consistently achieving accelerated training while maintaining superior synthesis quality. Extensive experiments reveal that our straightforward Group Training strategy achieves up to 30\\% faster convergence and improved rendering quality across diverse scenarios. Project Website: https://chengbo-wang.github.io/3DGS-with-Group-Training/",
    "published": "2024-12-10T15:47:17Z",
    "updated": "2025-11-24T01:58:56Z",
    "link": "http://arxiv.org/pdf/2412.07608v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Chengbo Wang",
      "Guozheng Ma",
      "Yifei Xue",
      "Yizhen Lao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18684v1",
    "title": "Now You See It, Now You Don't - Instant Concept Erasure for Safe Text-to-Image and Video Generation",
    "summary": "Robust concept removal for text-to-image (T2I) and text-to-video (T2V) models is essential for their safe deployment. Existing methods, however, suffer from costly retraining, inference overhead, or vulnerability to adversarial attacks. Crucially, they rarely model the latent semantic overlap between the target erase concept and surrounding content -- causing collateral damage post-erasure -- and even fewer methods work reliably across both T2I and T2V domains. We introduce Instant Concept Erasure (ICE), a training-free, modality-agnostic, one-shot weight modification approach that achieves precise, persistent unlearning with zero overhead. ICE defines erase and preserve subspaces using anisotropic energy-weighted scaling, then explicitly regularises against their intersection using a unique, closed-form overlap projector. We pose a convex and Lipschitz-bounded Spectral Unlearning Objective, balancing erasure fidelity and intersection preservation, that admits a stable and unique analytical solution. This solution defines a dissociation operator that is translated to the model's text-conditioning layers, making the edit permanent and runtime-free. Across targeted removals of artistic styles, objects, identities, and explicit content, ICE efficiently achieves strong erasure with improved robustness to red-teaming, all while causing only minimal degradation of original generative abilities in both T2I and T2V models.",
    "published": "2025-11-24T01:48:44Z",
    "updated": "2025-11-24T01:48:44Z",
    "link": "http://arxiv.org/pdf/2511.18684v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Shristi Das Biswas",
      "Arani Roy",
      "Kaushik Roy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18682v1",
    "title": "Hierarchical GraphCut Phase Unwrapping based on Invariance of Diffeomorphisms Framework",
    "summary": "Recent years have witnessed rapid advancements in 3D scanning technologies, with applications spanning VR/AR, digital human creation, and medical imaging. Structured-light scanning with phase-shifting techniques is preferred for its use of low-intensity visible light and high accuracy, making it well suited for capturing 4D facial dynamics. A key step is phase unwrapping, which recovers continuous phase values from measurements wrapped modulo 2pi. The goal is to estimate the unwrapped phase count k in the equation Phi = phi + 2pi k, where phi is the wrapped phase and Phi is the true phase. Noise, occlusions, and complex 3D geometry make recovering the true phase challenging because phase unwrapping is ill-posed: measurements only provide modulo 2pi values, and estimating k requires assumptions about surface continuity. Existing methods trade speed for accuracy: fast approaches lack precision, while accurate algorithms are too slow for real-time use. To overcome these limitations, this work proposes a phase unwrapping framework that reformulates GraphCut-based unwrapping as a pixel-labeling problem. This framework improves the estimation of the unwrapped phase count k through the invariance property of diffeomorphisms applied in image space via conformal and optimal transport (OT) maps. An odd number of diffeomorphisms are precomputed from the input phase data, and a hierarchical GraphCut algorithm is applied in each domain. The resulting label maps are fused via majority voting to robustly estimate k at each pixel. Experimental results demonstrate a 45.5x speedup and lower L2 error in real experiments and simulations, showing potential for real-time applications.",
    "published": "2025-11-24T01:45:26Z",
    "updated": "2025-11-24T01:45:26Z",
    "link": "http://arxiv.org/pdf/2511.18682v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiang Gao",
      "Xinmu Wang",
      "Zhou Zhao",
      "Junqi Huang",
      "Xianfeng David Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18680v1",
    "title": "Inverse Rendering for High-Genus Surface Meshes from Multi-View Images",
    "summary": "We present a topology-informed inverse rendering approach for reconstructing high-genus surface meshes from multi-view images. Compared to 3D representations like voxels and point clouds, mesh-based representations are preferred as they enable the application of differential geometry theory and are optimized for modern graphics pipelines. However, existing inverse rendering methods often fail catastrophically on high-genus surfaces, leading to the loss of key topological features, and tend to oversmooth low-genus surfaces, resulting in the loss of surface details. This failure stems from their overreliance on Adam-based optimizers, which can lead to vanishing and exploding gradients. To overcome these challenges, we introduce an adaptive V-cycle remeshing scheme in conjunction with a re-parametrized Adam optimizer to enhance topological and geometric awareness. By periodically coarsening and refining the deforming mesh, our method informs mesh vertices of their current topology and geometry before optimization, mitigating gradient issues while preserving essential topological features. Additionally, we enforce topological consistency by constructing topological primitives with genus numbers that match those of ground truth using Gauss-Bonnet theorem. Experimental results demonstrate that our inverse rendering approach outperforms the current state-of-the-art method, achieving significant improvements in Chamfer Distance and Volume IoU, particularly for high-genus surfaces, while also enhancing surface details for low-genus surfaces.",
    "published": "2025-11-24T01:44:09Z",
    "updated": "2025-11-24T01:44:09Z",
    "link": "http://arxiv.org/pdf/2511.18680v1.pdf",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "authors": [
      "Xiang Gao",
      "Xinmu Wang",
      "Xiaolong Wu",
      "Jiazhi Li",
      "Jingyu Shi",
      "Yu Guo",
      "Yuanpeng Liu",
      "Xiyun Song",
      "Heather Yu",
      "Zongfang Lin",
      "Xianfeng David Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18679v1",
    "title": "Neural Geometry Image-Based Representations with Optimal Transport (OT)",
    "summary": "Neural representations for 3D meshes are emerging as an effective solution for compact storage and efficient processing. Existing methods often rely on neural overfitting, where a coarse mesh is stored and progressively refined through multiple decoder networks. While this can restore high-quality surfaces, it is computationally expensive due to successive decoding passes and the irregular structure of mesh data. In contrast, images have a regular structure that enables powerful super-resolution and restoration frameworks, but applying these advantages to meshes is difficult because their irregular connectivity demands complex encoder-decoder architectures. Our key insight is that a geometry image-based representation transforms irregular meshes into a regular image grid, making efficient image-based neural processing directly applicable. Building on this idea, we introduce our neural geometry image-based representation, which is decoder-free, storage-efficient, and naturally suited for neural processing. It stores a low-resolution geometry-image mipmap of the surface, from which high-quality meshes are restored in a single forward pass. To construct geometry images, we leverage Optimal Transport (OT), which resolves oversampling in flat regions and undersampling in feature-rich regions, and enables continuous levels of detail (LoD) through geometry-image mipmapping. Experimental results demonstrate state-of-the-art storage efficiency and restoration accuracy, measured by compression ratio (CR), Chamfer distance (CD), and Hausdorff distance (HD).",
    "published": "2025-11-24T01:43:19Z",
    "updated": "2025-11-24T01:43:19Z",
    "link": "http://arxiv.org/pdf/2511.18679v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Xiang Gao",
      "Yuanpeng Liu",
      "Xinmu Wang",
      "Jiazhi Li",
      "Minghao Guo",
      "Yu Guo",
      "Xiyun Song",
      "Heather Yu",
      "Zhiqiang Lao",
      "Xianfeng David Gu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.18921v2",
    "title": "Full-scale Representation Guided Network for Retinal Vessel Segmentation",
    "summary": "The U-Net architecture and its variants have remained state-of-the-art (SOTA) for retinal vessel segmentation over the past decade. In this study, we introduce a Full-Scale Guided Network (FSG-Net), where a novel feature representation module using modernized convolution blocks effectively captures full-scale structural information, while a guided convolution block subsequently refines this information. Specifically, we introduce an attention-guided filter within the guided convolution block, leveraging its similarity to unsharp masking to enhance fine vascular structures. Passing full-scale information to the attention block facilitates the generation of more contextually relevant attention maps, which are then passed to the attention-guided filter, providing further refinement to the segmentation performance. The structure preceding the guided convolution block can be replaced by any U-Net variant, ensuring flexibility and scalability across various segmentation tasks. For a fair comparison, we re-implemented recent studies available in public repositories to evaluate their scalability and reproducibility. Our experiments demonstrate that, despite its compact architecture, FSG-Net delivers performance competitive with SOTA methods across multiple public datasets. Ablation studies further demonstrate that each proposed component meaningfully contributes to this competitive performance. Our code is available on https://github.com/ZombaSY/FSG-Net-pytorch.",
    "published": "2025-01-31T06:52:57Z",
    "updated": "2025-11-24T01:29:11Z",
    "link": "http://arxiv.org/pdf/2501.18921v2.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Sunyong Seo",
      "Sangwook Yoo",
      "Huisu Yoon"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18677v1",
    "title": "A Theory-Inspired Framework for Few-Shot Cross-Modal Sketch Person Re-Identification",
    "summary": "Sketch based person re-identification aims to match hand-drawn sketches with RGB surveillance images, but remains challenging due to significant modality gaps and limited annotated data. To address this, we introduce KTCAA, a theoretically grounded framework for few-shot cross-modal generalization. Motivated by generalization theory, we identify two key factors influencing target domain risk: (1) domain discrepancy, which quantifies the alignment difficulty between source and target distributions; and (2) perturbation invariance, which evaluates the model's robustness to modality shifts. Based on these insights, we propose two components: (1) Alignment Augmentation (AA), which applies localized sketch-style transformations to simulate target distributions and facilitate progressive alignment; and (2) Knowledge Transfer Catalyst (KTC), which enhances invariance by introducing worst-case perturbations and enforcing consistency. These modules are jointly optimized under a meta-learning paradigm that transfers alignment knowledge from data-rich RGB domains to sketch-based scenarios. Experiments on multiple benchmarks demonstrate that KTCAA achieves state-of-the-art performance, particularly in data-scarce conditions.",
    "published": "2025-11-24T01:26:46Z",
    "updated": "2025-11-24T01:26:46Z",
    "link": "http://arxiv.org/pdf/2511.18677v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yunpeng Gong",
      "Yongjie Hou",
      "Jiangming Shi",
      "Kim Long Diep",
      "Min Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18673v1",
    "title": "Edit2Perceive: Image Editing Diffusion Models Are Strong Dense Perceivers",
    "summary": "Recent advances in diffusion transformers have shown remarkable generalization in visual synthesis, yet most dense perception methods still rely on text-to-image (T2I) generators designed for stochastic generation. We revisit this paradigm and show that image editing diffusion models are inherently image-to-image consistent, providing a more suitable foundation for dense perception task. We introduce Edit2Perceive, a unified diffusion framework that adapts editing models for depth, normal, and matting. Built upon the FLUX.1 Kontext architecture, our approach employs full-parameter fine-tuning and a pixel-space consistency loss to enforce structure-preserving refinement across intermediate denoising states. Moreover, our single-step deterministic inference yields up to faster runtime while training on relatively small datasets. Extensive experiments demonstrate comprehensive state-of-the-art results across all three tasks, revealing the strong potential of editing-oriented diffusion transformers for geometry-aware perception.",
    "published": "2025-11-24T01:13:51Z",
    "updated": "2025-11-24T01:13:51Z",
    "link": "http://arxiv.org/pdf/2511.18673v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yiqing Shi",
      "Yiren Song",
      "Mike Zheng Shou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18672v1",
    "title": "Sphinx: Efficiently Serving Novel View Synthesis using Regression-Guided Selective Refinement",
    "summary": "Novel View Synthesis (NVS) is the task of generating new images of a scene from viewpoints that were not part of the original input. Diffusion-based NVS can generate high-quality, temporally consistent images, however, remains computationally prohibitive. Conversely, regression-based NVS offers suboptimal generation quality despite requiring significantly lower compute; leaving the design objective of a high-quality, inference-efficient NVS framework an open challenge. To close this critical gap, we present Sphinx, a training-free hybrid inference framework that achieves diffusion-level fidelity at a significantly lower compute. Sphinx proposes to use regression-based fast initialization to guide and reduce the denoising workload for the diffusion model. Additionally, it integrates selective refinement with adaptive noise scheduling, allowing more compute to uncertain regions and frames. This enables Sphinx to provide flexible navigation of the performance-quality trade-off, allowing adaptation to latency and fidelity requirements for dynamically changing inference scenarios. Our evaluation shows that Sphinx achieves an average 1.8x speedup over diffusion model inference with negligible perceptual degradation of less than 5%, establishing a new Pareto frontier between quality and latency in NVS serving.",
    "published": "2025-11-24T01:09:23Z",
    "updated": "2025-11-24T01:09:23Z",
    "link": "http://arxiv.org/pdf/2511.18672v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Yuchen Xia",
      "Souvik Kundu",
      "Mosharaf Chowdhury",
      "Nishil Talati"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18668v1",
    "title": "Data Augmentation Strategies for Robust Lane Marking Detection",
    "summary": "Robust lane detection is essential for advanced driver assistance and autonomous driving, yet models trained on public datasets such as CULane often fail to generalise across different camera viewpoints. This paper addresses the challenge of domain shift for side-mounted cameras used in lane-wheel monitoring by introducing a generative AI-based data enhancement pipeline. The approach combines geometric perspective transformation, AI-driven inpainting, and vehicle body overlays to simulate deployment-specific viewpoints while preserving lane continuity. We evaluated the effectiveness of the proposed augmentation in two state-of-the-art models, SCNN and UFLDv2. With the augmented data trained, both models show improved robustness to different conditions, including shadows. The experimental results demonstrate gains in precision, recall, and F1 score compared to the pre-trained model.\n  By bridging the gap between widely available datasets and deployment-specific scenarios, our method provides a scalable and practical framework to improve the reliability of lane detection in a pilot deployment scenario.",
    "published": "2025-11-24T00:47:27Z",
    "updated": "2025-11-24T00:47:27Z",
    "link": "http://arxiv.org/pdf/2511.18668v1.pdf",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "authors": [
      "Flora Lian",
      "Dinh Quang Huynh",
      "Hector Penades",
      "J. Stephany Berrio Perez",
      "Mao Shan",
      "Stewart Worrall"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.06714v5",
    "title": "FCDM: A Physics-Guided Bidirectional Frequency Aware Convolution and Diffusion-Based Model for Sinogram Inpainting",
    "summary": "Computed tomography (CT) is widely used in scientific imaging systems such as synchrotron and laboratory-based nano-CT, but acquiring full-view sinograms requires high radiation dose and long scan times. Sparse-view CT alleviates this burden but yields incomplete sinograms with structured signal loss, hampering accurate reconstruction. Unlike RGB images, sinograms encode overlapping features along projection paths and exhibit distinct directional spectral patterns, which make conventional RGB-oriented inpainting approaches--including diffusion models--ineffective for sinogram restoration, as they disregard the angular dependencies and physical constraints inherent to tomographic data. To overcome these limitations, we propose FCDM, a diffusion-based framework tailored for sinograms, which restores global structure through bidirectional frequency reasoning and angular-aware masking, while enforcing physical plausibility via physics-guided constraints and frequency-adaptive noise control. Experiments on real-world datasets show that FCDM consistently outperforms baselines, achieving SSIM over 0.93 and PSNR above 31 dB across diverse sparse-view scenarios.",
    "published": "2024-08-26T12:31:38Z",
    "updated": "2025-11-24T00:13:36Z",
    "link": "http://arxiv.org/pdf/2409.06714v5.pdf",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "authors": [
      "Jiaze E",
      "Srutarshi Banerjee",
      "Tekin Bicer",
      "Guannan Wang",
      "Yanfu Zhang",
      "Bin Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18656v1",
    "title": "Robust Physical Adversarial Patches Using Dynamically Optimized Clusters",
    "summary": "Physical adversarial attacks on deep learning systems is concerning due to the ease of deploying such attacks, usually by placing an adversarial patch in a scene to manipulate the outcomes of a deep learning model. Training such patches typically requires regularization that improves physical realizability (e.g., printability, smoothness) and/or robustness to real-world variability (e.g. deformations, viewing angle, noise). One type of variability that has received little attention is scale variability. When a patch is rescaled, either digitally through downsampling/upsampling or physically through changing imaging distances, interpolation-induced color mixing occurs. This smooths out pixel values, resulting in a loss of high-frequency patterns and degrading the adversarial signal. To address this, we present a novel superpixel-based regularization method that guides patch optimization to scale-resilient structures. Our ap proach employs the Simple Linear Iterative Clustering (SLIC) algorithm to dynamically cluster pixels in an adversarial patch during optimization. The Implicit Function Theorem is used to backpropagate gradients through SLIC to update the superpixel boundaries and color. This produces patches that maintain their structure over scale and are less susceptible to interpolation losses. Our method achieves greater performance in the digital domain, and when realized physically, these performance gains are preserved, leading to improved physical performance. Real-world performance was objectively assessed using a novel physical evaluation protocol that utilizes screens and cardboard cut-outs to systematically vary real-world conditions.",
    "published": "2025-11-23T23:43:31Z",
    "updated": "2025-11-23T23:43:31Z",
    "link": "http://arxiv.org/pdf/2511.18656v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Harrison Bagley",
      "Will Meakin",
      "Simon Lucey",
      "Yee Wei Law",
      "Tat-Jun Chin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18654v1",
    "title": "From Healthy Scans to Annotated Tumors: A Tumor Fabrication Framework for 3D Brain MRI Synthesis",
    "summary": "The scarcity of annotated Magnetic Resonance Imaging (MRI) tumor data presents a major obstacle to accurate and automated tumor segmentation. While existing data synthesis methods offer promising solutions, they often suffer from key limitations: manual modeling is labor intensive and requires expert knowledge. Deep generative models may be used to augment data and annotation, but they typically demand large amounts of training pairs in the first place, which is impractical in data limited clinical settings. In this work, we propose Tumor Fabrication (TF), a novel two-stage framework for unpaired 3D brain tumor synthesis. The framework comprises a coarse tumor synthesis process followed by a refinement process powered by a generative model. TF is fully automated and leverages only healthy image scans along with a limited amount of real annotated data to synthesize large volumes of paired synthetic data for enriching downstream supervised segmentation training. We demonstrate that our synthetic image-label pairs used as data enrichment can significantly improve performance on downstream tumor segmentation tasks in low-data regimes, offering a scalable and reliable solution for medical image enrichment and addressing critical challenges in data scarcity for clinical AI applications.",
    "published": "2025-11-23T23:28:49Z",
    "updated": "2025-11-23T23:28:49Z",
    "link": "http://arxiv.org/pdf/2511.18654v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Nayu Dong",
      "Townim Chowdhury",
      "Hieu Phan",
      "Mark Jenkinson",
      "Johan Verjans",
      "Zhibin Liao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.12544v3",
    "title": "Neural Collapse-Inspired Multi-Label Federated Learning under Label-Distribution Skew",
    "summary": "Federated Learning (FL) enables collaborative model training across distributed clients while preserving data privacy, yet it remains challenging as data distributions can be highly heterogeneous. These challenges are further amplified in multi-label scenarios, where data exhibit characteristics such as label co-occurrence, inter-label dependency, and discrepancies between local and global label relationships. While most existing FL studies focus on single-label classification, real-world applications, such as in medical imaging, involve multi-label data with highly skewed label distributions across clients. To address this important yet underexplored problem, we propose FedNCA-ML, a novel FL framework that aligns feature distributions across clients and learns discriminative, well-clustered representations inspired by Neural Collapse (NC) theory. NC describes an ideal latent-space geometry where each class's features collapse to their mean, forming a maximally separated simplex. To extend this theory to multi-label settings, we introduce a feature disentanglement module that extracts class-specific representations. The clustering of these disentangled features is guided by a shared NC-inspired structure, mitigating conflicts among client models caused by heterogeneous local data. Furthermore, we design regularisation losses to encourage compact and consistent feature clustering in the latent space. Experiments on four benchmark datasets under eight FL settings demonstrate the effectiveness of the proposed method, achieving improvements of up to 3.92% in class-wise AUC and 4.93% in class-wise F1 score.",
    "published": "2025-09-16T00:53:11Z",
    "updated": "2025-11-23T22:03:46Z",
    "link": "http://arxiv.org/pdf/2509.12544v3.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Can Peng",
      "Yuyuan Liu",
      "Yingyu Yang",
      "Pramit Saha",
      "Qianye Yang",
      "J. Alison Noble"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18627v1",
    "title": "Functional Localization Enforced Deep Anomaly Detection Using Fundus Images",
    "summary": "Reliable detection of retinal diseases from fundus images is challenged by the variability in imaging quality, subtle early-stage manifestations, and domain shift across datasets. In this study, we systematically evaluated a Vision Transformer (ViT) classifier under multiple augmentation and enhancement strategies across several heterogeneous public datasets, as well as the AEyeDB dataset, a high-quality fundus dataset created in-house and made available for the research community. The ViT demonstrated consistently strong performance, with accuracies ranging from 0.789 to 0.843 across datasets and diseases. Diabetic retinopathy and age-related macular degeneration were detected reliably, whereas glaucoma remained the most frequently misclassified disease. Geometric and color augmentations provided the most stable improvements, while histogram equalization benefited datasets dominated by structural subtlety. Laplacian enhancement reduced performance across different settings.\n  On the Papila dataset, the ViT with geometric augmentation achieved an AUC of 0.91, outperforming previously reported convolutional ensemble baselines (AUC of 0.87), underscoring the advantages of transformer architectures and multi-dataset training. To complement the classifier, we developed a GANomaly-based anomaly detector, achieving an AUC of 0.76 while providing inherent reconstruction-based explainability and robust generalization to unseen data. Probabilistic calibration using GUESS enabled threshold-independent decision support for future clinical implementation.",
    "published": "2025-11-23T21:56:40Z",
    "updated": "2025-11-23T21:56:40Z",
    "link": "http://arxiv.org/pdf/2511.18627v1.pdf",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "authors": [
      "Jan Benedikt Ruhland",
      "Thorsten Papenbrock",
      "Jan-Peter Sowa",
      "Ali Canbay",
      "Nicole Eter",
      "Bernd Freisleben",
      "Dominik Heider"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18617v1",
    "title": "AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations",
    "summary": "AutoFocus-IL is a simple yet effective method to improve data efficiency and generalization in visual imitation learning by guiding policies to attend to task-relevant features rather than distractors and spurious correlations. Although saliency regularization has emerged as a promising way to achieve this, existing approaches typically require costly supervision such as human gaze data or manual saliency annotations. In contrast, AutoFocus-IL leverages vision-language models (VLMs) to automatically identify and track key objects in demonstrations, generating temporal saliency maps that highlight causal visual signals while suppressing distractors. These maps are then used to regularize behavior cloning policies, yielding stronger alignment between visual attention and task-relevant cues. Experiments in both the CARLA simulator and real-robot manipulation tasks demonstrate that AutoFocus-IL not only outperforms standard behavior cloning but also surpasses state-of-the-art baselines that assume privileged access to human supervision, such as gaze data. Code, datasets, and trained policy videos are available at https://AutoFocus-IL.github.io/.",
    "published": "2025-11-23T21:21:10Z",
    "updated": "2025-11-23T21:21:10Z",
    "link": "http://arxiv.org/pdf/2511.18617v1.pdf",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "authors": [
      "Litian Gong",
      "Fatemeh Bahrani",
      "Yutai Zhou",
      "Amin Banayeeanzade",
      "Jiachen Li",
      "Erdem Biyik"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18601v1",
    "title": "RigAnyFace: Scaling Neural Facial Mesh Auto-Rigging with Unlabeled Data",
    "summary": "In this paper, we present RigAnyFace (RAF), a scalable neural auto-rigging framework for facial meshes of diverse topologies, including those with multiple disconnected components. RAF deforms a static neutral facial mesh into industry-standard FACS poses to form an expressive blendshape rig. Deformations are predicted by a triangulation-agnostic surface learning network augmented with our tailored architecture design to condition on FACS parameters and efficiently process disconnected components. For training, we curated a dataset of facial meshes, with a subset meticulously rigged by professional artists to serve as accurate 3D ground truth for deformation supervision. Due to the high cost of manual rigging, this subset is limited in size, constraining the generalization ability of models trained exclusively on it. To address this, we design a 2D supervision strategy for unlabeled neutral meshes without rigs. This strategy increases data diversity and allows for scaled training, thereby enhancing the generalization ability of models trained on this augmented data. Extensive experiments demonstrate that RAF is able to rig meshes of diverse topologies on not only our artist-crafted assets but also in-the-wild samples, outperforming previous works in accuracy and generalizability. Moreover, our method advances beyond prior work by supporting multiple disconnected components, such as eyeballs, for more detailed expression animation. Project page: https://wenchao-m.github.io/RigAnyFace.github.io",
    "published": "2025-11-23T19:55:08Z",
    "updated": "2025-11-23T19:55:08Z",
    "link": "http://arxiv.org/pdf/2511.18601v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wenchao Ma",
      "Dario Kneubuehler",
      "Maurice Chu",
      "Ian Sachs",
      "Haomiao Jiang",
      "Sharon Xiaolei Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18600v1",
    "title": "NeAR: Coupled Neural Asset-Renderer Stack",
    "summary": "Neural asset authoring and neural rendering have emerged as fundamentally disjoint threads: one generates digital assets using neural networks for traditional graphics pipelines, while the other develops neural renderers that map conventional assets to images. However, the potential of jointly designing the asset representation and renderer remains largely unexplored. We argue that coupling them can unlock an end-to-end learnable graphics stack with benefits in fidelity, consistency, and efficiency. In this paper, we explore this possibility with NeAR: a Coupled Neural Asset-Renderer Stack. On the asset side, we build on Trellis-style Structured 3D Latents and introduce a lighting-homogenized neural asset: from a casually lit input, a rectified-flow backbone predicts a Lighting-Homogenized SLAT that encodes geometry and intrinsic material cues in a compact, view-agnostic latent. On the renderer side, we design a lighting-aware neural renderer that uses this neural asset, along with explicit view embeddings and HDR environment maps, to achieve real-time, relightable rendering. We validate NeAR on four tasks: (1) G-buffer-based forward rendering, (2) random-lit single-image reconstruction, (3) unknown-lit single-image relighting, and (4) novel-view relighting. Our coupled stack surpasses state-of-the-art baselines in both quantitative metrics and perceptual quality. We hope this coupled asset-renderer perspective inspires future graphics stacks that view neural assets and renderers as co-designed components instead of independent entities.",
    "published": "2025-11-23T19:50:05Z",
    "updated": "2025-11-23T19:50:05Z",
    "link": "http://arxiv.org/pdf/2511.18600v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Hong Li",
      "Chongjie Ye",
      "Houyuan Chen",
      "Weiqing Xiao",
      "Ziyang Yan",
      "Lixing Xiao",
      "Zhaoxi Chen",
      "Jianfeng Xiang",
      "Shaocong Xu",
      "Xuhui Liu",
      "Yikai Wang",
      "Baochang Zhang",
      "Xiaoguang Han",
      "Jiaolong Yang",
      "Hao Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14620v2",
    "title": "Fusing Biomechanical and Spatio-Temporal Features for Fall Prediction: Characterizing and Mitigating the Simulation-to-Reality Gap",
    "summary": "Falls are a leading cause of injury and loss of independence among older adults. Vision-based fall prediction systems offer a non-invasive solution to anticipate falls seconds before impact, but their development is hindered by the scarcity of available fall data. Contributing to these efforts, this study proposes the Biomechanical Spatio-Temporal Graph Convolutional Network (BioST-GCN), a dual-stream model that combines both pose and biomechanical information using a cross-attention fusion mechanism. Our model outperforms the vanilla ST-GCN baseline by 5.32% and 2.91% F1-score on the simulated MCF-UA stunt-actor and MUVIM datasets, respectively. The spatio-temporal attention mechanisms in the ST-GCN stream also provide interpretability by identifying critical joints and temporal phases. However, a critical simulation-reality gap persists. While our model achieves an 89.0% F1-score with full supervision on simulated data, zero-shot generalization to unseen subjects drops to 35.9%. This performance decline is likely due to biases in simulated data, such as 'intent-to-fall' cues. For older adults, particularly those with diabetes or frailty, this gap is exacerbated by their unique kinematic profiles. To address this, we propose personalization strategies and advocate for privacy-preserving data pipelines to enable real-world validation. Our findings underscore the urgent need to bridge the gap between simulated and real-world data to develop effective fall prediction systems for vulnerable elderly populations.",
    "published": "2025-11-18T16:13:11Z",
    "updated": "2025-11-23T19:30:21Z",
    "link": "http://arxiv.org/pdf/2511.14620v2.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Md Fokhrul Islam",
      "Sajeda Al-Hammouri",
      "Christopher J. Arellano",
      "Kavan Hazeli",
      "Heman Shakeri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18591v1",
    "title": "Zero-Reference Joint Low-Light Enhancement and Deblurring via Visual Autoregressive Modeling with VLM-Derived Modulation",
    "summary": "Real-world dark images commonly exhibit not only low visibility and contrast but also complex noise and blur, posing significant restoration challenges. Existing methods often rely on paired data or fail to model dynamic illumination and blur characteristics, leading to poor generalization. To tackle this, we propose a generative framework based on visual autoregressive (VAR) modeling, guided by perceptual priors from the vision-language model (VLM). Specifically, to supply informative conditioning cues for VAR models, we deploy an adaptive curve estimation scheme to modulate the diverse illumination based on VLM-derived visibility scores. In addition, we integrate dynamic and spatial-frequency-aware Rotary Positional Encodings (SF-RoPE) into VAR to enhance its ability to model structures degraded by blur. Furthermore, we propose a recursive phase-domain modulation strategy that mitigates blur-induced artifacts in the phase domain via bounded iterative refinement guided by VLM-assessed blur scores. Our framework is fully unsupervised and achieves state-of-the-art performance on benchmark datasets.",
    "published": "2025-11-23T19:08:45Z",
    "updated": "2025-11-23T19:08:45Z",
    "link": "http://arxiv.org/pdf/2511.18591v1.pdf",
    "category": [
      "cs.CV"
    ],
    "authors": [
      "Wei Dong",
      "Han Zhou",
      "Junwei Lin",
      "Jun Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.12491v3",
    "title": "Cost-Aware Contrastive Routing for LLMs",
    "summary": "We study cost-aware routing for large language models across diverse and dynamic pools of models. Existing approaches often overlook prompt-specific context, rely on expensive model profiling, assume a fixed set of experts, or use inefficient trial-and-error strategies. We introduce Cost-Spectrum Contrastive Routing (CSCR), a lightweight framework that maps both prompts and models into a shared embedding space to enable fast, cost-sensitive selection. CSCR uses compact, fast-to-compute logit footprints for open-source models and perplexity fingerprints for black-box APIs. A contrastive encoder is trained to favor the cheapest accurate expert within adaptive cost bands. At inference time, routing reduces to a single k-NN lookup via a FAISS index, requiring no retraining when the expert pool changes and enabling microsecond latency. Across multiple benchmarks, CSCR consistently outperforms baselines, improving the accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen LLMs and out-of-distribution prompts.",
    "published": "2025-08-17T20:16:44Z",
    "updated": "2025-11-24T18:59:36Z",
    "link": "http://arxiv.org/pdf/2508.12491v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Reza Shirkavand",
      "Shangqian Gao",
      "Peiran Yu",
      "Heng Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.13644v2",
    "title": "Collapsing Taylor Mode Automatic Differentiation",
    "summary": "Computing partial differential equation (PDE) operators via nested backpropagation is expensive, yet popular, and severely restricts their utility for scientific machine learning. Recent advances, like the forward Laplacian and randomizing Taylor mode automatic differentiation (AD), propose forward schemes to address this. We introduce an optimization technique for Taylor mode that 'collapses' derivatives by rewriting the computational graph, and demonstrate how to apply it to general linear PDE operators, and randomized Taylor mode. The modifications simply require propagating a sum up the computational graph, which could -- or should -- be done by a machine learning compiler, without exposing complexity to users. We implement our collapsing procedure and evaluate it on popular PDE operators, confirming it accelerates Taylor mode and outperforms nested backpropagation.",
    "published": "2025-05-19T18:31:31Z",
    "updated": "2025-11-24T18:57:49Z",
    "link": "http://arxiv.org/pdf/2505.13644v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Felix Dangel",
      "Tim Siebert",
      "Marius Zeinhofer",
      "Andrea Walther"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.17796v2",
    "title": "SING: SDE Inference via Natural Gradients",
    "summary": "Latent stochastic differential equation (SDE) models are important tools for the unsupervised discovery of dynamical systems from data, with applications ranging from engineering to neuroscience. In these complex domains, exact posterior inference of the latent state path is typically intractable, motivating the use of approximate methods such as variational inference (VI). However, existing VI methods for inference in latent SDEs often suffer from slow convergence and numerical instability. We propose SDE Inference via Natural Gradients (SING), a method that leverages natural gradient VI to efficiently exploit the underlying geometry of the model and variational posterior. SING enables fast and reliable inference in latent SDE models by approximating intractable integrals and parallelizing computations in time. We provide theoretical guarantees that SING approximately optimizes the intractable, continuous-time objective of interest. Moreover, we demonstrate that better state inference enables more accurate estimation of nonlinear drift functions using, for example, Gaussian process SDE models. SING outperforms prior methods in state inference and drift estimation on a variety of datasets, including a challenging application to modeling neural dynamics in freely behaving animals. Altogether, our results illustrate the potential of SING as a tool for accurate inference in complex dynamical systems, especially those characterized by limited prior knowledge and non-conjugate structure.",
    "published": "2025-06-21T19:36:11Z",
    "updated": "2025-11-24T18:49:51Z",
    "link": "http://arxiv.org/pdf/2506.17796v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Amber Hu",
      "Henry Smith",
      "Scott Linderman"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19405v1",
    "title": "Learning Robust Social Strategies with Large Language Models",
    "summary": "As agentic AI becomes more widespread, agents with distinct and possibly conflicting goals will interact in complex ways. These multi-agent interactions pose a fundamental challenge, particularly in social dilemmas, where agents' individual incentives can undermine collective welfare. While reinforcement learning (RL) has been effective for aligning large language models (LLMs) in the single-agent regime, prior small-network results suggest that standard RL in multi-agent settings often converges to defecting, self-interested policies. We show the same effect in LLMs: despite cooperative priors, RL-trained LLM agents develop opportunistic behavior that can exploit even advanced closed-source models. To address this tendency of RL to converge to poor equilibria, we adapt a recent opponent-learning awareness algorithm, Advantage Alignment, to fine-tune LLMs toward multi-agent cooperation and non-exploitability. We then introduce a group-relative baseline that simplifies advantage computation in iterated games, enabling multi-agent training at LLM scale. We also contribute a novel social dilemma environment, Trust and Split, which requires natural language communication to achieve high collective welfare. Across a wide range of social dilemmas, policies learned with Advantage Alignment achieve higher collective payoffs while remaining robust against exploitation by greedy agents.",
    "published": "2025-11-24T18:43:46Z",
    "updated": "2025-11-24T18:43:46Z",
    "link": "http://arxiv.org/pdf/2511.19405v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Dereck Piche",
      "Mohammed Muqeeth",
      "Milad Aghajohari",
      "Juan Duque",
      "Michael Noukhovitch",
      "Aaron Courville"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19404v1",
    "title": "Nonparametric Instrumental Variable Regression with Observed Covariates",
    "summary": "We study the problem of nonparametric instrumental variable regression with observed covariates, which we refer to as NPIV-O. Compared with standard nonparametric instrumental variable regression (NPIV), the additional observed covariates facilitate causal identification and enables heterogeneous causal effect estimation. However, the presence of observed covariates introduces two challenges for its theoretical analysis. First, it induces a partial identity structure, which renders previous NPIV analyses - based on measures of ill-posedness, stability conditions, or link conditions - inapplicable. Second, it imposes anisotropic smoothness on the structural function. To address the first challenge, we introduce a novel Fourier measure of partial smoothing; for the second challenge, we extend the existing kernel 2SLS instrumental variable algorithm with observed covariates, termed KIV-O, to incorporate Gaussian kernel lengthscales adaptive to the anisotropic smoothness. We prove upper $L^2$-learning rates for KIV-O and the first $L^2$-minimax lower learning rates for NPIV-O. Both rates interpolate between known optimal rates of NPIV and nonparametric regression (NPR). Interestingly, we identify a gap between our upper and lower bounds, which arises from the choice of kernel lengthscales tuned to minimize a projected risk. Our theoretical analysis also applies to proximal causal inference, an emerging framework for causal effect estimation that shares the same conditional moment restriction as NPIV-O.",
    "published": "2025-11-24T18:42:49Z",
    "updated": "2025-11-24T18:42:49Z",
    "link": "http://arxiv.org/pdf/2511.19404v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.ST"
    ],
    "authors": [
      "Zikai Shen",
      "Zonghao Chen",
      "Dimitri Meunier",
      "Ingo Steinwart",
      "Arthur Gretton",
      "Zhu Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19398v1",
    "title": "PTF Testing Lower Bounds for Non-Gaussian Component Analysis",
    "summary": "This work studies information-computation gaps for statistical problems. A common approach for providing evidence of such gaps is to show sample complexity lower bounds (that are stronger than the information-theoretic optimum) against natural models of computation. A popular such model in the literature is the family of low-degree polynomial tests. While these tests are defined in such a way that make them easy to analyze, the class of algorithms that they rule out is somewhat restricted. An important goal in this context has been to obtain lower bounds against the stronger and more natural class of low-degree Polynomial Threshold Function (PTF) tests, i.e., any test that can be expressed as comparing some low-degree polynomial of the data to a threshold. Proving lower bounds against PTF tests has turned out to be challenging. Indeed, we are not aware of any non-trivial PTF testing lower bounds in the literature.\n  In this paper, we establish the first non-trivial PTF testing lower bounds for a range of statistical tasks. Specifically, we prove a near-optimal PTF testing lower bound for Non-Gaussian Component Analysis (NGCA). Our NGCA lower bound implies similar lower bounds for a number of other statistical problems. Our proof leverages a connection to recent work on pseudorandom generators for PTFs and recent techniques developed in that context. At the technical level, we develop several tools of independent interest, including novel structural results for analyzing the behavior of low-degree polynomials restricted to random directions.",
    "published": "2025-11-24T18:35:29Z",
    "updated": "2025-11-24T18:35:29Z",
    "link": "http://arxiv.org/pdf/2511.19398v1.pdf",
    "category": [
      "cs.DS",
      "cs.IT",
      "cs.LG",
      "math.ST",
      "stat.ML"
    ],
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Sihan Liu",
      "Thanasis Pittas"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19379v1",
    "title": "Efficiency vs. Fidelity: A Comparative Analysis of Diffusion Probabilistic Models and Flow Matching on Low-Resource Hardware",
    "summary": "Denoising Diffusion Probabilistic Models (DDPMs) have established a new state-of-the-art in generative image synthesis, yet their deployment is hindered by significant computational overhead during inference, often requiring up to 1,000 iterative steps. This study presents a rigorous comparative analysis of DDPMs against the emerging Flow Matching (Rectified Flow) paradigm, specifically isolating their geometric and efficiency properties on low-resource hardware. By implementing both frameworks on a shared Time-Conditioned U-Net backbone using the MNIST dataset, we demonstrate that Flow Matching significantly outperforms Diffusion in efficiency. Our geometric analysis reveals that Flow Matching learns a highly rectified transport path (Curvature $\\mathcal{C} \\approx 1.02$), which is near-optimal, whereas Diffusion trajectories remain stochastic and tortuous ($\\mathcal{C} \\approx 3.45$). Furthermore, we establish an ``efficiency frontier'' at $N=10$ function evaluations, where Flow Matching retains high fidelity while Diffusion collapses. Finally, we show via numerical sensitivity analysis that the learned vector field is sufficiently linear to render high-order ODE solvers (Runge-Kutta 4) unnecessary, validating the use of lightweight Euler solvers for edge deployment. \\textbf{This work concludes that Flow Matching is the superior algorithmic choice for real-time, resource-constrained generative tasks.}",
    "published": "2025-11-24T18:19:42Z",
    "updated": "2025-11-24T18:19:42Z",
    "link": "http://arxiv.org/pdf/2511.19379v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Srishti Gupta",
      "Yashasvee Taiwade"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19368v1",
    "title": "LLM-Driven Stationarity-Aware Expert Demonstrations for Multi-Agent Reinforcement Learning in Mobile Systems",
    "summary": "Multi-agent reinforcement learning (MARL) has been increasingly adopted in many real-world applications. While MARL enables decentralized deployment on resource-constrained edge devices, it suffers from severe non-stationarity due to the synchronous updates of agent policies. This non stationarity results in unstable training and poor policy con vergence, especially as the number of agents increases. In this paper, we propose RELED, a scalable MARL framework that integrates large language model (LLM)-driven expert demonstrations with autonomous agent exploration. RELED incorporates a Stationarity-Aware Expert Demonstration module, which leverages theoretical non-stationarity bounds to enhance the quality of LLM-generated expert trajectories, thus providing high reward and training-stable samples for each agent. Moreover, a Hybrid Expert-Agent Policy Optimization module adaptively balances each agent's learning from both expert-generated and agent-generated trajectories, accelerating policy convergence and improving generalization. Extensive experiments with real city networks based on OpenStreetMap demonstrate that RELED achieves superior performance compared to state-of-the-art MARL methods.",
    "published": "2025-11-24T18:03:59Z",
    "updated": "2025-11-24T18:03:59Z",
    "link": "http://arxiv.org/pdf/2511.19368v1.pdf",
    "category": [
      "cs.LG",
      "cs.NI"
    ],
    "authors": [
      "Tianyang Duan",
      "Zongyuan Zhang",
      "Zheng Lin",
      "Songxiao Guo",
      "Xiuxian Guan",
      "Guangyu Wu",
      "Zihan Fang",
      "Haotian Meng",
      "Xia Du",
      "Ji-Zhe Zhou",
      "Heming Cui",
      "Jun Luo",
      "Yue Gao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19364v1",
    "title": "Neural surrogates for designing gravitational wave detectors",
    "summary": "Physics simulators are essential in science and engineering, enabling the analysis, control, and design of complex systems. In experimental sciences, they are increasingly used to automate experimental design, often via combinatorial search and optimization. However, as the setups grow more complex, the computational cost of traditional, CPU-based simulators becomes a major limitation. Here, we show how neural surrogate models can significantly reduce reliance on such slow simulators while preserving accuracy. Taking the design of interferometric gravitational wave detectors as a representative example, we train a neural network to surrogate the gravitational wave physics simulator Finesse, which was developed by the LIGO community. Despite that small changes in physical parameters can change the output by orders of magnitudes, the model rapidly predicts the quality and feasibility of candidate designs, allowing an efficient exploration of large design spaces. Our algorithm loops between training the surrogate, inverse designing new experiments, and verifying their properties with the slow simulator for further training. Assisted by auto-differentiation and GPU parallelism, our method proposes high-quality experiments much faster than direct optimization. Solutions that our algorithm finds within hours outperform designs that take five days for the optimizer to reach. Though shown in the context of gravitational wave detectors, our framework is broadly applicable to other domains where simulator bottlenecks hinder optimization and discovery.",
    "published": "2025-11-24T17:58:59Z",
    "updated": "2025-11-24T17:58:59Z",
    "link": "http://arxiv.org/pdf/2511.19364v1.pdf",
    "category": [
      "cs.LG",
      "astro-ph.IM",
      "gr-qc",
      "quant-ph"
    ],
    "authors": [
      "Carlos Ruiz-Gonzalez",
      "Sören Arlt",
      "Sebastian Lehner",
      "Arturs Berzins",
      "Yehonathan Drori",
      "Rana X Adhikari",
      "Johannes Brandstetter",
      "Mario Krenn"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19359v1",
    "title": "Enhancing Conformal Prediction via Class Similarity",
    "summary": "Conformal Prediction (CP) has emerged as a powerful statistical framework for high-stakes classification applications. Instead of predicting a single class, CP generates a prediction set, guaranteed to include the true label with a pre-specified probability. The performance of different CP methods is typically assessed by their average prediction set size. In setups where the classes can be partitioned into semantic groups, e.g., diseases that require similar treatment, users can benefit from prediction sets that are not only small on average, but also contain a small number of semantically different groups. This paper begins by addressing this problem and ultimately offers a widely applicable tool for boosting any CP method on any dataset. First, given a class partition, we propose augmenting the CP score function with a term that penalizes predictions with out-of-group errors. We theoretically analyze this strategy and prove its advantages for group-related metrics. Surprisingly, we show mathematically that, for common class partitions, it can also reduce the average set size of any CP score function. Our analysis reveals the class similarity factors behind this improvement and motivates us to propose a model-specific variant, which does not require any human semantic partition and can further reduce the prediction set size. Finally, we present an extensive empirical study, encompassing prominent CP methods, multiple models, and several datasets, which demonstrates that our class-similarity-based approach consistently enhances CP methods.",
    "published": "2025-11-24T17:56:42Z",
    "updated": "2025-11-24T17:56:42Z",
    "link": "http://arxiv.org/pdf/2511.19359v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ariel Fargion",
      "Lahav Dabah",
      "Tom Tirer"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19347v1",
    "title": "Artificial Intelligence Driven Workflow for Accelerating Design of Novel Photosensitizers",
    "summary": "The discovery of high-performance photosensitizers has long been hindered by the time-consuming and resource-intensive nature of traditional trial-and-error approaches. Here, we present \\textbf{A}I-\\textbf{A}ccelerated \\textbf{P}hoto\\textbf{S}ensitizer \\textbf{I}nnovation (AAPSI), a closed-loop workflow that integrates expert knowledge, scaffold-based molecule generation, and Bayesian optimization to accelerate the design of novel photosensitizers. The scaffold-driven generation in AAPSI ensures structural novelty and synthetic feasibility, while the iterative AI-experiment loop accelerates the discovery of novel photosensitizers. AAPSI leverages a curated database of 102,534 photosensitizer-solvent pairs and generate 6,148 synthetically accessible candidates. These candidates are screened via graph transformers trained to predict singlet oxygen quantum yield ($φ_Δ$) and absorption maxima ($λ_{max}$), following experimental validation. This work generates several novel candidates for photodynamic therapy (PDT), among which the hypocrellin-based candidate HB4Ph exhibits exceptional performance at the Pareto frontier of high quantum yield of singlet oxygen and long absorption maxima among current photosensitizers ($φ_Δ$=0.85, $λ_{max}$=650nm).",
    "published": "2025-11-24T17:46:54Z",
    "updated": "2025-11-24T17:46:54Z",
    "link": "http://arxiv.org/pdf/2511.19347v1.pdf",
    "category": [
      "cond-mat.mtrl-sci",
      "cs.LG",
      "physics.chem-ph"
    ],
    "authors": [
      "Hongyi Wang",
      "Xiuli Zheng",
      "Weimin Liu",
      "Zitian Tang",
      "Sheng Gong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19344v1",
    "title": "Annotation-Free Class-Incremental Learning",
    "summary": "Despite significant progress in continual learning ranging from architectural novelty to clever strategies for mitigating catastrophic forgetting most existing methods rest on a strong but unrealistic assumption the availability of labeled data throughout the learning process. In real-world scenarios, however, data often arrives sequentially and without annotations, rendering conventional approaches impractical. In this work, we revisit the fundamental assumptions of continual learning and ask: Can current systems adapt when labels are absent and tasks emerge incrementally over time? To this end, we introduce Annotation-Free Class-Incremental Learning (AFCIL), a more realistic and challenging paradigm where unlabeled data arrives continuously, and the learner must incrementally acquire new classes without any supervision. To enable effective learning under AFCIL, we propose CrossWorld CL, a Cross Domain World Guided Continual Learning framework that incorporates external world knowledge as a stable auxiliary source. The method retrieves semantically related ImageNet classes for each downstream category, maps downstream and ImageNet features through a cross domain alignment strategy and finally introduce a novel replay strategy. This design lets the model uncover semantic structure without annotations while keeping earlier knowledge intact. Across four datasets, CrossWorld-CL surpasses CLIP baselines and existing continual and unlabeled learning methods, underscoring the benefit of world knowledge for annotation free continual learning.",
    "published": "2025-11-24T17:44:48Z",
    "updated": "2025-11-24T17:44:48Z",
    "link": "http://arxiv.org/pdf/2511.19344v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hari Chandana Kuchibhotla",
      "K S Ananth",
      "Vineeth N Balasubramanian"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19335v1",
    "title": "High-throughput validation of phase formability and simulation accuracy of Cantor alloys",
    "summary": "High-throughput methods enable accelerated discovery of novel materials in complex systems such as high-entropy alloys, which exhibit intricate phase stability across vast compositional spaces. Computational approaches, including Density Functional Theory (DFT) and calculation of phase diagrams (CALPHAD), facilitate screening of phase formability as a function of composition and temperature. However, the integration of computational predictions with experimental validation remains challenging in high-throughput studies. In this work, we introduce a quantitative confidence metric to assess the agreement between predictions and experimental observations, providing a quantitative measure of the confidence of machine learning models trained on either DFT or CALPHAD input in accounting for experimental evidence. The experimental dataset was generated via high-throughput in-situ synchrotron X-ray diffraction on compositionally varied FeNiMnCr alloy libraries, heated from room temperature to ~1000 °C. Agreement between the observed and predicted phases was evaluated using either temperature-independent phase classification or a model that incorporates a temperature-dependent probability of phase formation. This integrated approach demonstrates where strong overall agreement between computation and experiment exists, while also identifying key discrepancies, particularly in FCC/BCC predictions at Mn-rich regions to inform future model refinement.",
    "published": "2025-11-24T17:31:16Z",
    "updated": "2025-11-24T17:31:16Z",
    "link": "http://arxiv.org/pdf/2511.19335v1.pdf",
    "category": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "authors": [
      "Changjun Cheng",
      "Daniel Persaud",
      "Kangming Li",
      "Michael J. Moorehead",
      "Natalie Page",
      "Christian Lavoie",
      "Beatriz Diaz Moreno",
      "Adrien Couet",
      "Samuel E Lofland",
      "Jason Hattrick-Simpers"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19330v1",
    "title": "Targeted Manipulation: Slope-Based Attacks on Financial Time-Series Data",
    "summary": "A common method of attacking deep learning models is through adversarial attacks, which occur when an attacker specifically modifies the input of a model to produce an incorrect result. Adversarial attacks have been deeply investigated in the image domain; however, there is less research in the time-series domain and very little for forecasting financial data. To address these concerns, this study aims to build upon previous research on adversarial attacks for time-series data by introducing two new slope-based methods aimed to alter the trends of the predicted stock forecast generated by an N-HiTS model. Compared to the normal N-HiTS predictions, the two new slope-based methods, the General Slope Attack and Least-Squares Slope Attack, can manipulate N-HiTS predictions by doubling the slope. These new slope attacks can bypass standard security mechanisms, such as a discriminator that filters real and perturbed inputs, reducing a 4-layered CNN's specificity to 28% and accuracy to 57%. Furthermore, the slope based methods were incorporated into a GAN architecture as a means of generating realistic synthetic data, while simultaneously fooling the model. Finally, this paper also proposes a sample malware designed to inject an adversarial attack in the model inference library, proving that ML-security research should not only focus on making the model safe, but also securing the entire pipeline.",
    "published": "2025-11-24T17:26:20Z",
    "updated": "2025-11-24T17:26:20Z",
    "link": "http://arxiv.org/pdf/2511.19330v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Dominik Luszczynski"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.00904v2",
    "title": "Random Spiking Neural Networks are Stable and Spectrally Simple",
    "summary": "Spiking neural networks (SNNs) are a promising paradigm for energy-efficient computation, yet their theoretical foundations-especially regarding stability and robustness-remain limited compared to artificial neural networks. In this work, we study discrete-time leaky integrate-and-fire (LIF) SNNs through the lens of Boolean function analysis. We focus on noise sensitivity and stability in classification tasks, quantifying how input perturbations affect outputs. Our main result shows that wide LIF-SNN classifiers are stable on average, a property explained by the concentration of their Fourier spectrum on low-frequency components. Motivated by this, we introduce the notion of spectral simplicity, which formalizes simplicity in terms of Fourier spectrum concentration and connects our analysis to the simplicity bias observed in deep networks. Within this framework, we show that random LIF-SNNs are biased toward simple functions. Experiments on trained networks confirm that these stability properties persist in practice. Together, these results provide new insights into the stability and robustness properties of SNNs.",
    "published": "2025-11-02T11:55:27Z",
    "updated": "2025-11-24T17:25:02Z",
    "link": "http://arxiv.org/pdf/2511.00904v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Ernesto Araya",
      "Massimiliano Datres",
      "Gitta Kutyniok"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19328v1",
    "title": "Understanding the Staged Dynamics of Transformers in Learning Latent Structure",
    "summary": "While transformers can discover latent structure from context, the dynamics of how they acquire different components of the latent structure remain poorly understood. In this work, we use the Alchemy benchmark, to investigate the dynamics of latent structure learning. We train a small decoder-only transformer on three task variants: 1) inferring missing rules from partial contextual information, 2) composing simple rules to solve multi-step sequences, and 3) decomposing complex multi-step examples to infer intermediate steps. By factorizing each task into interpretable events, we show that the model acquires capabilities in discrete stages, first learning the coarse grained rules, before learning the complete latent structure. We also identify a crucial asymmetry, where the model can compose fundamental rules robustly, but struggles to decompose complex examples to discover the fundamental rules. These findings offer new insights into understanding how a transformer model learns latent structures, providing a granular view of how these capabilities evolve during training.",
    "published": "2025-11-24T17:20:42Z",
    "updated": "2025-11-24T17:20:42Z",
    "link": "http://arxiv.org/pdf/2511.19328v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Rohan Saha",
      "Farzane Aminmansour",
      "Alona Fyshe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.07635v4",
    "title": "Interpreting Graph Inference with Skyline Explanations",
    "summary": "Inference queries have been routinely issued to graph machine learning models such as graph neural networks (GNNs) for various network analytical tasks. Nevertheless, GNN outputs are often hard to interpret comprehensively. Existing methods typically conform to individual pre-defined explainability measures (such as fidelity), which often leads to biased, ``one-side'' interpretations. This paper introduces skyline explanation, a new paradigm that interprets GNN outputs by simultaneously optimizing multiple explainability measures of users' interests. (1) We propose skyline explanations as a Pareto set of explanatory subgraphs that dominate others over multiple explanatory measures. We formulate skyline explanation as a multi-criteria optimization problem, and establish its hardness results. (2) We design efficient algorithms with an onion-peeling approach, which strategically prioritizes nodes and removes unpromising edges to incrementally assemble skyline explanations. (3) We also develop an algorithm to diversify the skyline explanations to enrich the comprehensive interpretation. (4) We introduce efficient parallel algorithms with load-balancing strategies to scale skyline explanation for large-scale GNN-based inference. Using real-world and synthetic graphs, we experimentally verify our algorithms' effectiveness and scalability.",
    "published": "2025-05-12T15:05:46Z",
    "updated": "2025-11-24T17:17:12Z",
    "link": "http://arxiv.org/pdf/2505.07635v4.pdf",
    "category": [
      "cs.LG",
      "cs.DB"
    ],
    "authors": [
      "Dazhuo Qiu",
      "Haolai Che",
      "Arijit Khan",
      "Yinghui Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.04898v2",
    "title": "When do World Models Successfully Learn Dynamical Systems?",
    "summary": "In this work, we explore the use of compact latent representations with learned time dynamics ('World Models') to simulate physical systems. Drawing on concepts from control theory, we propose a theoretical framework that explains why projecting time slices into a low-dimensional space and then concatenating to form a history ('Tokenization') is so effective at learning physics datasets, and characterise when exactly the underlying dynamics admit a reconstruction mapping from the history of previous tokenized frames to the next. To validate these claims, we develop a sequence of models with increasing complexity, starting with least-squares regression and progressing through simple linear layers, shallow adversarial learners, and ultimately full-scale generative adversarial networks (GANs). We evaluate these models on a variety of datasets, including modified forms of the heat and wave equations, the chaotic regime 2D Kuramoto-Sivashinsky equation, and a challenging computational fluid dynamics (CFD) dataset of a 2D Kármán vortex street around a fixed cylinder, where our model is successfully able to recreate the flow.",
    "published": "2025-07-07T11:29:18Z",
    "updated": "2025-11-24T17:16:42Z",
    "link": "http://arxiv.org/pdf/2507.04898v2.pdf",
    "category": [
      "math.NA",
      "cs.LG"
    ],
    "authors": [
      "Edmund Ross",
      "Claudia Drygala",
      "Leonhard Schwarz",
      "Samir Kaiser",
      "Francesca di Mare",
      "Tobias Breiten",
      "Hanno Gottschalk"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.15480v2",
    "title": "Learning Protein-Ligand Binding in Hyperbolic Space",
    "summary": "Protein-ligand binding prediction is central to virtual screening and affinity ranking, two fundamental tasks in drug discovery. While recent retrieval-based methods embed ligands and protein pockets into Euclidean space for similarity-based search, the geometry of Euclidean embeddings often fails to capture the hierarchical structure and fine-grained affinity variations intrinsic to molecular interactions. In this work, we propose HypSeek, a hyperbolic representation learning framework that embeds ligands, protein pockets, and sequences into Lorentz-model hyperbolic space. By leveraging the exponential geometry and negative curvature of hyperbolic space, HypSeek enables expressive, affinity-sensitive embeddings that can effectively model both global activity and subtle functional differences-particularly in challenging cases such as activity cliffs, where structurally similar ligands exhibit large affinity gaps. Our mode unifies virtual screening and affinity ranking in a single framework, introducing a protein-guided three-tower architecture to enhance representational structure. HypSeek improves early enrichment in virtual screening on DUD-E from 42.63 to 51.44 (+20.7%) and affinity ranking correlation on JACS from 0.5774 to 0.7239 (+25.4%), demonstrating the benefits of hyperbolic geometry across both tasks and highlighting its potential as a powerful inductive bias for protein-ligand modeling.",
    "published": "2025-08-21T11:56:25Z",
    "updated": "2025-11-24T16:47:54Z",
    "link": "http://arxiv.org/pdf/2508.15480v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jianhui Wang",
      "Wenyu Zhu",
      "Bowen Gao",
      "Xin Hong",
      "Ya-Qin Zhang",
      "Wei-Ying Ma",
      "Yanyan Lan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.11684v3",
    "title": "A Bayesian Model for Multi-stage Censoring",
    "summary": "Many sequential decision settings in healthcare feature funnel structures characterized by a series of stages, such as screenings or evaluations, where the number of patients who advance to each stage progressively decreases and decisions become increasingly costly. For example, an oncologist may first conduct a breast exam, followed by a mammogram for patients with concerning exams, followed by a biopsy for patients with concerning mammograms. A key challenge is that the ground truth outcome, such as the biopsy result, is only revealed at the end of this funnel. The selective censoring of the ground truth can introduce statistical biases in risk estimation, especially in underserved patient groups, whose outcomes are more frequently censored. We develop a Bayesian model for funnel decision structures, drawing from prior work on selective labels and censoring. We first show in synthetic settings that our model is able to recover the true parameters and predict outcomes for censored patients more accurately than baselines. We then apply our model to a dataset of emergency department visits, where in-hospital mortality is observed only for those who are admitted to either the hospital or ICU. We find that there are gender-based differences in hospital and ICU admissions. In particular, our model estimates that the mortality risk threshold to admit women to the ICU is higher for women (5.1%) than for men (4.5%).",
    "published": "2025-11-12T08:14:41Z",
    "updated": "2025-11-24T16:42:03Z",
    "link": "http://arxiv.org/pdf/2511.11684v3.pdf",
    "category": [
      "cs.LG",
      "stat.AP"
    ],
    "authors": [
      "Shuvom Sadhuka",
      "Sophia Lin",
      "Bonnie Berger",
      "Emma Pierson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19291v1",
    "title": "TorchQuantumDistributed",
    "summary": "TorchQuantumDistributed (tqd) is a PyTorch-based [Paszke et al., 2019] library for accelerator-agnostic differentiable quantum state vector simulation at scale. This enables studying the behavior of learnable parameterized near-term and fault- tolerant quantum circuits with high qubit counts.",
    "published": "2025-11-24T16:37:28Z",
    "updated": "2025-11-24T16:37:28Z",
    "link": "http://arxiv.org/pdf/2511.19291v1.pdf",
    "category": [
      "quant-ph",
      "cs.CE",
      "cs.LG"
    ],
    "authors": [
      "Oliver Knitter",
      "Jonathan Mei",
      "Masako Yamada",
      "Martin Roetteler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19289v1",
    "title": "Performance Guarantees for Quantum Neural Estimation of Entropies",
    "summary": "Estimating quantum entropies and divergences is an important problem in quantum physics, information theory, and machine learning. Quantum neural estimators (QNEs), which utilize a hybrid classical-quantum architecture, have recently emerged as an appealing computational framework for estimating these measures. Such estimators combine classical neural networks with parametrized quantum circuits, and their deployment typically entails tedious tuning of hyperparameters controlling the sample size, network architecture, and circuit topology. This work initiates the study of formal guarantees for QNEs of measured (Rényi) relative entropies in the form of non-asymptotic error risk bounds. We further establish exponential tail bounds showing that the error is sub-Gaussian, and thus sharply concentrates about the ground truth value. For an appropriate sub-class of density operator pairs on a space of dimension $d$ with bounded Thompson metric, our theory establishes a copy complexity of $O(|Θ(\\mathcal{U})|d/ε^2)$ for QNE with a quantum circuit parameter set $Θ(\\mathcal{U})$, which has minimax optimal dependence on the accuracy $ε$. Additionally, if the density operator pairs are permutation invariant, we improve the dimension dependence above to $O(|Θ(\\mathcal{U})|\\mathrm{polylog}(d)/ε^2)$. Our theory aims to facilitate principled implementation of QNEs for measured relative entropies and guide hyperparameter tuning in practice.",
    "published": "2025-11-24T16:36:06Z",
    "updated": "2025-11-24T16:36:06Z",
    "link": "http://arxiv.org/pdf/2511.19289v1.pdf",
    "category": [
      "quant-ph",
      "cs.IT",
      "cs.LG"
    ],
    "authors": [
      "Sreejith Sreekumar",
      "Ziv Goldfeld",
      "Mark M. Wilde"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19284v1",
    "title": "The Unified Non-Convex Framework for Robust Causal Inference: Overcoming the Gaussian Barrier and Optimization Fragility",
    "summary": "This document proposes a Unified Robust Framework that re-engineers the estimation of the Average Treatment Effect on the Overlap (ATO). It synthesizes gamma-Divergence for outlier robustness, Graduated Non-Convexity (GNC) for global optimization, and a \"Gatekeeper\" mechanism to address the impossibility of higher-order orthogonality in Gaussian regimes.",
    "published": "2025-11-24T16:32:07Z",
    "updated": "2025-11-24T16:32:07Z",
    "link": "http://arxiv.org/pdf/2511.19284v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Eichi Uehara"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19277v1",
    "title": "Closing Gaps in Emissions Monitoring with Climate TRACE",
    "summary": "Global greenhouse gas emissions estimates are essential for monitoring and mitigation planning. Yet most datasets lack one or more characteristics that enhance their actionability, such as accuracy, global coverage, high spatial and temporal resolution, and frequent updates. To address these gaps, we present Climate TRACE (climatetrace.org), an open-access platform delivering global emissions estimates with enhanced detail, coverage, and timeliness. Climate TRACE synthesizes existing emissions data, prioritizing accuracy, coverage, and resolution, and fills gaps using sector-specific estimation approaches. The dataset is the first to provide globally comprehensive emissions estimates for individual sources (e.g., individual power plants) for all anthropogenic emitting sectors. The dataset spans January 1, 2021, to the present, with a two-month reporting lag and monthly updates. The open-access platform enables non-technical audiences to engage with detailed emissions datasets for most subnational governments worldwide. Climate TRACE supports data-driven climate action at scales where decisions are made, representing a major breakthrough for emissions accounting and mitigation.",
    "published": "2025-11-24T16:28:44Z",
    "updated": "2025-11-24T16:28:44Z",
    "link": "http://arxiv.org/pdf/2511.19277v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Brittany V. Lancellotti",
      "Jordan M. Malof",
      "Aaron Davitt",
      "Gavin McCormick",
      "Shelby Anderson",
      "Pol Carbó-Mestre",
      "Gary Collins",
      "Verity Crane",
      "Zoheyr Doctor",
      "George Ebri",
      "Kevin Foster",
      "Trey M. Gowdy",
      "Michael Guzzardi",
      "John Heal",
      "Heather Hunter",
      "David Kroodsma",
      "Khandekar Mahammad Galib",
      "Paul J. Markakis",
      "Gavin McDonald",
      "Daniel P. Moore",
      "Eric D. Nguyen",
      "Sabina Parvu",
      "Michael Pekala",
      "Christine D. Piatko",
      "Amy Piscopo",
      "Mark Powell",
      "Krsna Raniga",
      "Elizabeth P. Reilly",
      "Michael Robinette",
      "Ishan Saraswat",
      "Patrick Sicurello",
      "Isabella Söldner-Rembold",
      "Raymond Song",
      "Charlotte Underwood",
      "Kyle Bradbury"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19273v1",
    "title": "Scalable Bayesian Network Structure Learning Using Tsetlin Machine to Constrain the Search Space",
    "summary": "The PC algorithm is a widely used method in causal inference for learning the structure of Bayesian networks. Despite its popularity, the PC algorithm suffers from significant time complexity, particularly as the size of the dataset increases, which limits its applicability in large-scale real-world problems. In this study, we propose a novel approach that utilises the Tsetlin Machine (TM) to construct Bayesian structures more efficiently. Our method leverages the most significant literals extracted from the TM and performs conditional independence (CI) tests on these selected literals instead of the full set of variables, resulting in a considerable reduction in computational time. We implemented our approach and compared it with various state-of-the-art methods. Our evaluation includes categorical datasets from the bnlearn repository, such as Munin1, Hepar2. The findings indicate that the proposed TM-based method not only reduces computational complexity but also maintains competitive accuracy in causal discovery, making it a viable alternative to traditional PC algorithm implementations by offering improved efficiency without compromising performance.",
    "published": "2025-11-24T16:23:19Z",
    "updated": "2025-11-24T16:23:19Z",
    "link": "http://arxiv.org/pdf/2511.19273v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kunal Dumbre",
      "Lei Jiao",
      "Ole-Christoffer Granmo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19272v1",
    "title": "Tiny-TSM: Efficiently Training a Lightweight SOTA Time Series Foundation Model",
    "summary": "We present Tiny-TSM, a time series foundation model characterized by small scale, economical training, and state-of-the-art performance. It comprises 23M total parameters, trained on a single A100 GPU in less than a week using a new synthetic data generation and data augmentation pipeline (SynthTS). Without any neural architecture search, hyperparameter tuning, or scaling up model size, Tiny-TSM achieves state-of-the-art performance on a wide range of time series benchmark datasets, often outperforming much larger models and even matching the performance of much larger, industrial-scale, likely highly tuned foundation models. Specifically, Tiny-TSM outperforms all other time series foundation models we evaluated on medium- and long-term forecasting tasks under MSE loss, while short-term accuracy is still competitive with state-of-the-art models.\n  We also introduce a causal input normalization scheme that enables time series models to be trained with dense next-token prediction loss, significantly accelerating convergence speed and reducing training time.\n  All experiments were conducted on a single A100 GPU, illustrating the practicality of the proposed approach in a resource-constrained setting.",
    "published": "2025-11-24T16:22:05Z",
    "updated": "2025-11-24T16:22:05Z",
    "link": "http://arxiv.org/pdf/2511.19272v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Felix Birkel"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19267v1",
    "title": "Leveraging Spatiotemporal Graph Neural Networks for Multi-Store Sales Forecasting",
    "summary": "This work evaluates the effectiveness of spatiotemporal Graph Neural Networks (GNNs) for multi-store retail sales forecasting and compares their performance against ARIMA, LSTM, and XGBoost baselines. Using weekly sales data from 45 Walmart stores, we construct a relational forecasting framework that models inter-store dependencies through a learned adaptive graph. The proposed STGNN predicts log-differenced sales and reconstructs final values through a residual path, enabling stable training and improved generalisation. Experiments show that STGNN achieves the lowest overall forecasting error, outperforming all baselines in Normalised Total Absolute Error, P90 MAPE, and variance of MAPE across stores. Analysis of the learned adjacency matrix reveals meaningful functional store clusters and high-influence nodes that emerge without geographic metadata. These results demonstrate that relational structure significantly improves forecast quality in interconnected retail environments and establishes STGNNs as a robust modelling choice for multi-store demand prediction.",
    "published": "2025-11-24T16:19:48Z",
    "updated": "2025-11-24T16:19:48Z",
    "link": "http://arxiv.org/pdf/2511.19267v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Manish Singh",
      "Arpita Dayama"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19265v1",
    "title": "Unboxing the Black Box: Mechanistic Interpretability for Algorithmic Understanding of Neural Networks",
    "summary": "The black box nature of deep neural networks poses a significant challenge for the deployment of transparent and trustworthy artificial intelligence (AI) systems. With the growing presence of AI in society, it becomes increasingly important to develop methods that can explain and interpret the decisions made by these systems. To address this, mechanistic interpretability (MI) emerged as a promising and distinctive research program within the broader field of explainable artificial intelligence (XAI). MI is the process of studying the inner computations of neural networks and translating them into human-understandable algorithms. It encompasses reverse engineering techniques aimed at uncovering the computational algorithms implemented by neural networks. In this article, we propose a unified taxonomy of MI approaches and provide a detailed analysis of key techniques, illustrated with concrete examples and pseudo-code. We contextualize MI within the broader interpretability landscape, comparing its goals, methods, and insights to other strands of XAI. Additionally, we trace the development of MI as a research area, highlighting its conceptual roots and the accelerating pace of recent work. We argue that MI holds significant potential to support a more scientific understanding of machine learning systems -- treating models not only as tools for solving tasks, but also as systems to be studied and understood. We hope to invite new researchers into the field of mechanistic interpretability.",
    "published": "2025-11-24T16:16:49Z",
    "updated": "2025-11-24T16:16:49Z",
    "link": "http://arxiv.org/pdf/2511.19265v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Bianka Kowalska",
      "Halina Kwaśnicka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19240v1",
    "title": "Empirical Comparison of Forgetting Mechanisms for UCB-based Algorithms on a Data-Driven Simulation Platform",
    "summary": "Many real-world bandit problems involve non-stationary reward distributions, where the optimal decision may shift due to evolving environments. However, the performance of some typical Multi-Armed Bandit (MAB) models such as Upper Confidence Bound (UCB) algorithms degrades significantly in non-stationary environments where reward distributions change over time. To address this limitation, this paper introduces and evaluates FDSW-UCB, a novel dual-view algorithm that integrates a discount-based long-term perspective with a sliding-window-based short-term view. A data-driven semi-synthetic simulation platform, built upon the MovieLens-1M and Open Bandit datasets, is developed to test algorithm adaptability under abrupt and gradual drift scenarios. Experimental results demonstrate that a well-configured sliding-window mechanism (SW-UCB) is robust, while the widely used discounting method (D-UCB) suffers from a fundamental learning failure, leading to linear regret. Crucially, the proposed FDSW-UCB, when employing an optimistic aggregation strategy, achieves superior performance in dynamic settings, highlighting that the ensemble strategy itself is a decisive factor for success.",
    "published": "2025-11-24T15:52:02Z",
    "updated": "2025-11-24T15:52:02Z",
    "link": "http://arxiv.org/pdf/2511.19240v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Minxin Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.26533v2",
    "title": "Higher-Order Regularization Learning on Hypergraphs",
    "summary": "Higher-Order Hypergraph Learning (HOHL) was recently introduced as a principled alternative to classical hypergraph regularization, enforcing higher-order smoothness via powers of multiscale Laplacians induced by the hypergraph structure. Prior work established the well- and ill-posedness of HOHL through an asymptotic consistency analysis in geometric settings. We extend this theoretical foundation by proving the consistency of a truncated version of HOHL and deriving explicit convergence rates when HOHL is used as a regularizer in fully supervised learning. We further demonstrate its strong empirical performance in active learning and in datasets lacking an underlying geometric structure, highlighting HOHL's versatility and robustness across diverse learning settings.",
    "published": "2025-10-30T14:22:57Z",
    "updated": "2025-11-24T15:37:40Z",
    "link": "http://arxiv.org/pdf/2510.26533v2.pdf",
    "category": [
      "cs.LG",
      "math.ST"
    ],
    "authors": [
      "Adrien Weihs",
      "Andrea L. Bertozzi",
      "Matthew Thorpe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.04112v2",
    "title": "Synthetic Counterfactual Labels for Efficient Conformal Counterfactual Inference",
    "summary": "This work addresses the problem of constructing reliable prediction intervals for individual counterfactual outcomes. Existing conformal counterfactual inference (CCI) methods provide marginal coverage guarantees but often produce overly conservative intervals, particularly under treatment imbalance when counterfactual samples are scarce. We introduce synthetic data-powered CCI (SP-CCI), a new framework that augments the calibration set with synthetic counterfactual labels generated by a pre-trained counterfactual model. To ensure validity, SP-CCI incorporates synthetic samples into a conformal calibration procedure based on risk-controlling prediction sets (RCPS) with a debiasing step informed by prediction-powered inference (PPI). We prove that SP-CCI achieves tighter prediction intervals while preserving marginal coverage, with theoretical guarantees under both exact and approximate importance weighting. Empirical results on different datasets confirm that SP-CCI consistently reduces interval width compared to standard CCI across all settings.",
    "published": "2025-09-04T11:22:08Z",
    "updated": "2025-11-24T15:33:40Z",
    "link": "http://arxiv.org/pdf/2509.04112v2.pdf",
    "category": [
      "cs.LG",
      "cs.IT"
    ],
    "authors": [
      "Amirmohammad Farzaneh",
      "Matteo Zecchin",
      "Osvaldo Simeone"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.25354v2",
    "title": "Analysis of Semi-Supervised Learning on Hypergraphs",
    "summary": "Hypergraphs provide a natural framework for modeling higher-order interactions, yet their theoretical underpinnings in semi-supervised learning remain limited. We provide an asymptotic consistency analysis of variational learning on random geometric hypergraphs, precisely characterizing the conditions ensuring the well-posedness of hypergraph learning as well as showing convergence to a weighted $p$-Laplacian equation. Motivated by this, we propose Higher-Order Hypergraph Learning (HOHL), which regularizes via powers of Laplacians from skeleton graphs for multiscale smoothness. HOHL converges to a higher-order Sobolev seminorm. Empirically, it performs strongly on standard baselines.",
    "published": "2025-10-29T10:19:32Z",
    "updated": "2025-11-24T15:26:34Z",
    "link": "http://arxiv.org/pdf/2510.25354v2.pdf",
    "category": [
      "cs.LG",
      "math.ST"
    ],
    "authors": [
      "Adrien Weihs",
      "Andrea L. Bertozzi",
      "Matthew Thorpe"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17123v2",
    "title": "Layer-wise Weight Selection for Power-Efficient Neural Network Acceleration",
    "summary": "Systolic array accelerators execute CNNs with energy dominated by the switching activity of multiply accumulate (MAC) units. Although prior work exploits weight dependent MAC power for compression, existing methods often use global activation models, coarse energy proxies, or layer-agnostic policies, which limits their effectiveness on real hardware. We propose an energy aware, layer-wise compression framework that explicitly leverages MAC and layer level energy characteristics. First, we build a layer-aware MAC energy model that combines per-layer activation statistics with an MSB-Hamming distance grouping of 22-bit partial sum transitions, and integrate it with a tile-level systolic mapping to estimate convolution-layer energy. On top of this model, we introduce an energy accuracy co-optimized weight selection algorithm within quantization aware training and an energy-prioritized layer-wise schedule that compresses high energy layers more aggressively under a global accuracy constraint. Experiments on different CNN models demonstrate up to 58.6\\% energy reduction with 2-3\\% accuracy drop, outperforming a state-of-the-art power-aware baseline.",
    "published": "2025-11-21T10:37:07Z",
    "updated": "2025-11-24T15:02:34Z",
    "link": "http://arxiv.org/pdf/2511.17123v2.pdf",
    "category": [
      "cs.AR",
      "cs.LG"
    ],
    "authors": [
      "Jiaxun Fang",
      "Grace Li Zhang",
      "Shaoyi Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19176v1",
    "title": "From Raw Features to Effective Embeddings: A Three-Stage Approach for Multimodal Recipe Recommendation",
    "summary": "Recipe recommendation has become an essential task in web-based food platforms. A central challenge is effectively leveraging rich multimodal features beyond user-recipe interactions. Our analysis shows that even simple uses of multimodal signals yield competitive performance, suggesting that systematic enhancement of these signals is highly promising. We propose TESMR, a 3-stage framework for recipe recommendation that progressively refines raw multimodal features into effective embeddings through: (1) content-based enhancement using foundation models with multimodal comprehension, (2) relation-based enhancement via message propagation over user-recipe interactions, and (3) learning-based enhancement through contrastive learning with learnable embeddings. Experiments on two real-world datasets show that TESMR outperforms existing methods, achieving 7-15% higher Recall@10.",
    "published": "2025-11-24T14:37:22Z",
    "updated": "2025-11-24T14:37:22Z",
    "link": "http://arxiv.org/pdf/2511.19176v1.pdf",
    "category": [
      "cs.LG",
      "cs.IR"
    ],
    "authors": [
      "Jeeho Shin",
      "Kyungho Kim",
      "Kijung Shin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.10879v2",
    "title": "A Goemans-Williamson type algorithm for identifying subcohorts in clinical trials",
    "summary": "We design an efficient algorithm that outputs tests for identifying predominantly homogeneous subcohorts of patients from large in-homogeneous datasets. Our theoretical contribution is a rounding technique, similar to that of Goemans and Wiliamson (1995), that approximates the optimal solution within a factor of $0.82$. As an application, we use our algorithm to trade-off sensitivity for specificity to systematically identify clinically interesting homogeneous subcohorts of patients in the RNA microarray dataset for breast cancer from Curtis et al. (2012). One such clinically interesting subcohort suggests a link between LXR over-expression and BRCA2 and MSH6 methylation levels for patients in that subcohort.",
    "published": "2025-06-12T16:44:32Z",
    "updated": "2025-11-24T14:29:04Z",
    "link": "http://arxiv.org/pdf/2506.10879v2.pdf",
    "category": [
      "q-bio.QM",
      "cs.LG"
    ],
    "authors": [
      "Pratik Worah"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19165v1",
    "title": "First-order Sobolev Reinforcement Learning",
    "summary": "We propose a refinement of temporal-difference learning that enforces first-order Bellman consistency: the learned value function is trained to match not only the Bellman targets in value but also their derivatives with respect to states and actions. By differentiating the Bellman backup through differentiable dynamics, we obtain analytically consistent gradient targets. Incorporating these into the critic objective using a Sobolev-type loss encourages the critic to align with both the value and local geometry of the target function. This first-order TD matching principle can be seamlessly integrated into existing algorithms, such as Q-learning or actor-critic methods (e.g., DDPG, SAC), potentially leading to faster critic convergence and more stable policy gradients without altering their overall structure.",
    "published": "2025-11-24T14:28:49Z",
    "updated": "2025-11-24T14:28:49Z",
    "link": "http://arxiv.org/pdf/2511.19165v1.pdf",
    "category": [
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Fabian Schramm",
      "Nicolas Perrin-Gilbert",
      "Justin Carpentier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19157v1",
    "title": "A Robust State Filter Against Unmodeled Process And Measurement Noise",
    "summary": "This paper introduces a novel Kalman filter framework designed to achieve robust state estimation under both process and measurement noise. Inspired by the Weighted Observation Likelihood Filter (WoLF), which provides robustness against measurement outliers, we applied generalized Bayesian approach to build a framework considering both process and measurement noise outliers.",
    "published": "2025-11-24T14:25:13Z",
    "updated": "2025-11-24T14:25:13Z",
    "link": "http://arxiv.org/pdf/2511.19157v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Weitao Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19152v1",
    "title": "Masked Diffusion Models are Secretly Learned-Order Autoregressive Models",
    "summary": "Masked Diffusion Models (MDMs) have emerged as one of the most promising paradigms for generative modeling over discrete domains. It is known that MDMs effectively train to decode tokens in a random order, and that this ordering has significant performance implications in practice. This observation raises a fundamental question: can we design a training framework that optimizes for a favorable decoding order? We answer this in the affirmative, showing that the continuous-time variational objective of MDMs, when equipped with multivariate noise schedules, can identify and optimize for a decoding order during training. We establish a direct correspondence between decoding order and the multivariate noise schedule and show that this setting breaks invariance of the MDM objective to the noise schedule. Furthermore, we prove that the MDM objective decomposes precisely into a weighted auto-regressive losses over these orders, which establishes them as auto-regressive models with learnable orders.",
    "published": "2025-11-24T14:17:56Z",
    "updated": "2025-11-24T14:17:56Z",
    "link": "http://arxiv.org/pdf/2511.19152v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Prateek Garg",
      "Bhavya Kohli",
      "Sunita Sarawagi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19150v1",
    "title": "Feature Ranking in Credit-Risk with Qudit-Based Networks",
    "summary": "In finance, predictive models must balance accuracy and interpretability, particularly in credit risk assessment, where model decisions carry material consequences. We present a quantum neural network (QNN) based on a single qudit, in which both data features and trainable parameters are co-encoded within a unified unitary evolution generated by the full Lie algebra. This design explores the entire Hilbert space while enabling interpretability through the magnitudes of the learned coefficients. We benchmark our model on a real-world, imbalanced credit-risk dataset from Taiwan. The proposed QNN consistently outperforms LR and reaches the results of random forest models in macro-F1 score while preserving a transparent correspondence between learned parameters and input feature importance. To quantify the interpretability of the proposed model, we introduce two complementary metrics: (i) the edit distance between the model's feature ranking and that of LR, and (ii) a feature-poisoning test where selected features are replaced with noise. Results indicate that the proposed quantum model achieves competitive performance while offering a tractable path toward interpretable quantum learning.",
    "published": "2025-11-24T14:15:57Z",
    "updated": "2025-11-24T14:15:57Z",
    "link": "http://arxiv.org/pdf/2511.19150v1.pdf",
    "category": [
      "quant-ph",
      "cs.LG"
    ],
    "authors": [
      "Georgios Maragkopoulos",
      "Lazaros Chavatzoglou",
      "Aikaterini Mandilara",
      "Dimitris Syvridis"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19103v1",
    "title": "Edge-Based Predictive Data Reduction for Smart Agriculture: A Lightweight Approach to Efficient IoT Communication",
    "summary": "The rapid growth of IoT devices has led to an enormous amount of sensor data that requires transmission to cloud servers for processing, resulting in excessive network congestion, increased latency and high energy consumption. This is particularly problematic in resource-constrained and remote environments where bandwidth is limited, and battery-dependent devices further emphasize the problem. Moreover, in domains such as agriculture, consecutive sensor readings often have minimal variation, making continuous data transmission inefficient and unnecessarily resource intensive. To overcome these challenges, we propose an analytical prediction algorithm designed for edge computing environments and validated through simulation. The proposed solution utilizes a predictive filter at the network edge that forecasts the next sensor data point and triggers data transmission only when the deviation from the predicted value exceeds a predefined tolerance. A complementary cloud-based model ensures data integrity and overall system consistency. This dual-model strategy effectively reduces communication overhead and demonstrates potential for improving energy efficiency by minimizing redundant transmissions. In addition to reducing communication load, our approach leverages both in situ and satellite observations from the same locations to enhance model robustness. It also supports cross-site generalization, enabling models trained in one region to be effectively deployed elsewhere without retraining. This makes our solution highly scalable, energy-aware, and well-suited for optimizing sensor data transmission in remote and bandwidth-constrained IoT environments.",
    "published": "2025-11-24T13:37:33Z",
    "updated": "2025-11-24T13:37:33Z",
    "link": "http://arxiv.org/pdf/2511.19103v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Dora Krekovic",
      "Mario Kusek",
      "Ivana Podnar Zarko",
      "Danh Le-Phuoc"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13732v2",
    "title": "Principled Coarse-Grained Acceptance for Speculative Decoding in Speech",
    "summary": "Speculative decoding accelerates autoregressive speech generation by letting a fast draft model propose tokens that a larger target model verifies. However, for speech LLMs that generate acoustic tokens, exact token matching is overly restrictive: many discrete tokens are acoustically or semantically interchangeable, reducing acceptance rates and limiting speedups. We introduce Principled Coarse-Graining (PCG), which verifies proposals at the level of Acoustic Similarity Groups (ASGs) derived from the target model's embedding space. By splitting each token's probability mass across the overlapping groups that contain it, we define an overlap-aware coarse-grained distribution and perform rejection sampling on the resulting group variable. This yields an exactness guarantee at the group level while allowing the accepted draft token to stand in for any member of the group in practice. On LibriTTS, PCG increases acceptance and throughput relative to standard speculative decoding and prior speech-specific relaxations while maintaining intelligibility and speaker similarity. These results suggest acoustically aware, group-level acceptance as a simple and general way to accelerate speech token generation while maintaining speech quality.",
    "published": "2025-11-05T10:49:30Z",
    "updated": "2025-11-24T13:32:45Z",
    "link": "http://arxiv.org/pdf/2511.13732v2.pdf",
    "category": [
      "eess.AS",
      "cs.LG"
    ],
    "authors": [
      "Moran Yanuka",
      "Paul Dixon",
      "Eyal Finkelshtein",
      "Daniel Rotman",
      "Raja Giryes"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19090v1",
    "title": "Optimization of Deep Learning Models for Dynamic Market Behavior Prediction",
    "summary": "The advent of financial technology has witnessed a surge in the utilization of deep learning models to anticipate consumer conduct, a trend that has demonstrated considerable potential in enhancing lending strategies and bolstering market efficiency. We study multi-horizon demand forecasting on e-commerce transactions using the UCI Online Retail II dataset. Unlike prior versions of this manuscript that mixed financial-loan narratives with retail data, we focus exclusively on retail market behavior and define a clear prediction target: per SKU daily demand (or revenue) for horizons H=1,7,14. We present a hybrid sequence model that combines multi-scale temporal convolutions, a gated recurrent module, and time-aware self-attention. The model is trained with standard regression losses and evaluated under MAE, RMSE, sMAPE, MASE, and Theil's U_2 with strict time-based splits to prevent leakage. We benchmark against ARIMA/Prophet, LSTM/GRU, LightGBM, and state-of-the-art Transformer forecasters (TFT, Informer, Autoformer, N-BEATS). Results show consistent accuracy gains and improved robustness on peak/holiday periods. We further provide ablations and statistical significance tests to ensure the reliability of improvements, and we release implementation details to facilitate reproducibility.",
    "published": "2025-11-24T13:30:52Z",
    "updated": "2025-11-24T13:30:52Z",
    "link": "http://arxiv.org/pdf/2511.19090v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Shenghan Zhao",
      "Yuzhen Lin",
      "Ximeng Yang",
      "Qiaochu Lu",
      "Haozhong Xue",
      "Gaozhe Jiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.10000v2",
    "title": "Neural Scaling Laws for Deep Regression",
    "summary": "Neural scaling laws--power-law relationships between generalization errors and characteristics of deep learning models--are vital tools for developing reliable models while managing limited resources. Although the success of large language models highlights the importance of these laws, their application to deep regression models remains largely unexplored. Here, we empirically investigate neural scaling laws in deep regression using a parameter estimation model for twisted van der Waals magnets. We observe power-law relationships between the loss and both training dataset size and model capacity across a wide range of values, employing various architectures--including fully connected networks, residual networks, and vision transformers. Furthermore, the scaling exponents governing these relationships range from 1 to 2, with specific values depending on the regressed parameters and model details. The consistent scaling behaviors and their large scaling exponents suggest that the performance of deep regression models can improve substantially with increasing data size.",
    "published": "2025-09-12T06:49:19Z",
    "updated": "2025-11-24T13:26:06Z",
    "link": "http://arxiv.org/pdf/2509.10000v2.pdf",
    "category": [
      "cs.LG",
      "cond-mat.other"
    ],
    "authors": [
      "Tilen Cadez",
      "Kyoung-Min Kim"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.20906v2",
    "title": "GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In Industrial Control Systems",
    "summary": "The continuous monitoring of the interactions between cyber-physical components of any industrial control system (ICS) is required to secure automation of the system controls, and to guarantee plant processes are fail-safe and remain in an acceptably safe state. Safety is achieved by managing actuation (where electric signals are used to trigger physical movement), dependent on corresponding sensor readings; used as ground truth in decision making. Timely detection of anomalies (attacks, faults and unascertained states) in ICSs is crucial for the safe running of a plant, the safety of its personnel, and for the safe provision of any services provided. We propose an anomaly detection method that involves accurate linearization of the non-linear forms arising from sensor-actuator(s) relationships, primarily because solving linear models is easier and well understood. We accomplish this by using a well-known water treatment testbed as a use case. Our experiments show millisecond time response to detect anomalies, all of which are explainable and traceable; this simultaneous coupling of detection speed and explainability has not been achieved by other state of the art Artificial Intelligence (AI)/ Machine Learning (ML) models with eXplainable AI (XAI) used for the same purpose. Our methods explainability enables us to pin-point the sensor(s) and the actuation state(s) for which the anomaly was detected. The proposed algorithm showed an accuracy of 97.72% by flagging deviations within safe operation limits as non-anomalous; indicative that slower detectors with highest detection resolution is unnecessary, for systems whose safety boundaries provide leeway within safety limits.",
    "published": "2025-04-29T16:24:11Z",
    "updated": "2025-11-24T13:25:33Z",
    "link": "http://arxiv.org/pdf/2504.20906v2.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Sarad Venugopalan",
      "Sridhar Adepu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.02779v2",
    "title": "Optimal Rates for Generalization of Gradient Descent for Deep ReLU Classification",
    "summary": "Recent advances have significantly improved our understanding of the generalization performance of gradient descent (GD) methods in deep neural networks. A natural and fundamental question is whether GD can achieve generalization rates comparable to the minimax optimal rates established in the kernel setting. Existing results either yield suboptimal rates of $O(1/\\sqrt{n})$, or focus on networks with smooth activation functions, incurring exponential dependence on network depth $L$. In this work, we establish optimal generalization rates for GD with deep ReLU networks by carefully trading off optimization and generalization errors, achieving only polynomial dependence on depth. Specifically, under the assumption that the data are NTK separable from the margin $γ$, we prove an excess risk rate of $\\widetilde{O}(L^4 (1 + γL^2) / (n γ^2))$, which aligns with the optimal SVM-type rate $\\widetilde{O}(1 / (n γ^2))$ up to depth-dependent factors. A key technical contribution is our novel control of activation patterns near a reference model, enabling a sharper Rademacher complexity bound for deep ReLU networks trained with gradient descent.",
    "published": "2025-10-03T07:22:36Z",
    "updated": "2025-11-24T13:14:48Z",
    "link": "http://arxiv.org/pdf/2510.02779v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yuanfan Li",
      "Yunwen Lei",
      "Zheng-Chu Guo",
      "Yiming Ying"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2504.16941v3",
    "title": "Mathematical Insights into Protein Architecture: Persistent Homology and Machine Learning Applied to the Flagellar Motor",
    "summary": "We present a machine learning approach that leverages persistent homology to classify bacterial flagellar motors into two functional states: rotated and stalled. By embedding protein structural data into a topological framework, we extract multiscale features from filtered simplicial complexes constructed over atomic coordinates. These topological invariants, specifically persistence diagrams and barcodes, capture critical geometric and connectivity patterns that correlate with motor function. The extracted features are vectorized and integrated into a machine learning pipeline that includes dimensionality reduction and supervised classification. Applied to a curated dataset of experimentally characterized flagellar motors from diverse bacterial species, our model demonstrates high classification accuracy and robustness to structural variation. This approach highlights the power of topological data analysis in revealing functionally relevant patterns beyond the reach of traditional geometric descriptors, offering a novel computational tool for protein function prediction.",
    "published": "2025-04-08T19:21:44Z",
    "updated": "2025-11-24T13:12:10Z",
    "link": "http://arxiv.org/pdf/2504.16941v3.pdf",
    "category": [
      "q-bio.BM",
      "cs.LG",
      "math.AT"
    ],
    "authors": [
      "Zakaria Lamine",
      "Abdelatif Hafid",
      "Mohamed Rahouti",
      "My Ismail Mamouni"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19075v1",
    "title": "Structured Matching via Cost-Regularized Unbalanced Optimal Transport",
    "summary": "Unbalanced optimal transport (UOT) provides a flexible way to match or compare nonnegative finite Radon measures. However, UOT requires a predefined ground transport cost, which may misrepresent the data's underlying geometry. Choosing such a cost is particularly challenging when datasets live in heterogeneous spaces, often motivating practitioners to adopt Gromov-Wasserstein formulations. To address this challenge, we introduce cost-regularized unbalanced optimal transport (CR-UOT), a framework that allows the ground cost to vary while allowing mass creation and removal. We show that CR-UOT incorporates unbalanced Gromov-Wasserstein type problems through families of inner-product costs parameterized by linear transformations, enabling the matching of measures or point clouds across Euclidean spaces. We develop algorithms for such CR-UOT problems using entropic regularization and demonstrate that this approach improves the alignment of heterogeneous single-cell omics profiles, especially when many cells lack direct matches.",
    "published": "2025-11-24T13:11:27Z",
    "updated": "2025-11-24T13:11:27Z",
    "link": "http://arxiv.org/pdf/2511.19075v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "authors": [
      "Emanuele Pardini",
      "Katerina Papagiannouli"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.19268v4",
    "title": "Health App Reviews for Privacy & Trust (HARPT): A Corpus for Analyzing Patient Privacy Concerns, Trust in Providers and Trust in Applications",
    "summary": "Background: User reviews of Telehealth and Patient Portal mobile applications (apps) hereon referred to as electronic health (eHealth) apps are a rich source of unsolicited patient feedback, revealing critical insights into patient perceptions. However, the lack of large-scale, annotated datasets specific to privacy and trust has limited the ability of researchers to systematically analyze these concerns using natural language processing (NLP) techniques.\n  Objective: This study aims to develop and benchmark Health App Reviews for Privacy & Trust (HARPT), a large-scale annotated corpus of patient reviews from eHealth apps to advance research in patient privacy and trust.\n  Methods: We employed a multistage data construction strategy. This integrated keyword-based filtering, iterative manual labeling with review, targeted data augmentation, and weak supervision using transformer-based classifiers. A curated subset of 7,000 reviews was manually annotated to support machine learning model development and evaluation. The resulting dataset was used to benchmark a broad range of models.\n  Results: The HARPT corpus comprises 480,000 patient reviews annotated across seven categories capturing critical aspects of trust in the application (TA), trust in the provider (TP), and privacy concerns (PC). We provide comprehensive benchmark performance for a range of machine learning models on the manually annotated subset, establishing a baseline for future research.\n  Conclusions: The HARPT corpus is a significant resource for advancing the study of privacy and trust in the eHealth domain. By providing a large-scale, annotated dataset and initial benchmarks, this work supports reproducible research in usable privacy and trust within health informatics. HARPT is released under an open resource license.",
    "published": "2025-06-24T02:59:14Z",
    "updated": "2025-11-24T13:11:18Z",
    "link": "http://arxiv.org/pdf/2506.19268v4.pdf",
    "category": [
      "cs.HC",
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Timoteo Kelly",
      "Abdulkadir Korkmaz",
      "Samuel Mallet",
      "Connor Souders",
      "Sadra Aliakbarpour",
      "Praveen Rao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.20192v2",
    "title": "FunReason: Enhancing Large Language Models' Function Calling via Self-Refinement Multiscale Loss and Automated Data Refinement",
    "summary": "The integration of large language models (LLMs) with function calling has emerged as a crucial capability for enhancing their practical utility in real-world applications. However, effectively combining reasoning processes with accurate function execution remains a significant challenge. Traditional training approaches often struggle to balance the detailed reasoning steps with the precision of function calls, leading to suboptimal performance. To address these limitations, we introduce FunReason, a novel framework that enhances LLMs' function calling capabilities through an automated data refinement strategy and a Self-Refinement Multiscale Loss (SRML) approach. FunReason leverages LLMs' natural reasoning abilities to generate high-quality training examples, focusing on query parseability, reasoning coherence, and function call precision. The SRML approach dynamically balances the contribution of reasoning processes and function call accuracy during training, addressing the inherent trade-off between these two critical aspects. FunReason achieves performance comparable to GPT-4o while effectively mitigating catastrophic forgetting during fine-tuning. FunReason provides a comprehensive solution for enhancing LLMs' function calling capabilities by introducing a balanced training methodology and a data refinement pipeline. For code and dataset, please refer to our repository at GitHub https://github.com/BingguangHao/FunReason",
    "published": "2025-05-26T16:38:06Z",
    "updated": "2025-11-24T12:52:02Z",
    "link": "http://arxiv.org/pdf/2505.20192v2.pdf",
    "category": [
      "cs.LG",
      "cs.IR"
    ],
    "authors": [
      "Bingguang Hao",
      "Maolin Wang",
      "Zengzhuang Xu",
      "Cunyin Peng",
      "Yicheng Chen",
      "Xiangyu Zhao",
      "Jinjie Gu",
      "Chenyi Zhuang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.20153v2",
    "title": "The inexact power augmented Lagrangian method for constrained nonconvex optimization",
    "summary": "This work introduces an unconventional inexact augmented Lagrangian method where the augmenting term is a Euclidean norm raised to a power between one and two. The proposed algorithm is applicable to a broad class of constrained nonconvex minimization problems that involve nonlinear equality constraints. In a first part of this work, we conduct a full complexity analysis of the method under a mild regularity condition, leveraging an accelerated first-order algorithm for solving the Hölder-smooth subproblems. Interestingly, this worst-case result indicates that using lower powers for the augmenting term leads to faster constraint satisfaction, albeit with a slower decrease of the dual residual. Notably, our analysis does not assume boundedness of the iterates. Thereafter, we present an inexact proximal point method for solving the weakly-convex and Hölder-smooth subproblems, and demonstrate that the combined scheme attains an improved rate that reduces to the best-known convergence rate whenever the augmenting term is a classical squared Euclidean norm. Different augmenting terms, involving a lower power, further improve the primal complexity at the cost of the dual complexity. Finally, numerical experiments validate the practical performance of unconventional augmenting terms.",
    "published": "2024-10-26T11:31:56Z",
    "updated": "2025-11-24T12:43:15Z",
    "link": "http://arxiv.org/pdf/2410.20153v2.pdf",
    "category": [
      "math.OC",
      "cs.LG"
    ],
    "authors": [
      "Alexander Bodard",
      "Konstantinos Oikonomidis",
      "Emanuel Laude",
      "Panagiotis Patrinos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.08542v3",
    "title": "Beyond Predictions: A Participatory Framework for Multi-Stakeholder Decision-Making",
    "summary": "Conventional automated decision-support systems often prioritize predictive accuracy, overlooking the complexities of real-world settings where stakeholders' preferences may diverge or conflict. This can lead to outcomes that disadvantage vulnerable groups and erode trust in algorithmic processes. Participatory AI approaches aim to address these issues but remain largely context-specific, limiting their broader applicability and scalability. To address these gaps, we propose a participatory framework that reframes decision-making as a multi-stakeholder learning and optimization problem. Our modular, model-agnostic approach builds on the standard machine learning training pipeline to fine-tune user-provided prediction models and evaluate decision strategies, including compromise functions that mediate stakeholder trade-offs. A synthetic scoring mechanism aggregates user-defined preferences across multiple metrics, ranking strategies and selecting an optimal decision-maker to generate actionable recommendations that jointly optimize performance, fairness, and domain-specific goals. Empirical validation on two high-stakes case studies demonstrates the versatility of the framework and its promise as a more accountable, context-aware alternative to prediction-centric pipelines for socially impactful deployments.",
    "published": "2025-02-12T16:27:40Z",
    "updated": "2025-11-24T12:23:10Z",
    "link": "http://arxiv.org/pdf/2502.08542v3.pdf",
    "category": [
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      "Vittoria Vineis",
      "Giuseppe Perelli",
      "Gabriele Tolomei"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19037v1",
    "title": "Resolving Node Identifiability in Graph Neural Processes via Laplacian Spectral Encodings",
    "summary": "Message passing graph neural networks are widely used for learning on graphs, yet their expressive power is limited by the one-dimensional Weisfeiler-Lehman test and can fail to distinguish structurally different nodes. We provide rigorous theory for a Laplacian positional encoding that is invariant to eigenvector sign flips and to basis rotations within eigenspaces. We prove that this encoding yields node identifiability from a constant number of observations and establishes a sample-complexity separation from architectures constrained by the Weisfeiler-Lehman test. The analysis combines a monotone link between shortest-path and diffusion distance, spectral trilateration with a constant set of anchors, and quantitative spectral injectivity with logarithmic embedding size. As an instantiation, pairing this encoding with a neural-process style decoder yields significant gains on a drug-drug interaction task on chemical graphs, improving both the area under the ROC curve and the F1 score and demonstrating the practical benefits of resolving theoretical expressiveness limitations with principled positional information.",
    "published": "2025-11-24T12:20:36Z",
    "updated": "2025-11-24T12:20:36Z",
    "link": "http://arxiv.org/pdf/2511.19037v1.pdf",
    "category": [
      "cs.LG",
      "math.PR"
    ],
    "authors": [
      "Zimo Yan",
      "Zheng Xie",
      "Chang Liu",
      "Yuan Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.23822v2",
    "title": "Node Embeddings via Neighbor Embeddings",
    "summary": "Node embeddings are a paradigm in non-parametric graph representation learning, where graph nodes are embedded into a given vector space to enable downstream processing. State-of-the-art node-embedding algorithms, such as DeepWalk and node2vec, are based on random-walk notions of node similarity and on contrastive learning. In this work, we introduce the graph neighbor-embedding (graph NE) framework that directly pulls together embedding vectors of adjacent nodes without relying on any random walks. We show that graph NE strongly outperforms state-of-the-art node-embedding algorithms in terms of local structure preservation. Furthermore, we apply graph NE to the 2D node-embedding problem, obtaining graph t-SNE layouts that also outperform existing graph-layout algorithms.",
    "published": "2025-03-31T08:16:03Z",
    "updated": "2025-11-24T12:16:52Z",
    "link": "http://arxiv.org/pdf/2503.23822v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jan Niklas Böhm",
      "Marius Keute",
      "Alica Guzmán",
      "Sebastian Damrich",
      "Andrew Draganov",
      "Dmitry Kobak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2409.14980v3",
    "title": "(De)-regularized Maximum Mean Discrepancy Gradient Flow",
    "summary": "We introduce a (de)-regularization of the Maximum Mean Discrepancy (DrMMD) and its Wasserstein gradient flow. Existing gradient flows that transport samples from source distribution to target distribution with only target samples, either lack tractable numerical implementation ($f$-divergence flows) or require strong assumptions, and modifications such as noise injection, to ensure convergence (Maximum Mean Discrepancy flows). In contrast, DrMMD flow can simultaneously (i) guarantee near-global convergence for a broad class of targets in both continuous and discrete time, and (ii) be implemented in closed form using only samples. The former is achieved by leveraging the connection between the DrMMD and the $χ^2$-divergence, while the latter comes by treating DrMMD as MMD with a de-regularized kernel. Our numerical scheme uses an adaptive de-regularization schedule throughout the flow to optimally trade off between discretization errors and deviations from the $χ^2$ regime. The potential application of the DrMMD flow is demonstrated across several numerical experiments, including a large-scale setting of training student/teacher networks.",
    "published": "2024-09-23T12:57:42Z",
    "updated": "2025-11-24T11:54:06Z",
    "link": "http://arxiv.org/pdf/2409.14980v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Zonghao Chen",
      "Aratrika Mustafi",
      "Pierre Glaser",
      "Anna Korba",
      "Arthur Gretton",
      "Bharath K. Sriperumbudur"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.04622v2",
    "title": "Forecasting-based Biomedical Time-series Data Synthesis for Open Data and Robust AI",
    "summary": "The limited data availability due to strict privacy regulations and significant resource demands severely constrains biomedical time-series AI development, which creates a critical gap between data requirements and accessibility. Synthetic data generation presents a promising solution by producing artificial datasets that maintain the statistical properties of real biomedical time-series data without compromising patient confidentiality. While GANs, VAEs, and diffusion models capture global data distributions, forecasting models offer inductive biases tailored for sequential dynamics. We propose a framework for synthetic biomedical time-series data generation based on recent forecasting models that accurately replicates complex electrophysiological signals such as EEG and EMG with high fidelity. These synthetic datasets can be freely shared for open AI development and consistently improve downstream model performance. Numerical results on sleep-stage classification show up to a 3.71\\% performance gain with augmentation and a 91.00\\% synthetic-only accuracy that surpasses the real-data-only baseline.",
    "published": "2025-10-06T09:32:10Z",
    "updated": "2025-11-24T11:53:20Z",
    "link": "http://arxiv.org/pdf/2510.04622v2.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Youngjoon Lee",
      "Seongmin Cho",
      "Yehhyun Jo",
      "Jinu Gong",
      "Hyunjoo Jenny Lee",
      "Joonhyuk Kang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19019v1",
    "title": "3D Dynamic Radio Map Prediction Using Vision Transformers for Low-Altitude Wireless Networks",
    "summary": "Low-altitude wireless networks (LAWN) are rapidly expanding with the growing deployment of unmanned aerial vehicles (UAVs) for logistics, surveillance, and emergency response. Reliable connectivity remains a critical yet challenging task due to three-dimensional (3D) mobility, time-varying user density, and limited power budgets. The transmit power of base stations (BSs) fluctuates dynamically according to user locations and traffic demands, leading to a highly non-stationary 3D radio environment. Radio maps (RMs) have emerged as an effective means to characterize spatial power distributions and support radio-aware network optimization. However, most existing works construct static or offline RMs, overlooking real-time power variations and spatio-temporal dependencies in multi-UAV networks. To overcome this limitation, we propose a {3D dynamic radio map (3D-DRM)} framework that learns and predicts the spatio-temporal evolution of received power. Specially, a Vision Transformer (ViT) encoder extracts high-dimensional spatial representations from 3D RMs, while a Transformer-based module models sequential dependencies to predict future power distributions. Experiments unveil that 3D-DRM accurately captures fast-varying power dynamics and substantially outperforms baseline models in both RM reconstruction and short-term prediction.",
    "published": "2025-11-24T11:47:17Z",
    "updated": "2025-11-24T11:47:17Z",
    "link": "http://arxiv.org/pdf/2511.19019v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Nguyen Duc Minh Quang",
      "Chang Liu",
      "Huy-Trung Nguyen",
      "Shuangyang Li",
      "Derrick Wing Kwan Ng",
      "Wei Xiang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.06761v3",
    "title": "When, Where and Why to Average Weights?",
    "summary": "Averaging checkpoints along the training trajectory is a simple yet powerful approach to improve the generalization performance of Machine Learning models and reduce training time. Motivated by these potential gains, and in an effort to fairly and thoroughly benchmark this technique, we present an extensive evaluation of averaging techniques in modern Deep Learning, which we perform using AlgoPerf \\citep{dahl_benchmarking_2023}, a large-scale benchmark for optimization algorithms. We investigate whether weight averaging can reduce training time, improve generalization, and replace learning rate decay, as suggested by recent literature. Our evaluation across seven architectures and datasets reveals that averaging significantly accelerates training and yields considerable efficiency gains, at the price of a minimal implementation and memory cost, while mildly improving generalization across all considered workloads. Finally, we explore the relationship between averaging and learning rate annealing and show how to optimally combine the two to achieve the best performances.",
    "published": "2025-02-10T18:40:48Z",
    "updated": "2025-11-24T10:35:14Z",
    "link": "http://arxiv.org/pdf/2502.06761v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Niccolò Ajroldi",
      "Antonio Orvieto",
      "Jonas Geiping"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18945v1",
    "title": "MIST: Mutual Information Via Supervised Training",
    "summary": "We propose a fully data-driven approach to designing mutual information (MI) estimators. Since any MI estimator is a function of the observed sample from two random variables, we parameterize this function with a neural network (MIST) and train it end-to-end to predict MI values. Training is performed on a large meta-dataset of 625,000 synthetic joint distributions with known ground-truth MI. To handle variable sample sizes and dimensions, we employ a two-dimensional attention scheme ensuring permutation invariance across input samples. To quantify uncertainty, we optimize a quantile regression loss, enabling the estimator to approximate the sampling distribution of MI rather than return a single point estimate. This research program departs from prior work by taking a fully empirical route, trading universal theoretical guarantees for flexibility and efficiency. Empirically, the learned estimators largely outperform classical baselines across sample sizes and dimensions, including on joint distributions unseen during training. The resulting quantile-based intervals are well-calibrated and more reliable than bootstrap-based confidence intervals, while inference is orders of magnitude faster than existing neural baselines. Beyond immediate empirical gains, this framework yields trainable, fully differentiable estimators that can be embedded into larger learning pipelines. Moreover, exploiting MI's invariance to invertible transformations, meta-datasets can be adapted to arbitrary data modalities via normalizing flows, enabling flexible training for diverse target meta-distributions.",
    "published": "2025-11-24T09:55:28Z",
    "updated": "2025-11-24T09:55:28Z",
    "link": "http://arxiv.org/pdf/2511.18945v1.pdf",
    "category": [
      "cs.LG",
      "cs.IT"
    ],
    "authors": [
      "German Gritsai",
      "Megan Richards",
      "Maxime Méloux",
      "Kyunghyun Cho",
      "Maxime Peyrard"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.13237v2",
    "title": "Counterfactual Explainable AI (XAI) Method for Deep Learning-Based Multivariate Time Series Classification",
    "summary": "Recent advances in deep learning have improved multivariate time series (MTS) classification and regression by capturing complex patterns, but their lack of transparency hinders decision-making. Explainable AI (XAI) methods offer partial insights, yet often fall short of conveying the full decision space. Counterfactual Explanations (CE) provide a promising alternative, but current approaches typically prioritize either accuracy, proximity or sparsity -- rarely all -- limiting their practical value. To address this, we propose CONFETTI, a novel multi-objective CE method for MTS. CONFETTI identifies key MTS subsequences, locates a counterfactual target, and optimally modifies the time series to balance prediction confidence, proximity and sparsity. This method provides actionable insights with minimal changes, improving interpretability, and decision support. CONFETTI is evaluated on seven MTS datasets from the UEA archive, demonstrating its effectiveness in various domains. CONFETTI consistently outperforms state-of-the-art CE methods in its optimization objectives, and in six other metrics from the literature, achieving $\\geq10\\%$ higher confidence while improving sparsity in $\\geq40\\%$.",
    "published": "2025-11-17T11:00:43Z",
    "updated": "2025-11-24T09:47:20Z",
    "link": "http://arxiv.org/pdf/2511.13237v2.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Alan G. Paredes Cetina",
      "Kaouther Benguessoum",
      "Raoni Lourenço",
      "Sylvain Kubler"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18940v1",
    "title": "Geometry-Aware Deep Congruence Networks for Manifold Learning in Cross-Subject Motor Imagery",
    "summary": "Cross-subject motor-imagery decoding remains a major challenge in EEG-based brain-computer interfaces due to strong subject variability and the curved geometry of covariance matrices on the symmetric positive definite (SPD) manifold. We address the zero-shot cross-subject setting, where no target-subject labels or adaptation are allowed, by introducing novel geometry-aware preprocessing modules and deep congruence networks that operate directly on SPD covariance matrices. Our preprocessing modules, DCR and RiFU, extend Riemannian Alignment by improving action separation while reducing subject-specific distortions. We further propose two manifold classifiers, SPD-DCNet and RiFUNet, which use hierarchical congruence transforms to learn discriminative, subject-invariant covariance representations. On the BCI-IV 2a benchmark, our framework improves cross-subject accuracy by 3-4% over the strongest classical baselines, demonstrating the value of geometry-aware transformations for robust EEG decoding.",
    "published": "2025-11-24T09:46:55Z",
    "updated": "2025-11-24T09:46:55Z",
    "link": "http://arxiv.org/pdf/2511.18940v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Sanjeev Manivannan",
      "Chandrashekar Lakshminarayan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.06567v2",
    "title": "SlimCaching: Edge Caching of Mixture-of-Experts for Distributed Inference",
    "summary": "Mixture-of-Experts (MoE) models improve the scalability of large language models (LLMs) by activating only a small subset of relevant experts per input. However, the sheer number of expert networks in an MoE model introduces a significant storage burden for an edge device. To address this challenge, we consider a scenario where experts are dispersed across an edge network for distributed inference. Based on the popular Top-$K$ expert selection strategy, we formulate a latency minimization problem by optimizing expert caching on edge servers under storage constraints. When $K=1$, the problem reduces to a monotone submodular maximization problem with knapsack constraints, for which we design a greedy-based algorithm with a $(1 - 1/e)$-approximation guarantee. For the general case where $K \\geq 1$, expert co-activation within the same MoE layer introduces non-submodularity, which renders greedy methods ineffective. To tackle this issue, we propose a successive greedy decomposition method to decompose the original problem into a series of subproblems, with each being solved by a dynamic programming approach. Furthermore, we design an accelerated algorithm based on the max-convolution technique to obtain the approximate solution with a provable guarantee in polynomial time. Simulation results on various MoE models demonstrate that our method significantly reduces inference latency compared to existing baselines.",
    "published": "2025-07-09T05:43:43Z",
    "updated": "2025-11-24T09:35:35Z",
    "link": "http://arxiv.org/pdf/2507.06567v2.pdf",
    "category": [
      "cs.LG",
      "cs.DC",
      "cs.NI"
    ],
    "authors": [
      "Qian Chen",
      "Xianhao Chen",
      "Kaibin Huang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.15107v3",
    "title": "Interpretability of Graph Neural Networks to Assess Effects of Global Change Drivers on Ecological Networks",
    "summary": "Pollinators play a crucial role for plant reproduction, either in natural ecosystem or in human-modified landscape. Global change drivers,including climate change or land use modifications, can alter the plant-pollinator interactions. To assess the potential influence of global change drivers on pollination, large-scale interactions, climate and land use data are required. While recent machine learning methods, such as graph neural networks (GNNs), allow the analysis of such datasets, interpreting their results can be challenging. We explore existing methods for interpreting GNNs in order to highlight the effects of various environmental covariates on pollination network connectivity. An extensive simulation study is performed to confirm whether these methods can detect the interactive effect between a covariate and a genus of plant on connectivity, and whether the application of debiasing techniques influences the estimation of these effects. An application on the Spipoll dataset, with and without accounting for sampling effects, highlights the potential impact of land use on network connectivity and shows that accounting for sampling effects partially alters the estimation of these effects.",
    "published": "2025-03-19T11:04:53Z",
    "updated": "2025-11-24T09:33:15Z",
    "link": "http://arxiv.org/pdf/2503.15107v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Emre Anakok",
      "Pierre Barbillon",
      "Colin Fontaine",
      "Elisa Thebault"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.00578v2",
    "title": "Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides",
    "summary": "Hydrogen atom transfer (HAT) reactions are essential in many biological processes, such as radical migration in damaged proteins, but their mechanistic pathways remain incompletely understood. Simulating HAT is challenging due to the need for quantum chemical accuracy at biologically relevant scales; thus, neither classical force fields nor DFT-based molecular dynamics are applicable. Machine-learned potentials offer an alternative, able to learn potential energy surfaces (PESs) with near-quantum accuracy. However, training these models to generalize across diverse HAT configurations, especially at radical positions in proteins, requires tailored data generation and careful model selection. Here, we systematically generate HAT configurations in peptides to build large datasets using semiempirical methods and DFT. We benchmark three graph neural network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT PESs and indirectly predict reaction barriers from energy predictions. MACE consistently outperforms the others in energy, force, and barrier prediction, achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT barrier predictions. Using molecular dynamics, we show our MACE potential is stable, reactive, and generalizes beyond training data to model HAT barriers in collagen I. This accuracy enables integration of ML potentials into large-scale collagen simulations to compute reaction rates from predicted barriers, advancing mechanistic understanding of HAT and radical migration in peptides. We analyze scaling laws, model transferability, and cost-performance trade-offs, and outline strategies for improvement by combining ML potentials with transition state search algorithms and active learning. Our approach is generalizable to other biomolecular systems, enabling quantum-accurate simulations of chemical reactivity in complex environments.",
    "published": "2025-08-01T12:21:49Z",
    "updated": "2025-11-24T08:44:20Z",
    "link": "http://arxiv.org/pdf/2508.00578v2.pdf",
    "category": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "physics.chem-ph",
      "physics.comp-ph",
      "q-bio.BM"
    ],
    "authors": [
      "Marlen Neubert",
      "Patrick Reiser",
      "Frauke Gräter",
      "Pascal Friederich"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18887v1",
    "title": "Hi-SAFE: Hierarchical Secure Aggregation for Lightweight Federated Learning",
    "summary": "Federated learning (FL) faces challenges in ensuring both privacy and communication efficiency, particularly in resource-constrained environments such as Internet of Things (IoT) and edge networks. While sign-based methods, such as sign stochastic gradient descent with majority voting (SIGNSGD-MV), offer substantial bandwidth savings, they remain vulnerable to inference attacks due to exposure of gradient signs. Existing secure aggregation techniques are either incompatible with sign-based methods or incur prohibitive overhead. To address these limitations, we propose Hi-SAFE, a lightweight and cryptographically secure aggregation framework for sign-based FL. Our core contribution is the construction of efficient majority vote polynomials for SIGNSGD-MV, derived from Fermat's Little Theorem. This formulation represents the majority vote as a low-degree polynomial over a finite field, enabling secure evaluation that hides intermediate values and reveals only the final result. We further introduce a hierarchical subgrouping strategy that ensures constant multiplicative depth and bounded per-user complexity, independent of the number of users n.",
    "published": "2025-11-24T08:42:40Z",
    "updated": "2025-11-24T08:42:40Z",
    "link": "http://arxiv.org/pdf/2511.18887v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Hyeong-Gun Joo",
      "Songnam Hong",
      "Seunghwan Lee",
      "Dong-Joon Shin"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18876v1",
    "title": "Fairness Meets Privacy: Integrating Differential Privacy and Demographic Parity in Multi-class Classification",
    "summary": "The increasing use of machine learning in sensitive applications demands algorithms that simultaneously preserve data privacy and ensure fairness across potentially sensitive sub-populations. While privacy and fairness have each been extensively studied, their joint treatment remains poorly understood. Existing research often frames them as conflicting objectives, with multiple studies suggesting that strong privacy notions such as differential privacy inevitably compromise fairness. In this work, we challenge that perspective by showing that differential privacy can be integrated into a fairness-enhancing pipeline with minimal impact on fairness guarantees. We design a postprocessing algorithm, called DP2DP, that enforces both demographic parity and differential privacy. Our analysis reveals that our algorithm converges towards its demographic parity objective at essentially the same rate (up logarithmic factor) as the best non-private methods from the literature. Experiments on both synthetic and real datasets confirm our theoretical results, showing that the proposed algorithm achieves state-of-the-art accuracy/fairness/privacy trade-offs.",
    "published": "2025-11-24T08:31:02Z",
    "updated": "2025-11-24T08:31:02Z",
    "link": "http://arxiv.org/pdf/2511.18876v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Lilian Say",
      "Christophe Denis",
      "Rafael Pinot"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2507.07456v2",
    "title": "General-Purpose Models for the Chemical Sciences: LLMs and Beyond",
    "summary": "Data-driven techniques have a large potential to transform and accelerate the chemical sciences. However, chemical sciences also pose the unique challenge of very diverse, small, fuzzy datasets that are difficult to leverage in conventional machine learning approaches. A new class of models, which can be summarized under the term general-purpose models (GPMs) such as large language models, has shown the ability to solve tasks they have not been directly trained on, and to flexibly operate with low amounts of data in different formats. In this review, we discuss fundamental building principles of GPMs and review recent and emerging applications of those models in the chemical sciences across the entire scientific process. While many of these applications are still in the prototype phase, we expect that the increasing interest in GPMs will make many of them mature in the coming years.",
    "published": "2025-07-10T06:18:46Z",
    "updated": "2025-11-24T08:29:00Z",
    "link": "http://arxiv.org/pdf/2507.07456v2.pdf",
    "category": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "physics.chem-ph"
    ],
    "authors": [
      "Nawaf Alampara",
      "Anagha Aneesh",
      "Martiño Ríos-García",
      "Adrian Mirza",
      "Mara Schilling-Wilhelmi",
      "Ali Asghar Aghajani",
      "Meiling Sun",
      "Gordan Prastalo",
      "Kevin Maik Jablonka"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2111.03201v3",
    "title": "Compressing Sensor Data for Remote Assistance of Autonomous Vehicles using Deep Generative Models",
    "summary": "In the foreseeable future, autonomous vehicles will require human assistance in situations they can not resolve on their own. In such scenarios, remote assistance from a human can provide the required input for the vehicle to continue its operation. Typical sensors used in autonomous vehicles include camera and lidar sensors. Due to the massive volume of sensor data that must be sent in real-time, highly efficient data compression is elementary to prevent an overload of network infrastructure. Sensor data compression using deep generative neural networks has been shown to outperform traditional compression approaches for both image and lidar data, regarding compression rate as well as reconstruction quality. However, there is a lack of research about the performance of generative-neural-network-based compression algorithms for remote assistance. In order to gain insights into the feasibility of deep generative models for usage in remote assistance, we evaluate state-of-the-art algorithms regarding their applicability and identify potential weaknesses. Further, we implement an online pipeline for processing sensor data and demonstrate its performance for remote assistance using the CARLA simulator.",
    "published": "2021-11-05T00:16:06Z",
    "updated": "2025-11-24T08:17:47Z",
    "link": "http://arxiv.org/pdf/2111.03201v3.pdf",
    "category": [
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Daniel Bogdoll",
      "Johannes Jestram",
      "Jonas Rauch",
      "Christin Scheib",
      "Moritz Wittig",
      "J. Marius Zöllner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2109.09607v4",
    "title": "Description of Corner Cases in Automated Driving: Goals and Challenges",
    "summary": "Scaling the distribution of automated vehicles requires handling various unexpected and possibly dangerous situations, termed corner cases (CC). Since many modules of automated driving systems are based on machine learning (ML), CC are an essential part of the data for their development. However, there is only a limited amount of CC data in large-scale data collections, which makes them challenging in the context of ML. With a better understanding of CC, offline applications, e.g., dataset analysis, and online methods, e.g., improved performance of automated driving systems, can be improved. While there are knowledge-based descriptions and taxonomies for CC, there is little research on machine-interpretable descriptions. In this extended abstract, we will give a brief overview of the challenges and goals of such a description.",
    "published": "2021-09-20T15:04:55Z",
    "updated": "2025-11-24T07:58:18Z",
    "link": "http://arxiv.org/pdf/2109.09607v4.pdf",
    "category": [
      "cs.LG",
      "cs.RO"
    ],
    "authors": [
      "Daniel Bogdoll",
      "Jasmin Breitenstein",
      "Florian Heidecker",
      "Maarten Bieshaar",
      "Bernhard Sick",
      "Tim Fingscheidt",
      "J. Marius Zöllner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18835v1",
    "title": "Auto-ML Graph Neural Network Hypermodels for Outcome Prediction in Event-Sequence Data",
    "summary": "This paper introduces HGNN(O), an AutoML GNN hypermodel framework for outcome prediction on event-sequence data. Building on our earlier work on graph convolutional network hypermodels, HGNN(O) extends four architectures-One Level, Two Level, Two Level Pseudo Embedding, and Two Level Embedding-across six canonical GNN operators. A self-tuning mechanism based on Bayesian optimization with pruning and early stopping enables efficient adaptation over architectures and hyperparameters without manual configuration. Empirical evaluation on both balanced and imbalanced event logs shows that HGNN(O) achieves accuracy exceeding 0.98 on the Traffic Fines dataset and weighted F1 scores up to 0.86 on the Patients dataset without explicit imbalance handling. These results demonstrate that the proposed AutoML-GNN approach provides a robust and generalizable benchmark for outcome prediction in complex event-sequence data.",
    "published": "2025-11-24T07:13:34Z",
    "updated": "2025-11-24T07:13:34Z",
    "link": "http://arxiv.org/pdf/2511.18835v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Fang Wang",
      "Lance Kosca",
      "Adrienne Kosca",
      "Marko Gacesa",
      "Ernesto Damiani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18830v1",
    "title": "Leveraging Duration Pseudo-Embeddings in Multilevel LSTM and GCN Hypermodels for Outcome-Oriented PPM",
    "summary": "Existing deep learning models for Predictive Process Monitoring (PPM) struggle with temporal irregularities, particularly stochastic event durations and overlapping timestamps, limiting their adaptability across heterogeneous datasets. We propose a dual input neural network strategy that separates event and sequence attributes, using a duration-aware pseudo-embedding matrix to transform temporal importance into compact, learnable representations. This design is implemented across two baseline families: B-LSTM and B-GCN, and their duration-aware variants D-LSTM and D-GCN. All models incorporate self-tuned hypermodels for adaptive architecture selection. Experiments on balanced and imbalanced outcome prediction tasks show that duration pseudo-embedding inputs consistently improve generalization, reduce model complexity, and enhance interpretability. Our results demonstrate the benefits of explicit temporal encoding and provide a flexible design for robust, real-world PPM applications.",
    "published": "2025-11-24T07:06:08Z",
    "updated": "2025-11-24T07:06:08Z",
    "link": "http://arxiv.org/pdf/2511.18830v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Fang Wang",
      "Paolo Ceravolo",
      "Ernesto Damiani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18829v1",
    "title": "Towards Characterizing Knowledge Distillation of PPG Heart Rate Estimation Models",
    "summary": "Heart rate estimation from photoplethysmography (PPG) signals generated by wearable devices such as smartwatches and fitness trackers has significant implications for the health and well-being of individuals. Although prior work has demonstrated deep learning models with strong performance in the heart rate estimation task, in order to deploy these models on wearable devices, these models must also adhere to strict memory and latency constraints. In this work, we explore and characterize how large pre-trained PPG models may be distilled to smaller models appropriate for real-time inference on the edge. We evaluate four distillation strategies through comprehensive sweeps of teacher and student model capacities: (1) hard distillation, (2) soft distillation, (3) decoupled knowledge distillation (DKD), and (4) feature distillation. We present a characterization of the resulting scaling laws describing the relationship between model size and performance. This early investigation lays the groundwork for practical and predictable methods for building edge-deployable models for physiological sensing.",
    "published": "2025-11-24T07:06:06Z",
    "updated": "2025-11-24T07:06:06Z",
    "link": "http://arxiv.org/pdf/2511.18829v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kanav Arora",
      "Girish Narayanswamy",
      "Shwetak Patel",
      "Richard Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2304.13037v3",
    "title": "VeML: An End-to-End Machine Learning Lifecycle for Large-scale and High-dimensional Data",
    "summary": "An end-to-end machine learning (ML) lifecycle consists of many iterative processes, from data preparation and ML model design to model training and then deploying the trained model for inference. When building an end-to-end lifecycle for an ML problem, many ML pipelines must be designed and executed that produce a huge number of lifecycle versions. Therefore, this paper introduces VeML, a Version management system dedicated to end-to-end ML Lifecycle. Our system tackles several crucial problems that other systems have not solved. First, we address the high cost of building an ML lifecycle, especially for large-scale and high-dimensional dataset. We solve this problem by proposing to transfer the lifecycle of similar datasets managed in our system to the new training data. We design an algorithm based on the core set to compute similarity for large-scale, high-dimensional data efficiently. Another critical issue is the model accuracy degradation by the difference between training data and testing data during the ML lifetime, which leads to lifecycle rebuild. Our system helps to detect this mismatch without getting labeled data from testing data and rebuild the ML lifecycle for a new data version. To demonstrate our contributions, we conduct experiments on real-world, large-scale datasets of driving images and spatiotemporal sensor data and show promising results.",
    "published": "2023-04-25T07:32:16Z",
    "updated": "2025-11-24T07:05:54Z",
    "link": "http://arxiv.org/pdf/2304.13037v3.pdf",
    "category": [
      "cs.LG",
      "cs.DB",
      "cs.HC"
    ],
    "authors": [
      "Van-Duc Le",
      "Tien-Cuong Bui",
      "Wen-Syan Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18820v1",
    "title": "Solution of Incompressible Flow Equations with Physics and Equality Constrained Artificial Neural Networks",
    "summary": "We present a meshless method for the solution of incompressible Navier-Stokes equations in advection-dominated regimes using physics- and equality-constrained artificial neural networks combined with a conditionally adaptive augmented Lagrangian formulation. A single neural network parameterizes both the velocity and pressure fields, and is trained by minimizing the residual of a Poisson's equation for pressure, constrained by the momentum and continuity equations, together with boundary conditions on the velocity field. No boundary conditions are imposed on the pressure field aside from anchoring the pressure at a point to prevent its unbounded development. The training is performed from scratch without labeled data, relying solely on the governing equations and constraints. To enhance accuracy in advection-dominated flows, we employ a single Fourier feature mapping of the input coordinates. The proposed method is demonstrated for the canonical lid-driven cavity flow up to a Reynolds number of 7,500 and for laminar flow over a circular cylinder with inflow-outflow boundary conditions, achieving excellent agreement with benchmark solutions. We further compare the present formulation against alternative objective-function constructions based on different arrangements of the flow equations, thereby highlighting the algorithmic advantages of the proposed formulation centered around the Poisson's equation for pressure.",
    "published": "2025-11-24T06:54:20Z",
    "updated": "2025-11-24T06:54:20Z",
    "link": "http://arxiv.org/pdf/2511.18820v1.pdf",
    "category": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "authors": [
      "Qifeng Hu",
      "Inanc Senocak"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18813v1",
    "title": "Uncertainty of Network Topology with Applications to Out-of-Distribution Detection",
    "summary": "Persistent homology (PH) is a crucial concept in computational topology, providing a multiscale topological description of a space. It is particularly significant in topological data analysis, which aims to make statistical inference from a topological perspective. In this work, we introduce a new topological summary for Bayesian neural networks, termed the predictive topological uncertainty (pTU). The proposed pTU measures the uncertainty in the interaction between the model and the inputs. It provides insights from the model perspective: if two samples interact with a model in a similar way, then they are considered identically distributed. We also show that the pTU is insensitive to the model architecture. As an application, pTU is used to solve the out-of-distribution (OOD) detection problem, which is critical to ensure model reliability. Failure to detect OOD input can lead to incorrect and unreliable predictions. To address this issue, we propose a significance test for OOD based on the pTU, providing a statistical framework for this issue. The effectiveness of the framework is validated through various experiments, in terms of its statistical power, sensitivity, and robustness.",
    "published": "2025-11-24T06:39:45Z",
    "updated": "2025-11-24T06:39:45Z",
    "link": "http://arxiv.org/pdf/2511.18813v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "authors": [
      "Sing-Yuan Yeh",
      "Chun-Hao Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.09527v2",
    "title": "Time-Aware and Transition-Semantic Graph Neural Networks for Interpretable Predictive Business Process Monitoring",
    "summary": "Predictive Business Process Monitoring (PBPM) aims to forecast future events in ongoing cases based on historical event logs. While Graph Neural Networks (GNNs) are well suited to capture structural dependencies in process data, existing GNN-based PBPM models remain underdeveloped. Most rely either on short prefix subgraphs or global architectures that overlook temporal relevance and transition semantics. We propose a unified, interpretable GNN framework that advances the state of the art along three key axes. First, we compare prefix-based Graph Convolutional Networks(GCNs) and full trace Graph Attention Networks(GATs) to quantify the performance gap between localized and global modeling. Second, we introduce a novel time decay attention mechanism that constructs dynamic, prediction-centered windows, emphasizing temporally relevant history and suppressing noise. Third, we embed transition type semantics into edge features to enable fine grained reasoning over structurally ambiguous traces. Our architecture includes multilevel interpretability modules, offering diverse visualizations of attention behavior. Evaluated on five benchmarks, the proposed models achieve competitive Top-k accuracy and DL scores without per-dataset tuning. By addressing architectural, temporal, and semantic gaps, this work presents a robust, generalizable, and explainable solution for next event prediction in PBPM.",
    "published": "2025-08-13T06:21:42Z",
    "updated": "2025-11-24T06:23:22Z",
    "link": "http://arxiv.org/pdf/2508.09527v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Fang Wang",
      "Ernesto Damiani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18789v1",
    "title": "Doubly Wild Refitting: Model-Free Evaluation of High Dimensional Black-Box Predictions under Convex Losses",
    "summary": "We study the problem of excess risk evaluation for empirical risk minimization (ERM) under general convex loss functions. Our contribution is an efficient refitting procedure that computes the excess risk and provides high-probability upper bounds under the fixed-design setting. Assuming only black-box access to the training algorithm and a single dataset, we begin by generating two sets of artificially modified pseudo-outcomes termed wild response, created by stochastically perturbing the gradient vectors with carefully chosen scaling. Using these two pseudo-labeled datasets, we then refit the black-box procedure twice to obtain two corresponding wild predictors. Finally, leveraging the original predictor, the two wild predictors, and the constructed wild responses, we derive an efficient excess risk upper bound. A key feature of our analysis is that it requires no prior knowledge of the complexity of the underlying function class. As a result, the method is essentially model-free and holds significant promise for theoretically evaluating modern opaque machine learning system--such as deep nerral networks and generative model--where traditional capacity-based learning theory becomes infeasible due to the extreme complexity of the hypothesis class.",
    "published": "2025-11-24T05:38:47Z",
    "updated": "2025-11-24T05:38:47Z",
    "link": "http://arxiv.org/pdf/2511.18789v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Haichen Hu",
      "David Simchi-Levi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18783v1",
    "title": "Hypergraph Contrastive Learning for both Homophilic and Heterophilic Hypergraphs",
    "summary": "Hypergraphs, as a generalization of traditional graphs, naturally capture high-order relationships. In recent years, hypergraph neural networks (HNNs) have been widely used to capture complex high-order relationships. However, most existing hypergraph neural network methods inherently rely on the homophily assumption, which often does not hold in real-world scenarios that exhibit significant heterophilic structures. To address this limitation, we propose \\textbf{HONOR}, a novel unsupervised \\textbf{H}ypergraph c\\textbf{ON}trastive learning framework suitable for both hom\\textbf{O}philic and hete\\textbf{R}ophilic hypergraphs. Specifically, HONOR explicitly models the heterophilic relationships between hyperedges and nodes through two complementary mechanisms: a prompt-based hyperedge feature construction strategy that maintains global semantic consistency while suppressing local noise, and an adaptive attention aggregation module that dynamically captures the diverse local contributions of nodes to hyperedges. Combined with high-pass filtering, these designs enable HONOR to fully exploit heterophilic connection patterns, yielding more discriminative and robust node and hyperedge representations. Theoretically, we demonstrate the superior generalization ability and robustness of HONOR. Empirically, extensive experiments further validate that HONOR consistently outperforms state-of-the-art baselines under both homophilic and heterophilic datasets.",
    "published": "2025-11-24T05:35:46Z",
    "updated": "2025-11-24T05:35:46Z",
    "link": "http://arxiv.org/pdf/2511.18783v1.pdf",
    "category": [
      "cs.LG",
      "cs.SI"
    ],
    "authors": [
      "Renchu Guan",
      "Xuyang Li",
      "Yachao Zhang",
      "Wei Pang",
      "Fausto Giunchiglia",
      "Ximing Li",
      "Yonghao Liu",
      "Xiaoyue Feng"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2509.02476v7",
    "title": "Perturbing the Derivative: Wild Refitting for Model-Free Evaluation of Machine Learning Models under Bregman Losses",
    "summary": "We study the excess risk evaluation of classical penalized empirical risk minimization (ERM) with Bregman losses. We show that by leveraging the idea of wild refitting, one can efficiently upper bound the excess risk through the so-called \"wild optimism,\" without relying on the global structure of the underlying function class. This property makes our approach inherently model-free. Unlike conventional analysis, our framework operates with just one dataset and black-box access to the training procedure. The method involves randomized Rademacher symmetrization and constructing artificially modified outputs by perturbation in the derivative space with appropriate scaling, upon which we retrain a second predictor for excess risk estimation. We establish high-probability performance guarantee under the fixed design setting, demonstrating that wild refitting under Bregman losses, with an appropriately chosen wild noise scale, yields a valid upper bound on the excess risk. Thus, our work is promising for theoretically evaluating modern opaque ML models, such as deep neural networks and generative models, where the function class is too complex for classical learning theory and empirical process techniques.",
    "published": "2025-09-02T16:26:03Z",
    "updated": "2025-11-24T05:35:06Z",
    "link": "http://arxiv.org/pdf/2509.02476v7.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Haichen Hu",
      "David Simchi-Levi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18777v1",
    "title": "SAOT: An Enhanced Locality-Aware Spectral Transformer for Solving PDEs",
    "summary": "Neural operators have shown great potential in solving a family of Partial Differential Equations (PDEs) by modeling the mappings between input and output functions. Fourier Neural Operator (FNO) implements global convolutions via parameterizing the integral operators in Fourier space. However, it often results in over-smoothing solutions and fails to capture local details and high-frequency components. To address these limitations, we investigate incorporating the spatial-frequency localization property of Wavelet transforms into the Transformer architecture. We propose a novel Wavelet Attention (WA) module with linear computational complexity to efficiently learn locality-aware features. Building upon WA, we further develop the Spectral Attention Operator Transformer (SAOT), a hybrid spectral Transformer framework that integrates WA's localized focus with the global receptive field of Fourier-based Attention (FA) through a gated fusion block. Experimental results demonstrate that WA significantly mitigates the limitations of FA and outperforms existing Wavelet-based neural operators by a large margin. By integrating the locality-aware and global spectral representations, SAOT achieves state-of-the-art performance on six operator learning benchmarks and exhibits strong discretization-invariant ability.",
    "published": "2025-11-24T05:22:28Z",
    "updated": "2025-11-24T05:22:28Z",
    "link": "http://arxiv.org/pdf/2511.18777v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Chenhong Zhou",
      "Jie Chen",
      "Zaifeng Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.01836v3",
    "title": "Priors in Time: Missing Inductive Biases for Language Model Interpretability",
    "summary": "Recovering meaningful concepts from language model activations is a central aim of interpretability. While existing feature extraction methods aim to identify concepts that are independent directions, it is unclear if this assumption can capture the rich temporal structure of language. Specifically, via a Bayesian lens, we demonstrate that Sparse Autoencoders (SAEs) impose priors that assume independence of concepts across time, implying stationarity. Meanwhile, language model representations exhibit rich temporal dynamics, including systematic growth in conceptual dimensionality, context-dependent correlations, and pronounced non-stationarity, in direct conflict with the priors of SAEs. Taking inspiration from computational neuroscience, we introduce a new interpretability objective -- Temporal Feature Analysis -- which possesses a temporal inductive bias to decompose representations at a given time into two parts: a predictable component, which can be inferred from the context, and a residual component, which captures novel information unexplained by the context. Temporal Feature Analyzers correctly parse garden path sentences, identify event boundaries, and more broadly delineate abstract, slow-moving information from novel, fast-moving information, while existing SAEs show significant pitfalls in all the above tasks. Overall, our results underscore the need for inductive biases that match the data in designing robust interpretability tools.",
    "published": "2025-11-03T18:43:48Z",
    "updated": "2025-11-24T05:16:44Z",
    "link": "http://arxiv.org/pdf/2511.01836v3.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Ekdeep Singh Lubana",
      "Can Rager",
      "Sai Sumedh R. Hindupur",
      "Valerie Costa",
      "Greta Tuckute",
      "Oam Patel",
      "Sonia Krishna Murthy",
      "Thomas Fel",
      "Daniel Wurgaft",
      "Eric J. Bigelow",
      "Johnny Lin",
      "Demba Ba",
      "Martin Wattenberg",
      "Fernanda Viegas",
      "Melanie Weber",
      "Aaron Mueller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.07372v2",
    "title": "Provable Benefit of Curriculum in Transformer Tree-Reasoning Post-Training",
    "summary": "Recent curriculum techniques in the post-training stage of LLMs have been widely observed to outperform non-curriculum approaches in enhancing reasoning performance, yet a principled understanding of why and to what extent they work remains elusive. To address this gap, we develop a theoretical framework grounded in the intuition that progressively learning through manageable steps is more efficient than directly tackling a hard reasoning task, provided each stage stays within the model's effective competence. Under mild complexity conditions linking consecutive curriculum stages, we show that curriculum post-training avoids the exponential complexity bottleneck.\n  To substantiate this result, drawing insights from the Chain-of-Thoughts (CoTs) solving mathematical problems such as Countdown and parity, we model CoT generation as a states-conditioned autoregressive reasoning tree, define a uniform-branching base model to capture pretrained behavior, and formalize curriculum stages as either depth-increasing (longer reasoning chains) or hint-decreasing (shorter prefixes) subtasks. Our analysis shows that, under outcome-only reward signals, reinforcement learning finetuning achieves high accuracy with polynomial sample complexity, whereas direct learning suffers from an exponential bottleneck. We further establish analogous guarantees for test-time scaling, where curriculum-aware querying reduces both reward oracle calls and sampling cost from exponential to polynomial order.",
    "published": "2025-11-10T18:29:54Z",
    "updated": "2025-11-24T04:50:07Z",
    "link": "http://arxiv.org/pdf/2511.07372v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Dake Bu",
      "Wei Huang",
      "Andi Han",
      "Atsushi Nitanda",
      "Hau-San Wong",
      "Qingfu Zhang",
      "Taiji Suzuki"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2505.01218v4",
    "title": "Quantitative Attractor Analysis of High-Capacity Kernel Logistic Regression Hopfield Networks",
    "summary": "Kernel-based learning methods such as Kernel Logistic Regression (KLR) can substantially increase the storage capacity of Hopfield networks, but the principles governing their performance and stability remain largely uncharacterized. This paper presents a comprehensive quantitative analysis of the attractor landscape in KLR-trained networks to establish a solid foundation for their design and application. Through extensive, statistically validated simulations, we address critical questions of generality, scalability, and robustness. Our comparative analysis shows that KLR and Kernel Ridge Regression (KRR) exhibit similarly high storage capacities and clean attractor landscapes under typical operating conditions, suggesting that this behavior is a general property of kernel regression methods, although KRR is computationally much faster. We identify a non-trivial, scale-dependent law for the kernel width $γ$, demonstrating that optimal capacity requires $γ$ to be scaled such that $γN$ increases with network size $N$. This finding implies that larger networks require more localized kernels, in which each pattern's influence is more spatially confined, to mitigate inter-pattern interference. Under this optimized scaling, we provide clear evidence that storage capacity scales linearly with network size~($P \\propto N$). Furthermore, our sensitivity analysis shows that performance is remarkably robust with respect to the choice of the regularization parameter $λ$. Collectively, these findings provide a concise set of empirical principles for designing high-capacity and robust associative memories and clarify the mechanisms that enable kernel methods to overcome the classical limitations of Hopfield-type models.",
    "published": "2025-05-02T12:13:23Z",
    "updated": "2025-11-24T04:42:20Z",
    "link": "http://arxiv.org/pdf/2505.01218v4.pdf",
    "category": [
      "cs.LG",
      "cs.NE"
    ],
    "authors": [
      "Akira Tamamori"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18750v1",
    "title": "On Instability of Minimax Optimal Optimism-Based Bandit Algorithms",
    "summary": "Statistical inference from data generated by multi-armed bandit (MAB) algorithms is challenging due to their adaptive, non-i.i.d. nature. A classical manifestation is that sample averages of arm rewards under bandit sampling may fail to satisfy a central limit theorem. Lai and Wei's stability condition provides a sufficient, and essentially necessary criterion, for asymptotic normality in bandit problems. While the celebrated Upper Confidence Bound (UCB) algorithm satisfies this stability condition, it is not minimax optimal, raising the question of whether minimax optimality and statistical stability can be achieved simultaneously. In this paper, we analyze the stability properties of a broad class of bandit algorithms that are based on the optimism principle. We establish general structural conditions under which such algorithms violate the Lai-Wei stability criterion. As a consequence, we show that widely used minimax-optimal UCB-style algorithms, including MOSS, Anytime-MOSS, Vanilla-MOSS, ADA-UCB, OC-UCB, KL-MOSS, KL-UCB++, KL-UCB-SWITCH, and Anytime KL-UCB-SWITCH, are unstable. We further complement our theoretical results with numerical simulations demonstrating that, in all these cases, the sample means fail to exhibit asymptotic normality.\n  Overall, our findings suggest a fundamental tension between stability and minimax optimal regret, raising the question of whether it is possible to design bandit algorithms that achieve both. Understanding whether such simultaneously stable and minimax optimal strategies exist remains an important open direction.",
    "published": "2025-11-24T04:23:26Z",
    "updated": "2025-11-24T04:23:26Z",
    "link": "http://arxiv.org/pdf/2511.18750v1.pdf",
    "category": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.ST"
    ],
    "authors": [
      "Samya Praharaj",
      "Koulik Khamaru"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18732v1",
    "title": "OceanForecastBench: A Benchmark Dataset for Data-Driven Global Ocean Forecasting",
    "summary": "Global ocean forecasting aims to predict key ocean variables such as temperature, salinity, and currents, which is essential for understanding and describing oceanic phenomena. In recent years, data-driven deep learning-based ocean forecast models, such as XiHe, WenHai, LangYa and AI-GOMS, have demonstrated significant potential in capturing complex ocean dynamics and improving forecasting efficiency. Despite these advancements, the absence of open-source, standardized benchmarks has led to inconsistent data usage and evaluation methods. This gap hinders efficient model development, impedes fair performance comparison, and constrains interdisciplinary collaboration. To address this challenge, we propose OceanForecastBench, a benchmark offering three core contributions: (1) A high-quality global ocean reanalysis data over 28 years for model training, including 4 ocean variables across 23 depth levels and 4 sea surface variables. (2) A high-reliability satellite and in-situ observations for model evaluation, covering approximately 100 million locations in the global ocean. (3) An evaluation pipeline and a comprehensive benchmark with 6 typical baseline models, leveraging observations to evaluate model performance from multiple perspectives. OceanForecastBench represents the most comprehensive benchmarking framework currently available for data-driven ocean forecasting, offering an open-source platform for model development, evaluation, and comparison. The dataset and code are publicly available at: https://github.com/Ocean-Intelligent-Forecasting/OceanForecastBench.",
    "published": "2025-11-24T03:57:43Z",
    "updated": "2025-11-24T03:57:43Z",
    "link": "http://arxiv.org/pdf/2511.18732v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Haoming Jia",
      "Yi Han",
      "Xiang Wang",
      "Huizan Wang",
      "Wei Wu",
      "Jianming Zheng",
      "Peikun Xiao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18730v1",
    "title": "Large-Scale In-Game Outcome Forecasting for Match, Team and Players in Football using an Axial Transformer Neural Network",
    "summary": "Football (soccer) is a sport that is characterised by complex game play, where players perform a variety of actions, such as passes, shots, tackles, fouls, in order to score goals, and ultimately win matches. Accurately forecasting the total number of each action that each player will complete during a match is desirable for a variety of applications, including tactical decision-making, sports betting, and for television broadcast commentary and analysis. Such predictions must consider the game state, the ability and skill of the players in both teams, the interactions between the players, and the temporal dynamics of the game as it develops. In this paper, we present a transformer-based neural network that jointly and recurrently predicts the expected totals for thirteen individual actions at multiple time-steps during the match, and where predictions are made for each individual player, each team and at the game-level. The neural network is based on an \\emph{axial transformer} that efficiently captures the temporal dynamics as the game progresses, and the interactions between the players at each time-step. We present a novel axial transformer design that we show is equivalent to a regular sequential transformer, and the design performs well experimentally. We show empirically that the model can make consistent and reliable predictions, and efficiently makes $\\sim$75,000 live predictions at low latency for each game.",
    "published": "2025-11-24T03:47:59Z",
    "updated": "2025-11-24T03:47:59Z",
    "link": "http://arxiv.org/pdf/2511.18730v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Michael Horton",
      "Patrick Lucey"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18728v1",
    "title": "Reinforcement Learning for Self-Healing Material Systems",
    "summary": "The transition to autonomous material systems necessitates adaptive control methodologies to maximize structural longevity. This study frames the self-healing process as a Reinforcement Learning (RL) problem within a Markov Decision Process (MDP), enabling agents to autonomously derive optimal policies that efficiently balance structural integrity maintenance against finite resource consumption. A comparative evaluation of discrete-action (Q-learning, DQN) and continuous-action (TD3) agents in a stochastic simulation environment revealed that RL controllers significantly outperform heuristic baselines, achieving near-complete material recovery. Crucially, the TD3 agent utilizing continuous dosage control demonstrated superior convergence speed and stability, underscoring the necessity of fine-grained, proportional actuation in dynamic self-healing applications.",
    "published": "2025-11-24T03:42:00Z",
    "updated": "2025-11-24T03:42:00Z",
    "link": "http://arxiv.org/pdf/2511.18728v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Maitreyi Chatterjee",
      "Devansh Agarwal",
      "Biplab Chatterjee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18727v1",
    "title": "LogSyn: A Few-Shot LLM Framework for Structured Insight Extraction from Unstructured General Aviation Maintenance Logs",
    "summary": "Aircraft maintenance logs hold valuable safety data but remain underused due to their unstructured text format. This paper introduces LogSyn, a framework that uses Large Language Models (LLMs) to convert these logs into structured, machine-readable data. Using few-shot in-context learning on 6,169 records, LogSyn performs Controlled Abstraction Generation (CAG) to summarize problem-resolution narratives and classify events within a detailed hierarchical ontology. The framework identifies key failure patterns, offering a scalable method for semantic structuring and actionable insight extraction from maintenance logs. This work provides a practical path to improve maintenance workflows and predictive analytics in aviation and related industries.",
    "published": "2025-11-24T03:41:57Z",
    "updated": "2025-11-24T03:41:57Z",
    "link": "http://arxiv.org/pdf/2511.18727v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Devansh Agarwal",
      "Maitreyi Chatterjee",
      "Biplab Chatterjee"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18721v1",
    "title": "Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM",
    "summary": "The SmoothLLM defense provides a certification guarantee against jailbreaking attacks, but it relies on a strict `k-unstable' assumption that rarely holds in practice. This strong assumption can limit the trustworthiness of the provided safety certificate. In this work, we address this limitation by introducing a more realistic probabilistic framework, `(k, $\\varepsilon$)-unstable,' to certify defenses against diverse jailbreaking attacks, from gradient-based (GCG) to semantic (PAIR). We derive a new, data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success, providing a more trustworthy and practical safety certificate. By introducing the notion of (k, $\\varepsilon$)-unstable, our framework provides practitioners with actionable safety guarantees, enabling them to set certification thresholds that better reflect the real-world behavior of LLMs. Ultimately, this work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to the exploitation of their safety alignments, a critical challenge in secure AI deployment.",
    "published": "2025-11-24T03:25:16Z",
    "updated": "2025-11-24T03:25:16Z",
    "link": "http://arxiv.org/pdf/2511.18721v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Adarsh Kumarappan",
      "Ayushi Mehrotra"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18717v1",
    "title": "When and What to Recommend: Joint Modeling of Timing and Content for Active Sequential Recommendation",
    "summary": "Sequential recommendation models user preferences to predict the next target item. Most existing work is passive, where the system responds only when users open the application, missing chances after closure. We investigate active recommendation, which predicts the next interaction time and actively delivers items. Two challenges: accurately estimating the Time of Interest (ToI) and generating Item of Interest (IoI) conditioned on the predicted ToI. We propose PASRec, a diffusion-based framework that aligns ToI and IoI via a joint objective. Experiments on five benchmarks show superiority over eight state-of-the-art baselines under leave-one-out and temporal splits.",
    "published": "2025-11-24T03:16:10Z",
    "updated": "2025-11-24T03:16:10Z",
    "link": "http://arxiv.org/pdf/2511.18717v1.pdf",
    "category": [
      "cs.IR",
      "cs.LG"
    ],
    "authors": [
      "Jin Chai",
      "Xiaoxiao Ma",
      "Jian Yang",
      "Jia Wu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17240v2",
    "title": "A Fast Binary Splitting Approach for Non-Adaptive Learning of Erdős--Rényi Graphs",
    "summary": "We study the problem of learning an unknown graph via group queries on node subsets, where each query reports whether at least one edge is present among the queried nodes. In general, learning arbitrary graphs with $n$ nodes and $k$ edges is hard in the non-adaptive setting, requiring $Ω\\big(\\min\\{k^2\\log n,\\,n^2\\}\\big)$ tests even when a small error probability is allowed. We focus on learning Erdős--Rényi (ER) graphs $G\\sim\\mathrm{ER}(n,q)$ in the non-adaptive setting, where the expected number of edges is $\\bar{k}=q\\binom{n}{2}$, and we aim to design an efficient testing--decoding scheme achieving asymptotically vanishing error probability. Prior work (Li--Fresacher--Scarlett, NeurIPS 2019) presents a testing--decoding scheme that attains an order-optimal number of tests $O(\\bar{k}\\log n)$ but incurs $Ω(n^2)$ decoding time, whereas their proposed sublinear-time algorithm incurs an extra $(\\log \\bar{k})(\\log n)$ factor in the number of tests. We extend the binary splitting approach, recently developed for non-adaptive group testing, to the ER graph learning setting, and prove that the edge set can be recovered with high probability using $O(\\bar{k}\\log n)$ tests while attaining decoding time $O(\\bar{k}^{1+δ}\\log n)$ for any fixed $δ>0$.",
    "published": "2025-11-21T13:34:29Z",
    "updated": "2025-11-24T03:13:19Z",
    "link": "http://arxiv.org/pdf/2511.17240v2.pdf",
    "category": [
      "cs.IT",
      "cs.DM",
      "cs.LG",
      "math.PR"
    ],
    "authors": [
      "Hoang Ta",
      "Jonathan Scarlett"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.05709v2",
    "title": "G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation",
    "summary": "User feedback is critical for refining recommendation systems, yet explicit feedback (e.g., likes or dislikes) remains scarce in practice. As a more feasible alternative, inferring user preferences from massive implicit feedback has shown great potential (e.g., a user quickly skipping a recommended video usually indicates disinterest). Unfortunately, implicit feedback is often noisy: a user might skip a video due to accidental clicks or other reasons, rather than disliking it. Such noise can easily misjudge user interests, thereby undermining recommendation performance. To address this issue, we propose a novel Group-aware User Behavior Simulation (G-UBS) paradigm, which leverages contextual guidance from relevant user groups, enabling robust and in-depth interpretation of implicit feedback for individual users. Specifically, G-UBS operates via two key agents. First, the User Group Manager (UGM) effectively clusters users to generate group profiles utilizing a ``summarize-cluster-reflect\" workflow based on LLMs. Second, the User Feedback Modeler (UFM) employs an innovative group-aware reinforcement learning approach, where each user is guided by the associated group profiles during the reinforcement learning process, allowing UFM to robustly and deeply examine the reasons behind implicit feedback. To assess our G-UBS paradigm, we have constructed a Video Recommendation benchmark with Implicit Feedback (IF-VR). To the best of our knowledge, this is the first multi-modal benchmark for implicit feedback evaluation in video recommendation, encompassing 15k users, 25k videos, and 933k interaction records with implicit feedback. Extensive experiments on IF-VR demonstrate that G-UBS significantly outperforms mainstream LLMs and MLLMs, with a 4.0% higher proportion of videos achieving a play rate > 30% and 14.9% higher reasoning accuracy on IF-VR.",
    "published": "2025-08-07T07:26:08Z",
    "updated": "2025-11-24T02:57:36Z",
    "link": "http://arxiv.org/pdf/2508.05709v2.pdf",
    "category": [
      "cs.IR",
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      "Boyu Chen",
      "Siran Chen",
      "Zhengrong Yue",
      "Kainan Yan",
      "Chenyun Yu",
      "Beibei Kong",
      "Cheng Lei",
      "Chengxiang Zhuo",
      "Zang Li",
      "Yali Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2408.08493v4",
    "title": "Parallel Unlearning in Inherited Model Networks",
    "summary": "Unlearning is challenging in generic learning frameworks with the continuous growth and updates of models exhibiting complex inheritance relationships. This paper presents a novel unlearning framework that enables fully parallel unlearning among models exhibiting inheritance. We use a chronologically Directed Acyclic Graph (DAG) to capture various unlearning scenarios occurring in model inheritance networks. Central to our framework is the Fisher Inheritance Unlearning (FIUn) method, designed to enable efficient parallel unlearning within the DAG. FIUn utilizes the Fisher Information Matrix (FIM) to assess the significance of model parameters for unlearning tasks and adjusts them accordingly. To handle multiple unlearning requests simultaneously, we propose the Merging-FIM (MFIM) function, which consolidates FIMs from multiple upstream models into a unified matrix. This design supports all unlearning scenarios captured by the DAG, enabling one-shot removal of inherited knowledge while significantly reducing computational overhead. Experiments confirm the effectiveness of our unlearning framework. For single-class tasks, it achieves complete unlearning with 0% accuracy for unlearned labels while maintaining 94.53% accuracy for retained labels. For multi-class tasks, the accuracy is 1.07% for unlearned labels and 84.77% for retained labels. Our framework accelerates unlearning by 99% compared to alternative methods. Code is in https://github.com/MJLee00/Parallel-Unlearning-in-Inherited-Model-Networks.",
    "published": "2024-08-16T02:29:38Z",
    "updated": "2025-11-24T02:24:03Z",
    "link": "http://arxiv.org/pdf/2408.08493v4.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Xiao Liu",
      "Mingyuan Li",
      "Guangsheng Yu",
      "Lixiang Li",
      "Haipeng Peng",
      "Ren Ping Liu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18689v1",
    "title": "QuantKAN: A Unified Quantization Framework for Kolmogorov Arnold Networks",
    "summary": "Kolmogorov Arnold Networks (KANs) represent a new class of neural architectures that replace conventional linear transformations and node-based nonlinearities with spline-based function approximations distributed along network edges. Although KANs offer strong expressivity and interpretability, their heterogeneous spline and base branch parameters hinder efficient quantization, which remains unexamined compared to CNNs and Transformers. In this paper, we present QuantKAN, a unified framework for quantizing KANs across both quantization aware training (QAT) and post-training quantization (PTQ) regimes. QuantKAN extends modern quantization algorithms, such as LSQ, LSQ+, PACT, DoReFa, QIL, GPTQ, BRECQ, AdaRound, AWQ, and HAWQ-V2, to spline based layers with branch-specific quantizers for base, spline, and activation components. Through extensive experiments on MNIST, CIFAR 10, and CIFAR 100 across multiple KAN variants (EfficientKAN, FastKAN, PyKAN, and KAGN), we establish the first systematic benchmarks for low-bit spline networks. Our results show that KANs, particularly deeper KAGN variants, are compatible with low-bit quantization but exhibit strong method architecture interactions: LSQ, LSQ+, and PACT preserve near full precision accuracy at 4 bit for shallow KAN MLP and ConvNet models, while DoReFa provides the most stable behavior for deeper KAGN under aggressive low-bit settings. For PTQ, GPTQ and Uniform consistently deliver the strongest overall performance across datasets, with BRECQ highly competitive on simpler regimes such as MNIST. Our proposed QuantKAN framework thus unifies spline learning and quantization, and provides practical tools and guidelines for efficiently deploying KANs in real-world, resource-constrained environments.",
    "published": "2025-11-24T02:05:16Z",
    "updated": "2025-11-24T02:05:16Z",
    "link": "http://arxiv.org/pdf/2511.18689v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kazi Ahmed Asif Fuad",
      "Lizhong Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18671v1",
    "title": "Multi-Agent Cross-Entropy Method with Monotonic Nonlinear Critic Decomposition",
    "summary": "Cooperative multi-agent reinforcement learning (MARL) commonly adopts centralized training with decentralized execution (CTDE), where centralized critics leverage global information to guide decentralized actors. However, centralized-decentralized mismatch (CDM) arises when the suboptimal behavior of one agent degrades others' learning. Prior approaches mitigate CDM through value decomposition, but linear decompositions allow per-agent gradients at the cost of limited expressiveness, while nonlinear decompositions improve representation but require centralized gradients, reintroducing CDM. To overcome this trade-off, we propose the multi-agent cross-entropy method (MCEM), combined with monotonic nonlinear critic decomposition (NCD). MCEM updates policies by increasing the probability of high-value joint actions, thereby excluding suboptimal behaviors. For sample efficiency, we extend off-policy learning with a modified k-step return and Retrace. Analysis and experiments demonstrate that MCEM outperforms state-of-the-art methods across both continuous and discrete action benchmarks.",
    "published": "2025-11-24T01:04:42Z",
    "updated": "2025-11-24T01:04:42Z",
    "link": "http://arxiv.org/pdf/2511.18671v1.pdf",
    "category": [
      "cs.LG",
      "cs.MA"
    ],
    "authors": [
      "Yan Wang",
      "Ke Deng",
      "Yongli Ren"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18667v1",
    "title": "Equivariant Deep Equilibrium Models for Imaging Inverse Problems",
    "summary": "Equivariant imaging (EI) enables training signal reconstruction models without requiring ground truth data by leveraging signal symmetries. Deep equilibrium models (DEQs) are a powerful class of neural networks where the output is a fixed point of a learned operator. However, training DEQs with complex EI losses requires implicit differentiation through fixed-point computations, whose implementation can be challenging. We show that backpropagation can be implemented modularly, simplifying training. Experiments demonstrate that DEQs trained with implicit differentiation outperform those trained with Jacobian-free backpropagation and other baseline methods. Additionally, we find evidence that EI-trained DEQs approximate the proximal map of an invariant prior.",
    "published": "2025-11-24T00:43:54Z",
    "updated": "2025-11-24T00:43:54Z",
    "link": "http://arxiv.org/pdf/2511.18667v1.pdf",
    "category": [
      "eess.IV",
      "cs.LG",
      "eess.SP"
    ],
    "authors": [
      "Alexander Mehta",
      "Ruangrawee Kitichotkul",
      "Vivek K Goyal",
      "Julián Tachella"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.00967v4",
    "title": "Pilot Contamination-Aware Graph Attention Network for Power Control in CFmMIMO",
    "summary": "Optimization-based power control algorithms are predominantly iterative with high computational complexity, making them impractical for real-time applications in cell-free massive multiple-input multiple-output (CFmMIMO) systems. Learning-based methods have emerged as a promising alternative, and among them, graph neural networks (GNNs) have demonstrated their excellent performance in solving power control problems. However, all existing GNN-based approaches assume ideal orthogonality among pilot sequences for user equipments (UEs), which is unrealistic given that the number of UEs exceeds the available orthogonal pilot sequences in CFmMIMO schemes. Moreover, most learning-based methods assume a fixed number of UEs, whereas the number of active UEs varies over time in practice. Additionally, supervised training necessitates costly computational resources for computing the target power control solutions for a large volume of training samples. To address these issues, we propose a graph attention network for downlink power control in CFmMIMO systems that operates in a self-supervised manner while effectively handling pilot contamination and adapting to a dynamic number of UEs. Experimental results show its effectiveness, even in comparison to the optimal accelerated projected gradient method as a baseline.",
    "published": "2025-06-01T11:28:36Z",
    "updated": "2025-11-24T00:28:33Z",
    "link": "http://arxiv.org/pdf/2506.00967v4.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Tingting Zhang",
      "Sergiy A. Vorobyov",
      "David J. Love",
      "Taejoon Kim",
      "Kai Dong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18661v1",
    "title": "Fast Escape, Slow Convergence: Learning Dynamics of Phase Retrieval under Power-Law Data",
    "summary": "Scaling laws describe how learning performance improves with data, compute, or training time, and have become a central theme in modern deep learning. We study this phenomenon in a canonical nonlinear model: phase retrieval with anisotropic Gaussian inputs whose covariance spectrum follows a power law. Unlike the isotropic case, where dynamics collapse to a two-dimensional system, anisotropy yields a qualitatively new regime in which an infinite hierarchy of coupled equations governs the evolution of the summary statistics. We develop a tractable reduction that reveals a three-phase trajectory: (i) fast escape from low alignment, (ii) slow convergence of the summary statistics, and (iii) spectral-tail learning in low-variance directions. From this decomposition, we derive explicit scaling laws for the mean-squared error, showing how spectral decay dictates convergence times and error curves. Experiments confirm the predicted phases and exponents. These results provide the first rigorous characterization of scaling laws in nonlinear regression with anisotropic data, highlighting how anisotropy reshapes learning dynamics.",
    "published": "2025-11-24T00:21:17Z",
    "updated": "2025-11-24T00:21:17Z",
    "link": "http://arxiv.org/pdf/2511.18661v1.pdf",
    "category": [
      "stat.ML",
      "cs.LG"
    ],
    "authors": [
      "Guillaume Braun",
      "Bruno Loureiro",
      "Ha Quang Minh",
      "Masaaki Imaizumi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18660v1",
    "title": "Subtract the Corruption: Training-Data-Free Corrective Machine Unlearning using Task Arithmetic",
    "summary": "Corrupted training data are ubiquitous. Corrective Machine Unlearning (CMU) seeks to remove the influence of such corruption post-training. Prior CMU typically assumes access to identified corrupted training samples (a ``forget set''). However, in many real-world scenarios the training data are no longer accessible. We formalize \\emph{source-free} CMU, where the original training data are unavailable and, consequently, no forget set of identified corrupted training samples can be specified. Instead, we assume a small proxy (surrogate) set of corrupted samples that reflect the suspected corruption type without needing to be the original training samples. In this stricter setting, methods relying on forget set are ineffective or narrow in scope. We introduce \\textit{Corrective Unlearning in Task Space} (CUTS), a lightweight weight space correction method guided by the proxy set using task arithmetic principles. CUTS treats the clean and the corruption signal as distinct tasks. Specifically, we briefly fine-tune the corrupted model on the proxy to amplify the corruption mechanism in the weight space, compute the difference between the corrupted and fine-tuned weights as a proxy task vector, and subtract a calibrated multiple of this vector to cancel the corruption. Without access to clean data or a forget set, CUTS recovers a large fraction of the lost utility under label noise and, for backdoor triggers, nearly eliminates the attack with minimal damage to utility, outperforming state-of-the-art specialized CMU methods in source-free setting.",
    "published": "2025-11-24T00:15:46Z",
    "updated": "2025-11-24T00:15:46Z",
    "link": "http://arxiv.org/pdf/2511.18660v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Mostafa Mozafari",
      "Farooq Ahmad Wani",
      "Maria Sofia Bucarelli",
      "Fabrizio Silvestri"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2501.18617v2",
    "title": "DarkMind: Latent Chain-of-Thought Backdoor in Customized LLMs",
    "summary": "With the rapid rise of personalized AI, customized large language models (LLMs) equipped with Chain of Thought (COT) reasoning now power millions of AI agents. However, their complex reasoning processes introduce new and largely unexplored security vulnerabilities. We present DarkMind, a novel latent reasoning level backdoor attack that targets customized LLMs by manipulating internal COT steps without altering user queries. Unlike prior prompt based attacks, DarkMind activates covertly within the reasoning chain via latent triggers, enabling adversarial behaviors without modifying input prompts or requiring access to model parameters. To achieve stealth and reliability, we propose dual trigger types instant and retrospective and integrate them within a unified embedding template that governs trigger dependent activation, employ a stealth optimization algorithm to minimize semantic drift, and introduce an automated conversation starter for covert activation across domains. Comprehensive experiments on eight reasoning datasets spanning arithmetic, commonsense, and symbolic domains, using five LLMs, demonstrate that DarkMind consistently achieves high attack success rates. We further investigate defense strategies to mitigate these risks and reveal that reasoning level backdoors represent a significant yet underexplored threat, underscoring the need for robust, reasoning aware security mechanisms.",
    "published": "2025-01-24T21:07:32Z",
    "updated": "2025-11-23T23:41:55Z",
    "link": "http://arxiv.org/pdf/2501.18617v2.pdf",
    "category": [
      "cs.CR",
      "cs.LG"
    ],
    "authors": [
      "Zhen Guo",
      "Shanghao Shi",
      "Shamim Yazdani",
      "Ning Zhang",
      "Reza Tourani"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.16917v3",
    "title": "Malliavin Calculus for Score-based Diffusion Models",
    "summary": "We introduce a new framework based on Malliavin calculus to derive exact analytical expressions for the score function $\\nabla \\log p_t(x)$, i.e., the gradient of the log-density associated with the solution to stochastic differential equations (SDEs). Our approach combines classical integration-by-parts techniques with modern stochastic analysis tools, such as Bismut's formula and Malliavin calculus, and it works for both linear and nonlinear SDEs. In doing so, we establish a rigorous connection between the Malliavin derivative, its adjoint, the Malliavin divergence (Skorokhod integral), and diffusion generative models, thereby providing a systematic method for computing $\\nabla \\log p_t(x)$. In the linear case, we present a detailed analysis showing that our formula coincides with the analytical score function derived from the solution of the Fokker--Planck equation. For nonlinear SDEs with state-independent diffusion coefficients, we derive a closed-form expression for $\\nabla \\log p_t(x)$. We evaluate the proposed framework across multiple generative tasks and find that its performance is comparable to state-of-the-art methods. These results can be generalised to broader classes of SDEs, paving the way for new score-based diffusion generative models.",
    "published": "2025-03-21T07:27:10Z",
    "updated": "2025-11-23T23:21:43Z",
    "link": "http://arxiv.org/pdf/2503.16917v3.pdf",
    "category": [
      "cs.LG",
      "math.PR"
    ],
    "authors": [
      "Ehsan Mirafzali",
      "Utkarsh Gupta",
      "Patrick Wyrod",
      "Frank Proske",
      "Daniele Venturi",
      "Razvan Marinescu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18632v1",
    "title": "The Locally Deployable Virtual Doctor: LLM Based Human Interface for Automated Anamnesis and Database Conversion",
    "summary": "Recent advances in large language models made it possible to achieve high conversational performance with substantially reduced computational demands, enabling practical on-site deployment in clinical environments. Such progress allows for local integration of AI systems that uphold strict data protection and patient privacy requirements, yet their secure implementation in medicine necessitates careful consideration of ethical, regulatory, and technical constraints.\n  In this study, we introduce MedChat, a locally deployable virtual physician framework that integrates an LLM-based medical chatbot with a diffusion-driven avatar for automated and structured anamnesis. The chatbot was fine-tuned using a hybrid corpus of real and synthetically generated medical dialogues, while model efficiency was optimized via Low-Rank Adaptation. A secure and isolated database interface was implemented to ensure complete separation between patient data and the inference process. The avatar component was realized through a conditional diffusion model operating in latent space, trained on researcher video datasets and synchronized with mel-frequency audio features for realistic speech and facial animation.\n  Unlike existing cloud-based systems, this work demonstrates the feasibility of a fully offline, locally deployable LLM-diffusion framework for clinical anamnesis. The autoencoder and diffusion networks exhibited smooth convergence, and MedChat achieved stable fine-tuning with strong generalization to unseen data. The proposed system thus provides a privacy-preserving, resource-efficient foundation for AI-assisted clinical anamnesis, also in low-cost settings.",
    "published": "2025-11-23T22:12:35Z",
    "updated": "2025-11-23T22:12:35Z",
    "link": "http://arxiv.org/pdf/2511.18632v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Jan Benedikt Ruhland",
      "Doguhan Bahcivan",
      "Jan-Peter Sowa",
      "Ali Canbay",
      "Dominik Heider"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18631v1",
    "title": "FOS: A Large-Scale Temporal Graph Benchmark for Scientific Interdisciplinary Link Prediction",
    "summary": "Interdisciplinary scientific breakthroughs mostly emerge unexpectedly, and forecasting the formation of novel research fields remains a major challenge. We introduce FOS (Future Of Science), a comprehensive time-aware graph-based benchmark that reconstructs annual co-occurrence graphs of 65,027 research sub-fields (spanning 19 general domains) over the period 1827-2024. In these graphs, edges denote the co-occurrence of two fields in a single publication and are timestamped with the corresponding publication year. Nodes are enriched with semantic embeddings, and edges are characterized by temporal and topological descriptors. We formulate the prediction of new field-pair linkages as a temporal link-prediction task, emphasizing the \"first-time\" connections that signify pioneering interdisciplinary directions. Through extensive experiments, we evaluate a suite of state-of-the-art temporal graph architectures under multiple negative-sampling regimes and show that (i) embedding long-form textual descriptions of fields significantly boosts prediction accuracy, and (ii) distinct model classes excel under different evaluation settings. Case analyses show that top-ranked link predictions on FOS align with field pairings that emerge in subsequent years of academic publications. We publicly release FOS, along with its temporal data splits and evaluation code, to establish a reproducible benchmark for advancing research in predicting scientific frontiers.",
    "published": "2025-11-23T22:08:52Z",
    "updated": "2025-11-23T22:08:52Z",
    "link": "http://arxiv.org/pdf/2511.18631v1.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Kiyan Rezaee",
      "Morteza Ziabakhsh",
      "Niloofar Nikfarjam",
      "Mohammad M. Ghassemi",
      "Yazdan Rezaee Jouryabi",
      "Sadegh Eskandari",
      "Reza Lashgari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2510.11839v2",
    "title": "WaveletDiff: Multilevel Wavelet Diffusion For Time Series Generation",
    "summary": "Time series are ubiquitous in many applications that involve forecasting, classification and causal inference tasks, such as healthcare, finance, audio signal processing and climate sciences. Still, large, high-quality time series datasets remain scarce. Synthetic generation can address this limitation; however, current models confined either to the time or frequency domains struggle to reproduce the inherently multi-scaled structure of real-world time series. We introduce WaveletDiff, a novel framework that trains diffusion models directly on wavelet coefficients to exploit the inherent multi-resolution structure of time series data. The model combines dedicated transformers for each decomposition level with cross-level attention mechanisms that enable selective information exchange between temporal and frequency scales through adaptive gating. It also incorporates energy preservation constraints for individual levels based on Parseval's theorem to preserve spectral fidelity throughout the diffusion process. Comprehensive tests across six real-world datasets from energy, finance, and neuroscience domains demonstrate that WaveletDiff consistently outperforms state-of-the-art time-domain and frequency-domain generative methods on both short and long time series across five diverse performance metrics. For example, WaveletDiff achieves discriminative scores and Context-FID scores that are $3\\times$ smaller on average than the second-best baseline across all datasets.",
    "published": "2025-10-13T18:47:33Z",
    "updated": "2025-11-23T21:50:00Z",
    "link": "http://arxiv.org/pdf/2510.11839v2.pdf",
    "category": [
      "cs.LG"
    ],
    "authors": [
      "Yu-Hsiang Wang",
      "Olgica Milenkovic"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18615v1",
    "title": "Bayesian-based Online Label Shift Estimation with Dynamic Dirichlet Priors",
    "summary": "Label shift, a prevalent challenge in supervised learning, arises when the class prior distribution of test data differs from that of training data, leading to significant degradation in classifier performance. To accurately estimate the test priors and enhance classification accuracy, we propose a Bayesian framework for label shift estimation, termed Full Maximum A Posterior Label Shift (FMAPLS), along with its online version, online-FMAPLS. Leveraging batch and online Expectation-Maximization (EM) algorithms, these methods jointly and dynamically optimize Dirichlet hyperparameters $\\boldsymbolα$ and class priors $\\boldsymbolπ$, thereby overcoming the rigid constraints of the existing Maximum A Posterior Label Shift (MAPLS) approach. Moreover, we introduce a linear surrogate function (LSF) to replace gradient-based hyperparameter updates, yielding closed-form solutions that reduce computational complexity while retaining asymptotic equivalence. The online variant substitutes the batch E-step with a stochastic approximation, enabling real-time adaptation to streaming data. Furthermore, our theoretical analysis reveals a fundamental trade-off between online convergence rate and estimation accuracy. Extensive experiments on CIFAR100 and ImageNet datasets under shuffled long-tail and Dirichlet test priors demonstrate that FMAPLS and online-FMAPLS respectively achieve up to 40% and 12% lower KL divergence and substantial improvements in post-shift accuracy over state-of-the-art baselines, particularly under severe class imbalance and distributional uncertainty. These results confirm the robustness, scalability, and suitability of the proposed methods for large-scale and dynamic learning scenarios.",
    "published": "2025-11-23T21:10:49Z",
    "updated": "2025-11-23T21:10:49Z",
    "link": "http://arxiv.org/pdf/2511.18615v1.pdf",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "authors": [
      "Jiawei Hu",
      "Javier A. Barria"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2503.16737v4",
    "title": "Revenue Maximization Under Sequential Price Competition Via The Estimation Of s-Concave Demand Functions",
    "summary": "We consider price competition among multiple sellers over a selling horizon of $T$ periods. In each period, sellers simultaneously offer their prices (which are made public) and subsequently observe their respective demand (not made public). The demand function of each seller depends on all sellers' prices through a private, unknown, and nonlinear relationship. We propose a dynamic pricing policy that uses semi-parametric least-squares estimation and show that when the sellers employ our policy, their prices converge at a rate of $O(T^{-1/7})$ to the Nash equilibrium prices that sellers would reach if they were fully informed. Each seller incurs a regret of $O(T^{5/7})$ relative to a dynamic benchmark policy. A theoretical contribution of our work is proving the existence of equilibrium under shape-constrained demand functions via the concept of $s$-concavity and establishing regret bounds of our proposed policy. Technically, we also establish new concentration results for the least squares estimator under shape constraints. Our findings offer significant insights into dynamic competition-aware pricing and contribute to the broader study of non-parametric learning in strategic decision-making.",
    "published": "2025-03-20T22:51:03Z",
    "updated": "2025-11-23T21:08:16Z",
    "link": "http://arxiv.org/pdf/2503.16737v4.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.PR",
      "math.ST"
    ],
    "authors": [
      "Daniele Bracale",
      "Moulinath Banerjee",
      "Cong Shi",
      "Yuekai Sun"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18611v1",
    "title": "CycleSL: Server-Client Cyclical Update Driven Scalable Split Learning",
    "summary": "Split learning emerges as a promising paradigm for collaborative distributed model training, akin to federated learning, by partitioning neural networks between clients and a server without raw data exchange. However, sequential split learning suffers from poor scalability, while parallel variants like parallel split learning and split federated learning often incur high server resource overhead due to model duplication and aggregation, and generally exhibit reduced model performance and convergence owing to factors like client drift and lag. To address these limitations, we introduce CycleSL, a novel aggregation-free split learning framework that enhances scalability and performance and can be seamlessly integrated with existing methods. Inspired by alternating block coordinate descent, CycleSL treats server-side training as an independent higher-level machine learning task, resampling client-extracted features (smashed data) to mitigate heterogeneity and drift. It then performs cyclical updates, namely optimizing the server model first, followed by client updates using the updated server for gradient computation. We integrate CycleSL into previous algorithms and benchmark them on five publicly available datasets with non-iid data distribution and partial client attendance. Our empirical findings highlight the effectiveness of CycleSL in enhancing model performance. Our source code is available at https://gitlab.lrz.de/hctl/CycleSL.",
    "published": "2025-11-23T21:00:21Z",
    "updated": "2025-11-23T21:00:21Z",
    "link": "http://arxiv.org/pdf/2511.18611v1.pdf",
    "category": [
      "cs.LG",
      "cs.DC"
    ],
    "authors": [
      "Mengdi Wang",
      "Efe Bozkir",
      "Enkelejda Kasneci"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18606v1",
    "title": "How to Train Your Latent Control Barrier Function: Smooth Safety Filtering Under Hard-to-Model Constraints",
    "summary": "Latent safety filters extend Hamilton-Jacobi (HJ) reachability to operate on latent state representations and dynamics learned directly from high-dimensional observations, enabling safe visuomotor control under hard-to-model constraints. However, existing methods implement \"least-restrictive\" filtering that discretely switch between nominal and safety policies, potentially undermining the task performance that makes modern visuomotor policies valuable. While reachability value functions can, in principle, be adapted to be control barrier functions (CBFs) for smooth optimization-based filtering, we theoretically and empirically show that current latent-space learning methods produce fundamentally incompatible value functions. We identify two sources of incompatibility: First, in HJ reachability, failures are encoded via a \"margin function\" in latent space, whose sign indicates whether or not a latent is in the constraint set. However, representing the margin function as a classifier yields saturated value functions that exhibit discontinuous jumps. We prove that the value function's Lipschitz constant scales linearly with the margin function's Lipschitz constant, revealing that smooth CBFs require smooth margins. Second, reinforcement learning (RL) approximations trained solely on safety policy data yield inaccurate value estimates for nominal policy actions, precisely where CBF filtering needs them. We propose the LatentCBF, which addresses both challenges through gradient penalties that lead to smooth margin functions without additional labeling, and a value-training procedure that mixes data from both nominal and safety policy distributions. Experiments on simulated benchmarks and hardware with a vision-based manipulation policy demonstrate that LatentCBF enables smooth safety filtering while doubling the task-completion rate over prior switching methods.",
    "published": "2025-11-23T20:15:28Z",
    "updated": "2025-11-23T20:15:28Z",
    "link": "http://arxiv.org/pdf/2511.18606v1.pdf",
    "category": [
      "cs.RO",
      "cs.LG"
    ],
    "authors": [
      "Kensuke Nakamura",
      "Arun L. Bishop",
      "Steven Man",
      "Aaron M. Johnson",
      "Zachary Manchester",
      "Andrea Bajcsy"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.08735v2",
    "title": "A Deep Learning-Based Method for Fully Coupled Non-Markovian FBSDEs with Applications",
    "summary": "In this work, we extend deep learning-based numerical methods to fully coupled forward-backward stochastic differential equations (FBSDEs) within a non-Markovian framework. Error estimates and convergence are provided. In contrast to the existing literature, our approach not only analyzes the non-Markovian framework but also addresses fully coupled settings, in which both the drift and diffusion coefficients of the forward process may be random and depend on the backward components $Y$ and $Z$. Furthermore, we illustrate the practical applicability of our framework by addressing utility maximization problems under rough volatility, which are solved numerically with the proposed deep learning-based methods.",
    "published": "2025-11-11T19:50:21Z",
    "updated": "2025-11-23T19:28:39Z",
    "link": "http://arxiv.org/pdf/2511.08735v2.pdf",
    "category": [
      "q-fin.MF",
      "cs.LG"
    ],
    "authors": [
      "Hasib Uddin Molla",
      "Matthew Backhouse",
      "Ankit Banarjee",
      "Jinniao Qiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18594v1",
    "title": "Autoencoder for Position-Assisted Beam Prediction in mmWave ISAC Systems",
    "summary": "Integrated sensing and communication and millimeter wave (mmWave) have emerged as pivotal technologies for 6G networks. However, the narrow nature of mmWave beams requires precise alignments that typically necessitate large training overhead. This overhead can be reduced by incorporating the position information with beam adjustments. This letter proposes a lightweight autorencoder (LAE) model that addresses the position-assisted beam prediction problem while significantly reducing computational complexity compared to the conventional baseline method, i.e., deep fully connected neural network. The proposed LAE is designed as a three-layer undercomplete network to exploit its dimensionality reduction capabilities and thereby mitigate the computational requirements of the trained model. Simulation results show that the proposed model achieves a similar beam prediction accuracy to the baseline with an 83% complexity reduction.",
    "published": "2025-11-23T19:27:29Z",
    "updated": "2025-11-23T19:27:29Z",
    "link": "http://arxiv.org/pdf/2511.18594v1.pdf",
    "category": [
      "eess.SP",
      "cs.LG"
    ],
    "authors": [
      "Ahmad A. Aziz El-Banna",
      "Octavia A. Dobre"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18593v1",
    "title": "Generative Myopia: Why Diffusion Models Fail at Structure",
    "summary": "Graph Diffusion Models (GDMs) optimize for statistical likelihood, implicitly acting as \\textbf{frequency filters} that favor abundant substructures over spectrally critical ones. We term this phenomenon \\textbf{Generative Myopia}. In combinatorial tasks like graph sparsification, this leads to the catastrophic removal of ``rare bridges,'' edges that are structurally mandatory ($R_{\\text{eff}} \\approx 1$) but statistically scarce. We prove theoretically and empirically that this failure is driven by \\textbf{Gradient Starvation}: the optimization landscape itself suppresses rare structural signals, rendering them unlearnable regardless of model capacity. To resolve this, we introduce \\textbf{Spectrally-Weighted Diffusion}, which re-aligns the variational objective using Effective Resistance. We demonstrate that spectral priors can be amortized into the training phase with zero inference overhead. Our method eliminates myopia, matching the performance of an optimal Spectral Oracle and achieving \\textbf{100\\% connectivity} on adversarial benchmarks where standard diffusion fails completely (0\\%).",
    "published": "2025-11-23T19:27:13Z",
    "updated": "2025-11-23T19:27:13Z",
    "link": "http://arxiv.org/pdf/2511.18593v1.pdf",
    "category": [
      "cs.LG",
      "eess.SY",
      "math.SP"
    ],
    "authors": [
      "Milad Siami"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18590v1",
    "title": "From Simulations to Surveys: Domain Adaptation for Galaxy Observations",
    "summary": "Large photometric surveys will image billions of galaxies, but we currently lack quick, reliable automated ways to infer their physical properties like morphology, stellar mass, and star formation rates. Simulations provide galaxy images with ground-truth physical labels, but domain shifts in PSF, noise, backgrounds, selection, and label priors degrade transfer to real surveys. We present a preliminary domain adaptation pipeline that trains on simulated TNG50 galaxies and evaluates on real SDSS galaxies with morphology labels (elliptical/spiral/irregular). We train three backbones (CNN, $E(2)$-steerable CNN, ResNet-18) with focal loss and effective-number class weighting, and a feature-level domain loss $L_D$ built from GeomLoss (entropic Sinkhorn OT, energy distance, Gaussian MMD, and related metrics). We show that a combination of these losses with an OT-based \"top_$k$ soft matching\" loss that focuses $L_D$ on the worst-matched source-target pairs can further enhance domain alignment. With Euclidean distance, scheduled alignment weights, and top-$k$ matching, target accuracy (macro F1) rises from $\\sim$46% ($\\sim$30%) at no adaptation to $\\sim$87% ($\\sim$62.6%), with a domain AUC near 0.5, indicating strong latent-space mixing.",
    "published": "2025-11-23T19:08:40Z",
    "updated": "2025-11-23T19:08:40Z",
    "link": "http://arxiv.org/pdf/2511.18590v1.pdf",
    "category": [
      "astro-ph.GA",
      "cs.LG"
    ],
    "authors": [
      "Kaley Brauer",
      "Aditya Prasad Dash",
      "Meet J. Vyas",
      "Ahmed Salim",
      "Stiven Briand Massala"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.20124v3",
    "title": "A Geometric Unification of Distributionally Robust Covariance Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set",
    "summary": "The state-of-the-art methods for estimating high-dimensional covariance matrices all shrink the eigenvalues of the sample covariance matrix towards a data-insensitive shrinkage target. The underlying shrinkage transformation is either chosen heuristically - without compelling theoretical justification - or optimally in view of restrictive distributional assumptions. In this paper, we propose a principled approach to construct covariance estimators without imposing restrictive assumptions. That is, we study distributionally robust covariance estimation problems that minimize the worst-case Frobenius error with respect to all data distributions close to a nominal distribution, where the proximity of distributions is measured via a divergence on the space of covariance matrices. We identify mild conditions on this divergence under which the resulting minimizers represent shrinkage estimators. We show that the corresponding shrinkage transformations are intimately related to the geometrical properties of the underlying divergence. We also prove that our robust estimators are efficiently computable and asymptotically consistent and that they enjoy finite-sample performance guarantees. We exemplify our general methodology by synthesizing explicit estimators induced by the Kullback-Leibler, Fisher-Rao, and Wasserstein divergences. Numerical experiments based on synthetic and real data show that our robust estimators are competitive with state-of-the-art estimators.",
    "published": "2024-05-30T15:01:18Z",
    "updated": "2025-11-23T19:03:23Z",
    "link": "http://arxiv.org/pdf/2405.20124v3.pdf",
    "category": [
      "stat.ML",
      "cs.LG",
      "math.OC"
    ],
    "authors": [
      "Man-Chung Yue",
      "Yves Rychener",
      "Daniel Kuhn",
      "Viet Anh Nguyen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18700v1",
    "title": "When Top-ranked Recommendations Fail: Modeling Multi-Granular Negative Feedback for Explainable and Robust Video Recommendation",
    "summary": "Existing video recommendation systems, relying mainly on ID-based embedding mapping and collaborative filtering, often fail to capture in-depth video content semantics. Moreover, most struggle to address biased user behaviors (e.g., accidental clicks, fast skips), leading to inaccurate interest modeling and frequent negative feedback in top recommendations with unclear causes. To tackle this issue, we collect real-world user video-watching sequences, annotate the reasons for users' dislikes, and construct a benchmark dataset for personalized explanations. We then introduce the Agentic Explainable Negative Feedback (ENF) framework, which integrates three core components: (1) the Profile Agent, extracting behavioral cues from users' historical data to derive psychological and personality profiles; (2) the Video Agent, performing comprehensive multimodal video analysis; and (3) the Reason Agent, synthesizing information from the other two agents to predict user engagement and generate explanations. Additionally, we propose the S-GRPO algorithm, enabling the model to progressively address complex tasks during reinforcement fine-tuning. Experimental results on the collected dataset show that our method significantly outperforms state-of-the-art baselines in negative feedback prediction and reason explanation. Notably, it achieves an 8.6% improvement over GPT-4o in reason classification. Deployment on the business platform further validates its benefits: increasing average user watch time by 6.2%, reducing the fast-skip rate by 9.4%, and significantly enhancing user satisfaction.",
    "published": "2025-11-24T02:44:51Z",
    "updated": "2025-11-24T02:44:51Z",
    "link": "http://arxiv.org/pdf/2511.18700v1.pdf",
    "category": [
      "cs.MM"
    ],
    "authors": [
      "Siran Chen",
      "Boyu Chen",
      "Chenyun Yu",
      "Yi Ouyang",
      "Cheng Lei",
      "Chengxiang Zhuo",
      "Zang Li",
      "Yali Wang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18686v1",
    "title": "Evaluation of Hardware-based Video Encoders on Modern GPUs for UHD Live-Streaming",
    "summary": "Many GPUs have incorporated hardware-accelerated video encoders, which allow video encoding tasks to be offloaded from the main CPU and provide higher power efficiency. Over the years, many new video codecs such as H.265/HEVC, VP9, and AV1 were added to the latest GPU boards. Recently, the rise of live video content such as VTuber, game live-streaming, and live event broadcasts, drives the demand for high-efficiency hardware encoders in the GPUs to tackle these real-time video encoding tasks, especially at higher resolutions such as 4K/8K UHD. In this paper, RD performance, encoding speed, as well as power consumption of hardware encoders in several generations of NVIDIA, Intel GPUs as well as Qualcomm Snapdragon Mobile SoCs were evaluated and compared to the software counterparts, including the latest H.266/VVC codec, using several metrics including PSNR, SSIM, and machine-learning based VMAF. The results show that modern GPU hardware encoders can match the RD performance of software encoders in real-time encoding scenarios, and while encoding speed increased in newer hardware, there is mostly negligible RD performance improvement between hardware generations. Finally, the bitrate required for each hardware encoder to match YouTube transcoding quality was also calculated.",
    "published": "2025-11-24T02:04:18Z",
    "updated": "2025-11-24T02:04:18Z",
    "link": "http://arxiv.org/pdf/2511.18686v1.pdf",
    "category": [
      "eess.IV",
      "cs.AR",
      "cs.MM"
    ],
    "authors": [
      "Kasidis Arunruangsirilert",
      "Jiro Katto"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19189v1",
    "title": "AvatarBrush: Monocular Reconstruction of Gaussian Avatars with Intuitive Local Editing",
    "summary": "The efficient reconstruction of high-quality and intuitively editable human avatars presents a pressing challenge in the field of computer vision. Recent advancements, such as 3DGS, have demonstrated impressive reconstruction efficiency and rapid rendering speeds. However, intuitive local editing of these representations remains a significant challenge. In this work, we propose AvatarBrush, a framework that reconstructs fully animatable and locally editable avatars using only a monocular video input. We propose a three-layer model to represent the avatar and, inspired by mesh morphing techniques, design a framework to generate the Gaussian model from local information of the parametric body model. Compared to previous methods that require scanned meshes or multi-view captures as input, our approach reduces costs and enhances editing capabilities such as body shape adjustment, local texture modification, and geometry transfer. Our experimental results demonstrate superior quality across two datasets and emphasize the enhanced, user-friendly, and localized editing capabilities of our method.",
    "published": "2025-11-24T14:58:11Z",
    "updated": "2025-11-24T14:58:11Z",
    "link": "http://arxiv.org/pdf/2511.19189v1.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Mengtian Li",
      "Shengxiang Yao",
      "Yichen Pan",
      "Haiyao Xiao",
      "Zhongmei Li",
      "Zhifeng Xie",
      "Keyu Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2105.01610v4",
    "title": "Reliving the Dataset: Combining the Visualization of Road Users' Interactions with Scenario Reconstruction in Virtual Reality",
    "summary": "One core challenge in the development of automated vehicles is their capability to deal with a multitude of complex trafficscenarios with many, hard to predict traffic participants. As part of the iterative development process, it is necessary to detect criticalscenarios and generate knowledge from them to improve the highly automated driving (HAD) function. In order to tackle this challenge,numerous datasets have been released in the past years, which act as the basis for the development and testing of such algorithms.Nevertheless, the remaining challenges are to find relevant scenes, such as safety-critical corner cases, in these datasets and tounderstand them completely.Therefore, this paper presents a methodology to process and analyze naturalistic motion datasets in two ways: On the one hand, ourapproach maps scenes of the datasets to a generic semantic scene graph which allows for a high-level and objective analysis. Here,arbitrary criticality measures, e.g. TTC, RSS or SFF, can be set to automatically detect critical scenarios between traffic participants.On the other hand, the scenarios are recreated in a realistic virtual reality (VR) environment, which allows for a subjective close-upanalysis from multiple, interactive perspectives.",
    "published": "2021-05-04T16:39:06Z",
    "updated": "2025-11-24T08:02:45Z",
    "link": "http://arxiv.org/pdf/2105.01610v4.pdf",
    "category": [
      "cs.GR"
    ],
    "authors": [
      "Lars Töttel",
      "Maximilian Zipfl",
      "Daniel Bogdoll",
      "Marc René Zofka",
      "J. Marius Zöllner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19377v1",
    "title": "Deployment Dynamics and Optimization of Novel Space Antenna Deployable Mechanism",
    "summary": "Given the increasing need for large aperture antennas in space missions, the difficulty of fitting such structures into small launch vehicles has prompted the design of deployable antenna systems. The thesis introduces a new Triple Scissors Deployable Truss Mechanism (TSDTM) for space antenna missions. The new mechanism is to be stowed during launch and efficiently deploy in orbit, offering maximum aperture size while taking up minimal launch volume. The thesis covers the entire design process from geometric modeling, kinematic analysis with screw theory and Newtonian approaches, dynamic analysis by eigenvalue and simulation methods, and verification with SolidWorks. In addition, optimization routines were coded based on Support Vector Machines for material choice in LEO environments and machine learning method for geometric setup. The TSDTM presented has enhanced structural dynamics with good comparison between simulation and analytical predictions. The structure optimized proved highly accurate, with a deviation of just 1.94% between machine learning-predicted and simulated natural frequencies, demonstrating the potential of incorporating AI-based methods in space structural design.",
    "published": "2025-11-24T18:17:28Z",
    "updated": "2025-11-24T18:17:28Z",
    "link": "http://arxiv.org/pdf/2511.19377v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Mamoon Aamir",
      "Mariyam Sattar",
      "Naveed Ur Rehman Junejo",
      "Aqsa Zafar Abbasi"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2410.02595v2",
    "title": "Extremum Seeking Controlled Wiggling for Tactile Insertion",
    "summary": "When humans perform complex insertion tasks such as pushing a cup into a cupboard, routing a cable, or putting a key in a lock, they wiggle the object and adapt the process through tactile feedback. A similar robotic approach has not been developed. We study an extremum seeking control law that wiggles end effector pose to maximize insertion depth while minimizing strain measured by a GelSight Mini sensor. Evaluation is conducted on four keys featuring complex geometry and five assembly tasks featuring basic geometry.\n  On keys, the algorithm achieves 71% success rate over 120 trials with 6-DOF perturbations, 84% over 240 trials with 1-DOF perturbations, and 75% over 40 trials initialized with vision. It significantly outperforms a baseline optimizer, CMA-ES, that replaces wiggling with random sampling. When tested on a state-of-the-art assembly benchmark featuring basic geometry, it achieves 98% over 50 vision-initialized trials. The benchmark's most similar baseline, which was trained on the objects, achieved 86%. These results, realized without contact modeling or learning, show that closed loop wiggling based on tactile feedback is a robust paradigm for robotic insertion.",
    "published": "2024-10-03T15:37:11Z",
    "updated": "2025-11-24T17:18:18Z",
    "link": "http://arxiv.org/pdf/2410.02595v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Levi Burner",
      "Pavan Mantripragada",
      "Gabriele M. Caddeo",
      "Lorenzo Natale",
      "Cornelia Fermüller",
      "Yiannis Aloimonos"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19315v1",
    "title": "Rethinking Intermediate Representation for VLM-based Robot Manipulation",
    "summary": "Vision-Language Model (VLM) is an important component to enable robust robot manipulation. Yet, using it to translate human instructions into an action-resolvable intermediate representation often needs a tradeoff between VLM-comprehensibility and generalizability. Inspired by context-free grammar, we design the Semantic Assembly representation named SEAM, by decomposing the intermediate representation into vocabulary and grammar. Doing so leads us to a concise vocabulary of semantically-rich operations and a VLM-friendly grammar for handling diverse unseen tasks. In addition, we design a new open-vocabulary segmentation paradigm with a retrieval-augmented few-shot learning strategy to localize fine-grained object parts for manipulation, effectively with the shortest inference time over all state-of-the-art parallel works. Also, we formulate new metrics for action-generalizability and VLM-comprehensibility, demonstrating the compelling performance of SEAM over mainstream representations on both aspects. Extensive real-world experiments further manifest its SOTA performance under varying settings and tasks.",
    "published": "2025-11-24T17:09:50Z",
    "updated": "2025-11-24T17:09:50Z",
    "link": "http://arxiv.org/pdf/2511.19315v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Weiliang Tang",
      "Jialin Gao",
      "Jia-Hui Pan",
      "Gang Wang",
      "Li Erran Li",
      "Yunhui Liu",
      "Mingyu Ding",
      "Pheng-Ann Heng",
      "Chi-Wing Fu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19211v1",
    "title": "Soft pneumatic grippers: Topology optimization, 3D-printing and experimental validation",
    "summary": "This paper presents a systematic topology optimization framework for designing a soft pneumatic gripper (SPG), explicitly considering the design-dependent nature of the actuating load. The load is modeled using Darcy's law with an added drainage term. A 2D soft arm unit is optimized by formulating it as a compliant mechanism design problem using the robust formulation. The problem is posed as a min-max optimization, where the output deformations of blueprint and eroded designs are considered. A volume constraint is imposed on the blueprint part, while a strain-energy constraint is enforced on the eroded part. The MMA is employed to solve the optimization problem and obtain the optimized soft unit. Finite element analysis with the Ogden material model confirms that the optimized 2D unit outperforms a conventional rectangular design under pneumatic loading. The optimized 2D unit is extruded to obtain a 3D module, and ten such units are assembled to create a soft arm. Deformation profiles of the optimized arm are analysed under different pressure loads. Four arms are 3D-printed and integrated with a supporting structure to realize the proposed SPG. The gripping performance of the SPG is demonstrated on objects with different weights, sizes, stiffness, and shapes.",
    "published": "2025-11-24T15:19:47Z",
    "updated": "2025-11-24T15:19:47Z",
    "link": "http://arxiv.org/pdf/2511.19211v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Prabhat Kumar",
      "Chandra Prakash",
      "Josh Pinskier",
      "David Howard",
      "Matthijs Langelaar"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19204v1",
    "title": "Reference-Free Sampling-Based Model Predictive Control",
    "summary": "We present a sampling-based model predictive control (MPC) framework that enables emergent locomotion without relying on handcrafted gait patterns or predefined contact sequences. Our method discovers diverse motion patterns, ranging from trotting to galloping, robust standing policies, jumping, and handstand balancing, purely through the optimization of high-level objectives. Building on model predictive path integral (MPPI), we propose a dual-space spline parameterization that operates on position and velocity control points. Our approach enables contact-making and contact-breaking strategies that adapt automatically to task requirements, requiring only a limited number of sampled trajectories. This sample efficiency allows us to achieve real-time control on standard CPU hardware, eliminating the need for GPU acceleration typically required by other state-of-the-art MPPI methods. We validate our approach on the Go2 quadrupedal robot, demonstrating various emergent gaits and basic jumping capabilities. In simulation, we further showcase more complex behaviors, such as backflips, dynamic handstand balancing and locomotion on a Humanoid, all without requiring reference tracking or offline pre-training.",
    "published": "2025-11-24T15:15:01Z",
    "updated": "2025-11-24T15:15:01Z",
    "link": "http://arxiv.org/pdf/2511.19204v1.pdf",
    "category": [
      "cs.RO",
      "eess.SY"
    ],
    "authors": [
      "Fabian Schramm",
      "Pierre Fabre",
      "Nicolas Perrin-Gilbert",
      "Justin Carpentier"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19201v1",
    "title": "Efficient Optimization of a Permanent Magnet Array for a Stable 2D Trap",
    "summary": "Untethered magnetic manipulation of biomedical millirobots has a high potential for minimally invasive surgical applications. However, it is still challenging to exert high actuation forces on the small robots over a large distance. Permanent magnets offer stronger magnetic torques and forces than electromagnetic coils, however, feedback control is more difficult. As proven by Earnshaw's theorem, it is not possible to achieve a stable magnetic trap in 3D by static permanent magnets. Here, we report a stable 2D magnetic force trap by an array of permanent magnets to control a millirobot. The trap is located in an open space with a tunable distance to the magnet array in the range of 20 - 120mm, which is relevant to human anatomical scales. The design is achieved by a novel GPU-accelerated optimization algorithm that uses mean squared error (MSE) and Adam optimizer to efficiently compute the optimal angles for any number of magnets in the array. The algorithm is verified using numerical simulation and physical experiments with an array of two magnets. A millirobot is successfully trapped and controlled to follow a complex trajectory. The algorithm demonstrates high scalability by optimizing the angles for 100 magnets in under three seconds. Moreover, the optimization workflow can be adapted to optimize a permanent magnet array to achieve the desired force vector fields.",
    "published": "2025-11-24T15:09:41Z",
    "updated": "2025-11-24T15:09:41Z",
    "link": "http://arxiv.org/pdf/2511.19201v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ann-Sophia Müller",
      "Moonkwang Jeong",
      "Jiyuan Tian",
      "Meng Zhang",
      "Tian Qiu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19135v1",
    "title": "Autonomous Docking of Multi-Rotor UAVs on Blimps under the Influence of Wind Gusts",
    "summary": "Multi-rotor UAVs face limited flight time due to battery constraints. Autonomous docking on blimps with onboard battery recharging and data offloading offers a promising solution for extended UAV missions. However, the vulnerability of blimps to wind gusts causes trajectory deviations, requiring precise, obstacle-aware docking strategies. To this end, this work introduces two key novelties: (i) a temporal convolutional network that predicts blimp responses to wind gusts, enabling rapid gust detection and estimation of points where the wind gust effect has subsided; (ii) a model predictive controller (MPC) that leverages these predictions to compute collision-free trajectories for docking, enabled by a novel obstacle avoidance method for close-range manoeuvres near the blimp. Simulation results show our method outperforms a baseline constant-velocity model of the blimp significantly across different scenarios. We further validate the approach in real-world experiments, demonstrating the first autonomous multi-rotor docking control strategy on blimps shown outside simulation. Source code is available here https://github.com/robot-perception-group/multi_rotor_airship_docking.",
    "published": "2025-11-24T13:59:31Z",
    "updated": "2025-11-24T13:59:31Z",
    "link": "http://arxiv.org/pdf/2511.19135v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Pascal Goldschmid",
      "Aamir Ahmad"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19094v1",
    "title": "Analysis of Deep-Learning Methods in an ISO/TS 15066-Compliant Human-Robot Safety Framework",
    "summary": "Over the last years collaborative robots have gained great success in manufacturing applications where human and robot work together in close proximity. However, current ISO/TS-15066-compliant implementations often limit the efficiency of collaborative tasks due to conservative speed restrictions. For this reason, this paper introduces a deep-learning-based human-robot-safety framework (HRSF) that aims at a dynamical adaptation of robot velocities depending on the separation distance between human and robot while respecting maximum biomechanical force and pressure limits. The applicability of the framework was investigated for four different deep learning approaches that can be used for human body extraction: human body recognition, human body segmentation, human pose estimation, and human body part segmentation. Unlike conventional industrial safety systems, the proposed HRSF differentiates individual human body parts from other objects, enabling optimized robot process execution. Experiments demonstrated a quantitative reduction in cycle time of up to 15% compared to conventional safety technology.",
    "published": "2025-11-24T13:33:23Z",
    "updated": "2025-11-24T13:33:23Z",
    "link": "http://arxiv.org/pdf/2511.19094v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "David Bricher",
      "Andreas Mueller"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19031v1",
    "title": "Multi-Agent Monocular Dense SLAM With 3D Reconstruction Priors",
    "summary": "Monocular Simultaneous Localization and Mapping (SLAM) aims to estimate a robot's pose while simultaneously reconstructing an unknown 3D scene using a single camera. While existing monocular SLAM systems generate detailed 3D geometry through dense scene representations, they are computationally expensive due to the need for iterative optimization. To address this challenge, MASt3R-SLAM utilizes learned 3D reconstruction priors, enabling more efficient and accurate estimation of both 3D structures and camera poses. However, MASt3R-SLAM is limited to single-agent operation. In this paper, we extend MASt3R-SLAM to introduce the first multi-agent monocular dense SLAM system. Each agent performs local SLAM using a 3D reconstruction prior, and their individual maps are fused into a globally consistent map through a loop-closure-based map fusion mechanism. Our approach improves computational efficiency compared to state-of-the-art methods, while maintaining similar mapping accuracy when evaluated on real-world datasets.",
    "published": "2025-11-24T12:05:13Z",
    "updated": "2025-11-24T12:05:13Z",
    "link": "http://arxiv.org/pdf/2511.19031v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Haihang Wu",
      "Yuchen Zhou"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.19011v1",
    "title": "End-to-end Autonomous Vehicle Following System using Monocular Fisheye Camera",
    "summary": "The increase in vehicle ownership has led to increased traffic congestion, more accidents, and higher carbon emissions. Vehicle platooning is a promising solution to address these issues by improving road capacity and reducing fuel consumption. However, existing platooning systems face challenges such as reliance on lane markings and expensive high-precision sensors, which limits their general applicability. To address these issues, we propose a vehicle following framework that expands its capability from restricted scenarios to general scenario applications using only a camera. This is achieved through our newly proposed end-to-end method, which improves overall driving performance. The method incorporates a semantic mask to address causal confusion in multi-frame data fusion. Additionally, we introduce a dynamic sampling mechanism to precisely track the trajectories of preceding vehicles. Extensive closed-loop validation in real-world vehicle experiments demonstrates the system's ability to follow vehicles in various scenarios, outperforming traditional multi-stage algorithms. This makes it a promising solution for cost-effective autonomous vehicle platooning. A complete real-world vehicle experiment is available at https://youtu.be/zL1bcVb9kqQ.",
    "published": "2025-11-24T11:40:24Z",
    "updated": "2025-11-24T11:40:24Z",
    "link": "http://arxiv.org/pdf/2511.19011v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jiale Zhang",
      "Yeqiang Qian",
      "Tong Qin",
      "Mingyang Jiang",
      "Siyuan Chen",
      "Ming Yang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17373v2",
    "title": "Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data",
    "summary": "Humanoid robots are envisioned to perform a wide range of tasks in human-centered environments, requiring controllers that combine agility with robust balance. Recent advances in locomotion and whole-body tracking have enabled impressive progress in either agile dynamic skills or stability-critical behaviors, but existing methods remain specialized, focusing on one capability while compromising the other. In this work, we introduce AMS (Agility Meets Stability), the first framework that unifies both dynamic motion tracking and extreme balance maintenance in a single policy. Our key insight is to leverage heterogeneous data sources: human motion capture datasets that provide rich, agile behaviors, and physically constrained synthetic balance motions that capture stability configurations. To reconcile the divergent optimization goals of agility and stability, we design a hybrid reward scheme that applies general tracking objectives across all data while injecting balance-specific priors only into synthetic motions. Further, an adaptive learning strategy with performance-driven sampling and motion-specific reward shaping enables efficient training across diverse motion distributions. We validate AMS extensively in simulation and on a real Unitree G1 humanoid. Experiments demonstrate that a single policy can execute agile skills such as dancing and running, while also performing zero-shot extreme balance motions like Ip Man's Squat, highlighting AMS as a versatile control paradigm for future humanoid applications.",
    "published": "2025-11-21T16:37:24Z",
    "updated": "2025-11-24T09:20:41Z",
    "link": "http://arxiv.org/pdf/2511.17373v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yixuan Pan",
      "Ruoyi Qiao",
      "Li Chen",
      "Kashyap Chitta",
      "Liang Pan",
      "Haoguang Mai",
      "Qingwen Bu",
      "Hao Zhao",
      "Cunyuan Zheng",
      "Ping Luo",
      "Hongyang Li"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18910v1",
    "title": "An Efficient Closed-Form Solution to Full Visual-Inertial State Initialization",
    "summary": "In this letter, we present a closed-form initialization method that recovers the full visual-inertial state without nonlinear optimization. Unlike previous approaches that rely on iterative solvers, our formulation yields analytical, easy-to-implement, and numerically stable solutions for reliable start-up. Our method builds on small-rotation and constant-velocity approximations, which keep the formulation compact while preserving the essential coupling between motion and inertial measurements. We further propose an observability-driven, two-stage initialization scheme that balances accuracy with initialization latency. Extensive experiments on the EuRoC dataset validate our assumptions: our method achieves 10-20% lower initialization error than optimization-based approaches, while using 4x shorter initialization windows and reducing computational cost by 5x.",
    "published": "2025-11-24T09:15:54Z",
    "updated": "2025-11-24T09:15:54Z",
    "link": "http://arxiv.org/pdf/2511.18910v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Samuel Cerezo",
      "Seong Hun Lee",
      "Javier Civera"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2105.06896v3",
    "title": "Towards Sensor Data Abstraction of Autonomous Vehicle Perception Systems",
    "summary": "Full-stack autonomous driving perception modules usually consist of data-driven models based on multiple sensor modalities. However, these models might be biased to the sensor setup used for data acquisition. This bias can seriously impair the perception models' transferability to new sensor setups, which continuously occur due to the market's competitive nature. We envision sensor data abstraction as an interface between sensor data and machine learning applications for highly automated vehicles (HAD).\n  For this purpose, we review the primary sensor modalities, camera, lidar, and radar, published in autonomous-driving related datasets, examine single sensor abstraction and abstraction of sensor setups, and identify critical paths towards an abstraction of sensor data from multiple perception configurations.",
    "published": "2021-05-14T15:31:28Z",
    "updated": "2025-11-24T08:01:04Z",
    "link": "http://arxiv.org/pdf/2105.06896v3.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Hannes Reichert",
      "Lukas Lang",
      "Kevin Rösch",
      "Daniel Bogdoll",
      "Konrad Doll",
      "Bernhard Sick",
      "Hans-Christian Reuss",
      "Christoph Stiller",
      "J. Marius Zöllner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18857v1",
    "title": "AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion",
    "summary": "Accurate proprioceptive odometry is fundamental for legged robot navigation in GPS-denied and visually degraded environments where conventional visual odometry systems fail. Current approaches face critical limitations: analytical filtering methods suffer from modeling uncertainties and cumulative drift, hybrid learning-filtering approaches remain constrained by their analytical components, while pure learning-based methods struggle with simulation-to-reality transfer and demand extensive real-world data collection. This paper introduces AutoOdom, a novel autoregressive proprioceptive odometry system that overcomes these challenges through an innovative two-stage training paradigm. Stage 1 employs large-scale simulation data to learn complex nonlinear dynamics and rapidly changing contact states inherent in legged locomotion, while Stage 2 introduces an autoregressive enhancement mechanism using limited real-world data to effectively bridge the sim-to-real gap. The key innovation lies in our autoregressive training approach, where the model learns from its own predictions to develop resilience against sensor noise and improve robustness in highly dynamic environments. Comprehensive experimental validation on the Booster T1 humanoid robot demonstrates that AutoOdom significantly outperforms state-of-the-art methods across all evaluation metrics, achieving 57.2% improvement in absolute trajectory error, 59.2% improvement in Umeyama-aligned error, and 36.2% improvement in relative pose error compared to the Legolas baseline. Extensive ablation studies provide critical insights into sensor modality selection and temporal modeling, revealing counterintuitive findings about IMU acceleration data and validating our systematic design choices for robust proprioceptive odometry in challenging locomotion scenarios.",
    "published": "2025-11-24T07:56:12Z",
    "updated": "2025-11-24T07:56:12Z",
    "link": "http://arxiv.org/pdf/2511.18857v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Changsheng Luo",
      "Yushi Wang",
      "Wenhan Cai",
      "Mingguo Zhao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2204.07974v2",
    "title": "Anomaly Detection in Autonomous Driving: A Survey",
    "summary": "Nowadays, there are outstanding strides towards a future with autonomous vehicles on our roads. While the perception of autonomous vehicles performs well under closed-set conditions, they still struggle to handle the unexpected. This survey provides an extensive overview of anomaly detection techniques based on camera, lidar, radar, multimodal and abstract object level data. We provide a systematization including detection approach, corner case level, ability for an online application, and further attributes. We outline the state-of-the-art and point out current research gaps.",
    "published": "2022-04-17T10:48:25Z",
    "updated": "2025-11-24T07:55:12Z",
    "link": "http://arxiv.org/pdf/2204.07974v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Daniel Bogdoll",
      "Maximilian Nitsche",
      "J. Marius Zöllner"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.03411v3",
    "title": "Greedy Heuristics for Sampling-Based Motion Planning in High-Dimensional State Spaces",
    "summary": "Informed sampling techniques accelerate the convergence of sampling-based motion planners by biasing sampling toward regions of the state space that are most likely to yield better solutions. However, when the current solution path contains redundant or tortuous segments, the resulting informed subset may remain unnecessarily large, slowing convergence. Our prior work addressed this issue by introducing the greedy informed set, which reduces the sampling region based on the maximum heuristic cost along the current solution path. In this article, we formally characterize the behavior of the greedy informed set within Rapidly-exploring Random Tree (RRT*)-like planners and analyze how greedy sampling affects exploration and asymptotic optimality. We then present Greedy RRT* (G-RRT*), a bi-directional anytime variant of RRT* that leverages the greedy informed set to focus sampling in the most promising regions of the search space. Experiments on abstract planning benchmarks, manipulation tasks from the MotionBenchMaker dataset, and a dual-arm Barrett WAM problem demonstrate that G-RRT* rapidly finds initial solutions and converges asymptotically to optimal paths, outperforming state-of-the-art sampling-based planners.",
    "published": "2024-05-06T12:22:11Z",
    "updated": "2025-11-24T07:25:30Z",
    "link": "http://arxiv.org/pdf/2405.03411v3.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Phone Thiha Kyaw",
      "Anh Vu Le",
      "Rajesh Elara Mohan",
      "Jonathan Kelly"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18810v1",
    "title": "MergeVLA: Cross-Skill Model Merging Toward a Generalist Vision-Language-Action Agent",
    "summary": "Recent Vision-Language-Action (VLA) models reformulate vision-language models by tuning them with millions of robotic demonstrations. While they perform well when fine-tuned for a single embodiment or task family, extending them to multi-skill settings remains challenging: directly merging VLA experts trained on different tasks results in near-zero success rates. This raises a fundamental question: what prevents VLAs from mastering multiple skills within one model? With an empirical decomposition of learnable parameters during VLA fine-tuning, we identify two key sources of non-mergeability: (1) Finetuning drives LoRA adapters in the VLM backbone toward divergent, task-specific directions beyond the capacity of existing merging methods to unify. (2) Action experts develop inter-block dependencies through self-attention feedback, causing task information to spread across layers and preventing modular recombination. To address these challenges, we present MergeVLA, a merging-oriented VLA architecture that preserves mergeability by design. MergeVLA introduces sparsely activated LoRA adapters via task masks to retain consistent parameters and reduce irreconcilable conflicts in the VLM. Its action expert replaces self-attention with cross-attention-only blocks to keep specialization localized and composable. When the task is unknown, it uses a test-time task router to adaptively select the appropriate task mask and expert head from the initial observation, enabling unsupervised task inference. Across LIBERO, LIBERO-Plus, RoboTwin, and multi-task experiments on the real SO101 robotic arm, MergeVLA achieves performance comparable to or even exceeding individually finetuned experts, demonstrating robust generalization across tasks, embodiments, and environments.",
    "published": "2025-11-24T06:30:04Z",
    "updated": "2025-11-24T06:30:04Z",
    "link": "http://arxiv.org/pdf/2511.18810v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yuxia Fu",
      "Zhizhen Zhang",
      "Yuqi Zhang",
      "Zijian Wang",
      "Zi Huang",
      "Yadan Luo"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2405.11094v4",
    "title": "Yummy Operations Robot Initiative: Autonomous Cooking System Utilizing a Modular Robotic Kitchen and a Dual-Arm Proprioceptive Manipulator",
    "summary": "This paper presents Yummy Operations Robot Initiative (YORI), a proprioceptive dual-arm robotic system that demonstrates autonomous multi-dish cooking for scalable food service applications. YORI integrates a dual-arm manipulator equipped with proprioceptive actuators, custom-designed tools, appliances, and a structured kitchen environment to address the complexities of cooking tasks. The proprioceptive actuators enable fast, precise, force-controlled movements while mitigating the risks associated with cooking-related impacts. The system's modular kitchen design and flexible tool-changing mechanism support simultaneous multi-dish preparation through torque control and optimization-based motion planning and scheduling. A comprehensive scheduling framework with dynamic rescheduling ensures reliable adaptation to new orders and delays. The system was publicly validated through live demonstrations, reliably preparing steak-frites across multiple convention sessions. This paper details YORI's design and explores future directions in kitchen optimization, task planning, and food quality control, demonstrating its potential as a scalable robotic cooking solution. A system introduction and cooking videos are available online.",
    "published": "2024-05-17T21:14:50Z",
    "updated": "2025-11-24T05:15:45Z",
    "link": "http://arxiv.org/pdf/2405.11094v4.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Donghun Noh",
      "Hyunwoo Nam",
      "Kyle Gillespie",
      "Yeting Liu",
      "Dennis Hong"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.17502v2",
    "title": "RynnVLA-002: A Unified Vision-Language-Action and World Model",
    "summary": "We introduce RynnVLA-002, a unified Vision-Language-Action (VLA) and world model. The world model leverages action and visual inputs to predict future image states, learning the underlying physics of the environment to refine action generation. Conversely, the VLA model produces subsequent actions from image observations, enhancing visual understanding and supporting the world model's image generation. The unified framework of RynnVLA-002 enables joint learning of environmental dynamics and action planning. Our experiments show that RynnVLA-002 surpasses individual VLA and world models, demonstrating their mutual enhancement. We evaluate RynnVLA-002 in both simulation and real-world robot tasks. RynnVLA-002 achieves 97.4% success rate on the LIBERO simulation benchmark without pretraining, while in real-world LeRobot experiments, its integrated world model boosts the overall success rate by 50%.",
    "published": "2025-11-21T18:59:32Z",
    "updated": "2025-11-24T04:49:33Z",
    "link": "http://arxiv.org/pdf/2511.17502v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jun Cen",
      "Siteng Huang",
      "Yuqian Yuan",
      "Kehan Li",
      "Hangjie Yuan",
      "Chaohui Yu",
      "Yuming Jiang",
      "Jiayan Guo",
      "Xin Li",
      "Hao Luo",
      "Fan Wang",
      "Deli Zhao",
      "Hao Chen"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18756v1",
    "title": "SP-VINS: A Hybrid Stereo Visual Inertial Navigation System based on Implicit Environmental Map",
    "summary": "Filter-based visual inertial navigation system (VINS) has attracted mobile-robot researchers for the good balance between accuracy and efficiency, but its limited mapping quality hampers long-term high-accuracy state estimation. To this end, we first propose a novel filter-based stereo VINS, differing from traditional simultaneous localization and mapping (SLAM) systems based on 3D map, which performs efficient loop closure constraints with implicit environmental map composed of keyframes and 2D keypoints. Secondly, we proposed a hybrid residual filter framework that combines landmark reprojection and ray constraints to construct a unified Jacobian matrix for measurement updates. Finally, considering the degraded environment, we incorporated the camera-IMU extrinsic parameters into visual description to achieve online calibration. Benchmark experiments demonstrate that the proposed SP-VINS achieves high computational efficiency while maintaining long-term high-accuracy localization performance, and is superior to existing state-of-the-art (SOTA) methods.",
    "published": "2025-11-24T04:32:19Z",
    "updated": "2025-11-24T04:32:19Z",
    "link": "http://arxiv.org/pdf/2511.18756v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Xueyu Du",
      "Lilian Zhang",
      "Fuan Duan",
      "Xincan Luo",
      "Maosong Wang",
      "Wenqi Wu",
      " JunMao"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2502.11461v3",
    "title": "Doppler Correspondence: Non-Iterative Scan Matching With Doppler Velocity-Based Correspondence",
    "summary": "Achieving successful scan matching is essential for LiDAR odometry. However, in challenging environments with adverse weather conditions or repetitive geometric patterns, LiDAR odometry performance is degraded due to incorrect scan matching. Recently, the emergence of frequency-modulated continuous wave 4D LiDAR and 4D radar technologies has provided the potential to address these unfavorable conditions. The term 4D refers to point cloud data characterized by range, azimuth, and elevation along with Doppler velocity. Although 4D data is available, most scan matching methods for 4D LiDAR and 4D radar still establish correspondence by repeatedly identifying the closest points between consecutive scans, overlooking the Doppler information. This paper introduces, for the first time, a simple Doppler velocity-based correspondence -- Doppler Correspondence -- that is invariant to translation and small rotation of the sensor, with its geometric and kinematic foundations. Extensive experiments demonstrate that the proposed method enables the direct matching of consecutive point clouds without an iterative process, making it computationally efficient. Additionally, it provides a more robust correspondence estimation in environments with repetitive geometric patterns.The implementation of our proposed method is publicly available at https://github.com/Tars0523/Doppler Correspondence.",
    "published": "2025-02-17T05:37:07Z",
    "updated": "2025-11-24T04:15:39Z",
    "link": "http://arxiv.org/pdf/2502.11461v3.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jiwoo Kim",
      "Geunsik Bae",
      "Changseung Kim",
      "Jinwoo Lee",
      "Woojae Shin",
      "Hyondong Oh"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18712v1",
    "title": "Head Stabilization for Wheeled Bipedal Robots via Force-Estimation-Based Admittance Control",
    "summary": "Wheeled bipedal robots are emerging as flexible platforms for field exploration. However, head instability induced by uneven terrain can degrade the accuracy of onboard sensors or damage fragile payloads. Existing research primarily focuses on stabilizing the mobile platform but overlooks active stabilization of the head in the world frame, resulting in vertical oscillations that undermine overall stability. To address this challenge, we developed a model-based ground force estimation method for our 6-degree-of-freedom wheeled bipedal robot. Leveraging these force estimates, we implemented an admittance control algorithm to enhance terrain adaptability. Simulation experiments validated the real-time performance of the force estimator and the robot's robustness when traversing uneven terrain.",
    "published": "2025-11-24T03:10:33Z",
    "updated": "2025-11-24T03:10:33Z",
    "link": "http://arxiv.org/pdf/2511.18712v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Tianyu Wang",
      "Chunxiang Yan",
      "Xuanhong Liao",
      "Tao Zhang",
      "Ping Wang",
      "Cong Wen",
      "Dingchuan Liu",
      "Haowen Yu",
      "Ximin Lyu"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18709v1",
    "title": "Autonomous Surface Selection For Manipulator-Based UV Disinfection In Hospitals Using Foundation Models",
    "summary": "Ultraviolet (UV) germicidal radiation is an established non-contact method for surface disinfection in medical environments. Traditional approaches require substantial human intervention to define disinfection areas, complicating automation, while deep learning-based methods often need extensive fine-tuning and large datasets, which can be impractical for large-scale deployment. Additionally, these methods often do not address scene understanding for partial surface disinfection, which is crucial for avoiding unintended UV exposure. We propose a solution that leverages foundation models to simplify surface selection for manipulator-based UV disinfection, reducing human involvement and removing the need for model training. Additionally, we propose a VLM-assisted segmentation refinement to detect and exclude thin and small non-target objects, showing that this reduces mis-segmentation errors. Our approach achieves over 92\\% success rate in correctly segmenting target and non-target surfaces, and real-world experiments with a manipulator and simulated UV light demonstrate its practical potential for real-world applications.",
    "published": "2025-11-24T03:06:55Z",
    "updated": "2025-11-24T03:06:55Z",
    "link": "http://arxiv.org/pdf/2511.18709v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Xueyan Oh",
      "Jonathan Her",
      "Zhixiang Ong",
      "Brandon Koh",
      "Yun Hann Tan",
      "U-Xuan Tan"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18708v1",
    "title": "GVD-TG: Topological Graph based on Fast Hierarchical GVD Sampling for Robot Exploration",
    "summary": "Topological maps are more suitable than metric maps for robotic exploration tasks. However, real-time updating of accurate and detail-rich environmental topological maps remains a challenge. This paper presents a topological map updating method based on the Generalized Voronoi Diagram (GVD). First, the newly observed areas are denoised to avoid low-efficiency GVD nodes misleading the topological structure. Subsequently, a multi-granularity hierarchical GVD generation method is designed to control the sampling granularity at both global and local levels. This not only ensures the accuracy of the topological structure but also enhances the ability to capture detail features, reduces the probability of path backtracking, and ensures no overlap between GVDs through the maintenance of a coverage map, thereby improving GVD utilization efficiency. Second, a node clustering method with connectivity constraints and a connectivity method based on a switching mechanism are designed to avoid the generation of unreachable nodes and erroneous nodes caused by obstacle attraction. A special cache structure is used to store all connectivity information, thereby improving exploration efficiency. Finally, to address the issue of frontiers misjudgment caused by obstacles within the scope of GVD units, a frontiers extraction method based on morphological dilation is designed to effectively ensure the reachability of frontiers. On this basis, a lightweight cost function is used to assess and switch to the next viewpoint in real time. This allows the robot to quickly adjust its strategy when signs of path backtracking appear, thereby escaping the predicament and increasing exploration flexibility. And the performance of system for exploration task is verified through comparative tests with SOTA methods.",
    "published": "2025-11-24T03:02:39Z",
    "updated": "2025-11-24T03:02:39Z",
    "link": "http://arxiv.org/pdf/2511.18708v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yanbin Li",
      "Canran Xiao",
      "Shenghai Yuan",
      "Peilai Yu",
      "Ziruo Li",
      "Zhiguo Zhang",
      "Wenzheng Chi",
      "Wei Zhang"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18703v1",
    "title": "Asynchronous Distributed Multi-Robot Motion Planning Under Imperfect Communication",
    "summary": "This paper addresses the challenge of coordinating multi-robot systems under realistic communication delays using distributed optimization. We focus on consensus ADMM as a scalable framework for generating collision-free, dynamically feasible motion plans in both trajectory optimization and receding-horizon control settings. In practice, however, these algorithms are sensitive to penalty tuning or adaptation schemes (e.g. residual balancing and adaptive parameter heuristics) that do not explicitly consider delays. To address this, we introduce a Delay-Aware ADMM (DA-ADMM) variant that adapts penalty parameters based on real-time delay statistics, allowing agents to down-weight stale information and prioritize recent updates during consensus and dual updates. Through extensive simulations in 2D and 3D environments with double-integrator, Dubins-car, and drone dynamics, we show that DA-ADMM significantly improves robustness, success rate, and solution quality compared to fixed-parameter, residual-balancing, and fixed-constraint baselines. Our results highlight that performance degradation is not solely determined by delay length or frequency, but by the optimizer's ability to contextually reason over delayed information. The proposed DA-ADMM achieves consistently better coordination performance across a wide range of delay conditions, offering a principled and efficient mechanism for resilient multi-robot motion planning under imperfect communication.",
    "published": "2025-11-24T02:55:12Z",
    "updated": "2025-11-24T02:55:12Z",
    "link": "http://arxiv.org/pdf/2511.18703v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Ardalan Tajbakhsh",
      "Augustinos Saravanos",
      "James Zhu",
      "Evangelos A. Theodorou",
      "Lorenz T. Biegler",
      "Aaron M. Johnson"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.18683v1",
    "title": "Online Learning-Enhanced Lie Algebraic MPC for Robust Trajectory Tracking of Autonomous Surface Vehicles",
    "summary": "Autonomous surface vehicles (ASVs) are easily influenced by environmental disturbances such as wind and waves, making accurate trajectory tracking a persistent challenge in dynamic marine conditions. In this paper, we propose an efficient controller for trajectory tracking of marine vehicles under unknown disturbances by combining a convex error-state MPC on the Lie group with an online learning module to compensate for these disturbances in real time. This design enables adaptive and robust control while maintaining computational efficiency. Extensive evaluations in numerical simulations, the Virtual RobotX (VRX) simulator, and real-world field experiments demonstrate that our method achieves superior tracking accuracy under various disturbance scenarios compared with existing approaches.",
    "published": "2025-11-24T01:47:50Z",
    "updated": "2025-11-24T01:47:50Z",
    "link": "http://arxiv.org/pdf/2511.18683v1.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Yinan Dong",
      "Ziyu Xu",
      "Tsimafei Lazouski",
      "Sangli Teng",
      "Maani Ghaffari"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2506.19815v6",
    "title": "ReactEMG: Stable, Low-Latency Intent Detection from sEMG via Masked Modeling",
    "summary": "Surface electromyography (sEMG) signals show promise for effective human-machine interfaces, particularly in rehabilitation and prosthetics. However, challenges remain in developing systems that respond quickly to user intent, produce stable flicker-free output suitable for device control, and work across different subjects without time-consuming calibration. In this work, we propose a framework for EMG-based intent detection that addresses these challenges. We cast intent detection as per-timestep segmentation of continuous sEMG streams, assigning labels as gestures unfold in real time. We introduce a masked modeling training strategy that aligns muscle activations with their corresponding user intents, enabling rapid onset detection and stable tracking of ongoing gestures. In evaluations against baseline methods, using metrics that capture accuracy, latency and stability for device control, our approach achieves state-of-the-art performance in zero-shot conditions. These results demonstrate its potential for wearable robotics and next-generation prosthetic systems. Our project website, video, code, and dataset are available at: https://reactemg.github.io/",
    "published": "2025-06-24T17:28:43Z",
    "updated": "2025-11-23T21:37:13Z",
    "link": "http://arxiv.org/pdf/2506.19815v6.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Runsheng Wang",
      "Xinyue Zhu",
      "Ava Chen",
      "Jingxi Xu",
      "Lauren Winterbottom",
      "Dawn M. Nilsen",
      "Joel Stein",
      "Matei Ciocarlie"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2511.14335v2",
    "title": "Simultaneous Localization and 3D-Semi Dense Mapping for Micro Drones Using Monocular Camera and Inertial Sensors",
    "summary": "Monocular simultaneous localization and mapping (SLAM) algorithms estimate drone poses and build a 3D map using a single camera. Current algorithms include sparse methods that lack detailed geometry, while learning-driven approaches produce dense maps but are computationally intensive. Monocular SLAM also faces scale ambiguities, which affect its accuracy. To address these challenges, we propose an edge-aware lightweight monocular SLAM system combining sparse keypoint-based pose estimation with dense edge reconstruction. Our method employs deep learning-based depth prediction and edge detection, followed by optimization to refine keypoints and edges for geometric consistency, without relying on global loop closure or heavy neural computations. We fuse inertial data with vision by using an extended Kalman filter to resolve scale ambiguity and improve accuracy. The system operates in real time on low-power platforms, as demonstrated on a DJI Tello drone with a monocular camera and inertial sensors. In addition, we demonstrate robust autonomous navigation and obstacle avoidance in indoor corridors and on the TUM RGBD dataset. Our approach offers an effective, practical solution to real-time mapping and navigation in resource-constrained environments.",
    "published": "2025-11-18T10:42:36Z",
    "updated": "2025-11-23T20:36:38Z",
    "link": "http://arxiv.org/pdf/2511.14335v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Jeryes Danial",
      "Yosi Ben Asher",
      "Itzik Klein"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2508.07387v2",
    "title": "MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control",
    "summary": "Navigating unknown environments with a single RGB camera is challenging, as the lack of depth information prevents reliable collision-checking. While some methods use estimated depth to build collision maps, we found that depth estimates from vision foundation models are too noisy for zero-shot navigation in cluttered environments. We propose an alternative approach: instead of using noisy estimated depth for direct collision-checking, we use it as a rich context input to a learned collision model. This model predicts the distribution of minimum obstacle clearance that the robot can expect for a given control sequence. At inference, these predictions inform a risk-aware MPC planner that minimizes estimated collision risk. We proposed a joint learning pipeline that co-trains the collision model and risk metric using both safe and unsafe trajectories. Crucially, our joint-training ensures well calibrated uncertainty in our collision model that improves navigation in highly cluttered environments. Consequently, real-world experiments show reductions in collision-rate and improvements in goal reaching and speed over several strong baselines.",
    "published": "2025-08-10T15:27:23Z",
    "updated": "2025-11-23T19:10:25Z",
    "link": "http://arxiv.org/pdf/2508.07387v2.pdf",
    "category": [
      "cs.RO"
    ],
    "authors": [
      "Basant Sharma",
      "Prajyot Jadhav",
      "Pranjal Paul",
      "K. Madhava Krishna",
      "Arun Kumar Singh"
    ]
  }
]